{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Welcome to TDengine Cases Docs","text":"<p>You can switch branches on this page. For more information about how to run cases, see README.</p> <p>Case list can be found on the top bar case list docs.</p> <p>For more information about how to write new case docstring format, see Test Case Specification</p>"},{"location":"case_list_docs/Cluster/","title":"70-Cluster","text":""},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_create_db_replica1.Test4dnode1mnodeBasicCreateDbReplica1.test_4dnode1mnode_basic_create_db_replica1","title":"","text":"Cluster 4 dnode 1 mnode replica 1 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 1 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Check vgroups info , ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_create_db_replica1.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_replica1_insertdatas.Test4dnode1mnodeBasicReplica1Insertdatas.test_4dnode1mnode_basic_replica1_insertdatas","title":"","text":"Cluster 4 dnodes 1 mnode replica 1 insert 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 1 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Insert each subtable 100 rows data 9. Check vgroups info , ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_replica1_insertdatas.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_replica1_insertdatas_querys.Test4dnode1mnodeBasicReplica1InsertdatasQuerys.test_4dnode1mnode_basic_replica1_insertdatas_querys","title":"","text":"Cluster 4 dnodes 1 mnode replica 1 insert-query 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 1 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Insert each subtable 100 rows data 9. Ensure above insert success by query 10. Check vgroups info , ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_replica1_insertdatas_querys.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_replica3_insertdatas.Test4dnode1mnodeBasicReplica3Insertdatas.test_4dnode1mnode_basic_replica3_insertdatas","title":"","text":"Cluster 4 dnodes 1 mnode replica 3 insert 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 3 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Insert each subtable 100 rows data 9. Check vgroups info , ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_replica3_insertdatas.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_replica3_insertdatas_querys.Test4dnode1mnodeBasicReplica3InsertdatasQuerys.test_4dnode1mnode_basic_replica3_insertdatas_querys","title":"","text":"Cluster 4 dnodes 1 mnode replica 3 insert-query 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 3 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Insert each subtable 100 rows data 9. Ensure above insert success by query 10. Check vgroups info , ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_replica3_insertdatas_querys.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_4dnode1mnode_basic_replica3_vgroups.Test4dnode1mnodeBasicReplica3Vgroups.test_4dnode1mnode_basic_replica3_vgroups","title":"","text":"Cluster 4 dnodes 1 mnode replica 3 vgroups 1. Create 4 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Create database with replica 3 5. Create 1 super table and 1 normal table 6. Create 5 subtables using super table 7. Ensure above tables created success 8. Create database with vgroups 1,10,30 respectively 9. ensure each vgroup only has 1 leader role                      path:                                            cases/70-Cluster/test_4dnode1mnode_basic_replica3_vgroups.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode1mnode.Test5dnode1mnode.test_5dnode1mnode","title":"","text":"Cluster 5 dnodes 1 mnode 1. Create 5 node and 1 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Check the cluster is alive                      path:                                            cases/70-Cluster/test_5dnode1mnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode2mnode.Test5dnode2mnode.test_5dnode2mnode","title":"","text":"Cluster 5 dnodes 2 mnode 1. Create 5 node and 2 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Stop dnode 2  5. Start dnode 2 6. Stop dnode 1 7. Start dnode 1 8. Check the cluster is alive                      path:                                            cases/70-Cluster/test_5dnode2mnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_add_1dnode.Test5dnode3mnodeAdd1dnode.test_5dnode3mnode_add_1dnode","title":"","text":"Cluster 5 dnodes 3 mnode add 1 dnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Add 1 dnode to cluster 6. Restart all dnodes 7. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_add_1dnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_recreate_mnode.Test5dnode3mnodeRecreateMnode.test_5dnode3mnode_recreate_mnode","title":"","text":"Cluster 5 dnodes 3 mnode recreate mnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Stop dnode 1 6. delete dnode 1 dataDir 7. Start dnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_recreate_mnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_restart_dnode_insert_data.Test5dnode3mnodeRestartDnodeInsertData.test_5dnode3mnode_restart_dnode_insert_data","title":"","text":"Cluster 5 dnodes 3 mnode insert 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Insert data 6. Stop dnode 1 7. Start dnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_restart_dnode_insert_data.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_restart_dnode_insert_data_async.Test5dnode3mnodeRestartDnodeInsertDataAsync.test_5dnode3mnode_restart_dnode_insert_data_async","title":"","text":"Cluster 5 dnodes 3 mnode insert async 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Insert data async by threading 6. Stop dnode 1 7. Start dnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_restart_dnode_insert_data_async.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_dnode_create_db.Test5dnode3mnodeSep1VnodeStopDnodeCreateDb.test_5dnode3mnode_sep1_vnode_stop_dnode_create_db","title":"","text":"Cluster 5 dnodes 3 mnode create db 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create database for four times 6. Stop dnode 1 7. Start dnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_dnode_create_db.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_dnode_create_stb.Test5dnode3mnodeSep1VnodeStopDnodeCreateStb.test_5dnode3mnode_sep1_vnode_stop_dnode_create_stb","title":"","text":"Cluster 5 dnodes 3 mnode create db 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create super table 6. Stop dnode 1 7. Start dnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_dnode_create_stb.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_dnode_modify_meta.Test5dnode3mnodeSep1VnodeStopDnodeModifyMeta.test_5dnode3mnode_sep1_vnode_stop_dnode_modify_meta","title":"","text":"Cluster 5 dnodes 3 mnode modify meta 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create super table 6. Insert data 7. Stop dnode 1 8. Start dnode 1 9. Check dnodes and cluster status                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_dnode_modify_meta.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_mnode_create_db.Test5dnode3mnodeSep1VnodeStopMnodeCreateDb.test_5dnode3mnode_sep1_vnode_stop_mnode_create_db","title":"","text":"Cluster 5 dnodes 3 mnode create db mnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create database for four times 6. Stop mnode 1 7. Start mnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_mnode_create_db.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_mnode_create_stb.Test5dnode3mnodeSep1VnodeStopMnodeCreateStb.test_5dnode3mnode_sep1_vnode_stop_mnode_create_stb","title":"","text":"Cluster 5 dnodes 3 mnode create stb 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create stable for 2 times 6. Stop dnode 1 7. Start dnode 1 8. Check stable number                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_mnode_create_stb.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_mnode_modify_meta.Test5dnode3mnodeSep1VnodeStopMnodeModifyMeta.test_5dnode3mnode_sep1_vnode_stop_mnode_modify_meta","title":"","text":"Cluster 5 dnodes 3 mnode modify meta mnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create super table 6. Insert data 7. Stop mnode 1 8. Start mnode 1 9. Check dnodes and cluster status                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_mnode_modify_meta.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_vnode_create_db.Test5dnode3mnodeSep1VnodeStopVnodeCreateDb.test_5dnode3mnode_sep1_vnode_stop_vnode_create_db","title":"","text":"Cluster 5 dnodes 3 mnode create db vnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create database for four times 6. Stop vnode 1 7. Start vnode 1 8. Ensure cluster work well                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_vnode_create_db.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_sep1_vnode_stop_vnode_create_stb.Test5dnode3mnodeSep1VnodeStopVnodeCreateStb.test_5dnode3mnode_sep1_vnode_stop_vnode_create_stb","title":"","text":"Cluster 5 dnodes 3 mnode create stb vnode 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Create stable for 2 times 6. Stop vnode  7. Start vnode 8. Check stable number                      path:                                            cases/70-Cluster/test_5dnode3mnode_sep1_vnode_stop_vnode_create_stb.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_stop.Test5dnode3mnodeStop.test_5dnode3mnode_stop","title":"","text":"Cluster 5 dnodes 3 mnode stop 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Stop dnode 2 check mnode have 3 4. Start dnode 2 5. Stop dnode 3 check mnode have 3 6. Start dnode 3 7. Stop dnode 1 check mnode have 3 8. Start dnode 1                      path:                                            cases/70-Cluster/test_5dnode3mnode_stop.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_stop_2follower.Test5dnode3mnodeStop2Follower.test_5dnode3mnode_stop2_follower","title":"","text":"Cluster 5 dnodes 3 mnode stop 2 follower 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Stop dnode 3 6. Check mnode 3 status is offline 7. Start dnode 3 8. Check mnode status is normal                      path:                                            cases/70-Cluster/test_5dnode3mnode_stop_2follower.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_stop_follower_leader.Test5dnode3mnodeStopFollowerLeader.test_5dnode3mnode_stop_follower_leader","title":"","text":"Cluster 5 dnodes 3 mnode stop follower 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Check mnode is leader and only 1 mnode 4. Except check some error operations 5. Stop dnode 0/1 6. Start dnode 0 7. Check mnode 2 status is offline 8. Create some database  9. Check database created successfully                      path:                                            cases/70-Cluster/test_5dnode3mnode_stop_follower_leader.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode3mnode_stop_loop.Test5dnode3mnodeStopLoop.test_5dnode3mnode_stop_loop","title":"","text":"Cluster 5 dnodes 3 mnode stop loop 1. Create 5 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Stop all dnodes 4. Start all dnode 5. Check dnodes status normally 6. Check mnode status normally                      path:                                            cases/70-Cluster/test_5dnode3mnode_stop_loop.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode_3mnode_add_1dnode.Test5dnode3mnodeAdd1Dnode.test_five_dnode_three_mnode","title":"","text":"Cluster 5 dnodes 3 mnodes 1. Create 5 dnode 3 mnode cluster 2. Create database and stables 3. Insert data into stables 4. Add 1 dnode to cluster during data insertion 5. Restart all dnodes one by one 6. Verify data integrity                      path:                                            cases/70-Cluster/test_5dnode_3mnode_add_1dnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_5dnode_3mnode_stop.Test5dnode3mnodeStop.test_five_dnode_three_mnode","title":"","text":"Cluster database with replica 3 1. Create 5 dnodes 3 mnodes cluster 2. Create database with replica 3 and vgroups 4 3. Stop dnode one by one and check mnode status 4. Restart dnode one by one and check mnode status 5. Check vgroups status and replica status                      path:                                            cases/70-Cluster/test_5dnode_3mnode_stop.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_6dnode3mnode_insert_less_data_alter_rep3to1to3.Test6dnode3mnodeInsertLessDataAlterRep3to1to3.test_6dnode3mnode_insert_less_data_alter_rep3to1to3","title":"","text":"Cluster 6 dnodes 3 mnode rep3to1to3 1. Create 6 node and 3 mnode cluster 2. Ensure above cluster setup success 3. Create database with replica 3 4. Create stable and child table, insert less data 5. Alter database replica to 1 6. Ensure cluster work well 7. Alter database replica to 3 8. Ensure cluster work well 9. Except check some error operations                      path:                                            cases/70-Cluster/test_6dnode3mnode_insert_less_data_alter_rep3to1to3.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_arbitrator.TestClusterArbitrator.test_cluster_arbitrator","title":"","text":"Cluster arbitrator basic 1. Create cluster with 3 dnodes 2. Create a database and a stable with 2 replicas 3. Create a child table 4. Stop one dnode which is follower 5. Check the vgroup status to be assigned 6. Insert data into the child table 7. Check inserted data is correct 8. Restart the dnodes 9. Check the vgroup status to be candidate 10. Check \"show arbgroups\" result                      path:                                            cases/70-Cluster/test_cluster_arbitrator.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_basic.TestClusterBasic.test_check_cluster_empty_db","title":"","text":"Cluster check empty db 1. Create 5 dnodes cluster 2. Create empty database 3. Start and stop dnode 2 4. Check cluster status                      path:                                            cases/70-Cluster/test_cluster_basic.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_basic.TestClusterBasic.test_check_cluster_with_db","title":"","text":"Cluster restart dnode one by one 1. Create 5 dnodes cluster 2. Create database with replica 3 and vgroups 3 3. Start and stop dnode 2 and dnode 3 one by one 4. Check cluster status                      path:                                            cases/70-Cluster/test_cluster_basic.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_drop_table_by_uid.TestClusterDropTableByUid.test_drop_table_by_uid","title":"","text":"Cluster drop table by uid 1. Create cluster with 3 dnodes 2. Verify the feature of 'drop table by uid' for TS-5111 on cluster FS: https://taosdata.feishu.cn/wiki/JgeDwZkH3iTNv2ksVkWcHenKnTf TS: https://taosdata.feishu.cn/wiki/DX3FwopwGiXCeRkBNXFcj0MBnnb                      path:                                            cases/70-Cluster/test_cluster_drop_table_by_uid.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_inc_snapshot.TestIncSnapshot.test_inc_snapshot","title":"","text":"Check data correct after remove wal 1. Create 3 dnode cluster environment 2. Create database with 2 vgroups and 3 replicas 3. Create stable and child tables 4. Insert initial data and flush 5. Stop one dnode and insert more data 6. Take incremental snapshot 7. Stop all dnodes and remove wal directories 8. Restart all dnodes and check vgroup status 9. Check data correctness and aggregation correctness                      path:                                            cases/70-Cluster/test_cluster_inc_snapshot.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_kill_restore_dnode.TestClusterKillRestoreDnode.test_cluster_kill_restore_dnode","title":"","text":"Cluster kill restore dnode 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 2  5. Delete the data folder of dnode 2 6. Start dnode 2 7. Restore dnode 2 data with \"restore dnode 2\" 8. Kill the restore transaction 9. Restart the restore dnode 2 10. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_kill_restore_dnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_restore_dnode.TestClusterRestoreDnode.test_cluster_restore_dnode","title":"","text":"Cluster restore dnode 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 2  5. Delete the data folder of dnode 2 6. Start dnode 2 7. Restore dnode 2 data with \"restore dnode 2\" 8. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_restore_dnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_restore_mnode.TestClusterRestoreMnode.test_cluster_restore_mnode","title":"","text":"Cluster restore mnode 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 3 5. Delete the mnode data folder of dnode 3 6. Start dnode 3 7. Restore dnode 3 mnode data with \"restore mnode on dnode 3\" 8. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_restore_mnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_restore_qnode.TestClusterRestoreQnode.test_cluster_restore_qnode","title":"","text":"Cluster restore qnode 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 5 5. Delete the qnode data folder of dnode 5 6. Start dnode 5 7. Restore dnode 5 qnode data with \"restore qnode on dnode 5\" 8. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_restore_qnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_restore_vnode.TestClusterRestoreVnode.test_cluster_restore_vnode","title":"","text":"Cluster restore vnode 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 4  5. Delete the vnodes data folder of dnode 4 6. Start dnode 4 7. Restore dnode 4 vnode data with \"restore vnode on dnode 4\" 8. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_restore_vnode.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_snapshot.TestSnapshot.test_snapshot","title":"","text":"Cluster snapshot aggregation 1. Create 3 dnode cluster environment 2. taosBenchmark insert data with full data-type columns 3. Check taosBenchmark insert data correct 4. Save snapshot with snapshot aggregation like avg, min, max, sum, count 5. Do cluster action: split vgroups, trim, balance vgroup leaders, alter replica, compact 6. Check snapshot aggregation result correct 7. Check taosBenchmark insert data correct again 8. Check float double value correct again                      path:                                            cases/70-Cluster/test_cluster_snapshot.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_split_vgroup_by_learner.TestClusterSplitVgroupByLearner.test_split_vgroup_by_learner","title":"","text":"Cluster split vgroups by learner 1. Create 3 dnode cluster environment 2. taosBenchmark insert data with full data-type columns 3. Check taosBenchmark insert data correct 4. Save snapshot with snapshot aggregation like avg, min, max, sum, count 5. Do cluster action: split vgroups, trim, balance vgroup leaders, alter replica, compact 6. Check snapshot aggregation result correct 7. Check taosBenchmark insert data correct again 8. Check float double value correct again                      path:                                            cases/70-Cluster/test_cluster_split_vgroup_by_learner.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_threads.TestDb.test_cluster_threads","title":"","text":"Cluster threads 1. Create 3 dnode cluster environment 2. Create 3 database for precision ns/us/ms 3. Create 3 normal tables in each database 4. Insert 2 rows data for each table 5. Start 10 threads to `desc table` concurrently for 100 times 6. Check no coredump happen 7. Show local/cluster variables like 'debugFlag' and check the results 8. Show cluster variables like 'ss%' and check the results 9. Show cluster variables like 'Max%' and check the results 10. Show cluster variables like 'ttl%' and check the results                      path:                                            cases/70-Cluster/test_cluster_threads.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_cluster_tsdb_snapshot.TestClusterTsdbSnapshot.test_tsdb_snapshot","title":"","text":"Cluster remove wal files 1. Create 3 dnode cluster environment 2. taosBenchmark insert 1 stb 100 child tables with 3 replica 3. flush database 4. stop dnode 3 5. taosBenchmark insert more data into the stb again 6. flush database 7. stop all dnodes 8. remove wal files from dnode1 and dnode2 9. start all dnodes 10. check coredump not happen                      path:                                            cases/70-Cluster/test_cluster_tsdb_snapshot.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_compact_db_conflict.TestCompactDbConflict.test_compact_db_conflict","title":"","text":"Cluster compact db conflict 1. Create database db vgroups 4 replica 1 2. Start multiple threads to do compact db 3. During compact db do alter database/split vgroup/redistribute vgroup/balance vgroup 4. Ensure all above operations report conflict error                      path:                                            cases/70-Cluster/test_compact_db_conflict.py"},{"location":"case_list_docs/Cluster/#70-Cluster.test_mnode_encrypt.TestMnodeEncrypt.test_mnode_encrypt","title":"","text":"Cluster mnode encrypt 1. Create database db 2. Create stable st with tags 3. Create 4 child tables t0,t1,t2,t3 using st 4. Check create child tables number is 4 5. Insert data into t0,t1,t2,t3 6. Query and check data from t0,t1,t2,t3                      path:                                            cases/70-Cluster/test_mnode_encrypt.py"},{"location":"case_list_docs/DataCompression/","title":"08-Data Compression","text":""},{"location":"case_list_docs/DataCompression/#08-DataCompression.test_compress_alter_option.TestCompressAlterOption.test_compress_alter_option","title":"","text":"Compress: alter options 1. Create a table containing data types including BOOL, TINYINT, SMALLINT, INT, BIGINT, FLOAT, DOUBLE, and BINARY; 2. insert records and query the results 3. Modify compression settings (compression option, level, and encoding method), including disabling compression entirely, then query the results 4. Execute FLUSH DATABASE and restart the taosdservice 5. Insert new data again and continue querying the results                      path:                                            cases/08-DataCompression/test_compress_alter_option.py"},{"location":"case_list_docs/DataCompression/#08-DataCompression.test_compress_alter_table.TestCompressBasic.test_compress_basic","title":"","text":"Compress: alter table 1. Insert data 2. Modify table structure 3. Execute FLUSH DATABASE 4. Insert data again and query the results                      path:                                            cases/08-DataCompression/test_compress_alter_table.py"},{"location":"case_list_docs/DataCompression/#08-DataCompression.test_compress_basic.TestCompressBasic.test_compress_basic","title":"","text":"Tool system tables inspect 1. Create 1 stb(17 columns) and 4 child tables 2. Insert each child table 1000 rows data 3. Check default encode/compress/level is correct 4. Alter encode/compress/level for columns and insert data 5. flush database 6. Add columns with encode/compress/level and insert data 7. Check all data is correct 8. Check error create/alter/add column with encode/compress/level                      path:                                            cases/08-DataCompression/test_compress_basic.py"},{"location":"case_list_docs/DataCompression/#08-DataCompression.test_compress_one_stage.TestOneStageComp.test_one_stage_comp","title":"","text":"Check compress data accuracy 1. taosBenchmark create 1 stb 10 ctb 2. Insert each child table 100000 rows with fixed column values 3. Check data accuracy with column value is not equal to fixed value 4. Check data accuracy with column value is equal to fixed value 5. Do snapshot aggregation 6. Check aggregation result correctness 7. Insert null values into all columns except timestamp column 8. Check null values correctness                      path:                                            cases/08-DataCompression/test_compress_one_stage.py"},{"location":"case_list_docs/DataCompression/#08-DataCompression.test_compress_tsz.TestCompressTsz1.test_compress_tsz","title":"","text":"Compress tsz algorithm 1. Init config open TSZ compression and set IfAdtFse to 1 2. Create 1 stable 5 child tables 3. each child table insert 50000 rows data with some null float/double values 4. Verify data correctness after insert with TSZ compression 5. Alter config IfAdtFse to 0 6. Repeat steps 1-3 to verify data correctness                      path:                                            cases/08-DataCompression/test_compress_tsz.py"},{"location":"case_list_docs/DataDeletion/","title":"07-Data Deletion","text":""},{"location":"case_list_docs/DataDeletion/#07-DataDeletion.test_delete.TestInsertDelete.test_insert_delete","title":"","text":"Delete data 1. Deleting data from normal tables 2. Deleting data from super tables 3. Deleting data from child tables                      path:                                            cases/07-DataDeletion/test_delete.py"},{"location":"case_list_docs/DataDeletion/#07-DataDeletion.test_delete_childtable.TestDeleteChildtable.test_delete_childtable","title":"","text":"Delete child table 1. Create child table 2. Insert data into child table 3. Delete data from child table with one row, all rows, multiple rows  4. Delete data from child table with error sql 5. Check  data in child table                      path:                                            cases/07-DataDeletion/test_delete_childtable.py"},{"location":"case_list_docs/DataDeletion/#07-DataDeletion.test_delete_normaltable.TestDeleteNormaltable.test_delete_normaltable","title":"","text":"Delete normal table 1. Create normal table 2. Insert data into normal table 3. Delete data from normal table with one row, all rows, multiple rows 4. Delete data from normal table with error sql 5. Check  data in normal table                      path:                                            cases/07-DataDeletion/test_delete_normaltable.py"},{"location":"case_list_docs/DataDeletion/#07-DataDeletion.test_delete_stable.TestDeleteStable.test_delete_stable","title":"","text":"Delete super table 1. Create super table 2. Insert data into super table 3. Delete data from super table with one row, all rows, multiple rows 4. Delete data from super table with error sql 5. Check  data in super table                      path:                                            cases/07-DataDeletion/test_delete_stable.py"},{"location":"case_list_docs/DataTypes/","title":"01-Data Types","text":""},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_column_tag_boundary.TestColumnTagBoundary.test_column_tag_boundary","title":"","text":"Column and tag boundary 1. Create stable with max column and tag length 2. Insert data with max column and tag length 3. Verify data correctness with query 4. Create column/tag with binary 5. Create column/tag with varchar 6. Create column/tag with nchar 7. Create column/tag with varbinary 8. Create tag with json 9. Insert data with chinese sring on nchar                      path:                                            cases/01-DataTypes/test_column_tag_boundary.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_bigint.TestDatatypeBigInt.test_datatype_bigint","title":"","text":"DataTypes: bigint 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_bigint.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_blob.TestDatatypeBlob.test_datatype_blob","title":"","text":"DataTypes: blob 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input 6. Check auto create table with blob cols                      path:                                            cases/01-DataTypes/test_datatype_blob.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_bool.TestDatatypeBool.test_datatype_bool","title":"","text":"DataTypes: bool 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_bool.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_decimal.TestDecimal.test_datatype_decimal","title":"","text":"DataTypes: decimal 1. Check decimal ddl 2. No decimal table test 3. Insert decimal values 4. Query decimal values 5. Verify JIRA TS-6333                      path:                                            cases/01-DataTypes/test_datatype_decimal.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_decimal64.TestDecimal2.test_datatype_decimal64","title":"","text":"DataTypes: decimal64 1. check decimal64 ddl 2. insert decimal64 values 3. query decimal64 values on where condition                      path:                                            cases/01-DataTypes/test_datatype_decimal64.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_decimal_last.TestDecimal3.test_decimal3","title":"","text":"DataTypes: decimal last 1. Check decimal ddl 2. Insert decimal values 3. Query decimal with last/last_row 4. Query decimal view with last/last_row                      path:                                            cases/01-DataTypes/test_datatype_decimal_last.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_double.TestDatatypeDouble.test_datatype_double","title":"","text":"DataTypes: double 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_double.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_float.TestDatatypeFloat.test_datatype_float","title":"","text":"DataTypes: float 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_float.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_geometry.TestDatatypeGeometry.test_datatype_geometry","title":"","text":"DataTypes: geometry 1. Create stable with geometry datatype on column and tag 2. Insert and query data with geometry datatype 3. Automatically create child table with geometry datatype on tag 4. Alter tag value with geometry datatype 5. Test illegal input for geometry datatype 6. Create normal table with geometry datatype on column 7. Insert and query data with geometry datatype 8. Insert geometry column/tag with NULL value 9. Insert geometry format: POINT/LINESTRING/POLYGON,/MULTIPOINT/MULTILINESTRING/MULTIPOLYGON/GEOMETRYCOLLECTION                      path:                                            cases/01-DataTypes/test_datatype_geometry.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_int.TestDatatypeInt.test_datatype_int","title":"","text":"DataTypes: int 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_int.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_json.TestDatatypeJson.test_datatype_json","title":"","text":"DataTypes: json 1. Create table 2. Insert data 3. Alter tag value 4. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_json.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_nchar.TestDatatypeNchar.test_datatype_nchar","title":"","text":"DataTypes: nchar 1. Create table 2. Insert data 3. Alter tag value 4. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_nchar.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_nchar_chinese.TestNChar.test_nchar","title":"","text":"DataTypes: nchar chinese 1. Create table 2. Insert data 3. Query data                      path:                                            cases/01-DataTypes/test_datatype_nchar_chinese.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_smallint.TestDatatypeSmallint.test_datatype_smallint","title":"","text":"DataTypes: smallint 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_smallint.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_timestamp.TestDatatypeTimestamp.test_datatype_timestamp","title":"","text":"DataTypes: timestamp 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_timestamp.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_tinyint.TestDatatypeTinyint.test_datatype_tinyint","title":"","text":"DataTypes: tinyint 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_tinyint.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_uint.TestDatatypeUint.test_datatype_uint","title":"","text":"DataTypes: unsigned int 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_uint.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_unsign.TestDatatypeUnsigned.test_datatype_unsigned","title":"","text":"DataTypes: unsigned numeric 1. Create table 2. Insert data 3. Alter tag value 4. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_unsign.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_varbinary.TestDatatypeVarbinary.test_datatype_varbinary","title":"","text":"DataTypes: varbinary 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input                      path:                                            cases/01-DataTypes/test_datatype_varbinary.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_datatype_varchar.TestDatatypeVarchar.test_datatype_varchar","title":"","text":"DataTypes: varchar 1. Create table 2. Insert data 3. Auto-create table 4. Alter tag value 5. Handle illegal input 6. Query with varchar values 7. Cast on varchar                      path:                                            cases/01-DataTypes/test_datatype_varchar.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_null_column.TestNullColumn.test_null_column","title":"","text":"NULL: column 1. Create table 2. Insert data with NULL 3. Query data                      path:                                            cases/01-DataTypes/test_null_column.py"},{"location":"case_list_docs/DataTypes/#01-DataTypes.test_null_tag.TestNullTag.test_null_tag","title":"","text":"NULL: tag 1. Create table with NULL tags 2. Select tags 3. Alter tags with NULL 4. Insert data with NULL tags 5. Query data with NULL tags                      path:                                            cases/01-DataTypes/test_null_tag.py"},{"location":"case_list_docs/Escape/","title":"29-Escape Characters","text":""},{"location":"case_list_docs/Escape/#29-Escape.test_binary_escape_character.TestBinaryEscapeCharacter.test_query_tag_filter","title":"","text":"Escape character 1. Validates escape characters in binary data types 2. Test the insertion and retrieval of strings containing various escape sequences like:     - single quotes ('), double quotes (\"), and backslashes () within binary columns. 3. Ensures that these special characters are correctly stored, processed, and returned in query results  4. Check without causing parsing errors or data corruption. 5. Jira TD-28164: Support backslash g escape character in like queries                      path:                                            cases/29-Escape/test_binary_escape_character.py"},{"location":"case_list_docs/Except/","title":"28-Except","text":""},{"location":"case_list_docs/Except/#24-Users.test_user_privilege_table.TestUserPrivilegeTable.test_except_reset_query_cache","title":"","text":"Except reset query cache 1. Reset query cache before grant/revoke privilege 2. Reset query cache after grant/revoke privilege 3. Check show command and query command correctness                      path:                                            cases/24-Users/test_user_privilege_table.py"},{"location":"case_list_docs/Except/#70-Cluster.test_cluster_kill_restore_dnode.TestClusterKillRestoreDnode.test_except_kill_transaction","title":"","text":"Except kill transaction 1. Create 5 dnode 3 mnode cluster 2. Create 1 db, 1 stable, 100 childs table 3. Insert 10w records for each child table 4. Stop dnode 2  5. Delete the data folder of dnode 2 6. Start dnode 2 7. Restore dnode 2 data with \"restore dnode 2\" 8. Kill the restore transaction 9. Restart the restore dnode 2 10. Check data correctness                      path:                                            cases/70-Cluster/test_cluster_kill_restore_dnode.py"},{"location":"case_list_docs/JoinQueries/","title":"14-Join Queries","text":""},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join.TestJoin.test_join","title":"","text":"Join basic 1. Join with inner/left/right/outer/asof/semi/anti/full 2. Join with tb1.ts = tb2.ts 3. Join with tb1.int = tb2.int limit  4. Join with tb1.int = tb2.int and ts filter 5. Join with multiple tables 6. Join with group by/order by/limit 7. Join with having condition 8. Join error cases 9. Join on two database 11. Join on two super table 12. Join on two normal table 13. Join on normal table and super table 14. Join semantic test 15. Join with interval 16. Join bug TS-5863                      path:                                            cases/14-JoinQueries/test_join.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_compare.TestCompare.test_join_compare","title":"","text":"Join compare 1. Create normal tables with full data types 2. Insert 6 rows data 3. Check in and not in filter 4. Check &gt;, &lt;, = comparisons between different data types 6. Left join with different data types comparison conditions                      path:                                            cases/14-JoinQueries/test_join_compare.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_condition.TestJoinCondition.test_join_condition","title":"","text":"Join condition 1. Generate join sql with different join conditions and query conditions 2. Generate error join sql with wrong join conditions and check error status 3. Join with group by and having clause condition 4. Join with where clause condition                      path:                                            cases/14-JoinQueries/test_join_condition.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_const.TestJoinConst.test_join_const","title":"","text":"Join full data types 1. Create stable sta/stb 2. Create child table a1/a2 from sta, b1/b2 from stb 3. Insert 4 rows data into a1/a2, b1/b2 4. Read query sql from .in file and execute 5. Validate the query result with expected .csv file 6. File .in sql include now()/today() and constant timestamps 7. File .in sql include inner/outer/semi/anti join 8. Check abnormal cases                      path:                                            cases/14-JoinQueries/test_join_const.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_full.TestJoinFull.test_join_full","title":"","text":"Join mode 1. test full_join 2. test inner_join 3. test join_boundary 4. test join_explain 5. test join_nested 6. test join_scalar1 7. test join_scalar2 8. test join_timeline 9. test left_anti_join 10. test left_asof_join 11. test left_join 12. test left_semi_join 13. test left_win_join 14. test right_anti_join 15. test right_asof_join 16. test right_join 17. test right_semi_join 18. test right_win_join 19. restart and test again                      path:                                            cases/14-JoinQueries/test_join_full.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_full2.TestJoin.test_join","title":"","text":"Join primay key 1. Create necessary databases and tables 2. Insert test data into the tables 3. Join with inner/left/outer/full/semi/anti/asof 4. Join with composite primary key (int32, int64, str) 5. Validate the results of each join query against expected outcomes 6. Join with us/ns/ms precision timestamps 7. Error join checked                      path:                                            cases/14-JoinQueries/test_join_full2.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_func.TestParaTms.test_para_tms","title":"","text":"Join functions cursor 1. Generate random sql than explain/execute 2. Join with math functions      - unique/mode/sample/abs/sqrt/sin/cos/tan/asin/acos/atan/pow/     - log/floor/ceil/round/mavg/hyperloglog/tail/csum/statecount/     - stateduration/histogram 3. Join with string functions      - ltrim/rtrim/lower/upper/length/     - char_length/substr/concat/concat_ws 4. Join with time functions      - cast/now/today/timezone/timetruncate/to_iso8601/     - to_unixtimestamp/elapsed/timediff 5. taos -f sql execution                      path:                                            cases/14-JoinQueries/test_join_func.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_func_cursor.TestParaTms2.test_para_tms2","title":"","text":"Join functions cursor 1. Generate random sql than explain/execute 2. Create another cursor to execute the same sql 3. Join with math functions      - unique/mode/sample/csum     - statecount/stateduration/histogram 5. Join with time functions      - TIMEDIFF_1/TIMEDIFF_2 6. taos -f sql execution                      path:                                            cases/14-JoinQueries/test_join_func_cursor.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_interval.TestJoinInterval.test_join_interval","title":"","text":"Join interval 1.Create database d1 and d2 2.Create table t1 in d1 with tags and t1 in d2 without tags 3.Insert data into d1.t1 with different tag values 4.Insert data into d2.t1 with same timestamps as d1.t1 5.Join query between d1.t1 and d2.t1 with interval(1a) 6. Check the result of join correctly 7. Jira TS-5803                      path:                                            cases/14-JoinQueries/test_join_interval.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_manyblocks.TestJoinManyBlocks.test_join_manyblocks","title":"","text":"Join many blocks 1. Create database and two super tables 2. Insert data into each child tables with same timestamps 3. Join two super tables on timestamps and tag columns 4. Check the result of join correctly                      path:                                            cases/14-JoinQueries/test_join_manyblocks.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_multitables.TestJoinMultitables.test_join_multitables","title":"","text":"Join multi-tables 1.Create super table st0-stb with same schema but different tag numbers 2.Create child tables from super tables with different tag values 3.Insert data into child tables with same timestamps 4.Join tables on timestamps and tag columns from different super tables  5. Check the result of join correctly                      path:                                            cases/14-JoinQueries/test_join_multitables.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_multivnode.TestJoinMultivnode.test_join_multivnode","title":"","text":"Join multi-vnode 1. Create database with multiple vnodes 2. Create two super tables 3. Insert data into each child tables with same timestamps 4. Join two super tables on timestamps and tag columns 5. Check the result of join correctly                      path:                                            cases/14-JoinQueries/test_join_multivnode.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_ns_db.TestJoinNsDb.test_join_ns_db","title":"","text":"Join with ns precision 1. Create two databases with ns precision 2. Create stable and child table in two databases 3. Insert data into two child tables with same timestamps 4. Inner join two tables from two databases on timetruncate(ts) and tag columns 5. Check join result rows is correct                      path:                                            cases/14-JoinQueries/test_join_ns_db.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_order.TestJoinOrder.test_join_order","title":"","text":"Join with order by 1. Create database with vgroup 1 2. Create 1 stable 'sta' and 1 child table 'tba1' 3. Insert 4 rows data into child table 'tba1' 4. child query as left join table 5. stba1 as right join table 6. Join two tables on timestamp column with different order by combinations 7. Check the result of join correctly                      path:                                            cases/14-JoinQueries/test_join_order.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_pk.TestJoinPk.test_join_pk","title":"","text":"Join inner  1. Create 1 database and 1 super table 2. Create 2 child tables 3. Insert 1 rows data to each child table with different timestamps 4. Inner join two child tables on timestamp with interval(1s) 5. Check the result of join correctly                       path:                                            cases/14-JoinQueries/test_join_pk.py"},{"location":"case_list_docs/JoinQueries/#14-JoinQueries.test_join_tbname.TestJoin.test_join","title":"","text":"Join with tbname 1. Create 1 database and 2 super tables with different schemas 2. Create child tables from super tables with different tag values 3. Insert data into child tables with same timestamps 4. Join left table is child query from first super table and where condition  5. Join right table is child query from second super table and where condition   6. Join on timestamps and tbname tag 7. Check the result of join correctly                      path:                                            cases/14-JoinQueries/test_join_tbname.py"},{"location":"case_list_docs/MetaData/","title":"21-Meta Data","text":""},{"location":"case_list_docs/MetaData/#21-MetaData.test_meta_bugs.TestMetaBugs.test_meta_bugs","title":"","text":"Meta bugs 1. Verify bug TS-5394(perf_queries should not exist in information_schema on init) 2. Verify bug TS-5580(ins_tags and ins_columns query performance issue)                      path:                                            cases/21-MetaData/test_meta_bugs.py"},{"location":"case_list_docs/MetaData/#21-MetaData.test_meta_change.TestSchemaChange.test_schema_change","title":"","text":"Meta changed on stable 1. Create database schema_change with 2 vgroups 2. Create stable meters with initial columns and tags 3. Randomly add/drop/rename columns and tags on stable meters 4. Query data from stable meters after schema changes 5. Flush database regularly during schema changes 6. Repeat step 3 to step 5 for 1000 times 7. Verify all operations are successful                      path:                                            cases/21-MetaData/test_meta_change.py"},{"location":"case_list_docs/MetaData/#21-MetaData.test_meta_information_schema.TestDdlInSysdb.test_meta_sysdb","title":"","text":"Meta information_schema 1. Creating databases with super/child/normal tables for metadata testing 2. Executing comprehensive queries on information_schema tables (ins_databases/ins_stables/ins_tables) 3. Testing large-scale stable table creation (70+ stables per database) 4. Verifying partition and limit operations on system tables 5. Checking table counting and distinct value operations 6. Create/Drop Database with same name as system database 7. Restart taosd service 8. Create/Drop Table with same name as system table 9. Check information_schema.ins_tables 10. Check information_schema.ins_stables 11. Check information_schema.ins_tags 12. Check information_schema.ins_databases 13. Check information_schema.ins_streams 14. Check information_schema.ins_users 15. Check information_schema.ins_user_privileges 16. Check information_schema.ins_filesets 17. Check information_schema.ins_vgroups 18. Check information_schema.ins_dnodes 19. Check information_schema.ins_mnodes 20. Check information_schema.ins_snodes 21. Check information_schema.ins_qnodes 22. Check information_schema.ins_bnodes 23. Check information_schema.ins_cluster 24. Check information_schema.ins_functions 25. Check information_schema.ins_indexes 26. Check information_schema.ins_tags 27. Check information_schema.ins_columns 28. Check information_schema.ins_virtual_child_columns 29. Check information_schema.ins_views 30. Check information_schema.ins_grants 31. Check information_schema.ins_configs 32. Check information_schema.ins_dnode_variables 33. Check information_schema.ins_stream_tasks 34. Check information_schema.ins_transaction_details 35. Check information_schema.ins_mounts 36. Check information_schema.ins_stream_recalculates 37. Check information_schema.ins_ssmigrates 38. Check information_schema.ins_scans 39. Check information_schema.ins_scan_details 40. Check information_schema.ins_rsmas 41. Check information_schema.ins_retentions 42. Check information_schema.ins_retention_details 43. Check table counting and distinct value operations again after all above tests 44. Check functions on information_schema tables     - count/sum/min/max/stddev/avg/apercentile/     - top/bottom/spread/histogram/hyperloglog/sample/mode 45. Check unsupported functions on information_schema tables     - unique/tail/leastSquares/elapsed/interp/percentile/     - derivative/irate/last_row/last/first/twa/diff/     - statecount/stateduration/csum/mavg                      path:                                            cases/21-MetaData/test_meta_information_schema.py"},{"location":"case_list_docs/MetaData/#21-MetaData.test_meta_ins_tables.TestMetaSysDb2.test_meta_sysdb","title":"","text":"Meta system database 1. Check table type in information_schema.ins_tables 2. Check ins_tables count plan optimization 3. Check ins_columns result correctly with table_name filter 4. Check table count scan with group by db_name and stable_name 5. Check table count scan after taosd restart 6. Check count(distinct ...) function NOT optimized on ins_tables                      path:                                            cases/21-MetaData/test_meta_ins_tables.py"},{"location":"case_list_docs/Mount/","title":"27-Mount","text":""},{"location":"case_list_docs/Mount/#27-Mount.test_mount_basic.TestMountBasic.test_mount_basic","title":"","text":"Mount basic 1. Prepare mount path with data. 2. Prepare host cluster. 3. Check mount error cases. 4. Create, drop, and show mount. 5. Check mount SDB object conflicts.                      path:                                            cases/27-Mount/test_mount_basic.py"},{"location":"case_list_docs/NameLimits/","title":"30-Name &amp; Limits","text":""},{"location":"case_list_docs/NameLimits/#30-NameLimits.test_boundary.TestBoundary.test_boundary","title":"","text":"Name length boundary 1. Database name length boundary check 2. Table name length boundary check 3. Column name length boundary check 4. Tag name length boundary check 5. User name length boundary check 6. Password length boundary check 7. SQL length boundary check 8. Row/Column/Tag max length check 9. Full name length check                      path:                                            cases/30-NameLimits/test_boundary.py"},{"location":"case_list_docs/NameLimits/#30-NameLimits.test_boundary.TestBoundary.test_sql_length_boundary","title":"","text":"SQL length boundary 1. Test normal insert sql with 10MB length 2. Test 10MB insert sql with 10MB length 3. Test 64MB insert sql with 64MB length 4. Test out of boundary value                      path:                                            cases/30-NameLimits/test_boundary.py"},{"location":"case_list_docs/NameLimits/#30-NameLimits.test_db_tb_name_check.TestDbTbNameCheck.test_db_tb_name_check","title":"","text":"Name table 1. Database name validation 2. Table name validation                      path:                                            cases/30-NameLimits/test_db_tb_name_check.py"},{"location":"case_list_docs/NameLimits/#30-NameLimits.test_dbtbname_validate.TestDbTbNameValidate.test_dbtbname_validate","title":"","text":"Name database 1. Validates naming conventions and boundary checks for databases and tables. 2. Verifies both valid and invalid identifiers across operations like CREATE, USE, DROP, and DESCRIBE, including handling of quoted identifiers and case sensitivity. 3. Ensures compliance with naming rules, which allow only English letters, numbers, and underscores, and prohibit names starting with numbers or containing spaces.                      path:                                            cases/30-NameLimits/test_dbtbname_validate.py"},{"location":"case_list_docs/PerformanceData/","title":"22-Performance Data","text":""},{"location":"case_list_docs/PerformanceData/#22-PerformanceData.test_performance_schema.TestPerformanceSchema.test_performance_schema","title":"","text":"Performance_schema basic 1. Create 1 database and 1 super table with full data types 2. Create 20 tables under the super table and insert 10 rows data into each table 3. Query all data from the 20 tables 4. Create a TMQ topic and a consumer to consume data from the topic 5. Create and drop a database in a separate thread to generate transaction actions 6. Check the performance_schema tables:     - perf_apps     - perf_connections     - perf_consumers     - perf_queries     - perf_trans 7. Check perf_trans table structure                      path:                                            cases/22-PerformanceData/test_performance_schema.py"},{"location":"case_list_docs/Privileges/","title":"25-Privileges","text":""},{"location":"case_list_docs/Privileges/#25-Privileges.test_priv_basic.TestPrivBasic.test_priv_basic","title":"","text":"Privileges basic 1. Test common user privileges 2. Test common user with create database privilege 3. Test grant read and write privileges with condition 4. Test grant privilege on multiple tables 5. Test grant privilege error cases 6. Test revoke privilege 7. Test grant on super/child/normal table                      path:                                            cases/25-Privileges/test_priv_basic.py"},{"location":"case_list_docs/Privileges/#25-Privileges.test_priv_bugs.TestGrantBugs.test_grant_bugs","title":"","text":"Privileges bugs 1. Verify bug TD-30642                      path:                                            cases/25-Privileges/test_priv_bugs.py"},{"location":"case_list_docs/Privileges/#25-Privileges.test_priv_subscribe.TestSubscribeStreamPrivilege.test_priv_subscribe","title":"","text":"Privileges subscribe 1. Prepare 1 database, 1 super table, 4 child tables 2. Insert data into child tables 3. Create topic on the database by admin user 4. Create normal user 5. Test subscribe topic privilege without granted 6. Grant subscribe privilege on the topic to normal user 7. Test subscribe topic privilege after granted 8. Revoke subscribe privilege on the topic from normal user 9. Test subscribe topic privilege after revoked                      path:                                            cases/25-Privileges/test_priv_subscribe.py"},{"location":"case_list_docs/RSMAs/","title":"20-RSMAs","text":""},{"location":"case_list_docs/RSMAs/#20-RSMAs.test_rsma.TestCase.test_rsma","title":"","text":"RSMAs basic 1. Create two databases d0 and d1 with retention policy and stt_trigger. 2. Create stable and table with various data types including decimal and composite key. 3. Insert data into tables. 4. Create rsma on tables with various functions. 5. Alter rsma to add more functions. 6. Show rsma and verify. 7. Drop rsma and verify. 8. Trim database to trigger retention policy. 9. Rollup database and verify rsma results. 10. Rollup vgroups and verify rsma results. 11. Test decimal data type and composite key with add/drop column operations. 12. Exceptional cases. 13. Retention task monitor. 14. Rollup automatically when execute: trim database. 15. Rollup manually when execute: rollup database.                      path:                                            cases/20-RSMAs/test_rsma.py"},{"location":"case_list_docs/ShowCommands/","title":"23-Show Commands","text":""},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_alive.TestShowAlive.test_show_alive","title":"","text":"Show alive Continuously start and stop multiple dnodes to verify the returned results of show alive.                      path:                                            cases/23-ShowCommands/test_show_alive.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_basic.TestShowBasic.test_show_basic","title":"","text":"Show basic 1. Verify show commands result with information_schema database 2. Verify show commands result after dnode restarts 3. Checking error handling for invalid operations 4. Check show command include:    show dnodes/modes/qnodes/databases/functions/stables/tables/vgroups    show apps/connections/consumers/queries/transactions/views/tags    show variables/local variables/cluster variables/compacts/cluster    show licences/grants/users    show create database/stable/table 5. Create super table/child table/view and insert data 6. Verify show tags/table tags/indexes command 7. Checking error handling for invalid operations 8. Check show command include:    show tags from super table/child table    show table tags from super table/child table    show indexes from super table/child table                      path:                                            cases/23-ShowCommands/test_show_basic.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_create_db.TestShowCreateDb.test_show_create_db","title":"","text":"Show create database 1. Create three databases with different options 2. Check \"show create database dbname\" output correctness 3. Restart taosd and recheck the output correctness 4. Drop and recreate the databases, recheck the output correctness                      path:                                            cases/23-ShowCommands/test_show_create_db.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_diskinfo.TestShowDiskInfo.test_show_diskinfo","title":"","text":"Show disk info 1. Create super tables and child tables, then write data 2. Perform a FLUSH operation on the database 3. Execute the show disk_info statement 4. Write bulk data into a database with multi-level storage configuration 5. Perform TRIM operation and validate data retention across levels 6. Compare disk usage statistics from show disk_info with actual disk usage                      path:                                            cases/23-ShowCommands/test_show_diskinfo.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_table_distributed.TestShowTableDistributed.test_show_table_distributed","title":"","text":"Show table distributed 1. Tests basic distributed table display for super/normal/temporary tables 2. Verifies error handling for system/internal tables 3. Includes block distribution validation with data insertion 4. Checks metadata consistency after operations 5. Covers edge cases from TD-5998/TD-22140/TD-22165 6. Validates both in-memory and on-disk data representation 7. Ensures proper cleanup of test artifacts 8. Confirms accurate row counts in various scenarios 9. Validates functionality across different cluster configurations 10. Assesses performance impact of show table distributed command                      path:                                            cases/23-ShowCommands/test_show_table_distributed.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_tables.TestShowDbTableKind.test_show_tables","title":"","text":"Show databases &amp; tables 1. Testing various show commands for database/table classification 2. Verifying filtering capabilities with like clauses 3. Checking metadata consistency across different database contexts                      path:                                            cases/23-ShowCommands/test_show_tables.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_transaction.TestShowTransactionDetail.test_show_transaction","title":"","text":"Show transaction 1. CREATE DATABASE db1 vgroups 16 replica 1 2. ALTER DATABASE db1 replica 3 3. CREATE DATABASE db2 vgroups 40 replica 3 4. During the above operations, stop a dnode to generate incomplete transactions 5. Use SHOW TRANSACTIONS to display ongoing transactions 6. Use SHOW TRANSACTION &lt;id&gt; to display transaction details 7. Query ins_transaction_details table to verify transaction details                      path:                                            cases/23-ShowCommands/test_show_transaction.py"},{"location":"case_list_docs/ShowCommands/#23-ShowCommands.test_show_vgroups_ready.TestShowBasic.test_show_basic","title":"","text":"Show Basic 1. build cluster with 3 dnodes 2. execute show vgroups commands                      path:                                            cases/23-ShowCommands/test_show_vgroups_ready.py"},{"location":"case_list_docs/TSMAs/","title":"19-TSMAs","text":""},{"location":"case_list_docs/TSMAs/#19-TSMAs.test_sma_basic.TestSmabasic.test_sma_basic","title":"","text":"Sma basic 1. Create 1 super table and 5 child tables 2. Insert 1 million rows data into each child table 3. Put special number value (8764231) on c2 column interval 3200 rows 4. Query and check the result of count/max/min/sum on c1/c2 column with different where condition 5. Query count(*) where c2 != specail number(8764231) as no using sma 6. Query count(*) no where as using sma 7. Expect the performance step5 &lt; step6 * 8 8. Query each function(count/max/min/avg/sum/spread/percentile/first/last) on all columns of the table ntb using sma                      path:                                            cases/19-TSMAs/test_sma_basic.py"},{"location":"case_list_docs/TSMAs/#19-TSMAs.test_sma_bugs.TestSmatest.test_smaTest","title":"","text":"Sma bugs 1. JIRA TD-33336 2. JIRA TS-5900                              path:                                            cases/19-TSMAs/test_sma_bugs.py"},{"location":"case_list_docs/TSMAs/#19-TSMAs.test_time_range_wise.TestTimeRangeWise.test_time_range_wise","title":"","text":"TSMAs correctness 1. Create database db1 without sma and db2 with sma 2. Create same super table and child tables on db1 and db2 3. Insert same data into child tables of db1 and db2 4. Query data from db1 and db2  5. Expect query result same from db1 and db2                      path:                                            cases/19-TSMAs/test_time_range_wise.py"},{"location":"case_list_docs/TSMAs/#19-TSMAs.test_tsma.TestTsma.test_tsma","title":"","text":"TSMAs basic 1. Create snode on dnode 1 2. Initialize data 3. Execute tsma ddl test cases 4. Execute tsma query test cases 5. Execute tsma flush query test cases 6. Execute tsma redistribute vgroups test cases if cluster dnode nums &gt; 1 7. Drop tsma test.tsma5 8. Verify TD-32519 9. Drop snode                      path:                                            cases/19-TSMAs/test_tsma.py"},{"location":"case_list_docs/TagIndices/","title":"15-Tag Indices","text":""},{"location":"case_list_docs/TagIndices/#15-TagIndices.test_index_create_drop.TestIndexCreateDrop.test_index_create_drop","title":"","text":"Tagindex: create and drop 1. Create a super table 2. Create an index on a specific tag column 3. Query using the indexed tag 4. Drop the existing index 5. Query using the tag whose index was just dropped                      path:                                            cases/15-TagIndices/test_index_create_drop.py"},{"location":"case_list_docs/TagIndices/#15-TagIndices.test_index_overflow.TestIndexOverflow.test_index_overflow","title":"","text":"Tagindex: overflow 1. Create a super table 2. Set a wide value range for a specific tag column 3. Create an index on that tag column 4. Query using the indexed tag                      path:                                            cases/15-TagIndices/test_index_overflow.py"},{"location":"case_list_docs/TagIndices/#15-TagIndices.test_index_perf.TestIndexPerf.test_index_perf","title":"","text":"Tagindex: perf 1. Create a super table 2. Create a large number of child tables (this example uses 10, but should use 100,000 after the data preloading feature is implemented) 3. Insert one record into each child table 4. Create an index 5. Query each child table using tag filtering                      path:                                            cases/15-TagIndices/test_index_perf.py"},{"location":"case_list_docs/TagIndices/#15-TagIndices.test_index_tag_basic.TestTagIndexBasic.test_index_tag_basic","title":"","text":"Tagindex basic 1. Create 1 stable and 1000 child tables 2. Create tag index for each tag column except the first one 3. Check error cases when creating tag index with invalid column names 4. Insert data into some child tables 5. Check create tag is successful 6. Query data using tag index and verify results 7. Drop a range of child tables 8. Drop all tag indexes 9. Attempt to create tag index with excessively long name and verify error 10. bug TS-4403: Create/drop tag index on supertable and verify behavior                      path:                                            cases/15-TagIndices/test_index_tag_basic.py"},{"location":"case_list_docs/UDFs/","title":"12-UDFs","text":""},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_c.TestUdfC.test_udf_c","title":"","text":"Udf for C language 1. Compile UDF C code 2. Create scalar UDF function bit_and 3. Create aggregate UDF function l2norm 4. Test scalar UDF function bit_and                      path:                                            cases/12-UDFs/test_udf_c.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_cfg1.TestUdfCfg1.test_udf_cfg1","title":"","text":"Udf config 1 1. prepare udf so files 2. prepare data for udf 2. create udf functions 3. basic udf query test 4. exception test for udf functions 5. drop udf functions                      path:                                            cases/12-UDFs/test_udf_cfg1.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_cfg2.TestUdfCfg2.test_udf_cfg2","title":"","text":"Udf config 2 1. prepare udf so files 2. prepare data for udf 3. create udf functions 4. basic udf query test 5. multi columns udf functions 6. try query sqls for udf functions 7. loop kill taosudf and query udf functions 8. restart taosd and query udf functions 9. drop and create udf functions without bufsize and without aggregate 10. try query sqls for udf functions 11. error create udf functions 12. drop udf functions                      path:                                            cases/12-UDFs/test_udf_cfg2.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_create.TestUdfCreate.test_udf_create","title":"","text":"Udf function create 1. prepare udf so files 2. prepare data for udf 3. create udf functions 4. basic udf query test 5. multi columns udf functions 6. try query sqls for udf functions 7. loop kill taosudf and query udf functions 8. restart taosd and query udf functions 9. drop and create udf functions without bufsize and without aggregate 10. try query sqls for udf functions 11. error create udf functions 12. drop udf functions                      path:                                            cases/12-UDFs/test_udf_create.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_main.TestUdfpyMain.test_udf_main","title":"","text":"Udf basic for python 1. Install taospyudf package 2. Create stable and child tables 3. Create scalar udfpy functions concat 4. Create aggregate udfpy functions min, sum, count 5. Insert data to child tables 6. Query scalar udfpy functions 7. Query aggregate udfpy functions 8. Verify all operations are successful                      path:                                            cases/12-UDFs/test_udf_main.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_py.TestUdf.test_udf","title":"","text":"Udf python sim case 1. Create database and normal table for udf test 2. Create scalar UDF function bit_and with python file 3. Create aggregate UDF function l2norm with python file 4. Insert data into normal table 5. Query scalar UDF function bit_and from normal table 6. Query aggregate UDF function l2norm from normal table 7. Test UDF with null values 8. Test UDF with multiple columns                      path:                                            cases/12-UDFs/test_udf_py.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_restart_taosd.TestUdfRestartTaosd.test_udf_restart_taosd","title":"","text":"Udf restart taosd 1. prepare udf so library 2. prepare data 3. create udf functions 4. basic udf query test 5. multi columns udf test 6. restart taosd and query udf functions                      path:                                            cases/12-UDFs/test_udf_restart_taosd.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_test.TestUdfTest.test_udf_test","title":"","text":"Udf kill taosudf process 1. Test command \"taosudf -c\" and \"taosudf -V\" 2. Prepare udf so files 3. Prepare data 4. Run unexpected using of udf functions 5. Create udf functions 6. Run change udf so file and query 7. Basic udf query test 8. Loop kill taosudf process and query udf functions 9. Test function name is not built-in functions                      path:                                            cases/12-UDFs/test_udf_test.py"},{"location":"case_list_docs/UDFs/#12-UDFs.test_udf_with_const.TestUdfPy.test_udf_py","title":"","text":"Udf C for const 1. Create database and normal table for udf test 2. Create function gpd with C code that has const parameter 3. Insert data into normal table 4. Query function gpd with const parameter from normal table                      path:                                            cases/12-UDFs/test_udf_with_const.py"},{"location":"case_list_docs/Users/","title":"24-Users","text":""},{"location":"case_list_docs/Users/#24-Users.test_user_basic.TestUserBasic.test_user_basic","title":"","text":"User: basic test 1. Verifies root user default privileges and restrictions on privilege modification attempts 2. Tests creation of users with different SYSINFO privilege levels (0/1) 3. Validates privilege alteration for enable/createdb/SYSINFO flags 4. Check system persistence after dnode restart 5. Ensures proper error handling for invalid privilege values 6. Check create multi users and grant/revoke privilege for them 7. Subscribe topic with different user privileges                      path:                                            cases/24-Users/test_user_basic.py"},{"location":"case_list_docs/Users/#24-Users.test_user_control.TestUserControl.test_user_control","title":"","text":"User control  1. Create 1 stable 20 child table 1 normal table 2. Insert each table 10 rows data 3. Restart taosd 4. Check root user exist 5. Create 5 test users 6. Check test users exist 7. Login with test users 8. Check test users can access their own data 9. Change test users privileges 10. Alter test users password 11. Login with altered password 12. Check test users can access their own data after privilege changed 13. Disable some users and check they can not access data                      path:                                            cases/24-Users/test_user_control.py"},{"location":"case_list_docs/Users/#24-Users.test_user_crypted_pass.TestUserPassword.test_user_password","title":"","text":"Password: crypted password Create encrypt_key and test to create user and login with crypted password                      path:                                            cases/24-Users/test_user_crypted_pass.py"},{"location":"case_list_docs/Users/#24-Users.test_user_passwd.TestPasswd.test_passwd","title":"","text":"Password call c unit test 1. Compile script/api/passwdTest.c to passwdTest 2. Run passwdTest and check retcode is 0                      path:                                            cases/24-Users/test_user_passwd.py"},{"location":"case_list_docs/Users/#24-Users.test_user_password.TestUserPassword.test_user_password","title":"","text":"Password: basic 1. Creation and modification of users with various password formats (valid/invalid patterns) 2. Verification of password complexity requirements (length/special characters) 3. Testing cross-user permission restrictions during password changes 4. Validation of system behavior with maximum password length boundaries 5. Special character handling in passwords and error case verification 6. Login with strong password                      path:                                            cases/24-Users/test_user_password.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_create_db.TestUserPrivilegeCreateDb.test_user_privilege_create_db","title":"","text":"Privilege: create db Verify user privileges for database creation, including grant, revoke, and query operations.                      path:                                            cases/24-Users/test_user_privilege_create_db.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_db.TestUserPrivilegeDb.test_user_privilege_db","title":"","text":"Privilege: db Verify user privileges related to database operations, including grant, revoke, and query privileges.                      path:                                            cases/24-Users/test_user_privilege_db.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_sysinfo.TestUserPrivilegeSysinfo.test_user_privilege_sysinfo","title":"","text":"Privilege: sysinfo 1. Verify user privileges related to sysinfo operation, including grant, revoke, and query privileges. 2. Verify bug TS-5130 (normal user with sysinfo privilege cannot access information_schema)                      path:                                            cases/24-Users/test_user_privilege_sysinfo.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_table.TestUserPrivilegeTable.test_user_privilege_table","title":"","text":"Privilege:  table Verify user privileges related to table operations, including grant, revoke, and query privileges.                      path:                                            cases/24-Users/test_user_privilege_table.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_table.TestUserPrivilegeTable.test_except_reset_query_cache","title":"","text":"Except reset query cache 1. Reset query cache before grant/revoke privilege 2. Reset query cache after grant/revoke privilege 3. Check show command and query command correctness                      path:                                            cases/24-Users/test_user_privilege_table.py"},{"location":"case_list_docs/Users/#24-Users.test_user_privilege_topic.TestUserPrivilegeTopic.test_user_privilege_topic","title":"","text":"Privilege: topic Verify user privileges related to topic operations, including grant, revoke, and query privileges.                      path:                                            cases/24-Users/test_user_privilege_topic.py"},{"location":"case_list_docs/Users/#24-Users.test_user_whitelist.TestUserWhiteList.test_user_whitelist","title":"","text":"Whitelist: basic test Verify basic usage of whitelist functionality, including creation and display operations.                      path:                                            cases/24-Users/test_user_whitelist.py"},{"location":"case_list_docs/Views/","title":"16-Views","text":""},{"location":"case_list_docs/Views/#16-Views.test_view_basic.TestViewBasic.test_view_basic","title":"","text":"View basic 1. Create view from one database 2. Create view from multi database 3. Create view with different view name params 4. Create view with different data type in query 5. Show view 6. Drop view 7. View permission test 8. Query from view 9. TMQ consume from view 10. Verify bug TD-33390                      path:                                            cases/16-Views/test_view_basic.py"},{"location":"case_list_docs/Views/#16-Views.test_view_mgmt.TestViewMgmt.test_view_mgmt","title":"","text":"View management 1. Create 3 super tables 2. Create child tables and insert data 3. Create view with root user 4. Grant /revoke privilege on view to normal users and test 5. Nested view privilege test 6. Query view test 7. show/desc view test 8. Same name table and view test 9. Test keepColumnName is 1 and 0 10. Restart server test 11. Drop view test                      path:                                            cases/16-Views/test_view_mgmt.py"},{"location":"case_list_docs/Views/#16-Views.test_view_nested_join.TestViewNestedJoin.test_view_nested_join","title":"","text":"View with nested join 1. Create 1 stable and 1 normal table 2. Create view with nested join of stable and normal table 3. Query view                      path:                                            cases/16-Views/test_view_nested_join.py"},{"location":"case_list_docs/VirtualTables/","title":"05-Virtual Tables","text":""},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_alter.TestVtableAlter.test_alter_virtual_normal_table","title":"","text":"Alter: virtual normal table 1. add column 2. drop column 3. change column reference 4. change column type length 5. change column name                      path:                                            cases/05-VirtualTables/test_vtable_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_alter.TestVtableAlter.test_alter_virtual_child_table","title":"","text":"Alter: virtual child table 1. change column reference 2. change tag value                      path:                                            cases/05-VirtualTables/test_vtable_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_alter.TestVtableAlter.test_alter_virtual_super_table","title":"","text":"Alter: virtual super table 1. add column 2. drop column 3. change column type length 4. add tag 5. drop tag 6. change tag name 7. change tag length                      path:                                            cases/05-VirtualTables/test_vtable_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_alter.TestVtableAlter.test_alter_virtual_super_table_and_create_child","title":"","text":"Alter: virtual stable create child table 1. add column 2. drop column                      path:                                            cases/05-VirtualTables/test_vtable_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_alter.TestVtableAlter.test_error_cases","title":"","text":"Alter: virtual table errors 1. normal table 2. child table 3. super table                      path:                                            cases/05-VirtualTables/test_vtable_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_alter_normaltable.TestVtableAuthAlterDrop.test_alter_drop_virtual_normal_table","title":"","text":"Auth: alter virtual normal table test \"write\", \"read\", \"none\", \"all\" each auth user alter opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_alter_normaltable.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_alter_subtable.TestVtableAuthAlterDropChild.test_alter_drop_virtual_child_table","title":"","text":"Auth: alter virtual child table test \"write\", \"read\", \"none\", \"all\" each auth user alter opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_alter_subtable.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_create.TestVtableAuthCreate.test_create_virtual_normal_table","title":"","text":"Auth: create virtual normal table test \"write\", \"read\", \"none\", \"all\" each auth user create opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_create.TestVtableAuthCreate.test_create_virtual_child_table","title":"","text":"Auth: create virtual child table test \"write\", \"read\", \"none\", \"all\" each auth user create opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_select.TestVtableAuthSelect.test_select_virtual_normal_table","title":"","text":"Auth: select virtual normal table test \"write\", \"read\", \"none\", \"all\" each auth user select opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_select.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_auth_select.TestVtableAuthSelect.test_select_virtual_child_table","title":"","text":"Auth: select virtual child table test \"write\", \"read\", \"none\", \"all\" each auth user select opration                      path:                                            cases/05-VirtualTables/test_vtable_auth_select.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_create.TestVtableCreate.test_create_virtual_super_table","title":"","text":"Create: virtual super table test create virtual super tables                      path:                                            cases/05-VirtualTables/test_vtable_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_create.TestVtableCreate.test_create_virtual_child_table","title":"","text":"Create: virtual child table 1.create virtual child table and don't use 'FROM' to specify the origin table 2.create virtual child table and use 'FROM' to specify the origin table                      path:                                            cases/05-VirtualTables/test_vtable_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_create.TestVtableCreate.test_create_virtual_normal_table","title":"","text":"Create: virtual normal table test create virtual normal tables                      path:                                            cases/05-VirtualTables/test_vtable_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_create.TestVtableCreate.test_error_cases","title":"","text":"Create: virtual table errors 1. create virtual child table using non-virtual super table 2. create child table using virtual super table 3. create virtual child table using non-exist super table 4. column definition different from referenced column 5. set data source for primary timestamp column 6. data source column does not exist 7. data source table does not exist 8. data source table has composite primary key 9. data source is tag 10. create virtual child table using from to specify some columns and do not use from for other columns 11. create virtual table using decimal                      path:                                            cases/05-VirtualTables/test_vtable_create.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_drop.TestVtableDrop.test_drop_virtual_child_table","title":"","text":"Drop: virtual child table test drop virtual child tables                      path:                                            cases/05-VirtualTables/test_vtable_drop.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_drop.TestVtableDrop.test_drop_virtual_normal_table","title":"","text":"Drop: virtual normal table test drop virtual normal tables                      path:                                            cases/05-VirtualTables/test_vtable_drop.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_drop.TestVtableDrop.test_drop_virtual_super_table","title":"","text":"Drop: virtual super table test drop virtual super table                      path:                                            cases/05-VirtualTables/test_vtable_drop.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_drop.TestVtableDrop.test_drop_virtual_not_exists","title":"","text":"Drop: virtual table errors test drop virtual not exists                      path:                                            cases/05-VirtualTables/test_vtable_drop.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_insert.TestVtableInsert.test_vtable_insert","title":"","text":"Insert: virtual table 1. Create db 2. Create supper table and sub table 3. Create virtual supper table and sub table 4. Create normal virtual table and normal table 5. Insert data into virtual super table or virtual sub table or virtual normal table, it should be return error                      path:                                            cases/05-VirtualTables/test_vtable_insert.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_join.TestVtableJoin.test_vtable_join","title":"","text":"Query: join test query virtual tables join                      path:                                            cases/05-VirtualTables/test_vtable_join.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_meta.TestVtableMeta.test_normal_query_new","title":"","text":"Query: meta test virtual table normal query                      path:                                            cases/05-VirtualTables/test_vtable_meta.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_after_alter.TestVtableQueryAfterAlter.test_virtual_stable_and_child_table","title":"","text":"Query: after alter super/child table test virtual table select after alter stable                      path:                                            cases/05-VirtualTables/test_vtable_query_after_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_after_alter.TestVtableQueryAfterAlter.test_virtual_normal_table","title":"","text":"Query: after alter normal table test virtual table select after alter normal table                      path:                                            cases/05-VirtualTables/test_vtable_query_after_alter.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_after_alter_origin_table.TestVtableQueryAfterAlterOriginTable.test_query_after_alter","title":"","text":"Query: after alter test query after alter origin tables                      path:                                            cases/05-VirtualTables/test_vtable_query_after_alter_origin_table.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_after_drop_origin_table.TestVtableQueryAfterDropOriginTable.test_query_after_drop","title":"","text":"Query: after drop test query after drop tables                      path:                                            cases/05-VirtualTables/test_vtable_query_after_drop_origin_table.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db.TestVtableQueryCrossDB.test_select_virtual_normal_table","title":"","text":"Query: v-ntable crossdb query 1. test vstable select normal table cross db projection 2. test vstable select normal table cross db projection filter 3. test vstable select normal table cross db projection timerange filter 4. test vstable select normal table cross db function 5. test vstable select normal table cross db interval 6. test vstable select normal table cross db state 7. test vstable select normal table cross db session 8. test vstable select normal table cross db event 9. test vstable select normal table cross db count 10. test vstable select normal table cross db partition 11. test vstable select normal table cross db group 12. test vstable select normal table cross db orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db.TestVtableQueryCrossDB.test_select_virtual_child_table","title":"","text":"Query: v-ctable crossdb query 1. test vstable select child table cross db projection 2. test vstable select child table cross db projection filter 3. test vstable select child table cross db projection timerange filter 4. test vstable select child table cross db function 5. test vstable select child table cross db interval 6. test vstable select child table cross db state 7. test vstable select child table cross db session 8. test vstable select child table cross db event 9. test vstable select child table cross db count 10. test vstable select child table cross db partition 11. test vstable select child table cross db group 12. test vstable select child table cross db orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db_stb_function.TestVtableQueryCrossDbStbFunction.test_select_virtual_super_table","title":"","text":"Query: v-stable crossdb function query 1. test vstable select super table cross db projection function                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db_stb_function.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db_stb_group.TestVtableQueryCrossDbStbGroup.test_select_virtual_super_table","title":"","text":"Query: v-stable crossdb group query 1. test vstable select super table cross db partition 2. test vstable select super table cross db group 3. test vstable select super table cross db orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db_stb_group.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db_stb_project.TestVtableQueryCrossDbStb.test_select_virtual_super_table","title":"","text":"Query: v-stable crossdb porject query 1. test vstable select super table cross db projection 2. test vstable select super table cross db projection filter 3. test vstable select super table cross db projection timerange filter                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db_stb_project.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_cross_db_stb_window.TestVtableQueryCrossDbStbWindow.test_select_virtual_super_table","title":"","text":"Query: v-stable crossdb window query 1. test vstable select super table cross db interval 2. test vstable select super table cross db state 3. test vstable select super table cross db session 4. test vstable select super table cross db event 5. test vstable select super table cross db count                      path:                                            cases/05-VirtualTables/test_vtable_query_cross_db_stb_window.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_db.TestVTableQuerySameDB.test_select_virtual_normal_table","title":"","text":"Query: virtual normal table 1. test vstable select normal table projection 2. test vstable select normal table projection filter 3. test vstable select normal table projection timerange filter 4. test vstable select normal table interval 5. test vstable select normal table state 6. test vstable select normal table session 7. test vstable select normal table event 8. test vstable select normal table count 9. test vstable select normal table partition 10. test vstable select normal table group 11. test vstable select normal table orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_same_db.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_db.TestVTableQuerySameDB.test_select_virtual_child_table","title":"","text":"Query: virtual child table 1. test vstable select child table projection 2. test vstable select child table projection filter 3. test vstable select child table projection timerange filter 4. test vstable select child table interval 5. test vstable select child table state 6. test vstable select child table session 7. test vstable select child table event 8. test vstable select child table count 9. test vstable select child table partition 10. test vstable select child table group 11. test vstable select child table orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_same_db.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_db_stb_group.TestVTableQuerySameDBStbGroup.test_select_virtual_super_table","title":"","text":"Query: virtual stable from same db group 1. test vstable select super table partition 2. test vstable select super table group 3. test vstable select super table orderby                      path:                                            cases/05-VirtualTables/test_vtable_query_same_db_stb_group.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_db_stb_project.TestVTableQuerySameDBStbProject.test_select_virtual_super_table","title":"","text":"Query: virtual stable from same db 1. test vstable select super table projection 2. test vstable select super table projection filter 3. test vstable select super table projection timerange filter 4. test vstable select super table function                      path:                                            cases/05-VirtualTables/test_vtable_query_same_db_stb_project.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_db_stb_window.TestVTableQuerySameDBStbWindow.test_select_virtual_super_table","title":"","text":"Query: virtual stable from same db 1. test vstable select super table same db interval 2. test vstable select super table same db state 3. test vstable select super table same db session 4. test vstable select super table same db event 5. test vstable select super table same db count                      path:                                            cases/05-VirtualTables/test_vtable_query_same_db_stb_window.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_same_reference_col.TestVTableQuery.test_select_virtualtable_same_reference_col","title":"","text":"Query: virtual table with same reference column 1. test vtable select normal table projection with same reference column 2. test vtable select child table projection with same reference column 3. test vtable select super table projection with same reference column                      path:                                            cases/05-VirtualTables/test_vtable_query_same_reference_col.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_query_with_null_value.TestVTableQuery.test_select_virtualtable_with_null_value","title":"","text":"Query: virtual table with null value 1. test vtable select normal table projection with null value 2. test vtable select child table projection with null value 3. test vtable select super table projection with null value                      path:                                            cases/05-VirtualTables/test_vtable_query_with_null_value.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_schema_is_old.TestVTableSchemaIsOld.test_vtable_schema_is_old","title":"","text":"Query: old schema (bugfix) schema is old when origin table's column has same prefix during virtual supertable query                      path:                                            cases/05-VirtualTables/test_vtable_schema_is_old.py"},{"location":"case_list_docs/VirtualTables/#05-VirtualTables.test_vtable_show_tag.TestVtableShowTag.test_vtable_show_tag","title":"","text":"Query: show tag (bugfix) 1. Create db 2. Create supper table and sub table 3. Create virtual supper table and sub table 4. Show tag of virtual table and check the result                      path:                                            cases/05-VirtualTables/test_vtable_show_tag.py"},{"location":"case_list_docs/Components/TDgpt/","title":"10-TDgpt","text":""},{"location":"case_list_docs/Components/TDgpt/#80-Components.10-TDgpt.test_tdgpt.TestTDgptBasic.test_not_exists_anode","title":"","text":"TDgpt anode 1. Create anode with wrong address 2. Expect create failed 3. Show anodes, expect 0 rows 4. Drop non-exist anode, expect error                      path:                                            cases/80-Components/10-TDgpt/test_tdgpt.py"},{"location":"case_list_docs/Components/TDgpt/#80-Components.10-TDgpt.test_tdgpt.TestTDgptBasic.test_analysis","title":"","text":"TDgpt analysis functions 1. Create 1 anode 2. Show anodes expect 1 row 3. Show anodes full expect 17 rows 4. Create database d0 with 1 vgroup 5. Create stable stb with 6 columns and 1 tag 6. Create child table ct1 using stb with tag value 1000 7. Insert 17 rows into ct1 8. Query forecast/anomaly_window on super/child/normal tables 9. Query forecast with _frowts/_flow/_fhigh 10. Query forecast with holtwinters/arima/moirai algorithms 11. Query anomaly_window with iqr/ksigma/lof/shesd/grubbs algorithms 12. Except query with not exist column 13. Except query with not supported algorithm                      path:                                            cases/80-Components/10-TDgpt/test_tdgpt.py"},{"location":"case_list_docs/Components/TDgpt/#80-Components.10-TDgpt.test_tdgpt.TestTDgptBasic.test_corr_table","title":"","text":"TDgpt corr() on tables 1. corr function query test cases on normal tables or child tables 2. Insert data into child/normal tables 3. Query corr() function with different column types 4. Query corr() function with invalid parameters 5. Query corr() function with insufficient data                      path:                                            cases/80-Components/10-TDgpt/test_tdgpt.py"},{"location":"case_list_docs/Components/TDgpt/#80-Components.10-TDgpt.test_tdgpt.TestTDgptBasic.test_corr_stable","title":"","text":"TDgpt corr() on stable 1. corr function query test cases on super table 2. Insert data into child tables 3. Query corr() function with different column types 4. Query corr() function with invalid parameters 5. Query corr() function with insufficient data                      path:                                            cases/80-Components/10-TDgpt/test_tdgpt.py"},{"location":"case_list_docs/Components/Taosc/","title":"02-Taosc","text":""},{"location":"case_list_docs/Components/Taosc/#80-Components.01-Taosd.test_com_config_refresh.TestComTaosdConfigRefresh.test_com_taosc_config","title":"","text":"Client config hot refresh 1. Alter taos.cfg item by \"alter\" sql 2. Show local variant to verify 3. Restart taosd 4. Show local variant to verify again                      path:                                            cases/80-Components/01-Taosd/test_com_config_refresh.py"},{"location":"case_list_docs/Components/Taosc/#80-Components.02-Taosc.test_com_count_always_return_value.TestCountalwaysreturnvalue.test_com_count_always_return_value","title":"","text":"Client options 1. Config set countAlwaysReturnValue to 0 2. Create 1 database and 1 normal table, 2 super table with 4 child tables 3. Query count/hyperloglog on empty stable and child tables 4. Expect return 0 rows for all above queries 5. Query count with group by on empty stable and select hyperloglog(NULL) 6. Expect return 1 row                       path:                                            cases/80-Components/02-Taosc/test_com_count_always_return_value.py"},{"location":"case_list_docs/Components/Taosc/#80-Components.02-Taosc.test_com_taosc_hot_refresh_config.TestHotRefreshConfigurations.test_com_taosc_hot_refresh_config","title":"","text":"Taosc config hot refresh 1. Execute \"alter all dnodes 'resetlog';\" 2. Expect found 'reset log file' in taosd logs 3. Hot refresh client config  queryPolicy/numOfLogLines/logKeepDays 4. Hot refresh server config  mndSdbWriteDelta/enableWhiteList/audit and more 5. Expect config value changed successfully                      path:                                            cases/80-Components/02-Taosc/test_com_taosc_hot_refresh_config.py"},{"location":"case_list_docs/Components/Taosd/","title":"01-Taosd","text":""},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_cmdline.TestComCmdLine.test_dumpsdb","title":"","text":"Taosd command line 1. Verify taosd -s options to dump sdb.json                      path:                                            cases/80-Components/01-Taosd/test_com_cmdline.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_config.TestAlterConfig.test_alter_config","title":"","text":"Server config basic 1. Verify alter support vnodes config 2. Verify alter ttl config 3. Verify alter bypass flag config 4. Verify alter audit config 5. Verify alter config on dnode 1 6. Verify alter timezone config 7. Verify alter memPoolReservedSizeMB config 8. Verify dismatch config refresh                      path:                                            cases/80-Components/01-Taosd/test_com_config.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_config_refresh.TestComTaosdConfigRefresh.test_com_taosd_config_refresh","title":"","text":"Server config hot refresh 1. Alter taos.cfg item by \"alter\" sql 2. Verify the altered item value take effect 3. Stop and restart taosd 4. Verify the altered item value take effect after restart 5. Config item include server and client side                      path:                                            cases/80-Components/01-Taosd/test_com_config_refresh.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_config_refresh.TestComTaosdConfigRefresh.test_com_taosc_config","title":"","text":"Client config hot refresh 1. Alter taos.cfg item by \"alter\" sql 2. Show local variant to verify 3. Restart taosd 4. Show local variant to verify again                      path:                                            cases/80-Components/01-Taosd/test_com_config_refresh.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_persisit_config.TestPersisitConfig.test_com_persisit_config","title":"","text":"Server persist config 1. Obtain taos.cfg file path 2. Modify fqdn/dataDir/logDir with new values 3. Restart taosd 4. Check config values loaded from mnd sdb 5. Expect new values go into effect                      path:                                            cases/80-Components/01-Taosd/test_com_persisit_config.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_taosd_audit.TestTaosdAudit.test_taosd_audit","title":"","text":"Taosd telemetry audit 1. Create database with vgroups 4 2. Create super table and table 3. Insert data into table 4. Delete data from table 5. Start http server to receive telemetry info 6. Check telemetry info content valid 7. Stop http server                      path:                                            cases/80-Components/01-Taosd/test_com_taosd_audit.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_taosd_log.TestTaosdlog.test_taosdlog","title":"","text":"Taosd log 1. Check log compress 2. Check log output 3. Check log rotate 4. Close taosd and taos                      path:                                            cases/80-Components/01-Taosd/test_com_taosd_log.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_taosd_monitor.TestTaosdMonitor.test_taosd_monitor","title":"","text":"Taosd telemetry monitor 1. Configure monitorFqdn/monitorPort/monitor params 2. Start http server to receive monitor info 3. Do some operations to generate monitor info 4. Check monitor info content valid 5. Check telemetry info content valid 6. Stop http server                      path:                                            cases/80-Components/01-Taosd/test_com_taosd_monitor.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_taosd_restart.TestCheckTsdb.test_com_taosd_restart","title":"","text":"Taosd restart 1. Create 1 stable and 4 child tables 2. Insert 13 rows for each child table 3. Restart taosd 5 times, and query sum of columns after each restart 4. Check the query results 5. Expect all query results are correct                      path:                                            cases/80-Components/01-Taosd/test_com_taosd_restart.py"},{"location":"case_list_docs/Components/Taosd/#80-Components.01-Taosd.test_com_telemetry.TestTelemetry.test_com_telemetry","title":"","text":"Server support telemetry  1. Configure telemetry params 2. Start http server to receive telemetry info 3. Check telemetry info content valid 4. Stop http server                      path:                                            cases/80-Components/01-Taosd/test_com_telemetry.py"},{"location":"case_list_docs/DataIngestion/Import/","title":"04-Import","text":""},{"location":"case_list_docs/DataIngestion/Import/#06-DataIngestion.04-Import.test_write_import_csv.TestInsertFromCsv.test_write_import_csv","title":"","text":"From csv file 1. Create table and import data from csv file 2. Check the imported data                      path:                                            cases/06-DataIngestion/04-Import/test_write_import_csv.py"},{"location":"case_list_docs/DataIngestion/SML/","title":"03-SML","text":""},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_cfg.TestSml.test_sml_bugs","title":"","text":"Sml config 1. Update taos.cfg with sml related configurations 2. Restart taosd to make configurations take effect 3. Use sml_test tool to ingest sml data 4. Verify the data correctness after ingestion                              path:                                            cases/06-DataIngestion/03-SML/test_write_sml_cfg.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_influxdb_line.TestInfluxdbLineTaoscInsert.test_write_sml_influxdb_line","title":"","text":"InfluxDB line protocol 1. Basic InfluxDB line protocol parsing 2. Automatic table schema creation   3. Data type inference and conversion 4. Dynamic schema evolution support 5. Batch insertion functionality 6. Multi-threading concurrent insertion 7. Column and tag limit validation 8. String length boundary testing 9. Error handling and validation 10. Timestamp format compatibility                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_influxdb_line.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_opentsdb_json.TestOpentsdbJsonTaoscInsert.test_write_sml_opentsdb_json","title":"","text":"OpenTSDB json protocol 1. Basic OpenTSDB JSON protocol parsing 2. Automatic schema creation and evolution 3. Data type validation and conversion 4. Timestamp format compatibility testing 5. Multi-threading concurrent insertion safety 6. Table and column naming restrictions 7. Batch insertion functionality validation 8. String length and encoding boundaries 9. Error handling and exception management 10. Performance and memory usage optimization                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_opentsdb_json.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_opentsdb_telnet.TestOpentsdbTelnetLineTaoscInsert.test_write_sml_opentsdb_telnet","title":"","text":"OpenTSDB telnet protocol 1. Basic OpenTSDB Telnet protocol parsing 2. Automatic table schema creation and evolution 3. Data type validation with overflow detection 4. Multi-threading concurrent insertion safety 5. TCP telnet protocol network insertion 6. String length and encoding boundaries 7. Table naming restrictions and validation 8. Batch insertion performance testing 9. Error handling and exception management 10. Tag and column limit enforcement                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_opentsdb_telnet.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_restart.TestSmlRestart.test_write_sml_restart","title":"","text":"Write sml restart  1. taosBenchmark sml data with json file 2. line_protocol include json/line/telnet 3. insert mode include: taosc/stmt 4. Restart taosd after writing over 5. Query server and client version 6. Verify taosBenchmark write sml data correct                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_restart.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_td19291.TestSml.test_sml_TD19291","title":"","text":"Sml bugs TD-19291 1. Jira TD-19291: Support schemaless insert with super long tag value 2. Verify the data correctness after ingestion 3. Cleanup the test data                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_td19291.py"},{"location":"case_list_docs/DataIngestion/SML/#06-DataIngestion.03-SML.test_write_sml_ts3724.TestSmlTs3724.test_sml_TS_3724","title":"","text":"Sml bugs TS-3724 1. Jira TS-3724: Support schemaless insert with special characters in tag values 2. Verify the data correctness after ingestion 3. Cleanup the test data                      path:                                            cases/06-DataIngestion/03-SML/test_write_sml_ts3724.py"},{"location":"case_list_docs/DataIngestion/SQL/","title":"01-SQL","text":""},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_wal_keep_version_high_availability.TestWalKeepVersionTrim.test_wal_keep_version_high_availability","title":"","text":"Wal keep restart This test verifies: 1. prepare data 2. stop dnode 3 3. set keep version 0 4. start dnode 3 5. check wal keep version                      path:                                            cases/06-DataIngestion/01-SQL/test_wal_keep_version_high_availability.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_wal_keep_version_trim.TestWalKeepVersionTrim.test_wal_keep_version_and_trim","title":"","text":"Wal keep trim This test verifies: 1. prepare data 2. set keep version 0 3. check wal keep version 4. trim database wal 5. check wal log dropped after trim                      path:                                            cases/06-DataIngestion/01-SQL/test_wal_keep_version_trim.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write.TestInsertDouble.test_write","title":"","text":"Write basic 1. Write data with timestamp 2. Write data with double 3. Insert and drop database concurrently 4. Write data with future timestamp 5. Write data with wide column                      path:                                            cases/06-DataIngestion/01-SQL/test_write.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_basic.TestWriteBasic.test_write_basic","title":"","text":"Write basic 1. Write data to a nanosecond-precision database 2. Write data to regular tables and child tables 3. Write data to specified columns 4. Batch write multiple records to different child tables in a single operation 5. Write data covering all supported data types 6. Insert data into multiple tables and databases 7. Query with order by desc 8. Validate data integrity after write operations and system restarts                              path:                                            cases/06-DataIngestion/01-SQL/test_write_basic.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_blob.TestInsertBasic.test_insert_basic","title":"","text":"Write ns precision 1. create table 2. insert data 3. query data                      path:                                            cases/06-DataIngestion/01-SQL/test_write_blob.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_bugs.TestWriteBug.test_write_bug","title":"","text":"Write bugs 1. TD-27388 2. TD-29157 3. TD-29793 4. TS-4219 5. TS-4272 6. TS-4295 7. TS-4479                      path:                                            cases/06-DataIngestion/01-SQL/test_write_bugs.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_column_value.TestInsertColumnValue.test_write_column_value","title":"","text":"Write special columns 1. Write data with different data types  2. Write data to super table with special column 3. Write data to child table with special column 4. Write data to normal table with special column 5. JIRA TS-5184                      path:                                            cases/06-DataIngestion/01-SQL/test_write_column_value.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_commit.TestWriteCommit.test_write_commit","title":"","text":"Write commit scenarios 1. Data exists across multiple files 2. Data distributed across multiple blocks 3. Data coexists in both memory and files 4. Restart the dnode (force kill) 5. Verify data integrity through queries                      path:                                            cases/06-DataIngestion/01-SQL/test_write_commit.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_csv_with_quote.TestInsertBasic.test_insert_basic","title":"","text":"insert use ns precision 1. create table 2. insert data 3. query data                      path:                                            cases/06-DataIngestion/01-SQL/test_write_csv_with_quote.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_datatypes.TestWriteDatatypes.test_write_datatypes","title":"","text":"Write data types 1. Write data with NULL values 2. Write data using different floating-point representations 3. Write Chinese character data 4. Write data with different timestamp representations 5. Write data with backquote                      path:                                            cases/06-DataIngestion/01-SQL/test_write_datatypes.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_delete.TestWriteDelete.test_write_delete","title":"","text":"Write mixed delete 1. Insert data 2. Flush the database 3. Delete data by specific timestamp 4. Delete data by timestamp range 5. Delete data using timestamp condition comparisons 6. Restart the dnode 7. Check data integrity                      path:                                            cases/06-DataIngestion/01-SQL/test_write_delete.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_insert_select.TestWriteInsertSelect.test_write_insert_select","title":"","text":"Write from select clause 1. Insert into select from child table 2. Insert into select from normal table 3. Insert into select from super table                      path:                                            cases/06-DataIngestion/01-SQL/test_write_insert_select.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_morevgroup.TestInsertwithmorevgroup.test_write_morevgroup","title":"","text":"Write more vgroups 1. Write data with taosBenchmark with 5 threads 2. Write data with taosBenchmark with 8 threads                      path:                                            cases/06-DataIngestion/01-SQL/test_write_morevgroup.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_null_none.TestInsertNullNone.test_insert_null_none","title":"","text":"Write null none 1. Create a database and super table with various data types. 2. Insert data into the super table with null and none values for different columns. 3. Flush the database to ensure all data is written to disk. 4. Verify that the data has been inserted correctly by querying the super table.                      path:                                            cases/06-DataIngestion/01-SQL/test_write_null_none.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_out_of_order_data.TestWriteOutOfOrderData.test_write_out_of_order_data","title":"","text":"Write expired data 1. Write out-of-order and expired data, including:     Data distributed across multiple files     Data existing in multiple blocks     Data present in both memory and files 2. Restart the dnode 3. Query data integrity                      path:                                            cases/06-DataIngestion/01-SQL/test_write_out_of_order_data.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_stb.TestInsertStb.test_insert_stb","title":"","text":"Write super table 1. Create a super table containing multiple tag types 2. Insert super table with multiple data types 3. Insert super table with consecutive data 4. Insert super table data with stmt                      path:                                            cases/06-DataIngestion/01-SQL/test_write_stb.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_update.TestWriteUpdate.test_write_update","title":"","text":"Write update 1. Update data in memory 2. Update data in files 3. Write to update multiple records at once 4. Update data using NULL values 5. Restart the dnode 6. Check data integrity                      path:                                            cases/06-DataIngestion/01-SQL/test_write_update.py"},{"location":"case_list_docs/DataIngestion/SQL/#06-DataIngestion.01-SQL.test_write_update_multi_rows.TestUpdateDataMutiRows.test_update_data_muti_rows","title":"","text":"Write with multi-rows 1. Write data with multi rows 2. Update multi rows with 10000 times 3. Update normal table 4. Update child  table                      path:                                            cases/06-DataIngestion/01-SQL/test_write_update_multi_rows.py"},{"location":"case_list_docs/DataIngestion/STMT/","title":"02-STMT","text":""},{"location":"case_list_docs/DataIngestion/STMT/#06-DataIngestion.02-STMT.test_stmt_basic.TestStmtBasic.test_stmt_basic","title":"","text":"STMT basic 1. stmt insert multi rows order by asc/desc 2. stmt set tbname and tags, and query with different functions 3. verify result is ok 4. clean env                      path:                                            cases/06-DataIngestion/02-STMT/test_stmt_basic.py"},{"location":"case_list_docs/DataIngestion/STMT/#06-DataIngestion.02-STMT.test_write_stmt_error.TestStmtError.test_stmt_error","title":"","text":"STMT error 1. Write data with STMT 2. Query data with STMT 3. Write to virtual table with STMT expect error 4. Write to super table with null timestamp expect error 5. Write to super table with normal value expect error                      path:                                            cases/06-DataIngestion/02-STMT/test_write_stmt_error.py"},{"location":"case_list_docs/DataQuerying/BiMode/","title":"17-BiMode","text":""},{"location":"case_list_docs/DataQuerying/BiMode/#09-DataQuerying.17-BiMode.test_bimode.TestBiStarTable.test_bi_star_table","title":"","text":"Bi mode 1. In BI mode, querying a supertable with SELECT *, LAST(*), or FIRST(*) will return an additional tbname column 2. In BI mode, querying only tag columns (without data columns) returns a number of records equal to the number of subtables 3. In BI mode, backticks can be added to tbname                      path:                                            cases/09-DataQuerying/17-BiMode/test_bimode.py"},{"location":"case_list_docs/DataQuerying/CaseWhen/","title":"13-CaseWhen","text":""},{"location":"case_list_docs/DataQuerying/CaseWhen/#09-DataQuerying.13-CaseWhen.test_query_case_when.TestQueryCaseWhen.test_query_case_when","title":"","text":"Query case when basic 1. Using in data columns and scalar functions within SELECT statements 2. Using in data columns within WHERE conditions 3. Using in data columns within GROUP BY statements 4. Using in data columns within STATE WINDOW 5. Using in aggregate functions while including the IS NULL operator                      path:                                            cases/09-DataQuerying/13-CaseWhen/test_query_case_when.py"},{"location":"case_list_docs/DataQuerying/Distinct/","title":"10-Distinct","text":""},{"location":"case_list_docs/DataQuerying/Distinct/#09-DataQuerying.10-Distinct.test_query_distinct.TestDistinct.test_query_distinct","title":"","text":"Distinct basic 1. Distinct with super/child/normal table 2. Distinct with multi-columns 3. Distinct with tag columns 4. Distinct with where condition 5. Distinct with sub-query 6. Distinct error cases 7. Distinct with CSUM function 8. Distinct with alias 9. Distinct with limit and offset 10. Distinct with order by/group by/fill/slimit (negative cases) 11. Distinct with aggregation function (negative cases) 12. Distinct with in/between condition 13. Distinct with join (negative cases)                      path:                                            cases/09-DataQuerying/10-Distinct/test_query_distinct.py"},{"location":"case_list_docs/DataQuerying/Explain/","title":"15-Explain","text":""},{"location":"case_list_docs/DataQuerying/Explain/#09-DataQuerying.15-Explain.test_query_explain.TestExplain.test_explain_basic","title":"","text":"Explain command basic 1. Performing EXPLAIN on queries involving various functions, windows, subqueries, and sorting operations 2. Verify bug TD-20582 (explain order by sql error)                      path:                                            cases/09-DataQuerying/15-Explain/test_query_explain.py"},{"location":"case_list_docs/DataQuerying/Filter/","title":"02-Filter","text":""},{"location":"case_list_docs/DataQuerying/Filter/#09-DataQuerying.02-Filter.test_filter_column.TestFilterColumn.test_filter_column","title":"","text":"Filter columns 1. Filtering super tables and regular tables by regular data columns 2. Applying mathematical operators in combination                      path:                                            cases/09-DataQuerying/02-Filter/test_filter_column.py"},{"location":"case_list_docs/DataQuerying/Filter/#09-DataQuerying.02-Filter.test_filter_operator.TestFilterOperator.test_operator","title":"","text":"Filter with operators 1. Filtering with logical operators 2. Filtering with comparison operators 3. Combined with GROUP BY, ORDER BY, and LIMIT OFFSET clauses 4. Including IS NULL operations                      path:                                            cases/09-DataQuerying/02-Filter/test_filter_operator.py"},{"location":"case_list_docs/DataQuerying/Filter/#09-DataQuerying.02-Filter.test_filter_sma.TestFilterSma.test_filter_sma","title":"","text":"Filter sma 1. Create db with STT_TRIGGER option and set value to 1, will flush data to disk easily 2. Create supper table and sub table 3. Insert some data into sub table 4. Flush database, the action will trigger the data to be written to disk 5. Query the sub table with filter condition on flag column 6. Check the number of rows returned by the query                      path:                                            cases/09-DataQuerying/02-Filter/test_filter_sma.py"},{"location":"case_list_docs/DataQuerying/Filter/#09-DataQuerying.02-Filter.test_filter_tag.TestFilterTag.test_filter_tag","title":"","text":"Filter tags 1. Projection queries with arithmetic operations and tag column filtering conditions                      path:                                            cases/09-DataQuerying/02-Filter/test_filter_tag.py"},{"location":"case_list_docs/DataQuerying/Filter/#09-DataQuerying.02-Filter.test_filter_timestamp.TestFilterTimestamp.test_filter_timestamp","title":"","text":"Filter timestamp 1. Projection queries with arithmetic operations and timestamp filtering conditions 2. Applying mathematical operators in combination 3. Verify after server restart 4. Verify with different data types 5. Verify with addition, subtraction, multiplication, and division 6. Verify with complex expressions 7. Filter with timestamp range like ts &gt; start and ts &lt; end                      path:                                            cases/09-DataQuerying/02-Filter/test_filter_timestamp.py"},{"location":"case_list_docs/DataQuerying/GroupBy/","title":"03-GroupBy","text":""},{"location":"case_list_docs/DataQuerying/GroupBy/#09-DataQuerying.03-GroupBy.test_query_groupby_alwaysreturn.TestAggGroupAlwarysReturnValue.test_query_groupby_alwaysreturn","title":"","text":"Group by always return option 1. CountAlwaysReturnValue option is true (default) 2. Group by on super table with multiple subtables 3. Group by with various aggregate functions 4. Group by with various where/having/order by clauses 5. Group by with nested queries 6. Group by with join queries 7. Group by after altering stable structure 8. Group by on random data columns and tags 9. Group by on random aggregate functions 10. Group by on random where/having/order by clauses 11. Group by on random nested queries 12. Group by on random join queries                      path:                                            cases/09-DataQuerying/03-GroupBy/test_query_groupby_alwaysreturn.py"},{"location":"case_list_docs/DataQuerying/GroupBy/#09-DataQuerying.03-GroupBy.test_query_groupby_basic.TestGroupByBasic.test_query_groupby_basic","title":"","text":"Group by basic 1. Including multiple data types 2. Including data columns and tag columns 3. With ORDER BY clause 4. With Limit offset clause 5. With filtering conditions 6. With various functions 7. With different windows 8. With join clauses 9. With group by now/now+1/1                      path:                                            cases/09-DataQuerying/03-GroupBy/test_query_groupby_basic.py"},{"location":"case_list_docs/DataQuerying/GroupBy/#09-DataQuerying.03-GroupBy.test_query_groupby_bugs.TestTS_3821.test_query_groupby_bugs","title":"","text":"Group by bugs 1. Verify bug TS-3821 (tag value not show with group by query) 2. Verify bug TD-28163 (group by query bugs with null values) 3. Verify bug TS-4382 (group by query bugs with various data types)                      path:                                            cases/09-DataQuerying/03-GroupBy/test_query_groupby_bugs.py"},{"location":"case_list_docs/DataQuerying/GroupBy/#09-DataQuerying.03-GroupBy.test_query_groupby_noreturn.TestAggGroupNotReturnValue.test_query_groupby_alwaysreturn","title":"","text":"Group by always return close 1. CountAlwaysReturnValue option is false 2. Group by with various count(*) queries 3. Group by with various count(column) queries 4. Group by with order by  5. Group by with having 6. Group by with where clause 7. Group by with union/union all 8. Group by with null and not null values 9. Group by on multiple tables 10. Group by with nested queries 11. Validate results against expected output                      path:                                            cases/09-DataQuerying/03-GroupBy/test_query_groupby_noreturn.py"},{"location":"case_list_docs/DataQuerying/Having/","title":"09-Having","text":""},{"location":"case_list_docs/DataQuerying/Having/#09-DataQuerying.09-Having.test_query_having.TestHaving.test_query_having","title":"","text":"Having Keyword 1. Using HAVING with GROUP BY and aggregate functions (AVG, SUM, COUNT, STDDEV, APERCENTILE, SPREAD, LAST) 2. Performing TOP, BOTTOM, and LAST operations on results 3. Applying ORDER BY and LIMIT OFFSET to results 4. Performing calculations and comparisons in the HAVING clause 5. Using HAVING with JOIN operations 6. Using HAVING with different types of window functions (sliding, session, event, count, state)                      path:                                            cases/09-DataQuerying/09-Having/test_query_having.py"},{"location":"case_list_docs/DataQuerying/Having/#09-DataQuerying.09-Having.test_query_having_bugs.TestHavingBugs.test_ts4806","title":"","text":"Having bug TS-4806 test event_windows + case when + having query fix                      path:                                            cases/09-DataQuerying/09-Having/test_query_having_bugs.py"},{"location":"case_list_docs/DataQuerying/Having/#09-DataQuerying.09-Having.test_query_having_bugs.TestHavingBugs.test_td31880","title":"","text":"Having bug TD-31880 test last_row(ts) query fix                      path:                                            cases/09-DataQuerying/09-Having/test_query_having_bugs.py"},{"location":"case_list_docs/DataQuerying/Having/#09-DataQuerying.09-Having.test_query_having_bugs.TestHavingBugs.test_td31966","title":"","text":"Having bug TD-31966 test percentile() from window query fix                      path:                                            cases/09-DataQuerying/09-Having/test_query_having_bugs.py"},{"location":"case_list_docs/DataQuerying/Having/#09-DataQuerying.09-Having.test_query_having_bugs.TestHavingBugs.test_td32059","title":"","text":"Having bug TD-32059 test having with interval and fill                      path:                                            cases/09-DataQuerying/09-Having/test_query_having_bugs.py"},{"location":"case_list_docs/DataQuerying/Interp/","title":"12-Interp","text":""},{"location":"case_list_docs/DataQuerying/Interp/#09-DataQuerying.12-Interp.test_query_interp_bugs.TestTS_3404.test_query_inerp_bugs","title":"","text":"Interp bugs 1. Verify bug TS-3404 (timestamp precision cause wrong window function result)                      path:                                            cases/09-DataQuerying/12-Interp/test_query_interp_bugs.py"},{"location":"case_list_docs/DataQuerying/Interp/#09-DataQuerying.12-Interp.test_query_interp_fill.TestInterpFill.test_normal_query_new","title":"","text":"Interp fill and psedo column 1. Used with PARTITION BY 2. Used with _isfilled and _irowts in both the select list and as ORDER BY columns 3. Testing more comprehensive fill modes                      path:                                            cases/09-DataQuerying/12-Interp/test_query_interp_fill.py"},{"location":"case_list_docs/DataQuerying/Interp/#09-DataQuerying.12-Interp.test_query_interp_fill.TestInterpFill.test_abnormal_query","title":"","text":"Interp abnormal query 1. Testing abnormal query                      path:                                            cases/09-DataQuerying/12-Interp/test_query_interp_fill.py"},{"location":"case_list_docs/DataQuerying/Interp/#09-DataQuerying.12-Interp.test_query_interp_fill.TestInterpFill.test_interp_extension","title":"","text":"Interp fill extension 1. Query interp fill extension with large data volume 2. Query interp fill extension with near mode 3. Query interp fill extension with linear mode 4. Query interp fill extension with prev mode 5. Query interp fill extension with next mode 6. Query interp fill extension with value mode 7. Query interp fill extension with null mode 8. Multi-threaded query interp fill extension                      path:                                            cases/09-DataQuerying/12-Interp/test_query_interp_fill.py"},{"location":"case_list_docs/DataQuerying/Limit/","title":"06-Limit","text":""},{"location":"case_list_docs/DataQuerying/Limit/#09-DataQuerying.06-Limit.test_query_limit_basic.TestLimit.test_query_limit_basic","title":"","text":"Limit basic 1. Including multiple data types 2. With ORDER BY clause 3. With GROUP BY clause 4. With PARTITION BY clause 5. With filtering conditions 6. With various functions 7. With different windows 8. Jira TS-6136                      path:                                            cases/09-DataQuerying/06-Limit/test_query_limit_basic.py"},{"location":"case_list_docs/DataQuerying/Limit/#09-DataQuerying.06-Limit.test_query_limit_offset.TestLimit.test_query_limit_offset","title":"","text":"Limit with offset 1. Limit offset with nested query 2. Limit offset with different vgroups 3. Limit offset with interval and fill 4. Limit offset with group by 5. Limit offset with partition by 6. Limit offset with different database vgroups 7. JIRA TS-6080                       path:                                            cases/09-DataQuerying/06-Limit/test_query_limit_offset.py"},{"location":"case_list_docs/DataQuerying/OrderBy/","title":"04-OrderBy","text":""},{"location":"case_list_docs/DataQuerying/OrderBy/#09-DataQuerying.04-OrderBy.test_orderby_basic.TestOrderByBasic.test_orderby_basic","title":"","text":"Order by basic 1. Order by asc/desc 2. Order by expr abs() 3. Order by with limit 4. Order by multiple columns 5. Order by in sub query 6. Order by _wstart with interval 7. Order by with agg functions:     - count     - max     - min     - first     - last     - sum 8. Order by with ambiguous names 9. Order by same column from different tables 10. Order by priority when column exists in both select list and table 11. Order by on joined tables 12. Memleak for order by 13. Bug TS-4467: join query with order by desc causes crash 14. Projection query with order by desc 15. Order by on select list columns 16. Order by with agg functions and alias 17. Order by with constant 'aaa'                      path:                                            cases/09-DataQuerying/04-OrderBy/test_orderby_basic.py"},{"location":"case_list_docs/DataQuerying/OrderBy/#09-DataQuerying.04-OrderBy.test_orderby_double.TestOrderByDouble.test_orderby_double","title":"","text":"Order by double 1. Create a database and table 2. Insert double values into the table 3. Query the table with order by double values; without the fix for TS-6772, it should be failed 4. Verify the order of the returned results                      path:                                            cases/09-DataQuerying/04-OrderBy/test_orderby_double.py"},{"location":"case_list_docs/DataQuerying/OrderBy/#09-DataQuerying.04-OrderBy.test_orderby_subquery.TestOrderByBasic.test_orderby_basic","title":"","text":"Order by subquery results 1. Sort the results of subqueries 2. Sort time data after applying the to_charfunction 3. Sort with multiple order by clauses 4. Sort before and after subqueries 5. Verify ascending and descending order combinations 6. Verify with limit and offset                      path:                                            cases/09-DataQuerying/04-OrderBy/test_orderby_subquery.py"},{"location":"case_list_docs/DataQuerying/PseudoColumn/","title":"11-PseudoColumn","text":""},{"location":"case_list_docs/DataQuerying/PseudoColumn/#09-DataQuerying.11-PseudoColumn.test_query_pseudo_basic.TestQueryPseudoColumn.test_query_pseudo_column","title":"","text":"Pseudo column basic 1. Create 1 database 1 stable 2 child tables 2. Insert 1 rows for each child table 3. select tbname from stable and check the result 4. order by tbname and check the result 5. select tbname with backquote and check the result 6. select tbname with table prefix and check the result 7. select _wstart, _wend, _wduration with interval clause and check the result 8. select _wstart, _wend, _wduration without interval clause and expect error 9. select _irowts with range clause and check the result 10. select _irowts without range clause and expect error 11. select _wstart, _wend, _wduration with nested query and check the result                      path:                                            cases/09-DataQuerying/11-PseudoColumn/test_query_pseudo_basic.py"},{"location":"case_list_docs/DataQuerying/PseudoColumn/#09-DataQuerying.11-PseudoColumn.test_query_pseudo_tbname.TestTbname.test_query_pseudo_tbname","title":"","text":"Pseudo column tbname 1. Create 1 database 1 stable 2000 child tables 2. Insert 10 rows for each child table 3. Select tbname from stable with tbname in (...)  4. Select tbname from child table with tbname in (...)  5. Select tbname from stable with tbname in (...) and other tag filtering  6. Select tbname from stable with tbname in (...) and group by tag  7. Select tbname from stable with duplicated tbnames in (...)  8. Select tbname from stable with wrong tbnames in (...)  9. Select tbname from stable with tbname in (...) and column filtering  10. Select tbname from stable with tbname in (...) with Upper case table name 11. Restart dnode and check tbname in query again 12. Query tbname in where clause 13. Query tbname in join condition 14. Query tbname with special characters: ` (backquote) 15. Query tbname with special characters in virtual table 16. Query tbname in virtual table 17. Show create table tbname with special characters: ` (backquote) 18. Show create table tbname in virtual table 19. Drop and recreate tables with special characters: ` (backquote) 20. Drop and recreate virtual table with special characters: ` (backquote) 21. Join query with tbname in virtual table 22. Tbname in clause with special characters in virtual table                      path:                                            cases/09-DataQuerying/11-PseudoColumn/test_query_pseudo_tbname.py"},{"location":"case_list_docs/DataQuerying/SLimit/","title":"07-SLimit","text":""},{"location":"case_list_docs/DataQuerying/SLimit/#09-DataQuerying.07-SLimit.test_slimit.TestSLimit.test_slimit","title":"","text":"SLimit 1. SLIMIT with PARTITION BY 2. SLIMIT with GROUP BY 3. SLIMIT with PARTITION BY + INTERVAL 4. Combined use of SLIMIT and SOFFSET 5. Verify SLIMIT results after modifying tags                      path:                                            cases/09-DataQuerying/07-SLimit/test_slimit.py"},{"location":"case_list_docs/DataQuerying/SLimit/#09-DataQuerying.07-SLimit.test_slimit_basic.TestSlimit.test_slimit","title":"","text":"Slimt basic 1. Create two databases with random number of vgroups, tables and data per table. 2. Run a series of SQL queries involving LIMIT and SLIMIT clauses on the created 3. databases to validate their behavior and correctness. 4. Query with slimit and limit together. 5. Validate results against expected outcomes.                      path:                                            cases/09-DataQuerying/07-SLimit/test_slimit_basic.py"},{"location":"case_list_docs/DataQuerying/Select/","title":"01-Select","text":""},{"location":"case_list_docs/DataQuerying/Select/#09-DataQuerying.01-Select.test_query_select_basic.TestSelectListBasic.test_selectlist","title":"","text":"Select basic 1. Projection queries 2. Aggregation queries 3. Scalar functions 4. Combining GROUP BY, ORDER BY, Limit, and WHERE clauses                      path:                                            cases/09-DataQuerying/01-Select/test_query_select_basic.py"},{"location":"case_list_docs/DataQuerying/Select/#09-DataQuerying.01-Select.test_query_select_bugs.TestQueryBugs.test_query_bugs","title":"","text":"Select bugs 1. Verify jira TS-5946 2. Verify jira TD-30686 3. Verify jira TS-5105 4. Verify jira TS-5143 5. Verify jira TS-5239 6. Verify jira TD-31684 7. Verify jira TS-5984 8. Verify jira TS-6058 9. Verify jira TS-5761 10. Verify jira TS-7058 11. Verify jira TS-5761 scalemode 12. Verify jira TS-5712 13. Verify jira TS-4348 14. Verify jira TS-4233 15. Verify jira TS-3405 16. Verify jira TD-32548 17. Verify jira TD-28068                      path:                                            cases/09-DataQuerying/01-Select/test_query_select_bugs.py"},{"location":"case_list_docs/DataQuerying/Select/#09-DataQuerying.01-Select.test_query_select_exact.TestQueryBasic.test_query_basic","title":"","text":"Select exact test 1. Insert data with taosBenchmark 1 stable 6 child tables 2. Insert each child table 10w rows with step 30s, total 60w rows 3. Insert each child with 5w rows disorder with step 60s  4. Flush database 5. Check correctness: csum/tail/top/bottom/statecount/stateduration/histogram/first/last/sample/spread/percent 6. Check correctness: count/sum/min/max/avg/stddev/leastsquares/derivative/irate/diff/twa/mavg/ 7. Window query with various condition combinations 8. Check function behavior with null input: abs/unique/concat_ws/timetruncate/timediff/to_timestamp 9. Check substr from 0 start 10. Check cast behavior 11. Check iso8601 behavior 12. Check null behavior                      path:                                            cases/09-DataQuerying/01-Select/test_query_select_exact.py"},{"location":"case_list_docs/DataQuerying/Select/#09-DataQuerying.01-Select.test_query_select_funtion_null.TestFunctionNull.test_function_null","title":"","text":"Select function null 1. Create table with various data types and insert data including nulls. 2. Execute various functions with parameter null or columns value null.      - abs      - floor      - ceil      - round       - sin      - cos      - tan      - asin      - acos      - atan      - log      - pow 3. Verify result as expected.                      path:                                            cases/09-DataQuerying/01-Select/test_query_select_funtion_null.py"},{"location":"case_list_docs/DataQuerying/Select/#09-DataQuerying.01-Select.test_query_select_null.TestSelectNull.test_select_null","title":"","text":"Select null 1. Create a super table with various data types including int, double, varchar, and timestamp. 2. Create multiple sub-tables using the super table with different tag values. 3. Insert data into the sub-tables, leaving some fields as null. 4. Execute various SELECT queries to test the handling of null values, including:    - COUNT on columns with null values.    - MAX and MIN functions on columns with null values.    - Queries with LIMIT and OFFSET. 5. Validate the results of each query to ensure correct handling of null values. 6. Query using Chinese characters in column and table names to verify UTF-8 support. 7. Clean up by dropping the created database and tables.                      path:                                            cases/09-DataQuerying/01-Select/test_query_select_null.py"},{"location":"case_list_docs/DataQuerying/SubQuery/","title":"08-SubQuery","text":""},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_nestedQuery.TestNestedquery.test_nestedQuery","title":"","text":"Subquery func total  1. Create database and many super/child tables  2. Insert data with random rows 3. Generate select clause list 4. Generate where clause list 5. Generate order by clause list 6. Generate limit clause list 7. Selected different sql clauses to form nested query 8. Replace function with different math function    - UNIQUE/MODE/SAMPLE    - CSUM/STATECOUNT/STATEDURATION/HISTOGRAM    - TIMEDIFF_1/TIMEDIFF_2 9. Execute sql and check results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_nestedQuery.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_nestedQuery_26.TestNestedQuery26Case.test_nestedQuery_26","title":"","text":"Subquery 2.6 compatible 1. Create database and many super/child tables  2. Insert data with random rows 3. Generate select clause list 4. Generate where clause list 5. Generate order by clause list 6. Generate limit clause list 7. Selected different sql clauses to form nested query with 2.6 syntax 9. Execute sql and check results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_nestedQuery_26.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_nestedQuery_math.TestNestedQueryMathCase.test_nestedQuery_math","title":"","text":"Subquery func math  1. Create database and many super/child tables  2. Insert data with random rows 3. Generate select clause list 4. Generate where clause list 5. Generate order by clause list 6. Generate limit clause list 7. Selected different sql clauses to form nested query 8. Replace math function:    - ABS/SQRT    - SIN/COS/TAN/ASIN/ACOS/ATAN    - POW/LOG    - FLOOR/CEIL/ROUND    - MAVG    - HYPERLOGLOG    - TAIL 9. Execute sql and check results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_nestedQuery_math.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_nestedQuery_str.TestNestedQueryStrCase.test_nestedQuery_str","title":"","text":"Subquery func string  1. Create database and many super/child tables  2. Insert data with random rows 3. Generate select clause list 4. Generate where clause list 5. Generate order by clause list 6. Generate limit clause list 7. Selected different sql clauses to form nested query 8. Replace stringfunction:    - LTRIM/RTRIM/LOWER/UPPER    - LENGTH/CHAR_LENGTH    - SUBSTR    - CONCAT    - CONCAT_WS 9. Execute sql and check results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_nestedQuery_str.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_nestedQuery_time.TestNestedQueryCase.test_nestedQuery_time","title":"","text":"Subquery func time  1. Create database and many super/child tables  2. Insert data with random rows 3. Generate select clause list 4. Generate where clause list 5. Generate order by clause list 6. Generate limit clause list 7. Selected different sql clauses to form nested query 8. Replace time function:    - NOW/TODAY/TIMEZONE/TIMETRUNCATE/    - TO_ISO8601/TO_UNIXTIMESTAMP/ELAPSED 9. Execute sql and check results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_nestedQuery_time.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_query_sub.TestQuerySub.test_query_sub","title":"","text":"Subquery basic 1. Perform projection queries on subquery results 2. Perform aggregate queries on subquery results 3. Perform window queries on subquery results 4. Perform DIFF function queries on subquery results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_query_sub.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_query_sub_bugs.TestSubqueryBugs.test_query_sub_bugs","title":"","text":"Subquery bugs 1. Verify bug TS-30189 2. Verify bug TS-5443 3. Verify bug TS-5878                      path:                                            cases/09-DataQuerying/08-SubQuery/test_query_sub_bugs.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_query_sub_bugs.TestSubqueryBugs.test_subquery_lastrow","title":"","text":"Subquery with lastrow 1. Create db 2. Create supper table and sub table 3. Insert data into sub table 4. Query last row from sub table as a sub query, it should return the last row data                      path:                                            cases/09-DataQuerying/08-SubQuery/test_query_sub_bugs.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_query_sub_interval.TestNestedqueryinterval.test_nestedQueryInterval","title":"","text":"Subquery interval 1. Create database and tables 2. Insert data 3. Flush database 4. Test subquery with interval clause and time series functions: twa, irate 5. Test to_char and to_timestamp functions 6. Test TS-3932                      path:                                            cases/09-DataQuerying/08-SubQuery/test_query_sub_interval.py"},{"location":"case_list_docs/DataQuerying/SubQuery/#09-DataQuerying.08-SubQuery.test_query_sub_interval.TestNestedqueryinterval.test_nestedQuery2","title":"","text":"Subquery alias name 1. Create dabase with vgroups 4 2. Create stable with various data types 3. Create 10 child tables under the stable 4. Insert data into the child tables, some columns contain null values 5. Select asterisk from subquery with duplicate alias name 6. Verify the query results                      path:                                            cases/09-DataQuerying/08-SubQuery/test_query_sub_interval.py"},{"location":"case_list_docs/DataQuerying/Tags/","title":"14-Tags","text":""},{"location":"case_list_docs/DataQuerying/Tags/#09-DataQuerying.14-Tags.test_tag_basic.TestTagBasic.test_tag_basic","title":"","text":"Tag query 1. Projection queries combining data columns and the tbname pseudocolumn 2. Projection queries with the DISTINCT keyword 3. Queries combining tags and selection functions like LAST\u3001FITST\u3001MAX\u3001MIN 4. Grouping, sorting, and filtering by tags                      path:                                            cases/09-DataQuerying/14-Tags/test_tag_basic.py"},{"location":"case_list_docs/DataQuerying/Tags/#09-DataQuerying.14-Tags.test_tag_json.TestSelectWithJsonTags.test_select_with_json_tags","title":"","text":"Operator json 1. Create db 2. Create supper table with json data-type tag 3. Create child table with json tag values 4. Query with json operators 5. Check the result value correctly                      path:                                            cases/09-DataQuerying/14-Tags/test_tag_json.py"},{"location":"case_list_docs/DataQuerying/Tags/#09-DataQuerying.14-Tags.test_tag_json.TestSelectWithJsonTags.test_select_with_json_tags","title":"","text":"Operator json 1. Create db 2. Create supper table with json data-type tag 3. Create child table with json tag values 4. Query with json operators 5. Check the result value correctly                      path:                                            cases/09-DataQuerying/14-Tags/test_tag_json.py"},{"location":"case_list_docs/DataSubscription/Consume/","title":"02-Consume","text":""},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db.TestCase.test_subscribeDB","title":"","text":"Subscribe database basic 1. Create database with tables 2. Create topics from database 3. Test database-level subscription 4. Verify all tables data consumption 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db0.TestCase.test_subscribeDb0","title":"","text":"Subscribe database0 1. Create database with multiple tables 2. Create database-level topics 3. Test consumption with replica settings 4. Verify data consistency across replicas 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db0.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db1.TestCase.test_subscribeDb1","title":"","text":"Subscribe database1 1. Create database with normal and super tables 2. Test database subscription with mixed table types 3. Verify consumption of all table types 4. Test data integrity 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db2.TestCase.test_subscribeDb2","title":"","text":"Subscribe database2 1. Create database with vgroups configuration 2. Test consumption across multiple vgroups 3. Verify data distribution and consumption 4. Test concurrent consumption 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db2.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db3.TestCase.test_subscribeDb3","title":"","text":"Subscribe database3 1. Create database with complex schema 2. Test subscription with schema changes 3. Verify consumption after DDL operations 4. Test data consistency 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db3.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_db4.TestCase.test_subscribeDb4","title":"","text":"Subscribe database4 1. Create database with specific configurations 2. Test advanced consumption scenarios 3. Verify performance and reliability 4. Test error handling 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_db4.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb.TestCase.test_subscribeStb","title":"","text":"Subscribe stable basic 1. Create database and stable 2. Create topics from stable 3. Test basic consumption functionality 4. Verify consumed data correctness 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb0.TestCase.test_subscribeStb0","title":"","text":"Subscribe stable0 1. Create database and stable 2. Create multiple topics from stable 3. Insert consume info to consume processor 4. Start consume processor 5. Check consume result 6. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb0.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb1.TestCase.test_subscribeStb1","title":"","text":"Subscribe stable1 1. Create database and stable 2. Create topics from stable with manual commit 3. Test auto commit functionality 4. Insert consume info to consume processor 5. Start consume processor 6. Check consume result 7. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb2.TestCase.test_subscribeStb2","title":"","text":"Subscribe stable2 1. Create database and stable 2. Create topics with manual commit disabled 3. Test multiple consumers with different commit modes 4. Insert data during consumption 5. Verify data consistency across consumers 6. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb2.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb3.TestCase.test_subscribeStb3","title":"","text":"Subscribe stable3 1. Create database and stable 2. Test multiple complex consumption scenarios 3. Test concurrent consumption with multiple threads 4. Verify offset management and commit behavior 5. Insert data during multiple consumer operations 6. Check data consistency and completeness 7. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb3.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_subscribe_stb4.TestCase.test_subscribeStb4","title":"","text":"Subscribe stable4 1. Create database and stable 2. Test complex consumption scenarios 3. Verify data consumption with filters 4. Test multiple topic subscriptions 5. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_subscribe_stb4.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_alter_schema.TestCase.test_tmq_alterschema","title":"","text":"Advanced: alter schema 1. Create topic and subscribe 2. Start consumption 3. Execute ALTER TABLE ADD COLUMN 4. Execute ALTER TABLE DROP COLUMN 5. Execute ALTER TABLE MODIFY COLUMN 6. Verify consumption continues 7. Check schema compatibility                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_alter_schema.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_auto_create_table.TestCase.test_tmq_autoCreate_tbl","title":"","text":"Advanced: auto create table 1. Configure auto-create-table parameter 2. Subscribe with auto-create enabled 3. Consume data with new table definitions 4. Verify tables auto-created 5. Check table schema correct 6. Validate data inserted                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_auto_create_table.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_basic.TestBasic5.test_tmq_basic","title":"","text":"Consumer basic 1. Create stable and child tables, insert data 2. Create topic from stable and child table 3. Create consume info table and consume result table 4. Start consume processor 5. Check consume result 6. Negative test: create topic with wrong sql 7. Clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_basic.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_bugs.TestTmqBugs.test_tmq_bugs","title":"","text":"Consumer bugs 1. Jira TD-31283:  - Tmq consumer fails to consume data from topic created on stable with tags after altering stable to add columns. 2. Jira TD-30270:  - Test tmq consumer subscribe/unsubscribe operations can be called multiple times. 3. Jira TD-32187:  - Test tmq consumption with meta topic on database containing stable with special tag names. 4. Jira TD-33225:  - Test tmq consumption after altering stable column compression and creating index. 5. Jira TD-32471:  - Test tmq consumption after altering stable to add new columns. 6. Jira TD-32526:  - Test tmq consumption with native C client after altering stable to add columns. 7. Jira TD-33504:  - Test tmq consumer can switch topics after unsubscribe. 8. Jira TD-35698:  - Test tmq consumption with meta topic containing decimal columns. 9. Jira TD-37436:  - Test tmq consumption with meta topic on database containing stream. 10. Jira TD-38404:  - Tmq_get_json_meta behaves unexpectedly when the tags of subscribed meta messages contain empty strings. 11. Jira TS-4563:  - Test tmq consumption of unordered data inserted by stmt. 12. Jira TS-5466:  - Test tmq consumption with meta topic after altering stable to add many columns. 13. Jira TS-5906:  - Test tmq consumption after altering child table tags and inserting new data. 14. Jira TS-6115:  - Test tmq consumption with large amount of data inserted by taosBenchmark. 15. Jira TS-6392:  - Test tmq consumer group rebalance and recovery after dnode restart with WAL retention. 16. Jira TS-7402:  - Test tmq consumption with meta topic created on stable with filter conditions. 17. Jira TS-7662:  - Test tmq consumption with meta topic created on stable with where clause. 19. Jira TS-4674:  - Test tmq consumption behavior during vgroup leader rebalance in multi-replica environment.                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_bugs.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_check_data.TestCase.test_tmq_check_data","title":"","text":"Consume: data verification 1. Insert known test data patterns 2. Create TMQ subscription 3. Consume and record all data 4. Compare consumed data with source 5. Verify data integrity (no loss, no duplicate)                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_check_data.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_check_data_db.TestCase.test_check_data1","title":"","text":"Consume: database verification 1. Create database with multiple tables 2. Insert test data to all tables 3. Subscribe database topic 4. Consume all data 5. Verify each table's data integrity                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_check_data_db.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons1_v1_snapshot.TestTmpSnapshot1.test_tmq_snapshot1","title":"","text":"Consumer one: from snapshot test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1.sim: vgroups=1, one topic for one consumer 2. basic2.sim: vgroups=1, multi topics for one consumer 3. basic3.sim: vgroups=4, one topic for one consumer 4. basic4.sim: vgroups=4, multi topics for one consumer 5. snapshot1.sim: vgroups=1, multi topics for one consumer, consume from snapshot                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons1_v1_snapshot.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons1_v1_t1.TestTmpBasic1.test_tmq_basic1","title":"","text":"Consumer one: vgroups=1 topics=1 test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1.sim: vgroups=1, one topic for one consumer 2. basic2.sim: vgroups=1, multi topics for one consumer 3. basic3.sim: vgroups=4, one topic for one consumer 4. basic4.sim: vgroups=4, multi topics for one consumer 5. snapshot1.sim: vgroups=1, multi topics for one consumer, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons1_v1_t1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons1_v1_tn.TestTmpBasic2.test_tmq_basic2","title":"","text":"Consumer one: vgroups=1 topics=n test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1.sim: vgroups=1, one topic for one consumer 2. basic2.sim: vgroups=1, multi topics for one consumer 3. basic3.sim: vgroups=4, one topic for one consumer 4. basic4.sim: vgroups=4, multi topics for one consumer 5. snapshot1.sim: vgroups=1, multi topics for one consumer, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons1_v1_tn.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons1_v4_t1.TestTmpBasic3.test_tmq_basic3","title":"","text":"Consumer one: vgroups=4 topics=1 test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1.sim: vgroups=1, one topic for one consumer 2. basic2.sim: vgroups=1, multi topics for one consumer 3. basic3.sim: vgroups=4, one topic for one consumer 4. basic4.sim: vgroups=4, multi topics for one consumer 5. snapshot1.sim: vgroups=1, multi topics for one consumer, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons1_v4_t1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons1_v4_tn.TestTmpBasic4.test_tmq_basic4","title":"","text":"Consumer one: vgroups=4 topics=n test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1.sim: vgroups=1, one topic for one consumer 2. basic2.sim: vgroups=1, multi topics for one consumer 3. basic3.sim: vgroups=4, one topic for one consumer 4. basic4.sim: vgroups=4, multi topics for one consumer 5. snapshot1.sim: vgroups=1, multi topics for one consumer, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons1_v4_tn.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v1_overlap.TestTmpConsOverlap.test_tmq_cons_overlap","title":"","text":"Consumer two: from snapshot test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v1_overlap.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v1_snapshot.TestTmpSnapshot2.test_tmq_snapshot2","title":"","text":"Consumer two: from snapshot test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v1_snapshot.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v1_t1.TestTmpCons1.test_tmq_Cons1","title":"","text":"Consumer two: vgroups=1 topics=1 test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v1_t1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v1_tn.TestTmpCons2.test_tmq_Cons2","title":"","text":"Consumer two: vgroups=1 topics=n test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v1_tn.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v4_t1.TestTmpCons3.test_tmq_Cons3","title":"","text":"Consumer two: vgroups=4 topics=1 test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v4_t1.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_cons2_v4_tn.TestTmpCons4.test_tmq_Cons4","title":"","text":"Consumer two: vgroups=4 topics=n test scenario, please refer to https://jira.taosdata.com:18090/pages/viewpage.action?pageId=135120406, firstly insert data, then start consume 1. basic1Of2Cons.sim: vgroups=1, one topic for 2 consumers 2. basic2Of2Cons.sim: vgroups=1, multi topics for 2 consumers 3. basic3Of2Cons.sim: vgroups=4, one topic for 2 consumers 4. basic4Of2Cons.sim: vgroups=4, multi topics for 2 consumers 5. basic2Of2ConsOverlap.sim: vgroups=1, multi topics for 2 consumers, the topics consumed by consumers overlap with each other 6. snapshot.sim: vgroups=1, multi topics for 2 consumers, consume from snapshot notes1: Scalar function: ABS/ACOS/ASIN/ATAN/CEIL/COS/FLOOR/LOG/POW/ROUND/SIN/SQRT/TAN The above use cases are combined with where filter conditions, such as: where ts &gt; \"2017-08-12 18:25:58.128Z\" and sin(a) &gt; 0.5; notes2: not support aggregate functions(such as sum/count/min/max) and time-windows(interval).                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_cons2_v4_tn.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_consumer_group.TestCase.test_tmq_cons_group","title":"","text":"Consume: group 1. Create consumer group 2. Add multiple consumers to group 3. Start consumption with load balancing 4. Verify partition assignment 5. Test consumer rebalance on add/remove                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_consumer_group.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_data_precision.TestCase.test_tmq_data_precision_unit","title":"","text":"Advanced: data precision 1. Test millisecond precision 2. Test microsecond precision 3. Test nanosecond precision 4. Verify timestamp conversion 5. Check precision preservation                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_data_precision.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_db_topic.TestCase.test_db","title":"","text":"Basic: database topic 1. Create database with multiple tables 2. Create database-level topic 3. Subscribe entire database 4. Insert data to various tables 5. Verify all tables data consumed                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_db_topic.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_delete_multi_ctb.TestCase.test_tmq_delete_multictb","title":"","text":"Operation: delete multi ctb 1. Create multiple child tables 2. Insert data to all tables 3. Subscribe super table topic 4. DELETE rows from multiple tables 5. Consume all delete messages 6. Verify deletions from all tables                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_delete_multi_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_delete_single_ctb.TestCase.test_tmq_delete_1ctb","title":"","text":"Operation: delete single ctb 1. Create child table with data 2. Create topic subscription 3. Execute DELETE operations 4. Consume delete messages 5. Verify deletion propagated correctly                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_delete_single_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_discontinuous_data.TestCase.test_tmq_cons_discontinuous_data","title":"","text":"Consume: discontinuous data 1. Insert data with discontinuous timestamps 2. Create topic subscription 3. Consume data in order 4. Verify all records received with correct timestamps                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_discontinuous_data.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_dnode_restart.TestCase.test_tmq_dnode_restart","title":"","text":"Cluster: dnode restart 1. Start consumption process 2. Restart dnode during consumption 3. Wait for dnode recovery 4. Resume consumption automatically 5. Verify no data loss 6. Check offset preserved                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_dnode_restart.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_dnode_restart2.TestCase.test_tmq_dnode_restart1","title":"","text":"Cluster: dnode restart variant 1. Setup multi-dnode cluster 2. Start TMQ consumption 3. Restart multiple dnodes sequentially 4. Verify automatic failover 5. Check data continuity 6. Validate recovery behavior                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_dnode_restart2.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_drop_consumer.TestCase.test_tmq_drop_consumer","title":"","text":"Operation: drop consumer 1. Create consumer and subscribe 2. Start consumption 3. Drop consumer connection 4. Verify consumer removed from group 5. Check offset committed 6. Verify cleanup                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_drop_consumer.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_drop_db_replica3.TestCase.test_dropdb","title":"","text":"Cluster: drop db replica3 1. Setup 3-replica cluster 2. Create database with replication 3. Start TMQ consumption 4. Drop database during consumption 5. Verify transaction conflict handling 6. Check graceful error reporting                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_drop_db_replica3.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_drop_ntb_snapshot.TestCase.test_tmq_drop_ntb_snapshot1","title":"","text":"Operation: drop table snapshot 1. Create normal table with data 2. Start snapshot mode consumption 3. Drop table after some consumption 4. Verify snapshot behavior with dropped table 5. Check graceful handling                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_drop_ntb_snapshot.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_drop_ntb_wal.TestCase.test_tmq_drop_ntb_snapshot0","title":"","text":"Operation: drop table wal 1. Create normal table with data 2. Start WAL mode consumption 3. Drop normal table during consumption 4. Verify drop event handling 5. Check consumer handles table removal                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_drop_ntb_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_drop_stb_ctb.TestCase.test_tmq_drop_stb_ctb","title":"","text":"Operation: drop super table 1. Create super table with child tables 2. Start consumption 3. Drop child tables one by one 4. Drop super table 5. Verify all drop events handled 6. Check subscription cleanup                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_drop_stb_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_error.TestCase.test_tmq_error","title":"","text":"Basic: error handling 1. Test invalid topic name 2. Test invalid consumer group.id 3. Test subscribe non-existent topic 4. Test invalid consumer parameters 5. Verify appropriate error messages                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_error.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_max_groups.TestCase.test_tmq_max_groupids","title":"","text":"Basic: max groups limit 1. Create database and topic 2. Create 100 consumer groups (maximum allowed) 3. Verify all groups work correctly 4. Try creating 101st group and verify limit                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_max_groups.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_max_topics.TestCase.test_tmq_max_topic","title":"","text":"Basic: max topics limit 1. Create database with super table 2. Create 20 topics (maximum allowed) 3. Verify topic creation success 4. Try creating 21st topic and verify error 5. Drop all topics and cleanup                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_max_topics.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_meta_json.TestCase.test_tmq_get_meta_json","title":"","text":"Advanced: metadata json 1. Create topics with metadata 2. Query metadata via JSON interface 3. Verify JSON format correctness 4. Check all metadata fields present 5. Validate JSON schema                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_meta_json.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_mnode_switch.TestCase.test_tmq3mnodesSwitch","title":"","text":"Cluster: mnode switch 1. Setup 3-mnode cluster 2. Start consumption 3. Trigger mnode leader switch 4. Continue consumption 5. Verify seamless transition 6. Check no interruption                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_mnode_switch.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_offset.TestCase.test_tmq_offset","title":"","text":"Basic: offset operations 1. Create topic and start consumption 2. Test seek operation to specific offset 3. Query current position 4. Commit offset manually 5. Restart consumer and verify offset restored 6. Call tmq_offset_test to test                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_offset.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_params.TestCase.test_tmq_params_test","title":"","text":"Basic: consumer parameters 1. Test auto.commit enabled/disabled 2. Test auto.offset.reset earliest/latest 3. Test group.id configuration 4. Verify consumer behavior with different parameters                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_params.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_primary_key.TestCase.test_tmq_primary_key","title":"","text":"Basic: primary key support 1. Create tables with primary key 2. Insert duplicate key data 3. Create TMQ subscription on primary key table 4. Consume and verify primary key constraints 5. Test UPDATE on primary key records                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_primary_key.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_raw_block_interface.TestCase.test_raw_block","title":"","text":"Advanced: raw block interface 1. Use raw block API for consumption 2. Fetch data in block format 3. Parse block structure 4. Verify block metadata 5. Check performance benefit 6. Validate block data                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_raw_block_interface.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_replay.TestCase.test_tmq_replay","title":"","text":"Advanced: replay operations 1. Run replay_test executable to test TMQ replay functionality 2. Verify no errors occur during execution 3. Confirm successful completion of the test                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_replay.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_restart.TestCase.test_tmq_tx484","title":"","text":"Tmq consume restart 1. create stable and topic 2. insert data 3. consume part of data and commit 4. restart taosd 5. continue consume data and check 6. kill taosd process 7. restart taosd 8. continue consume data and check 9. clean up environment                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_restart.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_schema.TestCase.test_schema","title":"","text":"Advanced: schema changes 1. Create tables and start consumption 2. Add column during consumption 3. Drop column during consumption 4. Modify column type 5. Verify schema evolution handled 6. Check backward compatibility                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_schema.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_seek_commit.TestCase.test_tmq_seek_and_commit","title":"","text":"Advanced: seek commit 1. Start consumption 2. Execute seek to offset 3. Consume from new position 4. Perform manual commit 5. Verify offset updated 6. Test commit persistence                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_seek_commit.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_basic.TestCase.test_tmq_cons_from_tsdb","title":"","text":"Consume: snapshot basic 1. Insert historical data to TSDB 2. Flush data to disk 3. Create topic with snapshot mode 4. Consume from TSDB snapshot 5. Verify complete historical data retrieved                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_basic.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_filter.TestCase.test_tmq_cons_from_tsdb1","title":"","text":"Consume: snapshot filter 1. Insert data to TSDB 2. Create filtered topic (SELECT with WHERE) 3. Enable snapshot consumption 4. Consume filtered historical data 5. Verify only matching records retrieved                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_func_filter.TestCase.test_tmq_cons_from_tsdb_1ctb_filter","title":"","text":"Consume: function filter 1. Insert data to child table 2. Create topic with UDF function 3. Add WHERE filter condition 4. Consume from snapshot with computation 5. Verify UDF results and filtering                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_func_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_func_filter2.TestCase.test_tmq_cons_from_tsdb1_1ctb_filter","title":"","text":"Consume: function filter variant 1. Setup child table with data 2. Apply complex UDF and filters 3. Enable snapshot mode 4. Consume computed results 5. Validate function output                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_func_filter2.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_func_filter_complex.TestCase.test_tmq_cons_from_tsdb_multiVg_multiCtb_filter","title":"","text":"Consume: complex function filter 1. Setup multi-vgroup multi-table structure 2. Apply UDF with complex filters 3. Create snapshot topic 4. Consume computed data from all vgroups 5. Verify UDF and filter correctness                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_func_filter_complex.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_func_filter_complex2.TestCase.test_tmq_cons_from_tsdb1_multiVg_multiCtb_fiter","title":"","text":"Consume: complex filter variant 1. Create complex table structure 2. Apply multiple UDFs 3. Add WHERE conditions 4. Consume snapshot with computations 5. Validate complex query results                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_func_filter_complex2.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_multi_ctb.TestCase.test_tmq_cons_from_tsdb_multiVg_multiCtb","title":"","text":"Consume: multi child tables 1. Create super table with multiple child tables 2. Insert data to all child tables 3. Flush to TSDB 4. Create snapshot topic on super table 5. Consume all child tables data 6. Verify complete consumption                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_multi_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_multi_ctb_filter.TestCase.test_tmq_cons_from_tsdb1_multiVg_multiCtb","title":"","text":"Consume: multi ctb filter 1. Create multiple child tables 2. Insert diverse data 3. Apply filters to topic 4. Consume snapshot with filtering 5. Verify filtered results from all tables                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_multi_ctb_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_multi_vg.TestCase.test_tmq_cons_from_tsdb_multiVg","title":"","text":"Consume: multi vgroups 1. Create database with 4+ vgroups 2. Insert data distributed across vgroups 3. Create snapshot topic 4. Consume from all vgroups simultaneously 5. Verify complete data from all vgroups                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_multi_vg.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_multi_vg_filter.TestCase.test_tmq_cons_from_tsdb1_multiVg","title":"","text":"Consume: multi vg filter 1. Setup multi-vgroup database 2. Distribute data across vgroups 3. Create filtered snapshot topic 4. Consume from all vgroups with filter 5. Verify filter consistency across vgroups                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_multi_vg_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_single_ctb.TestCase.test_tmq_cons_from_tsdb_1ctb","title":"","text":"Consume: single child table 1. Create single child table 2. Insert data and flush to TSDB 3. Create snapshot topic 4. Consume single table from snapshot 5. Verify data completeness                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_single_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_snapshot_single_ctb_filter.TestCase.test_tmq_cons_from_tsdb1_1ctb","title":"","text":"Consume: single ctb filter 1. Create child table with data 2. Apply column and WHERE filters 3. Create snapshot topic with filter 4. Consume filtered snapshot 5. Verify filter accuracy                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_snapshot_single_ctb_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_stb_filter.TestCase.test_stbFilter","title":"","text":"Filter: column filter 1. Create super table with multiple columns 2. Create topic selecting specific columns 3. Insert full row data 4. Consume with column filter 5. Verify only selected columns received                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_stb_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_stb_tag_filter.TestCase.test_stbTagFilter_1ctb","title":"","text":"Filter: tag filter 1. Create super table with tag columns 2. Create child tables with different tags 3. Create topic with tag filter 4. Insert data to all child tables 5. Consume filtered by tag 6. Verify only matching tags received                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_stb_tag_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_stb_tag_multi_ctb.TestCase.test_stbTagFilter_multictb","title":"","text":"Filter: tag multi filter 1. Create super table with tags 2. Create multiple child tables 3. Apply complex tag filter (AND/OR) 4. Insert data to all tables 5. Consume with tag filtering 6. Verify multi-table tag filter accuracy                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_stb_tag_multi_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_stb_where_filter.TestCase.test_stbFilterWhere","title":"","text":"Filter: where filter 1. Create super table with data 2. Create topic with WHERE condition 3. Insert matching and non-matching rows 4. Consume filtered data 5. Verify only matching rows received                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_stb_where_filter.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_subscribe_stb_r3.TestCase.test_tmq_subscribe_stb","title":"","text":"Cluster: subscribe replica3 1. Create 3-replica super table 2. Insert data to all replicas 3. Subscribe with replica awareness 4. Consume from replica set 5. Verify replica consistency 6. Check failover behavior                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_subscribe_stb_r3.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_taosx.TestCase.test_tmq_taosx","title":"","text":"Advanced: taosx sync 1. Configure taosx synchronization 2. Setup source and target clusters 3. Start taosx sync via TMQ 4. Insert data to source 5. Verify data synced to target 6. Check sync accuracy                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_taosx.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_topics_info.TestCase.test_ins_topics","title":"","text":"Basic: topics info query 1. Create database and topic 2. Query information_schema.ins_topics 3. Verify topic metadata (name, db, create_time, sql) 4. Drop topic and verify cleanup                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_topics_info.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_tsdb_and_wal.TestCase.test_datafromtsdb","title":"","text":"Consume: tsdb and wal 1. Insert historical data (flush to TSDB) 2. Insert new data (remain in WAL) 3. Create topic consuming both sources 4. Consume merged data stream 5. Verify correct merge and ordering                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_tsdb_and_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_tsdb_wal_multi_ctb.TestCase.test_datafromtsdb_multictb","title":"","text":"Consume: tsdb wal multi 1. Create multiple child tables 2. Write historical data to TSDB 3. Write recent data to WAL 4. Subscribe all tables 5. Consume from TSDB and WAL 6. Verify complete data from both sources                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_tsdb_wal_multi_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_udf.TestCase.test_tmq_udf","title":"","text":"Advanced: udf functions 1. Create UDF functions 2. Create topic with UDF in SELECT 3. Insert source data 4. Consume computed results 5. Verify UDF executed correctly 6. Check function output                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_udf.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_udf_snapshot_mode.TestCase.test_tmq_udf_multiCtb_snapshot1","title":"","text":"Advanced: udf snapshot mode 1. Configure snapshot with UDF 2. Flush data to TSDB 3. Apply UDF to snapshot topic 4. Consume computed snapshot 5. Verify UDF on historical data                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_udf_snapshot_mode.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_udf_wal_mode.TestCase.test_tmq_udf_multiCtb_snapshot0","title":"","text":"Advanced: udf wal mode 1. Setup UDF in topic 2. Configure WAL mode 3. Create topic with UDF 4. Consume from WAL with computation 5. Verify UDF results from WAL                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_udf_wal_mode.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_update_single_ctb.TestCase.test_tmq_update","title":"","text":"Operation: update single ctb 1. Create child table with initial data 2. Create topic subscription 3. Execute UPDATE on existing rows 4. Consume update messages 5. Verify updated values received                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_update_single_ctb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_update_snapshot_mode.TestCase.test_tmq_udf_multiCtb_snapshot1","title":"","text":"Operation: update snapshot mode 1. Configure snapshot mode (snapshot=1) 2. Flush data to TSDB 3. Execute UPDATE on historical data 4. Consume from snapshot + WAL 5. Verify snapshot mode update behavior                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_update_snapshot_mode.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_update_wal_mode.TestCase.test_tmq_update_multiCtb_snapshot0","title":"","text":"Operation: update wal mode 1. Configure WAL mode (snapshot=0) 2. Create subscription 3. Execute UPDATE operations 4. Consume from WAL only 5. Verify WAL-based update handling                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_update_wal_mode.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_update_while_consume.TestCase.test_tmq_update_with_consume","title":"","text":"Operation: update while consume 1. Start consumption process 2. Concurrently execute UPDATE operations 3. Consume updates in real-time 4. Verify no data loss during concurrent updates                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_update_while_consume.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_replicate.TestCase.test_tmq_vnode_replicate","title":"","text":"Cluster: vnode replicate 1. Setup replica configuration 2. Create replicated vgroups 3. Start consumption 4. Verify replica synchronization 5. Test consumption from different replicas 6. Check consistency                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_replicate.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_column.TestCase.test_tmq_vnode_split_column","title":"","text":"Cluster: vnode split column 1. Create column-based subscription 2. Start consumption 3. Trigger vnode split operation 4. Continue consumption after split 5. Verify no data loss during split 6. Check vnode rebalancing                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_column.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_db.TestCase.test_tmq_vnode_split_db","title":"","text":"Cluster: vnode split db 1. Create database subscription 2. Insert data distributed across vnodes 3. Trigger vnode split 4. Continue database-level consumption 5. Verify all vnode data consumed 6. Check integrity after split                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_db.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_db_no_wal.TestCase.test_tmq_vnode_split_db_false","title":"","text":"Cluster: vnode split db-nowal 1. Setup database topic 2. Configure WAL retention policy 3. Execute vnode split 4. Verify WAL behavior 5. Continue consumption 6. Check data completeness                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_db_no_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_dup_no_wal.TestCase.test_tmq_vnode_split_stb_sel_dup_false","title":"","text":"Cluster: vnode split dup-nowal 1. Setup duplicate data scenario 2. Configure WAL retention 3. Split vnodes 4. Verify duplicate handling with WAL 5. Check data accuracy                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_dup_no_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_duplicate.TestCase.test_tmq_vnode_split_stb_sel_dup","title":"","text":"Cluster: vnode split duplicate 1. Insert potentially duplicate data 2. Execute vnode split 3. Consume all data 4. Verify deduplication works 5. Check no duplicates after split                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_duplicate.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_no_remove.TestCase.test_tmq_vnode_split_column_false","title":"","text":"Cluster: vnode split no-remove 1. Setup vnode split test 2. Configure no WAL removal 3. Execute vnode split 4. Verify WAL retained 5. Continue consumption 6. Check data continuity                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_no_remove.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_ntb.TestCase.test_tmq_vnode_split_ntb_sel","title":"","text":"Cluster: vnode split ntb 1. Create normal table subscription 2. Insert data 3. Trigger vnode split 4. Continue consumption 5. Verify normal table unaffected 6. Check data integrity                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_ntb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_select_no_wal.TestCase.test_tmq_vnode_split_stb_sel_false","title":"","text":"Cluster: vnode split no-wal 1. Create SELECT topic 2. Configure no WAL removal 3. Split vnodes 4. Continue query consumption 5. Verify query continuity 6. Check WAL retention effect                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_select_no_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_stb.TestCase.test_tmq_vnode_split_stb","title":"","text":"Cluster: vnode split stb 1. Create super table subscription 2. Distribute child tables across vnodes 3. Execute vnode split 4. Resume consumption 5. Verify all child tables data 6. Check split handling                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_stb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_stb_no_wal.TestCase.test_tmq_vnode_split_stb_false","title":"","text":"Cluster: vnode split stb no-wal 1. Setup super table topic 2. Configure WAL retention 3. Split vnodes 4. Verify WAL behavior 5. Continue consumption 6. Check data completeness                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_stb_no_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_split_stb_select.TestCase.test_tmq_vnode_split_stb_sel","title":"","text":"Cluster: vnode split select 1. Create SELECT-based topic on super table 2. Insert data with computation 3. Trigger vnode split 4. Continue consuming query results 5. Verify computed data correct after split                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_split_stb_select.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_transform_db.TestCase.test_tmq_vnode_trans_db","title":"","text":"Cluster: vnode transform db 1. Create database topic 2. Start consumption 3. Execute vnode transform (rebalance) 4. Continue consumption 5. Verify data migration complete 6. Check no data loss                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_transform_db.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_transform_db_wal.TestCase.test_tmq_vnode_trans_db_rm_wal","title":"","text":"Cluster: vnode transform db-wal 1. Setup database topic 2. Transform vnodes with WAL removal 3. Consume during transformation 4. Verify WAL cleanup 5. Check data integrity                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_transform_db_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_transform_stb.TestCase.test_tmq_vnode_trans_stb","title":"","text":"Cluster: vnode transform stb 1. Create super table topic 2. Start consumption 3. Execute vnode transformation 4. Resume consumption 5. Verify transformation handled 6. Check data consistency                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_transform_stb.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_vnode_transform_stb_wal.TestCase.test_tmq_vnode_trans_stb_rm_wal","title":"","text":"Cluster: vnode transform stb-wal 1. Setup super table topic 2. Transform with WAL removal 3. Continue consumption 4. Verify WAL behavior 5. Check data completeness                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_vnode_transform_stb_wal.py"},{"location":"case_list_docs/DataSubscription/Consume/#17-DataSubscription.02-Consume.test_tmq_wal_remove.TestCase.test_tmq_walRemove","title":"","text":"Advanced: wal removal 1. Configure WAL retention period 2. Insert data generating WAL 3. Trigger WAL cleanup 4. Verify old WAL removed 5. Check space reclaimed 6. Ensure consumption not affected                      path:                                            cases/17-DataSubscription/02-Consume/test_tmq_wal_remove.py"},{"location":"case_list_docs/DataSubscription/MQTT/","title":"03-MQTT","text":""},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_bnodes.TestMqttBnodes.test_mqtt_bnodes","title":"","text":"MQTT: bnodes test Bnodes testing. -N 2~11                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_bnodes.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_qos.TestMqttCases.test_mqtt_qos","title":"","text":"MQTT: QOS test mqtt qos {0, 1, 2} testing                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_qos.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_rb.TestMqttCases.test_mqtt_rawblock","title":"","text":"MQTT: rawblock test mqtt rawblock testing                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_rb.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_rb.TestMqttCases.test_node_create_bnode","title":"","text":"Node create bnode 1. Create bnode for each dnode 2. Create database with us precision 3. Create stable with full data types 4. Create topic from stable 5. Insert data into stable 6. Subscribe topic with rawblock proto 7. Verify subscribed data 8. Drop bnodes and databases                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_rb.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_smoking.TestMqttDevBasic.test_mqtt_dev_smoke","title":"","text":"MQTT: development testing Verification testing during the development process.                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_smoking.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_soak.TestMqttCases.test_mqtt_soak","title":"","text":"MQTT: soak testing Soak testing for 72 hours to assess taosmqtt's behavior under prolonged stress. -N [6]                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_soak.py"},{"location":"case_list_docs/DataSubscription/MQTT/#17-DataSubscription.03-MQTT.test_mqtt_special.TestMqttCases.test_mqtt_special","title":"","text":"MQTT: special testing Special testing.                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_special.py"},{"location":"case_list_docs/DataSubscription/Mgmt/","title":"01-Mgmt","text":""},{"location":"case_list_docs/DataSubscription/Mgmt/#17-DataSubscription.01-Mgmt.test_drop_lost_comsumers.TestDropLostConsumers.test_drop_lost_comsumers","title":"","text":"Tmq: drop lost consumers 1. verifying that the boundary and valid values of session_timeout_ms are in effect 2. verifying that the boundary and valid values of max_poll_interval_ms are in effect 3. verifying that consumer will be closed when the session_timeout_ms and max_poll_interval_ms is expired                      path:                                            cases/17-DataSubscription/01-Mgmt/test_drop_lost_comsumers.py"},{"location":"case_list_docs/DataSubscription/Mgmt/#17-DataSubscription.01-Mgmt.test_force_drop_topic.TestTmqForceDropTopic.test_force_drop_topic","title":"","text":"Tmq: force drop topic 1. Create db 2. Create supper table and sub table 3. Insert data into sub table 3. Create topic and consume data from sub table 4. Force drop topic, check the consumer status in another topic, it will be still active                      path:                                            cases/17-DataSubscription/01-Mgmt/test_force_drop_topic.py"},{"location":"case_list_docs/DataSubscription/Mgmt/#17-DataSubscription.01-Mgmt.test_tmq_drop_stb.TestCase.test_tmq_drop_stb","title":"","text":"Tmq manager drop stb 1. Create database and stable 2. Create topic from database 3. Insert data into stable 4. Start consume processor 5. Drop stable 6. Check consume result expected 7. Drop topic                      path:                                            cases/17-DataSubscription/01-Mgmt/test_tmq_drop_stb.py"},{"location":"case_list_docs/DataSubscription/Mgmt/#17-DataSubscription.01-Mgmt.test_tmq_show.TestCase.test_tmq_show","title":"","text":"Tmq manager show 1. Create database and stable 2. Create topics 3. Insert data into stables 4. Start tmq_sim process to consume data 5. Check show topics, show consumers, show subscriptions 6. Drop topics                      path:                                            cases/17-DataSubscription/01-Mgmt/test_tmq_show.py"},{"location":"case_list_docs/DataSubscription/Mgmt/#17-DataSubscription.01-Mgmt.test_topic.TestTmpTopic.test_tmq_topic","title":"","text":"Tmq manager topic 1. Create, delete, show topics 2. Create topics of database type, super table type, and batch query type                      path:                                            cases/17-DataSubscription/01-Mgmt/test_topic.py"},{"location":"case_list_docs/Databases/Alter/","title":"03-Alter","text":""},{"location":"case_list_docs/Databases/Alter/#02-Databases.03-Alter.test_db_alter_database.TestAlterDatabase.test_db_alter_database","title":"","text":"Alter database 1. Alter database buffer 2. Alter database pages 3. Alter database encrypt_algorithm 4. Alter database with same options 5. Alter database keep_time_offset                      path:                                            cases/02-Databases/03-Alter/test_db_alter_database.py"},{"location":"case_list_docs/Databases/Alter/#02-Databases.03-Alter.test_db_alter_option.TestDatabaseAlterOption.test_db_alter_option","title":"","text":"Alter all options 1. Create database and inspect all option values. 2. Attempt to alter database with invalid options (expect failure). 3. Alter database with valid options and verify the changes. 4. Check alter buffer size 5. Check alter cache model 6. Check alter cache size 7. Check alter min rows 8. Check alter pages 9. Check alter wal_level 10. Check alter wal_fsync_period 11. Check alter stt_trigger 12. Check alter wal_retention_period 13. Check alter wal_retention_size 14. Check alter ss_keeplocal 15. Check alter ss_compact 16. Check alter keep_time_offset 17. Check alter compact_interval 18. Check alter compact_time_offset 19. Check alter unsupport option                      path:                                            cases/02-Databases/03-Alter/test_db_alter_option.py"},{"location":"case_list_docs/Databases/Alter/#02-Databases.03-Alter.test_db_alter_option_keep.TestDatabaseAlterOptionKeep.test_database_alter_option_keep","title":"","text":"Alter keep 1. Use invalid input to alter the KEEP option 2. Verify results after changing KEEP 3. Add or drop columns on the super table 4. Insert data 5. Check results 6. Repeat steps 3-5 several times                      path:                                            cases/02-Databases/03-Alter/test_db_alter_option_keep.py"},{"location":"case_list_docs/Databases/Alter/#02-Databases.03-Alter.test_db_alter_replica.TestAlterReplica.test_alter_replica","title":"","text":"Alter database replica 1. Alter replica basic operations 2. Alter replica count from 1 to 3 3. Alter replica count from 3 to 1                      path:                                            cases/02-Databases/03-Alter/test_db_alter_replica.py"},{"location":"case_list_docs/Databases/Create/","title":"01-Create","text":""},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_basic.TestDatabaseBasic1.test_database_basic","title":"","text":"Database create basic 1. Create database with vgroup option 2. Show vgroups and verify vgroups info 3. Drop database and verify 4. Create multiple databases and verify vgroups info 5. Drop some databases and verify 6. Restart dnode and verify database and vgroup info 7. Create more databases and verify vgroup info 8. Create same name db and drop loop 100 times(TD-25762) 9. Create super/child/normal tables in multiple databases 10. Create normal table with db. prefix in multiple databases 11. Create/drop tables in a database multiple times and verify 12. Create database with options (replica, duration, keep, minrows) 13. Query information_schema.ins_databases and verify results 14. Repeatedly execute create database, drop database, create table, and write data                        path:                                            cases/02-Databases/01-Create/test_db_basic.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_cachemode.TestDbCachemodel.test_db_cachemodel","title":"","text":"Options: cache model 1. Create database with different cachemodel options(none/last_row/last_value/both) 2. Insert data into subtables 3. Check cachemodel settings in information_schema and storage layer 4. Restart dnode multiple times and re-verify cachemodel settings                      path:                                            cases/02-Databases/01-Create/test_db_cachemode.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_commit.TestDatabaseCommit.test_database_commit","title":"","text":"Database: commit 1. Write data 2. Restart taosd 3. Append data to the same file 4. Verify row count                      path:                                            cases/02-Databases/01-Create/test_db_commit.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_compact.TestDbCompact.test_db_compact","title":"","text":"Database compact 1. Compact a empty database and verify no error occurs 2. Show compacts and get compact id 3. Show compact with the compact id and verify the result 4. Kill the compact operation and verify it is killed successfully 5. Create databases with different compact options 6. Verify the compact options are set correctly 7. Alter the compact options and verify the options are changed correctly 8. Verify error handling for invalid compact options 9. Create databases with vgroups 10. Compact specific vgroups and verify the operation is successful 11. Verify \"compact database\" command can return column names correctly                      path:                                            cases/02-Databases/01-Create/test_db_compact.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_compact_meta.TestCompactMeta.test_compact_meta","title":"","text":"Database compact meta 1. Create datbase and super table 2. Create many child tables 3. Insert data into child tables 4. Alter child table tags 5. Query data from child tables to verify 6. Compact meta only 7. Insert more data into child tables 8. Query data from child tables to verify again 9. Alter super table schema many times 10. Query data from child tables to verify again 11. Alter super table schema 12. Make sure compact meta works                      path:                                            cases/02-Databases/01-Create/test_db_compact_meta.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_create_encrypt.TestBasic.test_db_create_encrypt","title":"","text":"Option: encrypt_algorithm 1. Create encrypt key '1234567890' 2. Create database with encrypt_algorithm 'sm4' 3. Create stable and child tables 4. Insert data and query data 5. Recreate dnode encrypt key 6. Query data again 7. Create database with wrong encrypt key and expect error                      path:                                            cases/02-Databases/01-Create/test_db_create_encrypt.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_retention.TestDbRetention.test_db_retention","title":"","text":"Databases retention 1. Prepare environment with single level data directories 2. Write bulk data into database with retention policy 3. Switch to multi-level data directories 4. Trim database to trigger retention 5. Check data directories to verify retention is executed correctly                      path:                                            cases/02-Databases/01-Create/test_db_retention.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_tables.TestDatabaseTables.test_database_tables","title":"","text":"Database: cache 1. Create database and table 2. Write and query data 3. Drop both 4. Reset query cache 5. Retest                      path:                                            cases/02-Databases/01-Create/test_db_tables.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_wal_fsync_period.TestFsync.test_db_wal_fsync_period","title":"","text":"Database wal_fsync_period 1. Create database with wal_fsync_period options 2. Verify wal_fsync_period value from information_schema.ins_databases 3. Verify wal_fsync_period value after alter database 4. Verify wal_fsync_period value after restart taosd 5. Verify error cases for wal_fsync_period option 6. Verify error cases for alter wal_fsync_period option                      path:                                            cases/02-Databases/01-Create/test_db_wal_fsync_period.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_wal_level.TestWalLevelSkip.test_wal_level_skip","title":"","text":"Options: wal level  1. create database wal_level = 0 and insert data 2. stop/kill taosd before alter wal level 3. restart taosd 4. alter wal level from 0 to 1/2 5. insert data 6. stop/kill taosd after alter wal level 7. restart taosd                      path:                                            cases/02-Databases/01-Create/test_db_wal_level.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_db_wal_retention.TestWalRetention.test_wal_retention","title":"","text":"Options: wal retention 1. Create database with different wal_retention_period and wal_retention_size 2. Create super table and child tables 3. Insert data to child tables 4. Verify wal files retention based on period and size settings 5. Check that wal files are deleted according to retention policies 6. Use TMQ to consume data and verify data integrity after retention checks                      path:                                            cases/02-Databases/01-Create/test_db_wal_retention.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_name_all.TestDatabaseCreate.test_database_create","title":"","text":"DB Name: basic 1. Case sensitivity 2. Illegal names 3. Chinese names                      path:                                            cases/02-Databases/01-Create/test_name_all.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_name_len.TestDatabaseLen.test_database_len","title":"","text":"DB Name: length 1. Create database with an excessively long name 2. Test with invalid values                      path:                                            cases/02-Databases/01-Create/test_name_len.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_op_all.TestDatabaseCreateAllOptions.test_database_create_all_options","title":"","text":"Options: basic 1. Create database using all available options 2. Query information_schema.ins_databases to verify correct display 3. Test the valid ranges of each option                      path:                                            cases/02-Databases/01-Create/test_op_all.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_op_dnodelist.TestDatabaseDnodeList.test_database_dnode_list","title":"","text":"Options: dnodelist 1. Create database with DNODE list option 2. Test creation with varying replica counts and vgroup numbers 3. Alter database DNODE list option                      path:                                            cases/02-Databases/01-Create/test_op_dnodelist.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_op_keep.TestDatabaseKeep.test_database_Keep","title":"","text":"Options: keep     1. Create database with the KEEP option     2. Write and query data\u2014including data outside the KEEP range     3. ALTER database KEEP option     4. Write and query data again                      path:                                            cases/02-Databases/01-Create/test_op_keep.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_op_table_hash.TestDatabaseTableHash.test_database_table_hash","title":"","text":"Options: table hash 1. Create a database with 2 vgroups and explicitly set table_prefix / table_suffix 2. Create one super table and 5 child tables; query information_schema.ins_tables to confirm their vgroup distribution 3. Create 5 normal tables; query information_schema.ins_tables again to verify their vgroup placement                      path:                                            cases/02-Databases/01-Create/test_op_table_hash.py"},{"location":"case_list_docs/Databases/Create/#02-Databases.01-Create.test_op_table_prefix_suffix.TestDatabaseTablePrefixSuffix.test_database_table_prefix_suffix","title":"","text":"Options: table prefix &amp; suffix 1. Create database with TABLE_PREFIX and TABLE_SUFFIX options 2. Create tables 3. Verify that tables are distributed across vgroups as expected                      path:                                            cases/02-Databases/01-Create/test_op_table_prefix_suffix.py"},{"location":"case_list_docs/Databases/Drop/","title":"02-Drop","text":""},{"location":"case_list_docs/Databases/Drop/#02-Databases.02-Drop.test_db_catalog.TestDatabaseCatalog.test_database_catalog","title":"","text":"Drop db basic 1. Drop database with if exists 2. Drop empty database 3. Drop database with only meta 4. Drop database with super/child/normal tables 5. Loop drop and create database for many times 6. Verify drop database on information_schema.ins_databases                      path:                                            cases/02-Databases/02-Drop/test_db_catalog.py"},{"location":"case_list_docs/Databases/Drop/#02-Databases.02-Drop.test_db_delete_reuse.TestDatabaseDeleteReuse1.test_database_delete_reuse1","title":"","text":"Drop db while querying 1. Create database 2. Drop database 3. Create database again 4. reset query cache 5. Attempt to write data to its tables (expected to fail) 6. Create normal table with same name 7. Insert data 8. Query data 9. Drop database  10. Repeat 20 times from step 3 ~ 9                      path:                                            cases/02-Databases/02-Drop/test_db_delete_reuse.py"},{"location":"case_list_docs/Databases/Drop/#02-Databases.02-Drop.test_db_delete_reuse_vnode.TestDatabaseDeleteReuseVnode.test_database_delete_reuse_vnode","title":"","text":"Drop db repeatedly 1. Create a database and a normal table, insert data, and repeat the above 30 times using the same names 2. Restart the dnode 3. Create a database and a super table, create child tables, insert data, and repeat the above 10 times using the same names                      path:                                            cases/02-Databases/02-Drop/test_db_delete_reuse_vnode.py"},{"location":"case_list_docs/Databases/Drop/#02-Databases.02-Drop.test_db_repeat.TestDatabaseRepeat.test_database_repeat","title":"","text":"Drop db many repeatly 1. Create database 2. Create table 3. Drop both 4. Repeat several times                      path:                                            cases/02-Databases/02-Drop/test_db_repeat.py"},{"location":"case_list_docs/Databases/Drop/#02-Databases.02-Drop.test_db_writing.TestDatabaseDeleteWriting.test_database_delete_writing","title":"","text":"Drop db while writing 1. Create database 2. Create normal table 3. Insert data 4. Sleep 1s 5. Repeat 10 times with the same names 6. Meanwhile, start a thread that keeps inserting into that table regardless of success                      path:                                            cases/02-Databases/02-Drop/test_db_writing.py"},{"location":"case_list_docs/Databases/Flush/","title":"07-Flush","text":""},{"location":"case_list_docs/Databases/Flush/#02-Databases.07-Flush.test_db_flush.TestDbFlush.test_db_flush","title":"","text":"Flush database 1. Create a database with sst_trigger = 1. 2. Insert string-typed data. 3. Flush the database. 4. Continue inserting data (including duplicates). 5. Verify the query results for correctness.                      path:                                            cases/02-Databases/07-Flush/test_db_flush.py"},{"location":"case_list_docs/Databases/Precision/","title":"06-Precision","text":""},{"location":"case_list_docs/Databases/Precision/#02-Databases.06-Precision.test_db_precision_bugs.TestTS_3311.test_db_precision_bugs","title":"","text":"Precision bugs 1. Verify bug TS-3311 (timestamp precision cause wrong window function result)                      path:                                            cases/02-Databases/06-Precision/test_db_precision_bugs.py"},{"location":"case_list_docs/Databases/Precision/#02-Databases.06-Precision.test_db_precision_ns.TestDatabasePrecisionNs.test_database_precision_ns","title":"","text":"Precision: ns 1. Create a nanosecond-precision database. 2. Insert data using numeric timestamps. 3. Verify the row count. 4. Insert data using now(). 5. Filter data by timestamp. 6. Validate INTERVAL \u2026 SLIDING queries. 7. Validate time macro functions. 8. Validate where clause with timestamp comparisons.                      path:                                            cases/02-Databases/06-Precision/test_db_precision_ns.py"},{"location":"case_list_docs/Databases/Precision/#02-Databases.06-Precision.test_db_precision_us.TestDatabasePrecisionUs.test_database_precision_us","title":"","text":"Precision: ms and us 1. Millisecond-precision test 2. Create a millisecond-precision database 3. Insert both valid and invalid timestamps 4. Query the data 5. Microsecond-precision test 6. Create a microsecond-precision database 7. Repeat the same insert and query steps as above 8. Validate time macro functions. 9. Validate where clause with timestamp comparisons.                      path:                                            cases/02-Databases/06-Precision/test_db_precision_us.py"},{"location":"case_list_docs/Databases/Query/","title":"04-Query","text":""},{"location":"case_list_docs/Databases/Query/#02-Databases.04-Query.test_db_show_create_db.TestDatabaseShowCreateDb.test_database_show_create_db","title":"","text":"Show create db 1. Create database 2. Run SHOW CREATE DATABASE 3. Verify the result                      path:                                            cases/02-Databases/04-Query/test_db_show_create_db.py"},{"location":"case_list_docs/Databases/Query/#02-Databases.04-Query.test_db_show_create_table.TestDatabaseShowCreateTable.test_database_show_create_table","title":"","text":"Show create table 1. Create a normal table 2. Create a super table 3. Create child tables 4. Execute SHOW CREATE TABLE and verify the output 5. Change the showFullCreateTableColumn parameter 6. Execute SHOW CREATE TABLE again and verify the new output                      path:                                            cases/02-Databases/04-Query/test_db_show_create_table.py"},{"location":"case_list_docs/Databases/Query/#02-Databases.04-Query.test_db_show_create_table.TestDatabaseShowCreateTable.test_empty_nchar_tag","title":"","text":"Show create table empty nchar tag 1. when nchar-type tag is empty, show create table should output an empty string 2. alter table to set nchar-type tag to a non-empty string, show create table should output the new string 3. alter table to set nchar-type tag to an empty string, show create table should output an empty string again 4. alter table to set nchar-type tag to a non-empty string again, show create table should output the new string again 5. drop database                      path:                                            cases/02-Databases/04-Query/test_db_show_create_table.py"},{"location":"case_list_docs/Databases/Query/#02-Databases.04-Query.test_db_show_vgroup.TestDatabaseShowVgroup.test_database_show_vgroup","title":"","text":"Show vgroups 1. Create multiple databases 2. Repeatedly create and drop tables 3. Run SHOW VGROUPS after each cycle to confirm the expected vgroup count                      path:                                            cases/02-Databases/04-Query/test_db_show_vgroup.py"},{"location":"case_list_docs/Databases/Sync/","title":"05-Sync","text":""},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance1.TestBalance1.test_balance_1","title":"","text":"Scale-up: repica-1 (mnode) 1. Create a 1-dnode cluster 2. Create database d1 (1 vgroup, replica 1) and insert data 3. Start dnode2, join it to the cluster, run BALANCE VGROUP; verify vnode distribution and data integrity 4. Create database d2 (1 vgroup, replica 1) and insert data; check distribution &amp; integrity 5. Remove dnode2; verify vnode distribution and data integrity 6. Start dnode3, join it to the cluster, run BALANCE VGROUP; verify distribution &amp; integrity 7. Create database d3 (1 vgroup, replica 1) and insert data; check distribution &amp; integrity 8. Remove dnode3; verify vnode distribution and data integrity 9. Create database d4 (1 vgroup, replica 1) and insert data; check distribution &amp; integrity                      path:                                            cases/02-Databases/05-Sync/test_balance1.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance2.TestBalance2.test_balance_2","title":"","text":"Scale-up: repica-3 db-1 1. Create a 3-dnode cluster 2. Create four 1-vgroup, 3-replica databases and insert data; verify vnode distribution and data integrity 3. Start dnode4 and dnode5, then add them to the cluster 4. Drop dnode2; verify vnode re-distribution and data integrity 5. Drop dnode3; verify vnode re-distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_balance2.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance3.TestBalance3.test_balance_3","title":"","text":"Scale-up: repica-1 db-2 1. Start a 4-dnode cluster 2. Create two 1-vgroup, 3-replica databases d1 and d2; insert data and verify vnode distribution &amp; data integrity 3. Remove dnode2; verify vnode re-distribution &amp; data integrity 4. Start dnode5 and join it to the cluster; run BALANCE VGROUP; verify distribution &amp; integrity 5. Create one more 1-vgroup, 3-replica database d3; insert data and verify 6. Start dnode6 and join the cluster; run BALANCE VGROUP; verify distribution &amp; integrity 7. Remove dnode3; verify final vnode distribution &amp; data integrity                      path:                                            cases/02-Databases/05-Sync/test_balance3.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance_leader.TestBalanceLeader.test_balance_leader","title":"","text":"balance leader 1. -                      path:                                            cases/02-Databases/05-Sync/test_balance_leader.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance_replica_1.TestBalanceReplica1.test_balance_replica_1","title":"","text":"Balance: replica-1 1. Create a single-replica database with 2 vgroups and insert data 2. Start a new dnode and add it to the cluster 3. Execute BALANCE VGROUP 4. Verify vnode distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_balance_replica_1.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance_replica_3.TestBalanceReplica3.test_balance_replica_3","title":"","text":"Balance: replica-3 1. Create a 3-replica database with 4 vgroups and insert data 2. Start a new dnode and add it to the cluster 3. Execute BALANCE VGROUP 4. Verify vnode distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_balance_replica_3.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balance_vnode_clean.TestVnodeClean.test_vnode_clean","title":"","text":"Scale-up: repica-1 1. Start a 1-node cluster 2. Create database d1 (1 vgroup, 1 replica); create table, insert data, verify 3. Add dnode2 \u2192 run BALANCE VGROUP 4. Create database d2 (1 vgroup, 1 replica); create table, insert data, verify 5. Remove dnode2 6. Add dnode3 \u2192 run BALANCE VGROUP 7. Create database d3 (1 vgroup, 1 replica); create table, insert data, verify 8. Add dnode4 \u2192 run BALANCE VGROUP 9. Create database d4 (4 vgroups, 1 replica); create tables, insert data, verify 10. Remove dnode3 11. Check data integrity for all databases d1, d2, d3, and d4                      path:                                            cases/02-Databases/05-Sync/test_balance_vnode_clean.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_balancex.TestBalancex.test_balance_x","title":"","text":"Scale-up: repica mixed 1. Start a 1-dnode cluster 2. Create databases d1 and d2 (each 1 vgroup, replica 1) and insert data 3. Start dnode2 and dnode3, add them to the cluster 4. Create database d3 (3 vgroups, replica 3) and insert data; verify vnode distribution &amp; data integrity 5. Start dnode4 and join the cluster; run BALANCE VGROUP; verify distribution &amp; integrity 6. Drop dnode2; verify vnode re-distribution &amp; data integrity                      path:                                            cases/02-Databases/05-Sync/test_balancex.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica1.TestRedistributeVgroupReplica1.test_redistribute_vgroup_replica1","title":"","text":"RDST: replica-1 1. Start a 2-dnode cluster with supportVnodes=0 on dnode1 2. Create database d1 (1 vgroup, replica 1) and insert data 3. Add dnode3 and dnode4 to the cluster 4. Execute REDISTRIBUTE VGROUP to move the vnode to dnode3; verify distribution &amp; data integrity 5. Execute REDISTRIBUTE VGROUP to move the vnode to dnode4; verify 6. Execute REDISTRIBUTE VGROUP to move the vnode to dnode2; verify 7. Repeat steps 4-6 three more times, cycling the vnode among dnode3 \u2192 dnode4 \u2192 dnode2 \u2192 dnode3 \u2192 dnode2 \u2192 dnode3 \u2192 dnode2, verifying distribution &amp; data integrity after each move                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica1.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica2.TestRedistributeVgroupReplica2.test_redistribute_vgroup_replica2","title":"","text":"RDST: replica-2 1. Start a 3-dnode cluster with supportVnodes=0 on dnode1 2. Create database d1 (1 vgroup, replica 2) and insert data 3. Add dnode3 and dnode4 to the cluster 4. Execute REDISTRIBUTE VGROUP to move the vnode to dnode4 dnode5; verify distribution &amp; data integrity 5. Execute REDISTRIBUTE VGROUP to move the vnode to dnode2 dnode3; verify distribution &amp; data integrity                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica2.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica3_v1_follower.TestRedistributeVgroupReplica3V1Follower.test_redistribute_vgroup_replica3_v1_follower","title":"","text":"RDST: repica-3 follower 1. Start a 4-node cluster with dnode1 configured as supportVnodes=0 2. Create database d1 (1 vgroup, 3 replicas) and insert data 3. Execute illegal REDISTRIBUTE VGROUP commands (expected to fail because no eligible dnodes are available) 4. Add dnode5 to the cluster 5. Identify the vnode whose role is leader; keep this leader fixed 6. For the two follower vnodes, perform five round-trip moves among the remaining three dnodes. After each move, verify vnode distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica3_v1_follower.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica3_v1_leader.TestRedistributeVgroupReplica3V1Leader.test_redistribute_vgroup_replica3_v1_leader","title":"","text":"RDST: replica-3 leader 1. Start a 4-node cluster with dnode1 configured as supportVnodes=0 2. Create database d1 (1 vgroup, 3 replicas) and write data 3. Execute illegal REDISTRIBUTE VGROUP commands (expected to fail due to insufficient eligible dnodes) 4. Add dnode5 to the cluster 5. Identify the follower vnode and keep it unchanged 6. Move the leader vnode among the remaining three dnodes five times; after each move, check vnode distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica3_v1_leader.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica3_v2.TestRedistributeVgroupReplica3V2.test_redistribute_vgroup_replica3_v2","title":"","text":"RDST: replica-3 move-2 1. Start a 4-node cluster with dnode1 set to supportVnodes=0 2. Create database d1 (1 vgroup, 3 replicas) and write data 3. Add dnode5 and dnode6 to the cluster 4. In parallel, move two vnodes to the new nodes 5. After each move, verify vnode distribution and data integrity 6. Repeat steps 4-5 three times                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica3_v2.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_redistribute_vgroup_replica3_v3.TestRedistributeVgroupReplica3V3.test_redistribute_vgroup_replica3_v3","title":"","text":"RDST: replica-3 move-3 1. Start a 4-node cluster with dnode1 set to supportVnodes=0 2. Create database d1 (1 vgroup, 3 replicas) and write data 3. Add dnode5 and dnode6 to the cluster 4. In parallel, move three vnodes to the new nodes 5. After each move, verify vnode distribution and data integrity 6. Repeat steps 4-5 three times                      path:                                            cases/02-Databases/05-Sync/test_redistribute_vgroup_replica3_v3.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_split_vgroup.TestSplitVGroup.test_cluster_split_vgroup","title":"","text":"Cluster split vgroup 1. Generate at least two stt files of the same fileset for db2 and db1 2. Check db1 and db2 same after creating 3. Split vgroup on db2 4. Insert the same data per tables into splited vgroups 5. Check two db query result same 6. Check split vgroup on empty database 7. Check split vgroup forbidden when having topic and stream 8. Compact database and check query result same                      path:                                            cases/02-Databases/05-Sync/test_split_vgroup.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_split_vgroup_replica1.TestSplitVgroupReplica1.test_split_vgroup_replica1","title":"","text":"Split: replica-1 1. Start a 2-node cluster with dnode1 configured as supportVnodes=0 2. Create database d1 (1 vgroup, 1 replica) and insert data 3. Add a new dnode2 to the cluster 4. Run SPLIT VGROUP to split the vnode; verify the new vnode distribution and data integrity                      path:                                            cases/02-Databases/05-Sync/test_split_vgroup_replica1.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_split_vgroup_replica2.TestSplitVgroupReplica2.test_split_vgroup_replica2","title":"","text":"Split: replica-2 1. Start a 4-node cluster with dnode1 configured as supportVnodes=0 2. Create database d1 (1 vgroup, 2 replicas) and insert data 3. Execute SPLIT VGROUP to split the vnode                      path:                                            cases/02-Databases/05-Sync/test_split_vgroup_replica2.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_split_vgroup_replica3.TestSplitVgroupReplica3.test_split_vgroup_replica3","title":"","text":"Split: replica-3 1. Start a 4-node cluster with dnode1 configured as supportVnodes=0 2. Create database d1 (1 vgroup, 3 replicas) and insert data 3. Execute SPLIT VGROUP to split the vnode                      path:                                            cases/02-Databases/05-Sync/test_split_vgroup_replica3.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_stable_balance_replica1.TestStableBalanceReplica1.test_stable_balance_replica1","title":"","text":"Query: after balance 1. Launch a single-node cluster 2. Create a 1-replica database with 4 vgroups 3. Create one super table and 13 child tables; insert 200 rows into each 4. Add dnode2 to the cluster 5. Execute BALANCE VGROUP 6. Verify data integrity in all tables                      path:                                            cases/02-Databases/05-Sync/test_stable_balance_replica1.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_stable_dnode2.TestStableDnode.test_stable_dnode","title":"","text":"Query: after restart 1. Start a 2-node cluster 2. Create a 1-replica database with 3 vgroups 3. Create one super table and 10 child tables; insert 20 rows into each 4. Stop dnode2 \u2192 expect queries to fail 5. Restart dnode2 \u2192 queries succeed and all data are present                      path:                                            cases/02-Databases/05-Sync/test_stable_dnode2.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_stable_replica3_dnode6.TestStableReplica3Vnode3.test_stable_replica3_vnode3","title":"","text":"Query: repica-3 1. Start a 6-node cluster 2. Create a 3-replica database with 3 vgroups 3. Create one super table and 10 child tables; insert 20 rows into each 4. Run COUNT and INTERVAL queries; verify the results                      path:                                            cases/02-Databases/05-Sync/test_stable_replica3_dnode6.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_sync_3Replica1VgElect.TestSync3Replica5VgElect.test_sync_3Replica5VgElect","title":"","text":"Query: replica-3 restart 1. Start a 4-node cluster with dnode1 set to supportVnodes=0 2. Create a 3-replica database with 1 vgroup 3. Create one super table and 10 child tables; insert 20 rows into each 4. Restart each dnode multiple times 5. Verify data integrity                      path:                                            cases/02-Databases/05-Sync/test_sync_3Replica1VgElect.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_sync_vnodesnapshot_rsma.TestSyncVnodeSnapshotRsma.test_sync_vnode_snapshot_rsma","title":"","text":"Query: replica-3 rsma 1. Start a 4-node cluster with dnode1 supportVnodes=0 2. Create a 3-replica database with 1 vgroup 3. Create one RSMA-enabled super table and one child table 4. Stop dnode4 5. Insert data and flush database 6. Repeat steps 4-5 twice 7. Restart all dnodes 8. Query and verify results                      path:                                            cases/02-Databases/05-Sync/test_sync_vnodesnapshot_rsma.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_vnode_replica3_basic.TestVnodeReplica3Basic.test_vnode_replica3_basic","title":"","text":"Write: replica-3 mnode-3 1. Start a 3-node cluster with 3 mnodes. 2. Create a 1-replica, 1-vgroup database; create table, insert data, and verify. 3. Stop dnode2 \u2192 insert data \u2192 start dnode2 \u2192 insert data. 4. Stop dnode3 \u2192 insert data \u2192 start dnode3 \u2192 insert data. 5. Stop dnode1 \u2192 insert data \u2192 start dnode1 \u2192 insert data. 6. Verify data integrity across all nodes.                      path:                                            cases/02-Databases/05-Sync/test_vnode_replica3_basic.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_vnode_replica3_import.TestVnodeReplica3Import.test_vnode_replica3_import","title":"","text":"Write: replica-3 import data 1. Start a 4-node cluster. 2. Create a 3-replica, 1-vgroup database; create table, insert out-of-order data, and verify. 3. Restart dnode2 \u2192 insert out-of-order data \u2192 verify. 4. Restart dnode3 \u2192 insert out-of-order data \u2192 verify. 5. Restart dnode4 \u2192 insert out-of-order data \u2192 verify. 6. Restart dnode3 again \u2192 insert out-of-order data \u2192 verify.                      path:                                            cases/02-Databases/05-Sync/test_vnode_replica3_import.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_vnode_replica3_many.TestVnodeReplica3Many.test_vnode_replica3_many","title":"","text":"Write: replica-3 restart 1. Start a 4-node cluster. 2. Create four 1-vgroup, 3-replica databases and a normal table in each. 3. In a background thread, insert one record into every table every 0.1 s (ignore any failures). 4. Sequentially restart dnode1 \u2192 dnode2 \u2192 dnode3 \u2192 dnode4; repeat this full cycle 8 times. 5. After every restart, confirm that row counts never decrease.                      path:                                            cases/02-Databases/05-Sync/test_vnode_replica3_many.py"},{"location":"case_list_docs/Databases/Sync/#02-Databases.05-Sync.test_vnode_replica3_vgroup.TestVnodeReplica3Vgroup.test_vnode_replica3_vgroup","title":"","text":"Write: repica-3 vgroup-2 1. Start a 4-node cluster. 2. Create a 3-replica database with 2 vgroups and create a super table. 3. Create 300 child tables and insert one record into each. 4. Insert one earlier-timestamp record into each child table. 5. Verify the query results are correct.                      path:                                            cases/02-Databases/05-Sync/test_vnode_replica3_vgroup.py"},{"location":"case_list_docs/Functions/Aggregate/","title":"02-Aggregate","text":""},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_all.TestAggFunction.test_agg_function","title":"","text":"Agg: all 1. Aggregate function:     - stddev_pop     - varpop     - avg     - sum     - leastsquares     - statecount     - max     - min 2. Check error 3. Check aggregate function with null                      path:                                            cases/11-Functions/02-Aggregate/test_agg_all.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_bugs.TestTD_21561.test_select_bugs","title":"","text":"Agg function bugs 1. Verify bug TD-21561 (count fun with group by error)                      path:                                            cases/11-Functions/02-Aggregate/test_agg_bugs.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_gconcat.TestFuncGconcat.test_func_gconcat","title":"","text":"Agg-basic: group_concat Test the GROUP_CONCAT function                      path:                                            cases/11-Functions/02-Aggregate/test_agg_gconcat.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_last.Test_Last.test_last","title":"","text":"Agg-basic: last Test the LAST function                      path:                                            cases/11-Functions/02-Aggregate/test_agg_last.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_last.Test_Last.test_last_tag","title":"","text":"Agg: last/last_row with tag description: verify the behavior of selecting last/last_row with tag column outside.             For example: select last(ts), tag1, tag2 from stable group by tbname.             In this case, we should read cache data to get the tag column value.                      path:                                            cases/11-Functions/02-Aggregate/test_agg_last.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_last.Test_Last.test_last_pk","title":"","text":"Agg-basic: last with pk Test the LAST function with composite key outside. For example: select last(ts), pk from stb group by tbname.                      path:                                            cases/11-Functions/02-Aggregate/test_agg_last.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_leastsquares.TestFuncLeastsquares.test_func_leastsquares","title":"","text":"Agg-basic: Leastsquares Test the LeastSquares function, including time windows, filtering on ordinary data columns, filtering on tag columns.                      path:                                            cases/11-Functions/02-Aggregate/test_agg_leastsquares.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_func_agg_smoking","title":"","text":"Agg-basic: smoking cases Smoking the aggregate functions                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_fun_agg_stddev_samp","title":"","text":"Fun: stddev_samp() 1. create normal table with timestamp,int columns 2. insert 5 rows with int values 1,2,3,4,5 3. query stddev_samp(int column) and check the result                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_fun_agg_variance","title":"","text":"Fun: variance() 1. create normal table with timestamp,int columns 2. insert 5 rows with int values 1,2,3,4,5 3. query variance(int column) and check the result                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_func_agg_var_pop","title":"","text":"Fun: var_pop() same with variance()                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_fun_agg_var_samp","title":"","text":"Fun: var_samp() 1. create normal table with timestamp,int columns 2. insert 5 rows with int values 1,2,3,4,5 3. query var_samp(int column) and check the result                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_agg_smoking.TestFuncAggSmoking.test_fun_agg_group_concat","title":"","text":"Fun: group_concat() 1. create normal table with timestamp,int columns 2. insert 10 rows with int values 1,2,3,4,5,6,7,8,9,10 3. query group_concat(int column) and check the result                      path:                                            cases/11-Functions/02-Aggregate/test_agg_smoking.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_apercentile.TestFunApercentile.test_func_agg_apercentile","title":"","text":"Fun: apercentile() 1. Sim case including time windows, t-digest input, null value 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query on distribute                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_apercentile.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_avg.TestFunAvg.test_func_agg_avg","title":"","text":"Fun: avg() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Support types 3. Error cases 4. Boundary values 5. Basic query 6. AVG with filter conditions 7. AVG with unsigned types                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_avg.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_avg_dist.TestDistributeAggAvg.test_distribute_agg_avg","title":"","text":"Fun: distribute avg() 1. prepare data for distribute aggregate test 2. check distribute data 3. check avg function work status 4. distribute aggregate query test                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_avg_dist.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_count.TestFunCount.test_func_agg_count","title":"","text":"Fun: count() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Basic query 3. Error check 4. Query on stable/normal table 5. Query with interval clause 6. Query after restart taosd 7. Query on null data 8. Query on partition by clause 9. Query on distributed                       path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_count.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_elapsed.TestFunElapsed.test_func_agg_elapsed","title":"","text":"Fun: elapsed() 1. Query on super/child/normal table 2. Query with nested 3. Query with join 4. Query with union 5. Query with other function 6. Query with filter 7. Query with tags 8. Error cases                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_elapsed.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_histogram.TestFunHistogram.test_fun_agg_histogram","title":"","text":"Fun: histogram() 1. Query on super/child/normal table 2. Query with bin_type parameter as user_input/linear_bin/log_bin 3. Query with bin_description parameter  4. Query with different data type 5. Query with filter 6. Error cases 7. Check again after flush database                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_histogram.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_hyperloglog.TestFunHyperloglog.test_fun_agg_hyperloglog","title":"","text":"Fun: hyperloglog() 1. Query on super/child/normal table 2. Query with group by  3. Query with having 4. Query with different data type 5. Query with filter 6. Query with join 7. Error cases 8. Check again after flush database                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_hyperloglog.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_leastsquares.TestFunLeastsquares.test_fun_agg_leastsquares","title":"","text":"Fun: leastsquares() 1. Query on different data types 2. Query on super/child/normal table 3. Error cases 4. Query with partition by 5. Query with group by and having 6. Query with union                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_leastsquares.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_percentile.TestFunPercentile.test_func_agg_percentile","title":"","text":"Fun: percentile() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Check tags                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_percentile.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_spread.TestFunSpread.test_func_agg_spread","title":"","text":"Fun: spread() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group by 7. Query with distribute aggregate 8. Check function work status                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_spread.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_stddev.TestFunStddev.test_func_agg_stddev","title":"","text":"Fun: stddev() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group by 7. Query with distribute aggregate                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_stddev.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_stddev.TestFunStddev.test_func_agg_std","title":"","text":"Fun: std() same with stddev()                       path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_stddev.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_stddev.TestFunStddev.test_func_agg_stddev_pop","title":"","text":"Fun: stddev_pop() same with stddev()                       path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_stddev.py"},{"location":"case_list_docs/Functions/Aggregate/#11-Functions.02-Aggregate.test_fun_agg_sum.TestFunSum.test_func_agg_sum","title":"","text":"Fun: sum() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group by 7. Query with distribute aggregate                      path:                                            cases/11-Functions/02-Aggregate/test_fun_agg_sum.py"},{"location":"case_list_docs/Functions/Compare/","title":"05-Compare","text":""},{"location":"case_list_docs/Functions/Compare/#11-Functions.05-Compare.test_fun_cmp_if.TestFunIf.test_fun_cmp_if","title":"","text":"Fun: If 1. Using in data columns and scalar functions within SELECT statements 2. Using in data columns within WHERE conditions 3. Using in data columns within GROUP BY statements 4. Using in data columns within STATE WINDOW 5. Using in aggregate functions while including the IS NULL operator                      path:                                            cases/11-Functions/05-Compare/test_fun_cmp_if.py"},{"location":"case_list_docs/Functions/Compare/#11-Functions.05-Compare.test_fun_cmp_if.TestFunIf.test_fun_cmp_ifnull","title":"","text":"Fun: ifnull() 1. Check \"select ifnull(1, 0)\"; 2. Check \"select ifnull(null, 10)\"; 3. Check \"select ifnull(1/0, 10)\"; 4. Check \"select ifnull(1/0, 'yes')\";                      path:                                            cases/11-Functions/05-Compare/test_fun_cmp_if.py"},{"location":"case_list_docs/Functions/Compare/#11-Functions.05-Compare.test_fun_cmp_if.TestFunIf.test_fun_cmp_nvl","title":"","text":"Fun: nvl() same with ifnull()                       path:                                            cases/11-Functions/05-Compare/test_fun_cmp_if.py"},{"location":"case_list_docs/Functions/Compare/#11-Functions.05-Compare.test_fun_cmp_if.TestFunIf.test_fun_cmp_nullif","title":"","text":"Fun: nullif() 1. Check \"select nullif(1, 1)\"; 2. Check \"select nullif(1, 2)\";                      path:                                            cases/11-Functions/05-Compare/test_fun_cmp_if.py"},{"location":"case_list_docs/Functions/Compare/#11-Functions.05-Compare.test_fun_cmp_if.TestFunIf.test_fun_cmp_nvl2","title":"","text":"Fun: nvl2() 1. Check \"select nvl2(null, 1, 2)\"; 2. Check \"select nvl2('x', 1, 2)\";                      path:                                            cases/11-Functions/05-Compare/test_fun_cmp_if.py"},{"location":"case_list_docs/Functions/Geometry/","title":"07-Geometry","text":""},{"location":"case_list_docs/Functions/Geometry/#11-Functions.07-Geometry.test_fun_geo_basic.TestGeometry.test_fun_geo_basic","title":"","text":"Geometry basic 1. Create super/child/normal tables and insert geometry data 2. Query with ST_GeomFromText() and check results 3. Query with ST_AsText() and check results 4. Verify TD-28365 Bug                      path:                                            cases/11-Functions/07-Geometry/test_fun_geo_basic.py"},{"location":"case_list_docs/Functions/Geometry/#11-Functions.07-Geometry.test_fun_geo_basic.TestGeometry.test_fun_geo_st_geomfromtext","title":"","text":"Fun: st_geomfromtext() 1. Create 1 super table 2 child tables and 1 normal table 2. Insert geometry data and null into above tables  3. Insert invalid geometry data into child/normal table and expect error 4. Use st_geomfromtext() to query geometry data from above tables and check the results 5. Query with invalid parameter \"POIN(1.0 1.5)\" 6. Query with invalid parameter \"LINESTRING(1.0 1.0, 2.0 2.0, 5.0 5.0,)\" 7. Query with invalid parameter \"POLYGON((3.0 6.0, 5.0 6.0, 5.0 8.0, 3.0 8.0))\" 8. Query with invalid parameter \"XXX\"                      path:                                            cases/11-Functions/07-Geometry/test_fun_geo_basic.py"},{"location":"case_list_docs/Functions/Geometry/#11-Functions.07-Geometry.test_fun_geo_basic.TestGeometry.test_fun_geo_st_astext","title":"","text":"Fun: st_astext() 1. Create 1 super table 2 child tables and 1 normal table 2. Insert geometry data and null into above tables  3. Insert invalid geometry data into child/normal table and expect error 4. Query with st_astext() on super/child/normal tables and check the results 5. Query with parameter \"NULL\" 6. Query with invalid parameter \"XXX\" 7. Query with no parameter  8. Query on not geometry datatype column                      path:                                            cases/11-Functions/07-Geometry/test_fun_geo_basic.py"},{"location":"case_list_docs/Functions/Scalar/","title":"01-Scalar","text":""},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_abs.TestFunAbs.test_fun_sca_abs","title":"","text":"Fun: abs() 1. Support types 2. Basic query 3. Boundary values 4. Filter query 5. Tag compute for scalar function 6. Check result of query 7. Check abs result of stable query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_abs.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_abs.TestFunAbs.test_fun_sca_now","title":"","text":"Fun: now() 1. Insert with now +/- and d/s/a 2. Query with where now +/- d/m/h                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_abs.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_acos.TestFunAcos.test_fun_sca_acos","title":"","text":"Fun: acos() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_acos.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_asin.TestFunAsin.test_fun_sca_asin","title":"","text":"Fun: asin() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_asin.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_atan.TestFunAtan.test_fun_sca_atan","title":"","text":"Fun: atan() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_atan.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_cast.TestFunCast.test_fun_sca_cast","title":"","text":"Fun: cast() 1. CAST on super table and normal table 2. CAST between all data types 3. CAST with null values 4. CAST constant operation 5. CAST with aggregation functions 6. CAST with union all 7. CAST with function embedded 8. CAST without from table 9. verify JIRA TS-5972                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_cast.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_ceil.TestFunCeil.test_fun_sca_ceil","title":"","text":"Fun: ceil() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_ceil.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_char_length.TestCharLength.test_char_length","title":"","text":"Fun: char_length() 1. char_length with conditions on character columns 2. char_length with conditions on non-character columns 3. char_length with group by and having 4. char_length error conditions 5. char_length after wal log flush 6. char_length on stable and normal table 7. char_length with null values 8. char_length with upper function 9. char_length with cast function 10. char_length with different data types 11. char_length with boundary values 12. char_length with multiple table types 13. char_length with various data distributions 14. char_length with different timestamp formats 15. char_length with special characters in strings                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_char_length.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_concat.TestFunConcat.test_fun_sca_concat","title":"","text":"Fun: concat() 1. CONCAT on super/child/normal table 2. CONCAT between all data types 3. CONCAT with null values 4. CONCAT with different number of columns 5. CONCAT with negative test cases 6. CONCAT with chinese language                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_concat.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_concat2.TestConcat2.test_fun_sca_concat2","title":"","text":"Fun: concat() extend 1. Create super table and child tables 2. Insert data with null/chinese/single char values 3. Query with different concat conditions 4. Check the query result 5. Flush database and re-check the result 6. Clean up the environment                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_concat2.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_concat_ws.TestFunConcatWs.test_fun_sca_concat_ws","title":"","text":"Fun: concat_ws() 1. CONCAT_WS on super/child/normal table 2. CONCAT_WS between all data types 3. CONCAT_WS with null values 4. CONCAT_WS with different number of columns 5. CONCAT_WS with negative test cases                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_concat_ws.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_cos.TestFunCos.test_fun_sca_cos","title":"","text":"Fun: cos() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_cos.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_floor.TestFunFloor.test_fun_sca_floor","title":"","text":"Fun: floor() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_floor.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_length.TestFunLength.test_fun_sca_length","title":"","text":"Fun: length() 1. LENGTH on super/child/normal table 2. LENGTH between all data types 3. LENGTH with null values 4. LENGTH constant operation 5. LENGTH with invalid parameters                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_length.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_log.TestFunLog.test_fun_sca_log","title":"","text":"Fun: log() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_log.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_lower.TestFunLower.test_fun_sca_lower","title":"","text":"Fun: lower() 1. LOWER on super/child/normal table 2. LOWER between all data types 3. LOWER with null values 4. LOWER constant operation 5. LOWER with invalid parameters                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_lower.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_ltrim.TestFunLtrim.test_fun_sca_ltrim","title":"","text":"Fun: ltrim() 1. LTRIM on super/child/normal table 2. LTRIM between all data types 3. LTRIM with null values 4. LTRIM constant operation 5. LTRIM with invalid parameters                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_ltrim.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_now.TestNow.test_Now","title":"","text":"Fun: now() 1. Now with insert clause 2. Now with select clause 3. Now with where clause 4. Now with time arithmetic 5. Now with different precisions 6. Now with error values                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_now.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_pow.TestPow.test_pow","title":"","text":"Fun: pow() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Super/child/normal table query 7. Query with partition by 8. Nest query 9. Mix with other functions 10. Input invalid parameter                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_pow.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_round.TestFunRound.test_fun_sca_round","title":"","text":"Fun: round() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_round.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_rtrim.TestFunRtrim.test_fun_sca_rtrim","title":"","text":"Fun: rtrim() 1. RTRIM on super/child/normal table 2. RTRIM between all data types 3. RTRIM with null values 4. RTRIM constant operation 5. RTRIM with invalid parameters                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_rtrim.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_sin.TestFunSin.test_fun_sca_sin","title":"","text":"Fun: sin() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_sin.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_sqrt.TestFunSqrt.test_fun_sca_sqrt","title":"","text":"Fun: sqrt() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_sqrt.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_stateduration.TestFunctionStateduration.test_function_stateduration","title":"","text":"Fun: stateduration() 1. Query with support types 2. Query with support operators 3. Query with empty table 4. Unique with super tags 5. Unique with common column 6. Unique with scalar function 7. Unique with filter where 8. Unique with union all 9. Unique with join 10. Nest query 11. Check boundary values 12. Check unit time 13. Check errors                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_stateduration.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_substr.TestFunSubstr.test_fun_sca_substr","title":"","text":"Fun: substr() 1. SUBSTR on super/child/normal table 2. SUBSTR between all data types 3. SUBSTR with null values 4. SUBSTR constant operation 5. SUBSTR with invalid parameters                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_substr.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_tan.TestFunTan.test_fun_sca_tan","title":"","text":"Fun: tan() 1. Support types 2. Basic query 3. Big number query 4. Boundary query 5. Filter query 6. Stable table query 7. Error query                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_tan.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_timediff.TestFunTimediff.test_fun_sca_timediff","title":"","text":"Fun: timediff() 1. Constant timestamp test 2. Normal table test 3. Super table test 4. Without unit test 5. Multi-res parameters test                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_timediff.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_timetruncate.TestFunTimetruncate.test_fun_sca_timetruncate","title":"","text":"Fun: timetruncate() 1. Query from normal/child/super/without table 2. Query from ns/us/ms precision database 3. Query from different unit time character 4. Consider the influence of timezone 5. Query from different timestamp format, such as string/unix timestamp 6. Query Error unit time character                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_timetruncate.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_timezone.TestFunTimezone.test_fun_sca_timezone","title":"","text":"Fun: timezone() 1. Check show local/dnode variables timezone 2. Check timezone() function on normal table/stable/child table 3. Check timezone format when insert data                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_timezone.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_iso8601.TestFunToIso8601.test_fun_sca_to_iso8601","title":"","text":"Fun: to_iso8601() 1. Query from child/normal/super/without table 2. Query from ns/us/ms precision database 3. Query with different time format string 4. Query with different timezone string 5. Query with null value 6. Query with wrong parameter 7. Input parameter with now()/today()/null/constant/timestamp field                           path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_iso8601.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_iso8601.TestFunToIso8601.test_fun_sca_today","title":"","text":"Fun: today() 1. Insert normal/child table with now and today values 2. Query with input parameter of to_iso8601 function 3. Query in select/ where clause                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_iso8601.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_json.TestJsonTag.test_fun_sca_to_json","title":"","text":"Fun: to_json() 1. Create json tag on super table 2. Insert json tag with different data type 3. Query using to_json function with null/{\"abc\":123}/{\"key\"} parameter 4. Check query result right                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_json.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_timestamp.TestFuncToTimestamp.test_func_sca_to_timestamp","title":"","text":"Fun: to_timestamp() 1. Query from child/super/without table 2. Query from ns/us/ms precision database 3. Query from different timestamp format 4. Query Error timestamp format string                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_timestamp.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_timestamp.TestFuncToTimestamp.test_fun_sca_to_char","title":"","text":"Fun: to_char() 1. Support data types 2. Query with 'yyyy-mm-dd hh:mi:ss.ns' 3. Query with 'yyyy-mm-dd' 4. Query with 'yyyy-mm-dd hh:mi:ss.ns' 5. Query with 'yy-mon-dd hh24:mi:ss.msa.m.TZH Day' 6. Query on super/no table                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_timestamp.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_to_unixtimestamp.TestFunToUnixtimestamp.test_fun_sca_to_unixtimestamp","title":"","text":"Fun: to_unixtimestamp() 1. Query from normal/super/without table 2. Query from boundary timestamp 3. Query from different time zone string 4. Query Error timestamp format string                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_to_unixtimestamp.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_today.TestFunToday.test_fun_sca_today","title":"","text":"Fun: today() 1. Query from normal/super table 2. Query from ms/us/ns precision database 3. Query from where condition 4. Query Error parameter                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_today.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_fun_sca_upper.TestUpper.test_fun_sca_upper","title":"","text":"Fun: upper() 1. Query from super/child/normal table 2. Query from cast covert result 3. Query from group condition 4. Query Error parameter 5. Query after flush database                      path:                                            cases/11-Functions/01-Scalar/test_fun_sca_upper.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_salar_function","title":"","text":"Scalar: All test math function pi, round, exp, truncate, ln, mod, sign, degrees, radians, rand, greatest, least test char function char_length, char, ascii, position, replace, repeat, substr, substr_idx, trim test time function timediff, week, weekday, weekofyear, dayofweek                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_degrees","title":"","text":"Fun: degrees() 1. Support datatype types 2. Query with constant parameter 3. Query with function parameter (abs/sin/cos) 4. Query with limit 5. Query with order by 6. Query with null value 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_exp","title":"","text":"Fun: exp() 1. Support datatype types 2. Query with constant/boundary/null/expr parameter 3. Query with function parameter (abs/log/round) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_greatest","title":"","text":"Fun: greatest() 1. Support data types 2. Query with constant/boundary/null/chinese/now parameter 3. Query with function parameter (cast) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_least","title":"","text":"Fun: least() 1. Support data types 2. Query with constant/boundary/null/chinese/now parameter 3. Query with function parameter (cast) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_ln","title":"","text":"Fun: ln() 1. Support data types 2. Query with constant/boundary/null/chinese/now parameter 3. Query with function parameter (cast) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_mod","title":"","text":"Fun: mod() 1. Support data types 2. Query with constant/boundary/null/chinese/now parameter 3. Query with function parameter (cast) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_pi","title":"","text":"Fun: pi() 1. Support data types 2. Query with constant/boundary/null/chinese/now parameter 3. Query with function parameter (cast) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_radians","title":"","text":"Fun: radians() 1. Support data types 2. Query with constant/boundary/null parameter 3. Query with function parameter (sqrt/degrees) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_rand","title":"","text":"Fun: rand() 1. Support data types 2. Query with constant/boundary/null/big parameter 3. Query with limit 4. Query with order by 5. Query on stable/notable 6. Query on where clause                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_sign","title":"","text":"Fun: sign() 1. Support data types 2. Query with constant/boundary/null parameter 3. Query with function parameter (sqrt/abs/round/log) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with string parameter 9. Error query with two parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_truncate","title":"","text":"Fun: truncate() 1. Support data types 2. Query with constant/boundary/null parameter 3. Query with function parameter (exp/abs/log) 4. Query with limit 5. Query with order by 6. Query on stable/notable 7. Query like TRUNCATE(TRUNCATE(TRUNCATE(... 8. Error query with no parameter 9. Error query with string parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_crc32","title":"","text":"Fun: crc32() 1. Support data types 2. Query with constant/null/blank/chinese parameter 3. Query with function parameter (to_timestamp/to_char) 4. Query with float/int/expr parameter 5. Error query with no parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_base64","title":"","text":"Fun: base64() 1. Support data types 2. Query with constant/boundary/null/blank/chinese parameter 3. Query with function parameter (trim/repeat/concat/lower) 4. Error query with no parameter 5. Error query with number parameter 6. Error query with cast as integer parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_ascii","title":"","text":"Fun: ascii() 1. Support data types 2. Query with constant/null/blank/special char/chinese parameter 3. Query with input parameter cast/concat/substring 4. Query with output parameter pow/sqrt/cast 5. Query with limit/order by 6. Query on super/no table 7. Error query with no parameter 8. Error query with number parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_char","title":"","text":"Fun: char() 1. Support data types 2. Query with constant/null/string/float/int/expr parameter 3. Query with output parameter concat/cast 4. Query with 1 ~ 5 parameter 5. Query with limit/order by 6. Query on super/no table 7. Error query with no parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_char_length","title":"","text":"Fun: char_length() extend 1. Support data types 2. Query with constant/null/blank/chinese/japanese parameter 3. Query with input parameter concat/cast 4. Query with output parameter sqrt/cast/min/max/avg 5. Query with limit/order by/group by/ 6. Query on super/child/no table 7. Error query with no parameter 8. Error query with number parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_position","title":"","text":"Fun: position() 1. Support datatype varchar/nchar 2. Query with constant/null/blank/expr parameter 3. Call in function abs/pow 4. Call with function input substring/trim/upper/concat  5. Query with limit/order by 6. Query on stable/notable 7. Error query with no parameter 8. Error query with 1 parameter 9. Error query with number parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_repeat","title":"","text":"Fun: repeat() 1. Support datatype varchar/nchar 2. Query with first parameter null or second parameter null 3. Call in function concat/concat_ws/position 4. Call with function input trim/concat/length 5. Query with limit/order by/where 6. Query on stable/notable 7. Query on column/tag 8. Error query with no parameter 9. Error query with 1 and 3 parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_replace","title":"","text":"Fun: replace() 1. Support datatype varchar/nchar 2. Query with first and second parameter null 3. Call with function input lower/substr/concat/upper/trim 4. Query with limit/order by/where 5. Query on stable/notable 6. Query on column/tag/constant 7. Error query with no parameter 8. Error query with invalid datatype parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_substr","title":"","text":"Fun: substr() 1. Support datatype varchar/nchar 2. Query with 1 ~ 3 parameter null 3. Query with from/for keyword 4. Call with function input concat/upper/trim/sign 5. Query with limit/order by/where 6. Query on stable/notable 7. Query on column/tag/constant 8. Query with alias name substring 9. Error query with no parameter 10. Error query with invalid datatype parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_substring_index","title":"","text":"Fun: substring_index() 1. Support datatype varchar/nchar 2. Query with 1 ~ 3 parameter null 3. Call with function input concat/upper/trim/length 4. Query with limit/order by/where 5. Query on stable/child/notable 6. Error query with no parameter 7. Error query with first parameter number 8. Error query with second parameter string                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_trim","title":"","text":"Fun: trim() 1. Support data types varchar/nchar 2. Query with keyword both/leading/trailing/from 3. Query with constant/null/chinese parameter 4. Query with input function parameter concat/upper/substring/replace 5. Query with limit/order by asc/where 6. Query on super/child/no table 7. Error query with no parameter 8. Error query with number parameter 9. Error query with both from with number parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_date","title":"","text":"Fun: date() 1. Support data type timestamp/bigint/float 2. Query with group by 3. Query with null/boundary/0/-1000 parameter 4. Query with parameter \"9999-12-31\"/\"01-JAN-25\"/\"#$@!+-*/\"/\"abcd\" 5. Query with limit/order by asc/where 6. Query on super/no table 7. Error query with no parameter 8. Error query with invalid parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_dayofweek","title":"","text":"Fun: dayofweek() 1. Support data types timestamp/varchar/bigint 2. Query with null/'9999-12-31'/'01-JAN-20'/'abc' parameter 3. Query with input parameter timediff 4. Query with output parameter sum 5. Query with limit/order by/group by 6. Query on super/child/no table 7. Error query with no parameter 8. Error query with 2 parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_week","title":"","text":"Fun: week() 1. Support data types timestamp/varchar/bigint 2. Query with null/'abc'/'01-JAN-20'/'9999-12-31' parameter 3. Query with second parameter mode 0/1/2/3/4/5/6/7 4. Query with input parameter timediff 5. Query with output parameter sum 6. Query with limit/order by/group by 7. Query on super/child/no table 8. Error query with no parameter 9. Error query with no input first parameter 10. Error query with input second float parameter                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_weekday","title":"","text":"Fun: weekday() 1. Support data types timestamp/varchar/bigint 2. Query with null/'abc'/'01-JAN-20'/'9999-12-31' parameter 3. Query with input parameter timediff 4. Query with output parameter sum 5. Query with limit/order by/group by 6. Query on super/child/no table 7. Error query with no parameter 8. Error query with 2 parameters                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_all.TestScalarFunction.test_fun_sca_weekofyear","title":"","text":"Fun: weekofyear() 1. Support data types timestamp/varchar/bigint 2. Query with null/'abc'/'11/01/31'/'01-JAN-20'/'9999-12-31' parameter 3. Query with input parameter timediff 4. Query with output parameter sum 5. Query with limit/order by/group by/where 6. Query on super/child/no table 7. Error query with no parameter 8. Error query with 2 parameters                      path:                                            cases/11-Functions/01-Scalar/test_scalar_all.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_math.TestMath.test_math","title":"","text":"Scalar: Math Test mathematical functions, including abs, log, pow, sqrt, sin, cos, tan, asin, acos, atan, ceil, floor, round.                      path:                                            cases/11-Functions/01-Scalar/test_scalar_math.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_string.TestString.test_string","title":"","text":"Scalar: String Test string functions, including Char_length, lower, upper, ltrim, rtrim, concat, and concat_ws.                      path:                                            cases/11-Functions/01-Scalar/test_scalar_string.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_string.TestString.test_fun_sca_find_in_set","title":"","text":"Fun: find_in_set() 1. Support data types varchar/nchar 2. Query with constant/null/single char/chinese parameter 3. Query with different separator 4. Query from normal/no table 5. Query with 2 ~ 3 parameters                      path:                                            cases/11-Functions/01-Scalar/test_scalar_string.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_string.TestString.test_fun_sca_like_in_set","title":"","text":"Fun: like_in_set() 1. Support data types varchar/nchar 2. Query with constant/null/single char/special char/chinese parameter 3. Query with different separator 4. Query from normal/no table 5. Query with 2 ~ 3 parameters                      path:                                            cases/11-Functions/01-Scalar/test_scalar_string.py"},{"location":"case_list_docs/Functions/Scalar/#11-Functions.01-Scalar.test_scalar_time.TestTime.test_time","title":"","text":"Scalar: Time Test time functions, including TIMETRUNCATE, TIMEDIFF, and their combined usage.                      path:                                            cases/11-Functions/01-Scalar/test_scalar_time.py"},{"location":"case_list_docs/Functions/Scalar/#80-Components.10-TDgpt.test_tdgpt.TestTDgptBasic.test_fun_sca_corr","title":"","text":"Fun: corr() 1. Query with int and float data type parameter 2. Query with constant/null/bool parameter 3. Query with corr(cast(... 4. Query on super/child/no table                      path:                                            cases/80-Components/10-TDgpt/test_tdgpt.py"},{"location":"case_list_docs/Functions/Selection/","title":"03-Selection","text":""},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_bottom.TestBottom.test_func_select_bottom","title":"","text":"Fun: bottom() 1. Sim case 2. Query on all data types 3. Input parameter with different values 4. Query on stable/normal table 5. Query on null data 6. Query on where clause 7. Query with filter 8. Error check                      path:                                            cases/11-Functions/03-Selection/test_fun_select_bottom.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_cols.TestFunCols.test_func_select_cols","title":"","text":"Fun: cols() 1. Basic query for input different params 2. Query on super/child/normal/empty table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group/partition by/having/order by 7. Query with tags 8. Query with join/union/nest/interval/window 9. Check null value 10. Check single/multi output                      path:                                            cases/11-Functions/03-Selection/test_fun_select_cols.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_first.TestFunFirst.test_func_select_first","title":"","text":"Fun: first() 1. Sim case 2. Query on all data types 3. Input parameter with different values 4. Query on stable/normal table 5. Query on null data 6. Query on where clause 7. Query with filter 8. Error check                      path:                                            cases/11-Functions/03-Selection/test_fun_select_first.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_first_last.TestFunSelectFirstLast.test_first_last_window","title":"","text":"First Last with All Windows 1. select list only contains first, last and     _select_value functions with **INTERVAL** window 2. select list only contains first, last and     _select_value functions with **STATE** window 3. select list only contains first, last and     _select_value functions with **SESSION** window 4. select list only contains first, last and     _select_value functions with **EVENT** window 5. select list only contains first, last and     _select_value functions with **COUNT** window                      path:                                            cases/11-Functions/03-Selection/test_fun_select_first_last.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_last.TestFunLast.test_func_select_last","title":"","text":"Fun: last() 1. Perform Last queries on child tables and supertables. 2. Test time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 3. Test Last LRU (insufficient memory, multiple VGroups, complex queries). 4. Test scenarios where LAST() return multiple rows of data. 5. Test last_row, last function support 520 parameters.                      path:                                            cases/11-Functions/03-Selection/test_fun_select_last.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_last_row.TestFunLastRow.test_func_select_last_row","title":"","text":"Fun: last_row() 1. Including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Set cacheModel = both and retest. 3. Query on super/child/normal table 4. Support types 5. Error cases 6. Query with filter conditions 7. Query with group by 8. Query with empty table 9. Query with subquery 10. Query with 512 parameters 11. Check boundary values                      path:                                            cases/11-Functions/03-Selection/test_fun_select_last_row.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_max.TestFunMax.test_func_agg_max","title":"","text":"Fun: max() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group by 7. Query with distribute aggregate 8. Check function status                      path:                                            cases/11-Functions/03-Selection/test_fun_select_max.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_min.TestFunMin.test_func_agg_min","title":"","text":"Fun: min() 1. Sim case including time windows, filtering on ordinary data columns, filtering on tag columns, GROUP BY, and PARTITION BY. 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group by 7. Query with distribute aggregate 8. Check function status                      path:                                            cases/11-Functions/03-Selection/test_fun_select_min.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_mode.TestMode.test_func_select_mode","title":"","text":"Fun: mode() 1. Query with basic params 2. Query on super/child/normal table 3. Support types 4. Check null value                      path:                                            cases/11-Functions/03-Selection/test_fun_select_mode.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_tail.TestFunTail.test_func_select_tail","title":"","text":"Fun: tail() 1. Basic query for input different params 2. Query on super/child/normal/empty table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group/partition by 7. Query with tags 8. Query with join/union/nest 9. Boundary values                      path:                                            cases/11-Functions/03-Selection/test_fun_select_tail.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_top.TestSelectTop.test_func_select_top","title":"","text":"Fun: top() 1. Sim case 2. Query on all data types 3. Input parameter with different values 4. Query on stable/normal table 5. Query on null data 6. Query on where clause 7. Query with filter 8. Error check                      path:                                            cases/11-Functions/03-Selection/test_fun_select_top.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_fun_select_unique.TestUnique.test_func_select_unique","title":"","text":"Fun: unique() 1. Basic query for input different params 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with filter conditions 6. Query with group/partition/order by 7. Query with tags 8. Query with join/union/nest/interval/window 9. Check null value 10. Check boundary values                      path:                                            cases/11-Functions/03-Selection/test_fun_select_unique.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_all.TestSelectFunction.test_select_function","title":"","text":"Select: all test select function max, min                      path:                                            cases/11-Functions/03-Selection/test_select_all.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_bugs.TestSelectBugs.test_select_bugs","title":"","text":"Select function bugs 1. Verify bug TD-19201 (max function obtain float max value error) 2. Verify bug TS-3581 (first function return 0 randomly)                      path:                                            cases/11-Functions/03-Selection/test_select_bugs.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_last_and_last_row.TestFuncLast.test_last_as_operator_param","title":"","text":"Select: keepColumnName Test that 'last(col) - first(col)' is not equal to zero when keepColumnName is 1. Steps: 1. Create a database and a stable table. 2. Create sub-tables and insert data where the first and last values are different. 3. Set 'alter local 'keepColumnName' '1''. 4. Execute 'select last(tbcol) - first(tbcol) from stable_table group by tgcol'. 5. Verify that the result is the difference between the last and first value, which is not zero.                      path:                                            cases/11-Functions/03-Selection/test_select_last_and_last_row.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_last_and_last_row.TestFuncLast.test_last_as_func_param","title":"","text":"Select: keepColumnName first/last Steps: 1. Create a database and a stable table. 2. Create sub-tables and insert data where the first and last timestamps are different. 3. Set 'alter local 'keepColumnName' '1''. 4. Execute 'select timediff(last(ts), first(ts)) from stable_table group by tgcol'. 5. Verify that the result is the difference between the last and first timestamp, which is not zero.                      path:                                            cases/11-Functions/03-Selection/test_select_last_and_last_row.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_last_and_last_row.TestFuncLast.test_last_row_interval","title":"","text":"Last row interval 1. Query last row on super/normal table  2. Query last row with interval and sliding 3. Query last row with where condition 4. Query last row with time range condition 5. Query last row with mixed conditions 6. Query last row on multiple tables 7. Verify the results                      path:                                            cases/11-Functions/03-Selection/test_select_last_and_last_row.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_last_model.TestLastModel.test_select_last_model","title":"","text":"Last Row/Last model 1. Check none model 2. Check last Value model 3. Check Last Row model 4. Check Both model 5. Check explain plan 6. Check last/last row model on nested                      path:                                            cases/11-Functions/03-Selection/test_select_last_model.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_minmaxlast_interval.TestMaxMinLastInterval.test_max_min_last_interval","title":"","text":"Select min/max/last interval 1. Insert 1500 rows random data 2. Get min/max/last value for expect 3. Query min/max/last with interval(1d) 4. Compare query result with expect                      path:                                            cases/11-Functions/03-Selection/test_select_minmaxlast_interval.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_with_520_cols.TestSelect520Paras.test_select_520_cols","title":"","text":"Select: with 520 columns test last_row, first, last function support 520 parameters                      path:                                            cases/11-Functions/03-Selection/test_select_with_520_cols.py"},{"location":"case_list_docs/Functions/Selection/#11-Functions.03-Selection.test_select_with_json.TestSelectWithJson.test_select_with_json","title":"","text":"Select: with json params test select function with json params                      path:                                            cases/11-Functions/03-Selection/test_select_with_json.py"},{"location":"case_list_docs/Functions/System/","title":"06-System","text":""},{"location":"case_list_docs/Functions/System/#11-Functions.06-System.test_fun_sys_info.TestSysinfo.test_fun_sys_client_version","title":"","text":"Fun: client_version() 1. Get td_version value from version.c 2. Compare with the result of client_version()                      path:                                            cases/11-Functions/06-System/test_fun_sys_info.py"},{"location":"case_list_docs/Functions/System/#11-Functions.06-System.test_fun_sys_info.TestSysinfo.test_fun_sys_server_version","title":"","text":"Fun: server_version() 1. Get td_version value from version.c 2. Compare with the result of server_version()                      path:                                            cases/11-Functions/06-System/test_fun_sys_info.py"},{"location":"case_list_docs/Functions/System/#11-Functions.06-System.test_fun_sys_info.TestSysinfo.test_fun_sys_current_user","title":"","text":"Fun: current_user() 1. Query \"select current_user()\" 2. Check the result is \"root\"                      path:                                            cases/11-Functions/06-System/test_fun_sys_info.py"},{"location":"case_list_docs/Functions/System/#11-Functions.06-System.test_fun_sys_info.TestSysinfo.test_fun_sys_database","title":"","text":"Fun: database() 1. Create database test 2. Use database test 3. Query \"select database()\" 4. Check the result is \"test\"                      path:                                            cases/11-Functions/06-System/test_fun_sys_info.py"},{"location":"case_list_docs/Functions/System/#11-Functions.06-System.test_fun_sys_info.TestSysinfo.test_fun_sys_server_status","title":"","text":"Fun: server_status() 1. taosd server is running 2. Query server status expect 1 3. Stop taosd server 4. Sleep 15 seconds 5. Query server status throw error                      path:                                            cases/11-Functions/06-System/test_fun_sys_info.py"},{"location":"case_list_docs/Functions/Timeseries/","title":"04-Timeseries","text":""},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_csum.TestCsum.test_func_ts_csum","title":"","text":"Fun: csum() 1. Basic query for input different params 2. Query on super/child/normal table 3. Support types 4. Error cases 5. Query with where condition 6. Query with group/partition/order by 7. Query with tags 8. Query with join/union/nest/interval 9. Query with limit/slimit/offset/soffset 10. Check null value 11. Check boundary values                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_csum.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_derivative.TestFunDerivative.test_func_ts_derivative","title":"","text":"Fun: derivative() 1. Basic query for different params 2. Query on super/child/normal table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 7. Query with sub query 8. Query with function nested 9. Query with limit/slimit/offset/soffset 10. Check null value                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_derivative.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_diff.TestFunDiff.test_func_ts_diff","title":"","text":"Fun: diff() 1. Sim case for LIKE, timestamp comparisons, and ordinary column comparisons. 2. Basic query for input different params 3. Query on super/child/normal table 4. Support types 5. Error cases 6. Query with where condition 7. Query with group/partition/order by 8. Query with tags 9. Query with join/union/nest/interval 10. Query with limit/slimit/offset/soffset 11. Check null value                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_diff.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_interp.TestInterp.test_func_ts_interp","title":"","text":"Fun: interp() 1. Basic query for different params 2. Query on super/child/normal/empty table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 7. Query with sub query 8. Query with union/join/fill/every/range/interval 9. Select _irowts, _irowts_origin, _isfilled 10. Check null value 11. Single INTERP query covering multiple columns                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_interp.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_irate.TestFunIrate.test_func_ts_irate","title":"","text":"Fun: irate() 1. Basic query for input different params 2. Query on super/child table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/order by 7. Query with sub query 8. Query with function nested 9. Check null value                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_irate.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_mavg.TestFunMavg.test_func_ts_mavg","title":"","text":"Fun: mavg() 1. Basic query for different params 2. Query on super/child/normal table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 7. Query with sub query 8. Query with function nested 9. Query with limit/slimit/offset/soffset 10. Check null value                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_mavg.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_sample.TestFunSample.test_func_ts_sample","title":"","text":"Fun: sample() 1. Basic query for different params 2. Query on super/child/normal table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 8. Query with union/join/range/interval 9. Query with null value 10. Query with big data                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_sample.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_statecount.TestFunStatecount.test_func_ts_statedcount","title":"","text":"Fun: statecount() 1. Basic query for different params 2. Query on super/child/normal table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 7. Query with sub query 8. Query with union/join 9. Query with unit time 10. Check null value 11. Boundary values                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_statecount.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_stateduration.TestFunStateduration.test_func_ts_stateduration","title":"","text":"Fun: stateduration() 1. Basic query for different params 2. Query on super/child/normal table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group/order by 7. Query with sub query 8. Query with union/join 9. Query with unit time 10. Check null value 11. Boundary values                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_stateduration.py"},{"location":"case_list_docs/Functions/Timeseries/#11-Functions.04-Timeseries.test_fun_ts_twa.TestTwa.test_func_ts_twa","title":"","text":"Fun: twa() 1. Basic query for different params 2. Query on super/child table 3. Support data types 4. Error cases 5. Query with where condition 6. Query with partition/group by 7. Query with sub query 8. Query with union 9. Check null value                      path:                                            cases/11-Functions/04-Timeseries/test_fun_ts_twa.py"},{"location":"case_list_docs/NodeManager/Bnode/","title":"05-Bnode","text":""},{"location":"case_list_docs/NodeManager/Bnode/#17-DataSubscription.03-MQTT.test_mqtt_rb.TestMqttCases.test_node_create_bnode","title":"","text":"Node create bnode 1. Create bnode for each dnode 2. Create database with us precision 3. Create stable with full data types 4. Create topic from stable 5. Insert data into stable 6. Subscribe topic with rawblock proto 7. Verify subscribed data 8. Drop bnodes and databases                      path:                                            cases/17-DataSubscription/03-MQTT/test_mqtt_rb.py"},{"location":"case_list_docs/NodeManager/Dnode/","title":"01-Dnode","text":""},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_alter_dnode.TestDnodeAlterDebugFlag.test_dnode_alter_debugflag","title":"","text":"Dnode alter 1. Start only one dnode 2. Modify the monitor and debugflag parameters of the online dnode 3. Modify parameters of an offline dnode (error expected)                      path:                                            cases/26-NodeManager/01-Dnode/test_alter_dnode.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_create_dnode.TestCreateDnode.test_create_dnode","title":"","text":"Dnode create 1. Create dnode2 2. Check system tables such as ins_dnodes and ins_mnodes 3. Create database tables on these two dnodes and perform basic write and query operations                      path:                                            cases/26-NodeManager/01-Dnode/test_create_dnode.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_force.TestDropDnodeForce.test_drop_dnode_force","title":"","text":"Dnode drop force unsafe 1. Create 5 dnodes, establish a three-replica database on them, and write data 2. Create three mnodes 3. Stop one dnode and verify that it cannot be deleted 4. Use drop dnode force unsafe to forcibly delete this dnode                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_force.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_mnode.TestDropDnodeHasMnode.test_drop_dnode_has_mnode","title":"","text":"Drop drop with mnode Drop the dnode containing the mnode                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_mnode.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_multi_vnode_replica1.TestDropDnodeHasMultiVnodeReplica1.test_drop_dnode_has_multi_vnode_replica1","title":"","text":"Dnode drop with replca-1 vnodes Drop the dnode containing a single-replica vnode, and test the integrity of the data after vnode migration.                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_multi_vnode_replica1.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_multi_vnode_replica3.TestDropDnodeHasMultiVnodeReplica3.test_drop_dnode_has_multi_vnode_replica3","title":"","text":"Dnode drop with replca-3 vnodes Drop the dnode containing a three-replica vnode, and test the integrity of the data after vnode migration.                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_multi_vnode_replica3.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_qnode_snode.TestDropDnodeHasQnodeSnode.test_drop_dnode_has_qnode_snode","title":"","text":"Drop drop with qnode and snode Drop the dnode containing the mnode and snode                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_qnode_snode.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_vnode_replica1.TestDropDnodeHasVnodeReplica1.test_drop_dnode_has_vnode_replica1","title":"","text":"Dnode drop with replca-1 vnode Drop the dnode containing a single-replica vnode, and test the integrity of the data after vnode migration.                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_vnode_replica1.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_drop_dnode_has_vnode_replica3.TestDropDnodeHasVnodeReplica3.test_drop_dnode_has_vnode_replica3","title":"","text":"Dnode drop with replca-3 vnode Drop the dnode containing a three-replica vnode, and test the integrity of the data after vnode migration.                      path:                                            cases/26-NodeManager/01-Dnode/test_drop_dnode_has_vnode_replica3.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_offline_reason.TestOfflineReason.test_offline_reason","title":"","text":"Dnode check offline reason Check whether the offline_reason field of the offline dnode is correct.                      path:                                            cases/26-NodeManager/01-Dnode/test_offline_reason.py"},{"location":"case_list_docs/NodeManager/Dnode/#26-NodeManager.01-Dnode.test_use_dropped_dnode.TestUseDroppedDnode.test_use_dropped_dnode","title":"","text":"Drop reuse dropped dnode Check whether it is possible to repeatedly create and delete dnodes with the same FQDN.                      path:                                            cases/26-NodeManager/01-Dnode/test_use_dropped_dnode.py"},{"location":"case_list_docs/NodeManager/Mnode/","title":"02-Mnode","text":""},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic1.TestMnodeBasic1.test_mnode_basic1","title":"","text":"Mnode create on same dnode 1. Create an mnode on the dnode2 2. Delete mnode2 3. Repeat the above operations                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic1.py"},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic2.TestMnodeBasic2.test_mnode_basic2","title":"","text":"Mnode stop all then start 1. Create an mnode on the dnode2 2. Create a user (update mnode) 3. Restart dnode1 and dnode2 4. Check if the user exists                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic2.py"},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic3.TestMnodeBasic3.test_mnode_basic3","title":"","text":"Mnode kill -9 then restart 1. Create mnodes on the second and third dnodes 2. Create a user (update mnode) 3. Kill dnode1 with kill -9 4. Check if the user exists 5. Stop dnode2 and dnode3 sequentially 6. Check service availability                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic3.py"},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic4.TestMnodeBasic4.test_mnode_basic4","title":"","text":"Mnode kill -9 then drop 1. Create mnodes on the second and third dnodes 2. Force stop dnode3 3. Start dnode3 4. Delete dnode3 5. Check service availability                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic4.py"},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic5.TestMnodeBasic5.test_mnode_basic5","title":"","text":"Mnode basic 1. Create and delete mnodes on an offline dnode - expected to fail 2. Create mnodes on a dnode that already has an mnode - expected to fail 3. Use invalid mnode creation or deletion syntax 4. Check the status of the dnode                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic5.py"},{"location":"case_list_docs/NodeManager/Mnode/#26-NodeManager.02-Mnode.test_mnode_basic6.TestMnodeBasic6.test_mnode_basic6","title":"","text":"Mnode repeatedly restart 1. Create mnodes on dnode2 and dnode3 2. Repeatedly restart dnode1 to dnode3 sequentially 3. Check service availability                      path:                                            cases/26-NodeManager/02-Mnode/test_mnode_basic6.py"},{"location":"case_list_docs/NodeManager/Qnode/","title":"03-Qnode","text":""},{"location":"case_list_docs/NodeManager/Qnode/#26-NodeManager.03-Qnode.test_qnode_basic.TestQnodeBasic1.test_qnode_basic","title":"","text":"Qnode basic 1. Repeated create and drop qnodes 2. Check the results of ins_qnodes 3. Restart the dnode and check the results of the qnode                      path:                                            cases/26-NodeManager/03-Qnode/test_qnode_basic.py"},{"location":"case_list_docs/NodeManager/Snode/","title":"04-Snode","text":""},{"location":"case_list_docs/NodeManager/Snode/#26-NodeManager.04-Snode.test_snode_basic1.TestSnodeBasic1.test_snode_basic1","title":"","text":"Snode basic 1. Repeated create and drop snodes 2. Check the results of ins_snodes 3. Restart the dnode and check the results of the snode                      path:                                            cases/26-NodeManager/04-Snode/test_snode_basic1.py"},{"location":"case_list_docs/Operators/Arithmetic/","title":"01-Arithmetic","text":""},{"location":"case_list_docs/Operators/Arithmetic/#10-Operators.01-Arithmetic.test_arithmetic.TestArithmetic.test_arithmetic","title":"","text":"Operator arithmetic 1. Arithmetic operations between data columns 2. Arithmetic operations between functions 3. Filling when the operation result is null                      path:                                            cases/10-Operators/01-Arithmetic/test_arithmetic.py"},{"location":"case_list_docs/Operators/Comparison/","title":"05-Comparison","text":""},{"location":"case_list_docs/Operators/Comparison/#10-Operators.05-Comparison.test_between_and.TestBetweenAnd.test_and_or","title":"","text":"Operator between and 1. Comparison of numeric types 2. Comparison of timestamp types 3. Multiple between and operators together 4. Boundary value for numeric types 5. Between and for tag columns 6. Invalid between and usage 7. Null value comparison 8. Mixed data types comparison                      path:                                            cases/10-Operators/05-Comparison/test_between_and.py"},{"location":"case_list_docs/Operators/Comparison/#10-Operators.05-Comparison.test_in.TestIn.test_in","title":"","text":"Operator In 1. Using IN operator with numeric types 2. Using IN operator with timestamp types 3. Using IN operator in an EXPLAIN statement                      path:                                            cases/10-Operators/05-Comparison/test_in.py"},{"location":"case_list_docs/Operators/Comparison/#10-Operators.05-Comparison.test_like.TestAndOr.test_like","title":"","text":"Operator like 1. Like in SELECT statements 2. Like in SHOW statements 3. Like in tag queries 1. Like wildcard 2. Like cnc wildcard 3. Like multi wildcard 4. Like escape character 5. Like unicode 6. Like special character 7. Like backslash 8. Like backslash and wildcard  9. Like backslash and escape character 10. Like backslash, wildcard and escape character 11. Like backslash, wildcard and cnc character 12. Like on super/child table                       path:                                            cases/10-Operators/05-Comparison/test_like.py"},{"location":"case_list_docs/Operators/Comparison/#10-Operators.05-Comparison.test_match.TestRegex.test_match","title":"","text":"Operator match Match and nmatch for regular expression matching 1. Match wildcard 2. Match cnc wildcard 3. Match error wildcard 4. Match multithread 6. Match regexp cnc wildcard 7. Match error regexp wildcard 8. Match regexp not cnc wildcard         9. Match on super/child table                      path:                                            cases/10-Operators/05-Comparison/test_match.py"},{"location":"case_list_docs/Operators/Comparison/#10-Operators.05-Comparison.test_null.TestFuncScalarNull.test_func_scalar_null","title":"","text":"Operator null 1. Usage of NULL in the IN operator 2. Comparison of NULL values 3. Operations involving NULL values                      path:                                            cases/10-Operators/05-Comparison/test_null.py"},{"location":"case_list_docs/Operators/Json/","title":"03-Json","text":""},{"location":"case_list_docs/Operators/Json/#09-DataQuerying.14-Tags.test_tag_json.TestSelectWithJsonTags.test_select_with_json_tags","title":"","text":"Operator json 1. Create db 2. Create supper table with json data-type tag 3. Create child table with json tag values 4. Query with json operators 5. Check the result value correctly                      path:                                            cases/09-DataQuerying/14-Tags/test_tag_json.py"},{"location":"case_list_docs/Operators/Logical/","title":"06-Logical","text":""},{"location":"case_list_docs/Operators/Logical/#10-Operators.06-Logical.test_and_or.TestAndOr.test_and_or","title":"","text":"Logical and &amp; or &amp; in 1. And or with super table tags and columns 2. And or with normal table columns 3. And or with abs function 4. And or with boundary values 5. And or for byte 6. In on select clause 7. Is null / is not null on select clause 8. Between and on select clause 9. Not on select clause 10.In and not in on where clause 11.Query with timezone                      path:                                            cases/10-Operators/06-Logical/test_and_or.py"},{"location":"case_list_docs/Operators/Logical/#10-Operators.06-Logical.test_and_or_coltag.TestQueryColsTagsAndOr.test_and_or_coltag","title":"","text":"Logical and &amp; or on col and tag 1. And/or on various data types of columns in ordinary table 2. And/or on various data types of tags in super table 3. And/or on timestamp and columns in ordinary table 4. And/or on join clauses                      path:                                            cases/10-Operators/06-Logical/test_and_or_coltag.py"},{"location":"case_list_docs/Operators/Logical/#10-Operators.06-Logical.test_if_smoking.TestIfSmoking.test_if_smoking","title":"","text":"If 1. Using in data columns and scalar functions within SELECT statements 2. Using in data columns within WHERE conditions 3. Using in data columns within GROUP BY statements 4. Using in data columns within STATE WINDOW 5. Using in aggregate functions while including the IS NULL operator                      path:                                            cases/10-Operators/06-Logical/test_if_smoking.py"},{"location":"case_list_docs/Operators/Logical/#10-Operators.06-Logical.test_logical_bugs.TestOperator.test_operator","title":"","text":"Logical bugs 1. Jira TD-5757:      - Logical operator with IS NULL/IS NOT NULL and IN/NOT IN returns incorrect results 2. Jira TD-5760:      - Arithmetic operations on TIMESTAMP with negative numbers yield incorrect results 3. Jira TD-5758:      - Combining IN operator with BETWEEN clause yields incorrect results 4. Jira TD-5759:      - Combining BETWEEN clause with logical operators yields incorrect results 5. Jira TD-5823:      - Arithmetic operations on TIMESTAMP with various numeric data types yield incorrect results 6. Validate arithmetic operations on TIMESTAMP with different numeric data types:     - INT, BIGINT, SMALLINT, TINYINT, FLOAT, DOUBLE, etc.                              path:                                            cases/10-Operators/06-Logical/test_logical_bugs.py"},{"location":"case_list_docs/Operators/Set/","title":"04-Set","text":""},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_basic.TestUnionBasic.test_union_basic","title":"","text":"Operator union basic 1. Union of projection queries 2. Union of queries containing window and aggregate functions 3. Union of system table queries 4. Union of queries from databases with different precision levels 5. Union of same/diff limit 6. Union of three select clause 7. Union of order by                      path:                                            cases/10-Operators/04-Set/test_union_basic.py"},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_bugs.TestUnionBugs.test_ts6660","title":"","text":"Operator union order by 1. Create 1 database 1 stable 2 subtables 2. Insert data into 2 subtables 1 rows each 3. Use union operator to combine the result from 2 subtables 4. Use order by pseudo columns tbname, _wstart in union query 5. Use number column in order by clause in union query 6. Check error when order by column is not in select columns in union query                      path:                                            cases/10-Operators/04-Set/test_union_bugs.py"},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_bugs.TestUnionBugs.test_setOp_orderBy_pseudo","title":"","text":"Operator union 1. Create 1 database 1 stable 3 subtables 2. Insert data into 3 subtables 1 rows each 3. Use union operator to combine the result from 3 subtables 4. Use order by pseudo columns tbname, _wstart in union query                      path:                                            cases/10-Operators/04-Set/test_union_bugs.py"},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_bugs.TestUnionBugs.test_setOp_orderby_normal_func","title":"","text":"Operator union order by functions 1. Create 1 database 1 stable 3 subtables 2. Insert data into 3 subtables 1 rows each 3. Use union operator to combine the result from 3 subtables 4. Use normal functions abs(), ltrim(), lower() in order by clause in union query                      path:                                            cases/10-Operators/04-Set/test_union_bugs.py"},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_bugs.TestUnionBugs.test_setOp_with_const_condition","title":"","text":"union with const condition test for 'where 1=0' condition in UNION                      path:                                            cases/10-Operators/04-Set/test_union_bugs.py"},{"location":"case_list_docs/Operators/Set/#10-Operators.04-Set.test_union_bugs.TestUnionBugs.test_union_bugs","title":"","text":"Operator union bugs 1. JIRA TD-5630: Support UNION ALL operation for time-series data query 2. JIRA TD-33137: Fix UNION ALL query bugs 3. Add test case for nodes match node in UNION ALL query                      path:                                            cases/10-Operators/04-Set/test_union_bugs.py"},{"location":"case_list_docs/StreamProcessing/Compatibility/","title":"23-Compatibility","text":""},{"location":"case_list_docs/StreamProcessing/Compatibility/#18-StreamProcessing.23-Compatibility.test_compatibility_backward_forward.TestStreamCompatibility.test_stream_compatibility","title":"","text":"Comp: stream backward and forward Test compatibility across 5 baseline versions with stream processing validation: 1. Test [v3.2.0.0 Base Version Compatibility]     1.1 Install v3.2.0.0 and prepare data using tdCb.prepareDataOnOldVersion()         1.1.1 Create test databases and tables with taosBenchmark         1.1.2 Insert sample data and create streams         1.1.3 Setup TMQ topics and consumers         1.1.4 Verify stream functionality on v3.2.0.0     1.2 Upgrade to new version with mode 2 (no upgrade mode)         1.2.1 Kill all dnodes and update to new version         1.2.2 Start new version with existing data         1.2.3 Verify cross-major version compatibility (corss_major_version=True)     1.3 Verify data and functionality using tdCb.verifyData()         1.3.1 Check table counts and row counts consistency         1.3.2 Verify stream processing functionality         1.3.3 Test TMQ consumer operations         1.3.4 Validate aggregation results accuracy 2. Test [v3.3.3.0 Base Version Compatibility]     2.1 Install v3.3.3.0 and prepare data using tdCb.prepareDataOnOldVersion()         2.1.1 Create test databases and tables with taosBenchmark         2.1.2 Insert sample data and create streams         2.1.3 Setup TMQ topics and consumers         2.1.4 Verify stream functionality on v3.3.3.0     2.2 Upgrade to new version with mode 2 (no upgrade mode)         2.2.1 Kill all dnodes and update to new version         2.2.2 Start new version with existing data         2.2.3 Verify compatibility (corss_major_version=True)     2.3 Verify data and functionality using tdCb.verifyData()         2.3.1 Check table counts and row counts consistency         2.3.2 Verify stream processing functionality         2.3.3 Test TMQ consumer operations         2.3.4 Validate aggregation results accuracy 3. Test [v3.3.4.3 Base Version Compatibility]     3.1 Install v3.3.4.3 and prepare data using tdCb.prepareDataOnOldVersion()         3.1.1 Create test databases and tables with taosBenchmark         3.1.2 Insert sample data and create streams         3.1.3 Setup TMQ topics and consumers         3.1.4 Verify stream functionality on v3.3.4.3     3.2 Upgrade to new version with mode 2 (no upgrade mode)         3.2.1 Kill all dnodes and update to new version         3.2.2 Start new version with existing data         3.2.3 Verify compatibility (corss_major_version=True)     3.3 Verify data and functionality using tdCb.verifyData()         3.3.1 Check table counts and row counts consistency         3.3.2 Verify stream processing functionality         3.3.3 Test TMQ consumer operations         3.3.4 Validate aggregation results accuracy 4. Test [v3.3.5.0 Base Version Compatibility]     4.1 Install v3.3.5.0 and prepare data using tdCb.prepareDataOnOldVersion()         4.1.1 Create test databases and tables with taosBenchmark         4.1.2 Insert sample data and create streams         4.1.3 Setup TMQ topics and consumers         4.1.4 Verify stream functionality on v3.3.5.0     4.2 Upgrade to new version with mode 2 (no upgrade mode)         4.2.1 Kill all dnodes and update to new version         4.2.2 Start new version with existing data         4.2.3 Verify compatibility (corss_major_version=True)     4.3 Verify data and functionality using tdCb.verifyData()         4.3.1 Check table counts and row counts consistency         4.3.2 Verify stream processing functionality         4.3.3 Test TMQ consumer operations         4.3.4 Validate aggregation results accuracy 5. Test [v3.3.6.0 Base Version Compatibility - Final]     5.1 Install v3.3.6.0 and prepare data using tdCb.prepareDataOnOldVersion()         5.1.1 Create test databases and tables with taosBenchmark         5.1.2 Insert sample data and create streams         5.1.3 Setup TMQ topics and consumers         5.1.4 Verify stream functionality on v3.3.6.0     5.2 Upgrade to new version with mode 2 (no upgrade mode)         5.2.1 Kill all dnodes and update to new version         5.2.2 Start new version with existing data         5.2.3 Verify compatibility (corss_major_version=False as final version)     5.3 Verify data and functionality using tdCb.verifyData()         5.3.1 Check table counts and row counts consistency         5.3.2 Verify stream processing functionality         5.3.3 Test TMQ consumer operations         5.3.4 Validate aggregation results accuracy 6. Test [SQL Syntax Compatibility Verification]     6.1 Test backticks in SQL using tdCb.verifyBackticksInTaosSql()         6.1.1 Test database operations with backticks         6.1.2 Test table operations with backticks         6.1.3 Test stream operations with backticks         6.1.4 Verify error handling for invalid backtick usage                      path:                                            cases/18-StreamProcessing/23-Compatibility/test_compatibility_backward_forward.py"},{"location":"case_list_docs/StreamProcessing/Compatibility/#18-StreamProcessing.23-Compatibility.test_compatibility_cross_version.TestStreamCompatibility.test_stream_compatibility","title":"","text":"Comp: stream cross-version Test stream processing and TSMA compatibility across 4 base versions with actual stream/TSMA creation and verification: 1. Test [v3.3.3.0 Version Compatibility]     1.1 Install v3.3.3.0 enterprise package and create old format streams and TSMAs         1.1.1 Create avg_stream: INTERVAL(5s) aggregation on meters table         1.1.2 Create max_stream: trigger at_once with MAX aggregation by tbname         1.1.3 Create count_stream: INTERVAL(10s) with WHERE voltage &gt; 10 filter         1.1.4 Create tsma_meters: 1-minute TSMA with avg(voltage), max(current), min(voltage), count(ts)         1.1.5 Create tsma_meters_hourly: 1-hour TSMA with avg(voltage), max(current), min(current), count(ts)         1.1.6 Create tsma_meters_detail: 30-second TSMA with sum(voltage), avg(current), max(phase), min(phase)     1.2 Verify new version startup behavior with old streams and TSMAs         1.2.1 Attempt to start new version (should fail due to incompatible streams/TSMAs)         1.2.2 Verify stream and TSMA incompatibility detection     1.3 Clean up old streams/TSMAs and create new format streams         1.3.1 Drop all old format streams and TSMAs before database cleanup         1.3.2 Create s_interval: INTERVAL(5s) SLIDING(5s) with trigger/source separation         1.3.3 Create s_count: COUNT_WINDOW(5) with %%trows reference         1.3.4 Create s_period: PERIOD(30s) with cross-database computation         1.3.5 Create s_session: SESSION(ts, 5s) with window boundary functions 2. Test [v3.3.4.0 Version Compatibility]     2.1 Install v3.3.4.0 enterprise package and create old format streams and TSMAs         2.1.1 Create avg_stream: INTERVAL(5s) aggregation on meters table         2.1.2 Create max_stream: trigger at_once with MAX aggregation by tbname         2.1.3 Create count_stream: INTERVAL(10s) with WHERE voltage &gt; 10 filter         2.1.4 Create tsma_meters: 1-minute TSMA with avg(voltage), max(current), min(voltage), count(ts)         2.1.5 Create tsma_meters_hourly: 1-hour TSMA with avg(voltage), max(current), min(current), count(ts)         2.1.6 Create tsma_meters_detail: 30-second TSMA with sum(voltage), avg(current), max(phase), min(phase)     2.2 Verify new version startup behavior with old streams and TSMAs         2.2.1 Attempt to start new version (should fail due to incompatible streams/TSMAs)         2.2.2 Verify stream and TSMA incompatibility detection     2.3 Clean up old streams/TSMAs and create new format streams         2.3.1 Drop all old format streams and TSMAs before database cleanup         2.3.2 Create s_interval: INTERVAL(5s) SLIDING(5s) with trigger/source separation         2.3.3 Create s_count: COUNT_WINDOW(5) with %%trows reference         2.3.4 Create s_period: PERIOD(30s) with cross-database computation         2.3.5 Create s_session: SESSION(ts, 5s) with window boundary functions 3. Test [v3.3.5.0 Version Compatibility]     3.1 Install v3.3.5.0 enterprise package and create old format streams and TSMAs         3.1.1 Create avg_stream: INTERVAL(5s) aggregation on meters table         3.1.2 Create max_stream: trigger at_once with MAX aggregation by tbname         3.1.3 Create count_stream: INTERVAL(10s) with WHERE voltage &gt; 10 filter         3.1.4 Create tsma_meters: 1-minute TSMA with avg(voltage), max(current), min(voltage), count(ts)         3.1.5 Create tsma_meters_hourly: 1-hour TSMA with avg(voltage), max(current), min(current), count(ts)         3.1.6 Create tsma_meters_detail: 30-second TSMA with sum(voltage), avg(current), max(phase), min(phase)     3.2 Verify new version startup behavior with old streams and TSMAs         3.2.1 Attempt to start new version (should fail due to incompatible streams/TSMAs)         3.2.2 Verify stream and TSMA incompatibility detection     3.3 Clean up old streams/TSMAs and create new format streams         3.3.1 Drop all old format streams and TSMAs before database cleanup         3.3.2 Create s_interval: INTERVAL(5s) SLIDING(5s) with trigger/source separation         3.3.3 Create s_count: COUNT_WINDOW(5) with %%trows reference         3.3.4 Create s_period: PERIOD(30s) with cross-database computation         3.3.5 Create s_session: SESSION(ts, 5s) with window boundary functions 4. Test [v3.3.6.0 Version Compatibility]     4.1 Install v3.3.6.0 enterprise package and create old format streams and TSMAs         4.1.1 Create avg_stream: INTERVAL(5s) aggregation on meters table         4.1.2 Create max_stream: trigger at_once with MAX aggregation by tbname         4.1.3 Create count_stream: INTERVAL(10s) with WHERE voltage &gt; 10 filter         4.1.4 Create tsma_meters: 1-minute TSMA with avg(voltage), max(current), min(voltage), count(ts)         4.1.5 Create tsma_meters_hourly: 1-hour TSMA with avg(voltage), max(current), min(current), count(ts)         4.1.6 Create tsma_meters_detail: 30-second TSMA with sum(voltage), avg(current), max(phase), min(phase)     4.2 Verify new version startup behavior with old streams and TSMAs         4.2.1 Attempt to start new version (should fail due to incompatible streams/TSMAs)         4.2.2 Verify stream and TSMA incompatibility detection     4.3 Clean up old streams/TSMAs and create new format streams         4.3.1 Drop all old format streams and TSMAs before database cleanup         4.3.2 Create s_interval: INTERVAL(5s) SLIDING(5s) with trigger/source separation         4.3.3 Create s_count: COUNT_WINDOW(5) with %%trows reference         4.3.4 Create s_period: PERIOD(30s) with cross-database computation         4.3.5 Create s_session: SESSION(ts, 5s) with window boundary functions                      path:                                            cases/18-StreamProcessing/23-Compatibility/test_compatibility_cross_version.py"},{"location":"case_list_docs/StreamProcessing/Compatibility/#18-StreamProcessing.23-Compatibility.test_compatibility_rolling_upgrade.TestCompatibilityRollingUpgrade.test_compatibility_rolling_upgrade","title":"","text":"Comp: rolling upgrade Test incremental rolling upgrade of individual nodes with stream processing validation: 1. Test [Version Detection and Upgrade Mode Selection]     1.1 Get current server version and calculate last big version         1.1.1 Query SELECT SERVER_VERSION() to get current version         1.1.2 Calculate lastBigVersion as major.minor.patch.0 format         1.1.3 Verify version format and compatibility     1.2 Setup upgrade environment         1.2.1 Stop all dnodes with tdDnodes.stopAll()         1.2.2 Get dnode paths for 3 nodes (dnode1, dnode2, dnode3)         1.2.3 Verify base version package availability 2. Test [Base Version Installation and Cluster Setup]     2.1 Install old version for rolling upgrade         2.1.1 Install TDengine using tdCb.installTaosdForRollingUpgrade()         2.1.2 Verify successful installation of base version         2.1.3 Start old version services     2.2 Create multi-node cluster         2.2.1 Create dnode with hostname:6130 port         2.2.2 Create dnode with hostname:6230 port         2.2.3 Wait 10 seconds for cluster stabilization         2.2.4 Verify cluster formation and node status 3. Test [Data Preparation on Old Version]     3.1 Create test data using tdCb.prepareDataOnOldVersion()         3.1.1 Create test databases and tables with taosBenchmark         3.1.2 Insert sample data across multiple tables         3.1.3 Create stream processing objects         3.1.4 Verify data consistency before upgrade     3.2 Setup stream processing infrastructure         3.2.1 Create streams with various window types         3.2.2 Setup TMQ topics and consumers         3.2.3 Verify stream functionality on old version         3.2.4 Flush databases to ensure data persistence 4. Test [Rolling Upgrade Execution - Mode 0 (Single Node)]     4.1 Execute upgrade using tdCb.updateNewVersion() with mode 0         4.1.1 Upgrade single dnode incrementally (mode=0)         4.1.2 Monitor upgrade process for individual node         4.1.3 Verify mixed-version cluster operation         4.1.4 Wait 10 seconds for upgrade completion     4.2 Verify cluster stability during incremental upgrade         4.2.1 Check upgraded node is running new version         4.2.2 Verify remaining nodes still on old version         4.2.3 Confirm cluster connectivity maintained         4.2.4 Validate data accessibility during upgrade 5. Test [Post-Upgrade Data Verification]     5.1 Verify data integrity using tdCb.verifyData()         5.1.1 Check table counts and row counts consistency         5.1.2 Verify stream processing functionality         5.1.3 Test TMQ consumer operations         5.1.4 Validate aggregation results accuracy     5.2 Verify new features and compatibility         5.2.1 Test stream recalculation features         5.2.2 Verify tag size modifications         5.2.3 Check configuration parameter compatibility         5.2.4 Validate error handling improvements 6. Test [SQL Syntax Compatibility Verification]     6.1 Test backticks in SQL using tdCb.verifyBackticksInTaosSql()         6.1.1 Test database operations with backticks         6.1.2 Test table operations with backticks         6.1.3 Test stream operations with backticks         6.1.4 Verify error handling for invalid backtick usage                      path:                                            cases/18-StreamProcessing/23-Compatibility/test_compatibility_rolling_upgrade.py"},{"location":"case_list_docs/StreamProcessing/Compatibility/#18-StreamProcessing.23-Compatibility.test_compatibility_rolling_upgrade_all.TestCompatibilityRollingUpgradeAll.test_compatibility_rolling_upgrade_all","title":"","text":"Comp: rolling upgrade all dnodes Test rolling upgrade of all cluster nodes simultaneously with stream processing validation: 1. Test [Version Detection and Preparation]     1.1 Get current server version and calculate last big version         1.1.1 Query SELECT SERVER_VERSION() to get current version         1.1.2 Calculate lastBigVersion as major.minor.patch.0 format         1.1.3 Verify version format and compatibility     1.2 Setup cluster environment for upgrade testing         1.2.1 Get build path and dnode paths for 3 nodes         1.2.2 Kill all existing dnode processes         1.2.3 Verify base version package availability 2. Test [Base Version Installation and Cluster Setup]     2.1 Install old version across all dnodes         2.1.1 Install TDengine using tdCb.installTaosdForRollingUpgrade()         2.1.2 Verify successful installation of base version         2.1.3 Start old version services on all nodes     2.2 Create multi-node cluster         2.2.1 Create dnode with hostname:6130 port         2.2.2 Create dnode with hostname:6230 port         2.2.3 Wait 10 seconds for cluster stabilization         2.2.4 Verify cluster formation and node status 3. Test [Data Preparation on Old Version]     3.1 Create test data using tdCb.prepareDataOnOldVersion()         3.1.1 Create test databases and tables with taosBenchmark         3.1.2 Insert sample data across multiple tables         3.1.3 Create stream processing objects         3.1.4 Verify data consistency before upgrade     3.2 Setup stream processing infrastructure         3.2.1 Create streams with various window types         3.2.2 Setup TMQ topics and consumers         3.2.3 Verify stream functionality on old version         3.2.4 Flush databases to ensure data persistence 4. Test [Rolling Upgrade Execution - Mode 1 (All Dnodes)]     4.1 Execute upgrade using tdCb.updateNewVersion() with mode 1         4.1.1 Upgrade all dnodes simultaneously (mode=1)         4.1.2 Monitor upgrade process and timing         4.1.3 Handle upgrade failures and rollback if needed         4.1.4 Wait 10 seconds for upgrade completion     4.2 Verify cluster stability after upgrade         4.2.1 Check all nodes are running new version         4.2.2 Verify cluster connectivity and communication         4.2.3 Confirm no data loss during upgrade         4.2.4 Validate cluster configuration consistency 5. Test [Post-Upgrade Data Verification]     5.1 Verify data integrity using tdCb.verifyData()         5.1.1 Check table counts and row counts consistency         5.1.2 Verify stream processing functionality         5.1.3 Test TMQ consumer operations         5.1.4 Validate aggregation results accuracy     5.2 Verify new features and compatibility         5.2.1 Test stream recalculation features         5.2.2 Verify tag size modifications         5.2.3 Check configuration parameter compatibility         5.2.4 Validate error handling improvements 6. Test [SQL Syntax Compatibility Verification]     6.1 Test backticks in SQL using tdCb.verifyBackticksInTaosSql()         6.1.1 Test database operations with backticks         6.1.2 Test table operations with backticks           6.1.3 Test stream operations with backticks         6.1.4 Verify error handling for invalid backtick usage                      path:                                            cases/18-StreamProcessing/23-Compatibility/test_compatibility_rolling_upgrade_all.py"},{"location":"case_list_docs/StreamProcessing/Compatibility/#18-StreamProcessing.23-Compatibility.test_new_stream_compatibility.TestNewStreamCompatibility.test_stream_compatibility","title":"","text":"Comp: stream backward and forward Test compatibility across 3 baseline versions with stream processing validation: 1. Test [v3.3.7.9 Base Version Compatibility]     1.1 Install v3.3.7.9 and prepare data using tdCb.prepareDataOnOldVersion()         1.1.1 Create test databases and tables         1.1.2 Create streams and insert sample data         1.1.3 Verify stream functionality on v3.3.7.9     1.2 Upgrade to new version with mode 2 (no upgrade mode)         1.2.1 Kill all dnodes and update to new version         1.2.2 Start new version with existing data         1.2.3 Verify cross-major version compatibility (corss_major_version=True)     1.3 Verify data and functionality using tdCb.verifyData()         1.3.1 Check table counts and row counts consistency         1.3.2 Verify stream processing functionality         1.3.3 Validate aggregation results accuracy 2. Test [v3.3.8.5 Base Version Compatibility] 3. Test [v3.3.8.6 Base Version Compatibility]                      path:                                            cases/18-StreamProcessing/23-Compatibility/test_new_stream_compatibility.py"},{"location":"case_list_docs/StreamProcessing/Notify/","title":"05-Notify","text":""},{"location":"case_list_docs/StreamProcessing/Notify/#18-StreamProcessing.05-Notify.test_notify.TestStreamNotifyTrigger.test_stream_notify_trigger","title":"","text":"Notify basic 1. Stream notify on windows_open/windows_close trigger 2. Stream notify with options notify_history/on_failure_pause 3. Stream notify with different stream definitions 4. Stream create with no notify URL 5. Check notify results                      path:                                            cases/18-StreamProcessing/05-Notify/test_notify.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/","title":"30-OldPyCases","text":""},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_at_once.TestOthersOldCaseAtonce.test_others_oldcase_atonce","title":"","text":"OldPy: at once test replace the at once in old cases with the count(1) window function                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_at_once.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_backquote_check.TestOthersOldCaseBackquoteCheck.test_others_oldcase_backquote_check","title":"","text":"OldPy: back quote test back quote check                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_backquote_check.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_checkpoint_info.Test_checkpoint_info_Case.test_checkpoint_info","title":"","text":"OldPy: checkpoint 1. create snode 2. create stream and restart stream 3. drop snode  4. alter db replica 5. balance vgropu leader  6. drop stream 7. redistribute vgroup 8. drop snode 9. drop dnode   10. check checkpoint file                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_checkpoint_info.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_drop.TestStreamDrop.test_stream_drop","title":"","text":"OldPy: drop operations Test drop operations on tables with special characters and batch drop operations: 1. Test [Normal Table Drop] Operations     1.1 Create and drop normal table with timestamp column         1.1.1 Create table with 20 child tables using super table         1.1.2 Insert 10 rows per child table         1.1.3 Query and verify data by timestamp column         1.1.4 Drop each child table individually     1.2 Test drop with flush database operations         1.2.1 Recreate child tables after drop         1.2.2 Insert data again and query         1.2.3 Verify data consistency after flush         1.2.4 Drop super table and recreate 2. Test [Special Character Table Names] Drop Operations     2.1 Create databases and tables with special names         2.1.1 Create databases: dbtest_0, dbtest_1 with vgroups 4         2.1.2 Create super table with Unicode name: aa\u00bf\u200bstb0         2.1.3 Create child tables with special names: aa\u00bf\u200bctb0, aa\u00bf\u200bctb1         2.1.4 Create normal tables with special names: aa\u00bf\u200bntb0, aa\u00bf\u200bntb1     2.2 Test drop operations with special character handling         2.2.1 Insert data into tables with special names         2.2.2 Query data using backticks for table names         2.2.3 Drop tables with special character names         2.2.4 Clean up databases after testing 3. Test [Batch Drop Operations] with Super Tables     3.1 Query information_schema.ins_stables for batch operations         3.1.1 Find stable information across test databases         3.1.2 Verify stable count equals 2 (one per database)         3.1.3 Extract database and stable names for batch operations     3.2 Test batch drop with error scenarios         3.2.1 Test \"drop table with\" invalid table names (should error)         3.2.2 Test \"drop stable with\" non-existent tables (should error)         3.2.3 Test \"drop stable with\" space-containing names (should error)         3.2.4 Verify error message: \"Cannot drop super table in batch\" 4. Test [Error Handling] for Drop Operations     4.1 Test error messages for invalid drop operations         4.1.1 \"Table does not exist\" for invalid table drop         4.1.2 \"STable not exist\" for invalid stable drop         4.1.3 \"Cannot drop super table in batch\" for batch stable drop     4.2 Repeat error tests multiple times         4.2.1 Execute each error scenario 5 times         4.2.2 Verify consistent error handling         4.2.3 Check error message consistency         4.2.4 Validate connection stability after errors                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_drop.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_empty_identifier.TestEmptyIdentifier.test_empty_identifier","title":"","text":"OldPy: empty identifier validation  Test empty identifier `` handling in 28 specific SQL statements and verify error code -2147473897: 1. Test [Table Operations] with Empty Identifiers     1.1 show create table `` - verify error -2147473897     1.2 show create table test.`` - verify error -2147473897     1.3 create table `` (ts timestamp, c1 int) - verify error -2147473897     1.4 drop table `` - verify error -2147473897     1.5 alter table `` add column c2 int - verify error -2147473897     1.6 select * from `` - verify error -2147473897 2. Test [Column and Tag Operations] with Empty Identifiers     2.1 alter table meters add column `` int - verify error -2147473897     2.2 alter table meters drop column `` - verify error -2147473897     2.3 alter stable meters add tag `` int - verify error -2147473897     2.4 alter stable meters rename tag cc `` - verify error -2147473897     2.5 alter stable meters drop tag `` - verify error -2147473897 3. Test [Data Manipulation] with Empty Identifiers     3.1 insert into `` select * from t0 - verify error -2147473897     3.2 insert into t100 using `` tags('', '') values(1,1,1) - verify error -2147473897     3.3 insert into `` values(1,1,1) - verify error -2147473897 4. Test [View Operations] with Empty Identifiers     4.1 create view `` as select count(*) from meters interval(10s) - verify error -2147473897     4.2 create view ``.view1 as select count(*) from meters - verify error -2147473897     4.3 drop view `` - verify error -2147473897     4.4 drop view ``.st1 - verify error -2147473897 5. Test [TSMA Operations] with Empty Identifiers     5.1 create tsma `` on meters function(count(c1)) interval(1m) - verify error -2147473897     5.2 create tsma tsma1 on `` function(count(c1)) interval(1m) - verify error -2147473897 6. Test [Stream Operations] with Empty Identifiers     6.1 create stream `` interval(10s) sliding(10s) from meters into st1 as select count(*) from meters - verify error -2147473897     6.2 create stream stream1 interval(10s) sliding(10s) from meters into `` as select count(*) from meters - verify error -2147473897     6.3 create stream stream1 interval(10s) sliding(10s) from meters into st1 as select count(*) from `` - verify error -2147473897     6.4 create stream stream1 interval(10s) sliding(10s) from meters stream_options(max_delay(100s)) into st1 as select count(*) from `` - verify error -2147473897     6.5 create stream stream1 interval(10s) sliding(10s) from `` stream_options(max_delay(100s)) into st1 as select count(*) from meters - verify error -2147473897 7. Test [Topic Operations] with Empty Identifiers     7.1 create topic `` as select count(*) from meters interval(10s) - verify error -2147473897     7.2 drop topic `` - verify error -2147473897 8. Test [Error Code Verification] for All Cases     8.1 Execute all 28 SQL statements with empty identifiers     8.2 Verify each returns exact error code -2147473897     8.3 Confirm error message consistency     8.4 Validate connection stability after errors                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_empty_identifier.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_forcewindowclose.TestIntervalCases.test_period_interval","title":"","text":"OldPy: force window close interval + sliding simulates the force window close trigger model.                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_forcewindowclose.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_interval_partition.TestIntervalPartition.test_interval_partition","title":"","text":"OldPy: partitionby \u8001\u7528\u4f8b tests/system-test/8-stream/partition_interval.py \u8001\u7684\u5efa\u6d41\u8bed\u53e5 CREATE STREAM xxx INTO xxx AS SELECT _wstart,count(val) FROM stb PARTITION BY tbname INTERVAL(10s) \u65b0\u7684\u5efa\u6d41\u8bed\u53e5 CREATE STREAM xxx INTERVAL(10s) SLIDING(10s) FROM stb PARTITON BY tbname INTO xxx AS SELECT _tcurrent_ts as ts,count(val) FROM %%trows;                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_interval_partition.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_math_func.TestMathFunctionInStream.test_math_function","title":"","text":"OldPy: math function \u65e7\u7528\u4f8b tests/system-test/8-stream/scalar_function.py \u6d4b\u8bd5\u5728\u6d41\u8ba1\u7b97\u4e2d\u4f7f\u7528\u6570\u5b66\u51fd\u6570 \u65e7\u7684\u5efa\u6d41\u8bed\u53e5\uff1a create stream XXX trigger at_once ignore expired 0 ignore update 0 fill_history 1 into XXX as select ts, log(c1, 2), log(c2, 2), c3 from scalar_tb \u65b0\u7684\u5efa\u6d41\u8bed\u53e5\uff1a CREATE STREAM XXX SLIDING(10s) FROM tb INTO XXX AS SELECT ts, log(val, 2) as val FROM %%trows;                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_math_func.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_sliding_partition.TestSlindingPartition.test_sliding_partition","title":"","text":"OldPy: sliding \u8001\u7528\u4f8b tests/system-test/8-stream/partition_interval.py \u8001\u7684\u5efa\u6d41\u8bed\u53e5 CREATE STREAM xxx INTO xxx AS SELECT _wstart,count(val) FROM stb PARTITION BY tbname INTERVAL(10s) \u65b0\u7684\u5efa\u6d41\u8bed\u53e5 CREATE STREAM xxx SLINDING(10s) FROM stb PARTITON BY tbname INTO xxx AS SELECT _tcurrent_ts as ts,count(val) FROM %%trows;                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_sliding_partition.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_snode_restart_with_checkpoint.Test_snode_restart_with_checkpoint.test_case1","title":"","text":"OldPy: snode 1. -                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_snode_restart_with_checkpoint.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_state_window.TestStateWindow.test_state_window","title":"","text":"OldPy: state window \u8fc1\u79fb\u81ea\u8001\u7528\u4f8b: tests/system-test/8-stream/state_window_case.py                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_state_window.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_stream_basic.TestStreamBasicCase.test_stream_basic","title":"","text":"OldPy: basic test 1 1. test stream basic                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_stream_basic.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_stream_multi_agg.TestStreamMultiAggCase.test_steram_multi_agg","title":"","text":"OldPy: aggregation func 1. test_Stream_Multi_Agg                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_stream_multi_agg.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_string_func.TestStringFunctionInStream.test_string_function","title":"","text":"OldPy: string function \u65e7\u7528\u4f8b tests/system-test/8-stream/scalar_function.py \u6d4b\u8bd5\u5728\u6d41\u8ba1\u7b97\u4e2d\u4f7f\u7528\u5b57\u7b26\u4e32\u51fd\u6570 \u65e7\u7684\u5efa\u6d41\u8bed\u53e5\uff1a create stream XXX trigger at_once ignore expired 0 ignore update 0 fill_history 1 into XXX as select ts, char_length(c3) from scalar_tb \u65b0\u7684\u5efa\u6d41\u8bed\u53e5\uff1a CREATE STREAM XXX SLIDING(10s) FROM tb INTO XXX AS SELECT ts, char_length(val) as val FROM %%trows;                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_string_func.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_taosdShell.TestOthersOldCaseTaosdshell.test_others_oldcase_taosdShell","title":"","text":"OldPy: shell create stream test taosd shell command                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_taosdShell.py"},{"location":"case_list_docs/StreamProcessing/OldPyCases/#18-StreamProcessing.30-OldPyCases.test_oldcase_window_true_for.TestWindowTrueFor.test_window_true_for","title":"","text":"OldPy: true for tests/system-test/2-query/test_window_true_for.py                      path:                                            cases/18-StreamProcessing/30-OldPyCases/test_oldcase_window_true_for.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/","title":"31-OldTsimCases","text":""},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_basic1.TestStreamOldCaseBasic1.test_stream_oldcase_basic1","title":"","text":"OldTsim: stream basic Basic test cases for streaming, part 1                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_basic1.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_basic2.TestStreamOldCaseBasic2.test_stream_oldcase_basic2","title":"","text":"OldTsim: stream basic status 1. Create snode 2. Create multiple databases 3. Create stream sliding window, tag stream, trigger interval 0, window close scenarios 4. Insert data and verify the correctness of stream processing results 5. Verify the status of all streams 6. Check data correctness for all streams                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_basic2.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_check.TestStreamOldCaseCheck.test_stream_oldcase_check","title":"","text":"OldTsim: check stable Verify the computation results of streams when triggered by different windows.                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_check.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_checkpoint.TestStreamOldCaseCheckPoint.test_stream_oldcase_checkpoint","title":"","text":"OldTsim: checkpoint Test if the stream continues to run after a restart.                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_checkpoint.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_concat.TestStreamOldCaseConcat.test_stream_oldcase_concat","title":"","text":"OldTsim: concat Test the use of the concat function in output_subtable and tags statements.                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_concat.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_continuewindowclose.TestStreamOldCaseContinueWindowClose.test_stream_oldcase_continue_window_close","title":"","text":"OldTsim: continue window close Verify the alternative approach to the original continuous window close trigger mode in the new streaming computation                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_continuewindowclose.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_count.TestStreamOldCaseCount.test_stream_oldcase_count","title":"","text":"OldTsim: count window Basic use cases of count window, include expired-data, out-of-order data, and data-deletion                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_count.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_delete.TestStreamOldCaseDelete.test_stream_oldcase_delete","title":"","text":"OldTsim: delete data Test the correctness of results when deleting data in various trigger windows                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_delete.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_distribute.TestStreamOldCaseDistribute.test_stream_oldcase_distribute","title":"","text":"OldTsim: distribute Perform multiple write triggers to verify the correctness of the calculation results                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_distribute.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_event.TestStreamOldCaseEvent.test_stream_oldcase_event","title":"","text":"OldTsim: event window Test event window deletion and update                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_event.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_fillhistory.TestStreamOldCaseFillHistory.test_stream_oldcase_fillhistory","title":"","text":"OldTsim: fill history Verify the correctness of historical data calculation results, as well as the calculation results at the boundary between historical and real-time computation.                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_fillhistory.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_fillinternal.TestStreamOldCaseFillInterval.test_stream_oldcase_fill_interval","title":"","text":"OldTsim: fill interval Test the results of various numerical fillings in the interval window                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_fillinternal.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_forcewindowclose.TestStreamOldCaseForceWindowClose.test_stream_oldcase_force_window_close","title":"","text":"OldTsim: force window close Verify the alternative approach to the original force window close trigger mode in the new streaming computation                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_forcewindowclose.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_delete.TestStreamOldCaseInterpDelete.test_stream_oldcase_interp_delete","title":"","text":"OldTsim: interp delete Verify the calculation results of the interp function when deleting data                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_delete.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_fill.TestStreamOldCaseInterpFill.test_stream_oldcase_interp_fill","title":"","text":"OldTsim: interp fill Validate the calculation results of the interp function when filling data                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_fill.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_history.TestStreamOldCaseInterpHistory.test_stream_oldcase_interp_history","title":"","text":"OldTsim: interp history Validate the calculation results of the interp function when processing historical data                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_history.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_partitionby.TestStreamOldCaseInterpPartitionBy.test_stream_oldcase_interp_partitionby","title":"","text":"OldTsim: interp partition by Validate the calculation results of the \u200b\u200binterp\u200b\u200b function under \u200b\u200bPARTITION BY\u200b\u200b clauses                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_partitionby.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_primary.TestStreamOldCaseInterpPrimary.test_stream_oldcase_interp_primary","title":"","text":"OldTsim: interp compisite key Validate the calculation results of the interp function with cmposite keys                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_primary.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_interp_update.TestStreamOldCaseInterpUpdate.test_stream_oldcase_interp_update","title":"","text":"OldTsim: interp update Validate the calculation results of the interp function during data updates                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_interp_update.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_options.TestStreamOldCaseOptions.test_stream_oldcase_options","title":"","text":"OldTsim: options Validate the calculation results when ignore update and ignore delete are applied                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_options.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_partitionby.TestStreamOldCasePartitionBy.test_stream_oldcase_partitionby","title":"","text":"OldTsim: partition by Validate the calculation results under PARTITION BY clauses                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_partitionby.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_primary.TestStreamOldCaseInterpPrimary.test_stream_oldcase_interp_primary","title":"","text":"OldTsim: composite key Validate the calculation results with composite keys                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_primary.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_session.TestStreamOldCaseSession.test_stream_oldcase_session","title":"","text":"OldTsim: session window Test the correctness of session windows                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_session.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_snode.TestStreamOldCaseSnode.test_stream_oldcase_snode","title":"","text":"OldTsim: snode Test basic operations of snode                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_snode.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_state.TestStreamOldCaseState.test_stream_oldcase_state","title":"","text":"OldTsim: state window Test the correctness of state windows                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_state.py"},{"location":"case_list_docs/StreamProcessing/OldTsimCases/#18-StreamProcessing.31-OldTsimCases.test_oldcase_twa.TestStreamOldCaseTwa.test_stream_oldcase_twa","title":"","text":"OldTsim: twa Verify the behavior of the legacy TWA function in the new streaming computation system                      path:                                            cases/18-StreamProcessing/31-OldTsimCases/test_oldcase_twa.py"},{"location":"case_list_docs/StreamProcessing/Options/","title":"04-Options","text":""},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_abnormal_data_table.TestStreamDisorderTable.test_stream_disnorder_table","title":"","text":"Abnormal data: table test data disorder/update/delete change cases to stream                      path:                                            cases/18-StreamProcessing/04-Options/test_abnormal_data_table.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_abnormal_data_vtable.TestStreamDisorderVtable.test_stream_disnorder_vtable","title":"","text":"Abnormal data: virtual table test data disorder/update/delete change cases to stream for virtual table                      path:                                            cases/18-StreamProcessing/04-Options/test_abnormal_data_vtable.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_meta_change_table.TestStreamMetaChangeTable.test_stream_meta_change_table","title":"","text":"Meta change: table test meta change (add/drop/modify) cases to stream                      path:                                            cases/18-StreamProcessing/04-Options/test_meta_change_table.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_meta_change_vtable.TestStreamMetaChangeVTable.test_stream_meta_change_vtable","title":"","text":"Meta Change: virtual table test meta change (add/drop/modify) cases to stream for virtual table                      path:                                            cases/18-StreamProcessing/04-Options/test_meta_change_vtable.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_options_abnormal.TestStreamOptionsAbnormal.test_stream_options_abnormal","title":"","text":"Options: abnormal test abnormal cases to stream                      path:                                            cases/18-StreamProcessing/04-Options/test_options_abnormal.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_options_basic.TestStreamOptionsBasic.test_stream_options_basic","title":"","text":"Options: basic test test options item of stream                      path:                                            cases/18-StreamProcessing/04-Options/test_options_basic.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_options_ns.TestStreamOptionsNs.test_stream_options_ns","title":"","text":"Options: precision ns test options item of stream to precision ns                      path:                                            cases/18-StreamProcessing/04-Options/test_options_ns.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_options_us.TestStreamOptionsUs.test_stream_options_us","title":"","text":"Options: precision us test options item of stream                      path:                                            cases/18-StreamProcessing/04-Options/test_options_us.py"},{"location":"case_list_docs/StreamProcessing/Options/#18-StreamProcessing.04-Options.test_options_vtable.TestStreamOptionsVtable.test_stream_options_vtable","title":"","text":"Options: virtual table test options item of stream to virtual table                      path:                                            cases/18-StreamProcessing/04-Options/test_options_vtable.py"},{"location":"case_list_docs/StreamProcessing/Recalc/","title":"08-Recalc","text":""},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_10.TestStreamRecalcWatermark.test_stream_recalc_watermark","title":"","text":"Recalc: super table watermark  Test WATERMARK option with out-of-order data: 1. Create database and super table with WATERMARK option 2. Create trigger tables for different stream types 3. Create streams with various trigger types using the trigger tables 4. Write initial trigger data to set baseline 5. Write source data to test WATERMARK handling 6. Check stream status to ensure they are running 7. Check results to verify correct handling of out-of-order data                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_10.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_13.TestStreamRecalcBugs13.test_stream_recalc","title":"","text":"Meta change: table test recalc bugs in stream                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_13.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_5.TestStreamRecalcDeleteRecalc.test_stream_recalc_delete_recalc","title":"","text":"Recalc: delete data Test DELETE_RECALC option with data deletion: 1. Delete data from trigger table - streams with DELETE_RECALC should trigger recalculation 2. Delete child table - streams with DELETE_RECALC should trigger recalculation 3. Different trigger types behavior with data deletion                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_5.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_6.TestStreamRecalcDeleteRecalc.test_stream_recalc_delete_recalc","title":"","text":"Recalc: delete child table Test DELETE_RECALC option with data deletion: 1. Delete data from trigger table - streams with DELETE_RECALC should trigger recalculation 2. Delete child table - streams with DELETE_RECALC should trigger recalculation 3. Different trigger types behavior with data deletion                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_6.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_7.TestStreamRecalcWatermark.test_stream_recalc_watermark","title":"","text":"Recalc: watermark with out-of-order data Test WATERMARK option with out-of-order data: 1. Write out-of-order data within WATERMARK tolerance - should trigger recalculation 2. Write out-of-order data exceeding WATERMARK tolerance - should be handled by recalculation mechanism 3. Different trigger types behavior with WATERMARK                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_7.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_8.TestStreamRecalcManual.test_stream_recalc_manual","title":"","text":"Recalc: time range Test manual recalculation functionality: 1. Manual recalculation with time range - should recalculate specified time period 2. Manual recalculation without end time - should recalculate from start time to current 3. Different trigger types behavior with manual recalculation 4. Edge cases and error handling                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_8.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_bug_9.TestStreamRecalcWatermark.test_stream_recalc_watermark","title":"","text":"Recalc: different trigger with watermark Test WATERMARK option with out-of-order data: 1. Write out-of-order data within WATERMARK tolerance - should trigger recalculation 2. Write out-of-order data exceeding WATERMARK tolerance - should be handled by recalculation mechanism 3. Different trigger types behavior with WATERMARK 4. EVENT_WINDOW with WATERMARK - should handle out-of-order data within tolerance 5. Check data correctness                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_bug_9.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.recalc_expired_bug_1.TestStreamRecalcExpiredTime.test_stream_recalc_expired_time","title":"","text":"Recalc: watermark with expired_time option Test EXPIRED_TIME option with expired data: 1. Write expired data - all windows should not trigger recalculation 2. Combine with WATERMARK - test boundary value behavior 3. Different trigger types behavior with expired data                      path:                                            cases/18-StreamProcessing/08-Recalc/recalc_expired_bug_1.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_combined_options.TestStreamRecalcCombinedOptions.test_stream_recalc_combined_options","title":"","text":"Recalc: mixed options Test complex interactions between multiple stream recalculation options: 1. Test [EXPIRED_TIME + WATERMARK] Combination     1.1 Test option compatibility verification         1.1.1 Both options specified - verify legal combination         1.1.2 Option value conflict checking - verify error handling     1.2 Test data processing behavior         1.2.1 Data within watermark tolerance - should process normally         1.2.2 Data beyond watermark but within expired_time - should trigger recalculation         1.2.3 Data beyond both watermark and expired_time - should be ignored     1.3 Test boundary conditions         1.3.1 Data exactly at watermark boundary         1.3.2 Data exactly at expired_time boundary         1.3.3 Watermark value equals expired_time value 2. Test [IGNORE_DISORDER + WATERMARK] Combination     2.1 Test option conflict resolution         2.1.1 IGNORE_DISORDER true with WATERMARK - verify conflict handling         2.1.2 IGNORE_DISORDER false with WATERMARK - verify normal operation     2.2 Test out-of-order data handling         2.2.1 Disorder within watermark tolerance - test processing priority         2.2.2 Disorder beyond watermark tolerance - test ignore behavior     2.3 Test window trigger behavior         2.3.1 INTERVAL windows with conflicting options         2.3.2 SESSION windows with conflicting options         2.3.3 STATE_WINDOW with conflicting options 3. Test [DELETE_RECALC + EXPIRED_TIME] Combination     3.1 Test delete operation with expired data         3.1.1 Delete recent data - should trigger recalculation         3.1.2 Delete expired data - should not trigger recalculation         3.1.3 Delete data at expired_time boundary     3.2 Test different deletion scenarios         3.2.1 Delete from trigger table         3.2.2 Delete entire child table         3.2.3 Batch delete operations 4. Test [WATERMARK + DELETE_RECALC + EXPIRED_TIME] Comprehensive Combination     4.1 Test three-option interaction         4.1.1 All options compatible - verify normal operation         4.1.2 Option precedence verification         4.1.3 Performance impact assessment     4.2 Test complex data scenarios         4.2.1 Mixed operations (insert, update, delete) with all options         4.2.2 Out-of-order data with deletion and expiration         4.2.3 Boundary data across all option thresholds     4.3 Test error handling and recovery         4.3.1 Invalid option combinations         4.3.2 Resource constraints with multiple options         4.3.3 Stream recovery after option conflicts 5. Test Window Type Compatibility     5.1 Test INTERVAL windows with combined options         5.1.1 Different sliding window configurations         5.1.2 Option behavior with overlapping windows     5.2 Test SESSION windows with combined options         5.2.1 Session timeout interaction with options         5.2.2 Session boundary handling     5.3 Test STATE_WINDOW with combined options         5.3.1 State change detection with multiple options         5.3.2 State persistence across option boundaries                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_combined_options.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_delete_recalc.TestStreamRecalcDeleteRecalc.test_stream_recalc_delete_recalc","title":"","text":"Recalc: full deletion scenarios Test DELETE_RECALC option behavior with various data deletion scenarios: 1. Test [DELETE_RECALC] Option Specification     1.1 Test option existence verification         1.1.1 DELETE_RECALC specified - verify recalculation on deletion         1.1.2 DELETE_RECALC not specified - verify no recalculation on deletion         1.1.3 DELETE_RECALC with invalid syntax - verify error handling     1.2 Test option value validation         1.2.1 Valid DELETE_RECALC specification         1.2.2 Invalid DELETE_RECALC syntax         1.2.3 DELETE_RECALC with other conflicting options 2. Test [Data Record Deletion] Scenarios     2.1 Test single record deletion         2.1.1 Delete recent data - should trigger recalculation         2.1.2 Delete historical data - should trigger recalculation         2.1.3 Delete data from closed window - verify window reopening     2.2 Test batch record deletion         2.2.1 Delete multiple records from same window         2.2.2 Delete records across multiple windows         2.2.3 Delete all records from a window     2.3 Test conditional deletion         2.3.1 DELETE with WHERE clause affecting single window         2.3.2 DELETE with WHERE clause affecting multiple windows         2.3.3 DELETE with complex WHERE conditions 3. Test [Child Table Deletion] Scenarios     3.1 Test entire child table deletion         3.1.1 DROP child table - verify impact on stream calculation         3.1.2 Delete all records from child table - verify empty table handling         3.1.3 Recreate child table after deletion - verify stream recovery     3.2 Test multiple child table operations         3.2.1 Delete multiple child tables simultaneously         3.2.2 Mix of record deletion and table deletion         3.2.3 Partial child table set deletion 4. Test [Window Type Behavior] with DELETE_RECALC     4.1 Test INTERVAL windows         4.1.1 Delete data from current window - verify immediate recalculation         4.1.2 Delete data from sliding windows - verify overlapping window updates         4.1.3 Delete data causing empty windows - verify window state handling     4.2 Test SESSION windows         4.2.1 Delete data from active session - verify session recalculation         4.2.2 Delete data causing session split - verify session boundary changes         4.2.3 Delete data causing session merge - verify session consolidation     4.3 Test STATE_WINDOW         4.3.1 Delete data causing state change - verify state window recalculation         4.3.2 Delete data from state boundary - verify window boundary updates         4.3.3 Delete all data from state window - verify window closure     4.4 Test EVENT_WINDOW         4.4.1 Delete start event data - verify window start recalculation         4.4.2 Delete end event data - verify window end recalculation         4.4.3 Delete intermediate data - verify window content recalculation 5. Test [Performance and Resource Impact]     5.1 Test large-scale deletion impact         5.1.1 Delete large volume of data - verify performance         5.1.2 Concurrent deletion operations - verify system stability         5.1.3 Resource usage during deletion recalculation     5.2 Test recovery scenarios         5.2.1 System restart after deletion - verify state recovery         5.2.2 Network interruption during deletion - verify consistency         5.2.3 Storage failure scenarios - verify data integrity                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_delete_recalc.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_expired_time.TestStreamRecalcExpiredTime.test_stream_recalc_expired_time","title":"","text":"Recalc:  6 different window with expire_time Test EXPIRED_TIME(1h) option with 6 different window types and verify expired data handling: 1. Test [INTERVAL+SLIDING Window] with EXPIRED_TIME(1h)     1.1 Create s_interval_expired: interval(2m) sliding(2m) with expired_time(1h)         1.1.1 Process data from '2025-01-01 02:00:00' onwards (within 1h)         1.1.2 Insert expired data from '2025-01-01 01:00:00' (beyond 1h)         1.1.3 Verify expired data does not increase result count         1.1.4 Check result table structure: ts, cnt, avg_val 2. Test [SESSION Window] with EXPIRED_TIME(1h)     2.1 Create s_session_expired: session(ts,45s) with expired_time(1h)         2.1.1 Insert normal trigger data at '2025-01-01 02:00:00' series         2.1.2 Insert non-expired data at '2025-01-01 01:30:00' (within 1h)         2.1.3 Insert expired data at '2025-01-01 01:00:00' (beyond 1h)         2.1.4 Verify session results: 3 sessions created, expired data ignored 3. Test [STATE_WINDOW] with EXPIRED_TIME(1h)     3.1 Create s_state_expired: state_window(status) with expired_time(1h)         3.1.1 Insert state changes: normal-&gt;warning-&gt;error at '2025-01-01 02:00:00'         3.1.2 Insert non-expired state data at '2025-01-01 01:30:00'         3.1.3 Insert expired state data at '2025-01-01 01:00:00'         3.1.4 Verify 4 state windows created, expired data ignored 4. Test [EVENT_WINDOW] with EXPIRED_TIME(1h)     4.1 Create s_event_expired: event_window(start with event_val &gt;= 5 end with event_val &gt; 10)         4.1.1 Insert event trigger data with event_val pattern: 6,7,12 at '2025-01-01 02:00:00'         4.1.2 Insert non-expired events at '2025-01-01 01:30:00'         4.1.3 Insert expired events at '2025-01-01 01:00:00'         4.1.4 Verify 3 event windows, expired data ignored in final result 5. Test [PERIOD Window] with EXPIRED_TIME(1h)     5.1 Create s_period_expired: period(30s) with expired_time(1h)|ignore_nodata_trigger         5.1.1 Insert period trigger data every 30s from '2025-01-01 02:00:00'         5.1.2 Test periodic triggering with current timestamp data         5.1.3 Verify period computation ignores expired data         5.1.4 Check ignore_nodata_trigger option interaction 6. Test [COUNT_WINDOW] with EXPIRED_TIME(1h) - Option Ignored     6.1 Create s_count_expired: count_window(3) with expired_time(1h)         6.1.1 Insert count trigger data in batches of 3         6.1.2 Insert both current and expired data         6.1.3 Verify COUNT_WINDOW ignores EXPIRED_TIME option         6.1.4 Confirm all data processed regardless of timestamp                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_expired_time.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_ignore_disorder.TestStreamRecalcIgnoreDisorder.test_stream_recalc_ignore_disorder","title":"","text":"Recalc:  6 different window with ignore_disorder Test IGNORE_DISORDER option behavior with six different window types to verify out-of-order data handling: 1. INTERVAL Window with IGNORE_DISORDER Test     1.1 Create interval(2m) sliding(2m) stream with ignore_disorder (s_interval_disorder)     1.2 Test out-of-order data processing behavior - should not trigger recalculation     1.3 Verify sliding window results without recalculation for disorder 2. SESSION Window with IGNORE_DISORDER Test     2.1 Create session(ts,45s) stream with ignore_disorder (s_session_disorder)     2.2 Test session boundary maintenance with out-of-order data     2.3 Verify session windows are not recalculated for disorder 3. STATE_WINDOW with IGNORE_DISORDER Test     3.1 Create state_window(status) stream with ignore_disorder (s_state_disorder)     3.2 Test state transition handling with out-of-order data     3.3 Verify state windows are not recalculated for disorder 4. EVENT_WINDOW with IGNORE_DISORDER Test     4.1 Create event_window(start with event_val &gt;= 5 end with event_val &gt; 10) stream with ignore_disorder (s_event_disorder)     4.2 Test event sequence maintenance with out-of-order events     4.3 Verify event windows are not recalculated for disorder 5. PERIOD Window with IGNORE_DISORDER Test     5.1 Create period(30s) stream with ignore_disorder (s_period_disorder)     5.2 Test periodic window handling with out-of-order data     5.3 Verify period windows are not recalculated for disorder 6. COUNT_WINDOW with IGNORE_DISORDER Test     6.1 Create count_window(3) stream with ignore_disorder (s_count_disorder)     6.2 Test count-based window handling with out-of-order data     6.3 Verify count windows are not recalculated for disorder                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_ignore_disorder.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_manual_basic.TestStreamRecalcManual.test_stream_recalc_manual","title":"","text":"Recalc: manual basic Test manual recalculation functionality for four different window types, verifying the recalculate stream command in various window scenarios: 1. INTERVAL Window Stream Manual Recalculation Test     1.1 Create interval(2m) sliding(2m) stream (s_interval_manual)     1.2 Insert test data and execute recalculation from specified time point     1.3 Verify data correctness in result table after recalculation 2. SESSION Window Stream Manual Recalculation Test     2.1 Create session(ts,45s) stream (s_session_manual)     2.2 Insert test data and execute recalculation from specified time point     2.3 Verify session window data correctness after recalculation 3. STATE_WINDOW Stream Manual Recalculation Test     3.1 Create state_window(status) stream (s_state_manual)     3.2 Insert test data and execute recalculation for specified time range     3.3 Verify state window data correctness after recalculation 4. EVENT_WINDOW Stream Manual Recalculation Test     4.1 Create event_window(start with event_val &gt;= 5 end with event_val &gt; 10) stream (s_event_manual)     4.2 Verify initial computation results for event window     4.3 Test event window manual recalculation functionality (currently blocked by TD-36691)                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_manual_basic.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_manual_with_options.TestStreamRecalcWithOptions.test_stream_recalc_with_options","title":"","text":"Recalc: manual with options Test manual recalculation functionality combined with four different stream options: 1. Manual Recalculation with WATERMARK Option Test     1.1 Create interval(2m) sliding(2m) stream with watermark(30s) (s_watermark_interval)     1.2 Test manual recalculation behavior within watermark tolerance     1.3 Verify watermark option interaction with manual recalc commands 2. Manual Recalculation with EXPIRED_TIME Option Test     2.1 Create interval(2m) sliding(2m) stream with expired_time(5m) (s_expired_interval)     2.2 Test manual recalculation for expired data processing     2.3 Verify expired_time option behavior during manual recalc 3. Manual Recalculation with IGNORE_DISORDER Option Test     3.1 Create interval(2m) sliding(2m) stream with ignore_disorder (s_disorder_interval)     3.2 Test manual recalculation for previously ignored out-of-order data     3.3 Verify disorder handling during manual recalc operations 4. Manual Recalculation without DELETE_RECALC Option Test     4.1 Create interval(2m) sliding(2m) stream without DELETE_RECALC (s_delete_interval)     4.2 Test manual recalculation behavior after data deletion     4.3 Verify recalculation consistency without automatic deletion handling                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_manual_with_options.py"},{"location":"case_list_docs/StreamProcessing/Recalc/#18-StreamProcessing.08-Recalc.test_recalc_watermark.TestStreamRecalcWatermark.test_stream_recalc_watermark","title":"","text":"Recalc: watermark basic Test WATERMARK option behavior with six different window types and out-of-order data handling: 1. INTERVAL Window with WATERMARK Test     1.1 Create interval(2m) sliding(2m) stream with watermark(45s) (s_interval_watermark)     1.2 Test out-of-order data handling within watermark tolerance     1.3 Verify recalculation triggered by data within watermark window 2. SESSION Window with WATERMARK Test     2.1 Create session(ts,45s) stream with watermark(1m) (s_session_watermark)     2.2 Test session modification with out-of-order data within tolerance     2.3 Verify session window recalculation behavior 3. STATE_WINDOW with WATERMARK Test     3.1 Create state_window(status) stream with watermark(45s) (s_state_watermark)     3.2 Test state window recalculation with delayed state changes     3.3 Verify state transition handling within watermark tolerance 4. EVENT_WINDOW with WATERMARK Test     4.1 Create event_window(start with event_val &gt;= 5 end with event_val &gt; 10) stream with watermark(1m) (s_event_watermark)     4.2 Test event sequence processing with out-of-order events     4.3 Verify event window completion with delayed events 5. PERIOD Window with WATERMARK Test     5.1 Create period(30s) stream with watermark(45s) (s_period_watermark)     5.2 Test periodic window recalculation with out-of-order data     5.3 Verify period-based time window behavior 6. COUNT_WINDOW with WATERMARK Test     6.1 Create count_window(3) stream with watermark(1m) (s_count_watermark)     6.2 Test count-based window recalculation with delayed records     6.3 Verify count window completion with out-of-order data                      path:                                            cases/18-StreamProcessing/08-Recalc/test_recalc_watermark.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/","title":"06-ResultSaved","text":""},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.result_saved_bug_2.TestStreamResultSavedComprehensive.test_stream_result_saved_comprehensive","title":"","text":"Result saved: comprehensive 1. Test [INTO [db_name.]table_name]     1.1 Test whether this option exists         1.1.1 Only notify without calculation and only notify without saving output can omit this option         1.1.2 Other scenarios must have this option     1.2 Test whether db_name is specified     1.3 Test output table types under different trigger conditions         1.3.1 With trigger grouping: output table is a super table         1.3.2 Without trigger grouping: output table is a normal table     1.4 Test scenarios where output table already exists         1.4.1 Existing table type matches output table type         1.4.2 Existing table type does not match output table type 2. Test [OUTPUT_SUBTABLE(tbname_expr)]     2.1 Test whether this option exists         2.1.1 With trigger grouping and exists (legal)         2.1.2 With trigger grouping and not exists (legal)         2.1.3 Without trigger grouping and exists (illegal)         2.1.4 Without trigger grouping and not exists (legal)     2.2 Test whether columns come from trigger table grouping columns     2.3 Test whether tbname_expr is an expression that outputs strings     2.4 Test scenarios where output length exceeds table maximum length (truncation) 3. Test [(column_name1, column_name2 [PRIMARY KEY][, ...])]     3.1 Test whether this option exists         3.1.1 Option exists             3.1.1.1 Test whether output table already exists                 3.1.1.1.1 Output table exists and column names match existing table (legal)                 3.1.1.1.2 Output table exists and column names don't match existing table (illegal)                 3.1.1.1.3 Output table doesn't exist (legal)             3.1.1.2 Test whether [PRIMARY KEY] is specified                 3.1.1.2.1 [PRIMARY KEY] specified                     3.1.1.2.1.1 Second column is integer or string type (legal)                     3.1.1.2.1.2 Second column is other type (illegal)                 3.1.1.2.2 Not specified         3.1.2 Option doesn't exist             3.1.2.1 Test whether default output table column names match calculation result column names 4. Test [TAGS (tag_definition [, ...])]     4.1 Test whether this option exists         4.1.1 Option exists             4.1.1.1 Test whether output table already exists                 4.1.1.1.1 Output table exists and tag types/names match existing table (legal)                 4.1.1.1.2 Output table exists and tag types/names don't match existing table (illegal)                 4.1.1.1.3 Output table doesn't exist (legal)         4.1.2 Option doesn't exist             4.1.2.1 Test whether default tag column definitions and values correspond to trigger grouping columns             4.1.2.2 Test whether tag column name is tag_tbname when grouping by table     4.2 Test whether grouping columns are specified         4.2.1 Grouping columns specified (legal)         4.2.2 Grouping columns not specified (illegal)     4.3 Test whether tag specified expr comes from trigger grouping columns     4.4 Test whether [COMMENT 'string_value'] is specified     4.5 Test correctness of generated column names in specified/unspecified scenarios 5. Test Target Table Management     5.1 Test deletion of target table after stream creation         5.1.1 Verify target table creation by stream         5.1.2 Test table deletion behavior         5.1.3 Test stream robustness after target table deletion         5.1.4 Verify error handling for missing target table                      path:                                            cases/18-StreamProcessing/06-ResultSaved/result_saved_bug_2.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.test_result_saved_comprehensive.TestStreamResultSavedComprehensive.test_stream_result_saved_comprehensive","title":"","text":"Result saved: summary 1. Test [INTO [db_name.]table_name]     1.1 Test whether this option exists         1.1.1 Only notify without calculation and only notify without saving output can omit this option         1.1.2 Other scenarios must have this option     1.2 Test whether db_name is specified     1.3 Test output table types under different trigger conditions         1.3.1 With trigger grouping: output table is a super table         1.3.2 Without trigger grouping: output table is a normal table     1.4 Test scenarios where output table already exists         1.4.1 Existing table type matches output table type         1.4.2 Existing table type does not match output table type 2. Test [OUTPUT_SUBTABLE(tbname_expr)]     2.1 Test whether this option exists         2.1.1 With trigger grouping and exists (legal)         2.1.2 With trigger grouping and not exists (legal)         2.1.3 Without trigger grouping and exists (illegal)         2.1.4 Without trigger grouping and not exists (legal)     2.2 Test whether columns come from trigger table grouping columns     2.3 Test whether tbname_expr is an expression that outputs strings     2.4 Test scenarios where output length exceeds table maximum length (truncation) 3. Test [(column_name1, column_name2 [PRIMARY KEY][, ...])]     3.1 Test whether this option exists         3.1.1 Option exists             3.1.1.1 Test whether output table already exists                 3.1.1.1.1 Output table exists and column names match existing table (legal)                 3.1.1.1.2 Output table exists and column names don't match existing table (illegal)                 3.1.1.1.3 Output table doesn't exist (legal)             3.1.1.2 Test whether [PRIMARY KEY] is specified                 3.1.1.2.1 [PRIMARY KEY] specified                     3.1.1.2.1.1 Second column is integer or string type (legal)                     3.1.1.2.1.2 Second column is other type (illegal)                 3.1.1.2.2 Not specified         3.1.2 Option doesn't exist             3.1.2.1 Test whether default output table column names match calculation result column names 4. Test [TAGS (tag_definition [, ...])]     4.1 Test whether this option exists         4.1.1 Option exists             4.1.1.1 Test whether output table already exists                 4.1.1.1.1 Output table exists and tag types/names match existing table (legal)                 4.1.1.1.2 Output table exists and tag types/names don't match existing table (illegal)                 4.1.1.1.3 Output table doesn't exist (legal)         4.1.2 Option doesn't exist             4.1.2.1 Test whether default tag column definitions and values correspond to trigger grouping columns             4.1.2.2 Test whether tag column name is tag_tbname when grouping by table     4.2 Test whether grouping columns are specified         4.2.1 Grouping columns specified (legal)         4.2.2 Grouping columns not specified (illegal)     4.3 Test whether tag specified expr comes from trigger grouping columns     4.4 Test whether [COMMENT 'string_value'] is specified     4.5 Test correctness of generated column names in specified/unspecified scenarios 5. Test Target Table Management     5.1 Test deletion of target table after stream creation         5.1.1 Verify target table creation by stream         5.1.2 Test table deletion behavior         5.1.3 Test stream robustness after target table deletion         5.1.4 Verify error handling for missing target table                      path:                                            cases/18-StreamProcessing/06-ResultSaved/test_result_saved_comprehensive.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.test_result_saved_datatype_precision.TestStreamResultSavedDatatypePrecision.test_stream_result_saved_datatype_precision","title":"","text":"Result saved: datatype precision This test focuses on precise datatype validation and edge cases: 1. Test precise column length calculations     1.1 VARCHAR length from string functions (CONCAT, SUBSTR, LPAD, RPAD)     1.2 NCHAR vs VARCHAR type differences     1.3 Binary data type handling     1.4 Maximum and minimum length constraints 2. Test numeric type precision and boundaries     2.1 Integer overflow and underflow scenarios     2.2 Float and double precision preservation     2.3 Numeric type casting edge cases     2.4 Aggregation result type precision 3. Test tag type precision validation     3.1 Tag length calculation from expressions     3.2 Tag type inheritance from source columns     3.3 Computed tag type determination     3.4 Tag name length limits and truncation 4. Test special data type scenarios     4.1 JSON data type handling (if supported)     4.2 Timestamp precision levels     4.3 NULL value handling in different types     4.4 Unicode and multi-byte character handling                      path:                                            cases/18-StreamProcessing/06-ResultSaved/test_result_saved_datatype_precision.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.test_result_saved_errors.TestStreamResultSavedErrors.test_stream_result_saved_errors","title":"","text":"Result saved: error cases This test covers error scenarios and boundary conditions for stream result saving: 1. Test error scenarios for [INTO [db_name.]table_name]     1.1 Missing INTO when required     1.2 Existing table with mismatched type 2. Test error scenarios for [OUTPUT_SUBTABLE(tbname_expr)]     2.1 OUTPUT_SUBTABLE without trigger grouping (illegal)     2.2 Invalid expressions in tbname_expr 3. Test error scenarios for [(column_name1, column_name2 [PRIMARY KEY][, ...])]     3.1 Column name mismatch with existing table     3.2 Invalid PRIMARY KEY column types 4. Test error scenarios for [TAGS (tag_definition [, ...])]     4.1 Tag mismatch with existing table     4.2 Missing grouping columns when tags specified     4.3 Invalid tag expressions                      path:                                            cases/18-StreamProcessing/06-ResultSaved/test_result_saved_errors.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.test_result_saved_primary_key.TestStreamResultSavedPrimaryKey.test_stream_result_saved_primary_key","title":"","text":"Result saved: primary key tests This test focuses specifically on PRIMARY KEY functionality in stream result saving: 1. Test valid PRIMARY KEY scenarios     1.1 Second column is integer type with PRIMARY KEY     1.2 Second column is string type with PRIMARY KEY     1.3 Multiple columns with PRIMARY KEY 2. Test invalid PRIMARY KEY scenarios     2.1 Second column is float type with PRIMARY KEY (should fail)     2.2 Second column is timestamp type with PRIMARY KEY (should fail)     2.3 PRIMARY KEY on first column (timestamp) - should fail or be ignored     2.4 PRIMARY KEY on non-existent column 3. Test PRIMARY KEY with existing tables     3.1 Existing table already has PRIMARY KEY     3.2 Existing table without PRIMARY KEY 4. Test PRIMARY KEY with different table types     4.1 PRIMARY KEY with normal tables     4.2 PRIMARY KEY with super tables (should be ignored or fail)                      path:                                            cases/18-StreamProcessing/06-ResultSaved/test_result_saved_primary_key.py"},{"location":"case_list_docs/StreamProcessing/ResultSaved/#18-StreamProcessing.06-ResultSaved.test_result_saved_schema_validation.TestStreamResultSavedSchemaValidation.test_stream_result_saved_schema_validation","title":"","text":"Result saved: schema validation This test focuses on precise validation of result table schemas: 1. Test column data types and lengths     1.1 Aggregation function result types (COUNT, SUM, AVG, MAX, MIN)     1.2 String function result types and lengths (CONCAT, SUBSTR, CAST)     1.3 Numeric type conversions and precision     1.4 Timestamp and datetime types     1.5 Boolean and binary types 2. Test tag data types and lengths     2.1 Tag types from trigger table columns     2.2 Computed tag expressions and their result types     2.3 Default tag lengths and custom tag lengths     2.4 Tag name length limits 3. Test column length calculations     3.1 VARCHAR length based on expressions     3.2 Fixed-length types (INT, BIGINT, DOUBLE, etc.)     3.3 Variable-length types (VARCHAR, NCHAR)     3.4 Maximum length constraints 4. Test PRIMARY KEY type validation     4.1 Valid PRIMARY KEY types and their specifications     4.2 Length constraints for PRIMARY KEY columns                      path:                                            cases/18-StreamProcessing/06-ResultSaved/test_result_saved_schema_validation.py"},{"location":"case_list_docs/StreamProcessing/Snode/","title":"01-Snode","text":""},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_mgmt_basic.TestSnodeMgmtBasic.test_snode_mgmt_basic","title":"","text":"Snode: create and drop 1. Create an 8-node dnode and create snodes on each dnode. 2. Check the results of each field in information_schema.ins_snodes. 3. Delete the snodes and check again. 4. Randomly create and delete snodes, and check the results.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_mgmt_basic.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_mgmt_replica3.TestSnodeMgmtReplica3.test_snode_mgmt_relica3","title":"","text":"Snode: repeatedly drop with stream 1. Create a 6-node dnode and a 3-replica database. 2. Create snodes on each node. 3. Then delete these snodes. 4. Repeat creating snodes. 5. Create a stream and check its status. 6. Continue deleting snodes. 7. Check the operational status of the stream.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_mgmt_replica3.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_mgmt_replicas.TestSnodeReplicas.test_snode_mgmt_replicas","title":"","text":"Snode: replica test Test the failover of 2-replica snodes.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_mgmt_replicas.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_params_alter_value.TestStreamParametersAlterParam.test_params_alter_value","title":"","text":"Parameter: alter config Modify the parameters streamBufferSize and numOfMnodeStreamMgmtThreads.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_params_alter_value.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_params_check_default.TestStreamParametersCheckDefault.test_params_check_default","title":"","text":"Parameter: check default value Check the default values of the following parameters: 1. numOfMnodeStreamMgmtThreads 2. numOfVnodeStreamReaderThreads 3. numOfStreamTriggerThreads 4. streamBufferSize 5. numOfStreamRunnerThreads 6. streamNotifyMessageSize 7. streamNotifyFrameSize                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_params_check_default.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_params_check_maxvalue.TestStreamParametersCheckMaxVal.test_params_check_maxval","title":"","text":"Parameter: check maximum value Check the maximum values of the following parameters: 1. numOfMnodeStreamMgmtThreads 2. numOfVnodeStreamReaderThreads 3. numOfStreamTriggerThreads 4. streamBufferSize 5. numOfStreamRunnerThreads 6. streamNotifyMessageSize 7. streamNotifyFrameSize                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_params_check_maxvalue.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_params_check_minvalue.TestStreamParametersCheckMinVal.test_params_check_minval","title":"","text":"Parameter: check maximum value Check the maximum values of the following parameters: 1. numOfMnodeStreamMgmtThreads 2. numOfVnodeStreamReaderThreads 3. numOfStreamTriggerThreads 4. streamBufferSize 5. numOfStreamRunnerThreads 6. streamNotifyMessageSize 7. streamNotifyFrameSize                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_params_check_minvalue.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_privileges_recalc.TestStreamPrivilegesRecalc.test_params_privilage_recalc","title":"","text":"Privilege: recalculate 1. Check normal user no write privilege to recalc stream. 2. Check normal user no query/write privilege to recalc stream. 3. Check normal user have write privilege to recalc stream.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_privileges_recalc.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_privileges_stream.TestStreamPrivilegesSnodeStream.test_params_snode_stream","title":"","text":"Privilege: snode and stream 1. Check normal user create snode. 2. Check normal user show snode. 3. Check normal user select ins_snodes. 4. Check normal user drop snode. 5. Check normal user create stream. 6. Check normal user drop stream.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_privileges_stream.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_privileges_systable.TestStreamPrivilegesSysTable.test_params_privilage_systable","title":"","text":"Privilege: show and systables 1. Check normal user query ins_streams. 2. Check normal user query ins_stream_tasks. 3. Check normal user query ins_stream_recalculates.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_privileges_systable.py"},{"location":"case_list_docs/StreamProcessing/Snode/#18-StreamProcessing.01-Snode.test_snode_privileges_twodb.TestStreamPrivilegesTwoDb.test_params_privilage_two_db","title":"","text":"Privilege: on multi database 1. Check normal user create stream in two db. 2. Check normal no source db read privilege to create stream. 3. Check grant read privilege on source db to user.                      path:                                            cases/18-StreamProcessing/01-Snode/test_snode_privileges_twodb.py"},{"location":"case_list_docs/StreamProcessing/Stream/","title":"02-Stream","text":""},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.stream_6570600210.TestSnodeMgmt.test_snode_mgmt","title":"","text":"Stream bug feishu-6570600210 1. Check stream td37724                       path:                                            cases/18-StreamProcessing/02-Stream/stream_6570600210.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.stream_partitionby.Test_STREAM_PartitionBy.test_stream_partition_by","title":"","text":"Stream nevados Refer: NULL                      path:                                            cases/18-StreamProcessing/02-Stream/stream_partitionby.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.stream_place_holder_column.TestStreamSchema.test_snode_mgmt","title":"","text":"Stream table modify 1. Check stream table modify                       path:                                            cases/18-StreamProcessing/02-Stream/stream_place_holder_column.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.stream_schema.TestStreamSchema.test_snode_mgmt","title":"","text":"Stream table rename 1. Check stream table modify  2. Check stream table modify with placeholder column 3. Check stream table modify after drop table 4. Check stream table modify after alter table tag 5. Check stream table modify after alter table tag rename/drop                      path:                                            cases/18-StreamProcessing/02-Stream/stream_schema.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.stream_td37724.TestSnodeMgmt.test_snode_mgmt","title":"","text":"Stream bug TD-37724 1. Check stream td37724                       path:                                            cases/18-StreamProcessing/02-Stream/stream_td37724.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.test_stream_check_name.TestStreamCheckName.test_stream_illegal_name","title":"","text":"Stream illegal name 1. Test stream with illegal names. 2. Test stream with special characters. 3. Test stream name length.                      path:                                            cases/18-StreamProcessing/02-Stream/test_stream_check_name.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.test_stream_long_name.TestStreamLongName.test_stream_long_name","title":"","text":"Stream long name 1. Test stream with excessively long names 2. Test stream with special characters in names 3. Test stream name length 4. Verify long stream name in information_schema.ins_streams                      path:                                            cases/18-StreamProcessing/02-Stream/test_stream_long_name.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.test_stream_no_snode.TestStreamNoSnode.test_stream_no_snode","title":"","text":"Stream no snode 1. Test that streams cannot be created without snode. 2. Test creating and dropping snodes. 3. Test creating streams after snodes are created. 4. Test dropping snodes and its impact on existing streams. 5. Test stream status after snode failures. 6. Test recreating snodes and streams.                      path:                                            cases/18-StreamProcessing/02-Stream/test_stream_no_snode.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.test_stream_output_table.TestStreamOutputTable.test_output_table_schema_validation","title":"","text":"Stream result match schema 1. Verify error is raised when calculation result and output table column type do not match 2. Verify error is raised when calculation result and output table column name do not match 3. Verify error is raised when calculation result and output table Tag column type do not match 4. Verify error is raised when calculation result and output table Tag column name do not match                      path:                                            cases/18-StreamProcessing/02-Stream/test_stream_output_table.py"},{"location":"case_list_docs/StreamProcessing/Stream/#18-StreamProcessing.02-Stream.test_stream_same_name.TestStreamSameName.test_stream_same_name","title":"","text":"Stream same name 1. Test stream with duplicate names. 2. Verify that creating a stream with an existing name fails. 3. Test recreating a stream with the same name. 4. Verify error handling for duplicate stream names. 5. Check stream name uniqueness in information_schema.ins_streams. 6. Ensure proper error messages for duplicate stream name attempts.                      path:                                            cases/18-StreamProcessing/02-Stream/test_stream_same_name.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/","title":"07-SubQuery","text":""},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_basic.TestStreamSubqueryBasic.test_stream_subquery_basic","title":"","text":"Subquery: basic test Verification testing during the development process.                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_basic.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_count_1.TestStreamSubqueryCount.test_stream_subquery_count_1","title":"","text":"Subquery: count(1) 1. Use count trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_count_1.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_count_2.TestStreamSubqueryCount.test_stream_subquery_count_2","title":"","text":"Subquery: count(2) 1. Use count trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_count_2.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_event.TestStreamSubqueryEvent.test_stream_subquery_event","title":"","text":"Subquery: event 1. Use event trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_event.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_session.TestStreamSubquerySession.test_stream_subquery_session","title":"","text":"Subquery: session 1. Use session trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_session.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_sliding.TestStreamSubquerySliding.test_stream_subquery_sliding","title":"","text":"Subquery: sliding 1. Use sliding trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_sliding.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_state.TestStreamSubqueryState.test_stream_subquery_state","title":"","text":"Subquery: state 1. Use state trigger mode 2. Output results include 4 dimensions:     No grouping     Group by table name     Group by tags     Group by ordinary columns 3. Generate 100 SQL statements using the following syntax combinations:     Tables: system tables, super tables, child tables, normal tables, virtual super tables, virtual child tables     Functions:         Single-row functions (math/string/conversion/time functions)         Aggregate functions         Selection functions         Time-series-specific functions         Geometry functions         System functions     Queries: projection queries, nested queries, join queries, window queries (time/event/count/session/state), SHOW commands, GROUP BY, PARTITION BY, ORDER BY, LIMIT, SLIMIT, UNION, etc.     Filters: time comparisons, ordinary column comparisons, tag column comparisons     Operators: arithmetic, string, bitwise, comparison, logical, JSON operators     Others:         Queries on databases/tables same as/different from the trigger table         View queries 4. Include the following combinations in step 3 query results:     Use all data types: numeric, binary, string, geometry, json, etc.     Use all pseudo-columns: _qstart, _qend, _wstart, _wend, _wduration, _c0, _rowts, irowts, _irowtsorigin, tbname, etc.     Include data columns and tag columns     Randomly include None and NULL in result sets     Result set sizes: 1 row, n rows     Include duplicate timestamp in result sets 5. Test placeholder usage in step 3's queries, including:     Placeholders in various positions like FROM, SELECT, WHERE     Each placeholder: _twstart, _twend, _twduration, _twrownum, _tcurrent_ts, _tgrpid, _tlocaltime, %%n, %%tbname, %%tbrows 6. Validation checks:     Verify table structures and table counts     Validate correctness of calculation results     Validate the accuracy of placeholder data, such as %%trows                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_state.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_usage_restrict.TestStreamSubqueryLimit.test_stream_subquery_limit","title":"","text":"Subquery: usage restrictions Verify the usage restrictions of each placeholder: 1. Non-window triggers cannot use _twstart, _twend, _twduration, _twrownum. 2. Non-sliding triggers cannot use _tcurrent_ts, _tprev_ts, _tnext_ts. 3. Only timed triggers can use _tprev_localtime, _tnext_localtime. 4. %%trows can only be used in the FROM clause. 5. Other placeholders can only be used in the SELECT and WHERE clauses. 6. The range of values for n in %%n. 7. Misspelled placeholders. 8. INSERT or other statements that do not return a result set are not allowed.                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_usage_restrict.py"},{"location":"case_list_docs/StreamProcessing/SubQuery/#18-StreamProcessing.07-SubQuery.test_subquery_vtable_change.TestStreamSubQueryVtableChange.test_stream_subquery_vtable_change","title":"","text":"Subquery: virtual table meta change test meta change (add/drop/modify) cases to stream for virtual table in subquery                      path:                                            cases/18-StreamProcessing/07-SubQuery/test_subquery_vtable_change.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/","title":"03-TriggerMode","text":""},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.count_dbg.TestStreamCountTrigger.test_stream_count_trigger","title":"","text":"Trigger mode count Verification testing during the development process.     1. Create database and super table     2. Create sub tables     3. Create streams with count trigger mode     4. Insert data into sub tables     5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/count_dbg.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.count_disorder.TestStreamCountTrigger.test_stream_count_trigger","title":"","text":"Trigger mode count many 1. Create database and super table 2. Create sub tables 3. Create streams with count trigger mode 4. Insert data into sub tables 5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/count_disorder.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_count.TestStreamCountTrigger.test_stream_count_trigger","title":"","text":"Trigger mode count 1. Create snode and database 2. Create super table and sub tables 3. Create streams with count_window trigger mode 4. Insert data into source tables 5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_count.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_event.TestStreamEventTrigger.test_stream_event_trigger","title":"","text":"Trigger mode stable event 1. Create snode and database 2. Create super table and sub tables 3. Create streams with event_window trigger mode 4. Insert data into source tables 5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_event.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_event_new.TestStreamEventTrigger.test_stream_event_trigger","title":"","text":"Trigger mode event Verification testing during the development process.                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_event_new.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_fill_history.TestStreamStateFillHistory.test_stream_fill_history","title":"","text":"Options: fill history 1. Create snode and database 2. Create super table and sub tables 3. Create streams with fill_history option 4. Insert data into source tables 5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_fill_history.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_period_1.TestStreamCheckpoint.test_stream_dev_basic","title":"","text":"Options: period 1. Create 10 streams, each stream has 10 source tables 2. Write data to source tables 3. Check stream results 4. Drop streams and tables                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_period_1.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_sliding.TestStreamSlidingTrigger.test_stream_sliding_trigger","title":"","text":"Options: sliding 1. Create stream with sliding trigger mode, different partition by columns and sliding time. 2. Execute various queries on the stream with different calculation tables and validate the results. 3. Validate the results against expected outputs or result files. 4. Clean up the created streams and databases after test execution.                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_sliding.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_state_disorder_update_new.TestStreamStateTrigger.test_stream_state_trigger","title":"","text":"Trigger mode state window 1. Create snode and database 2. Create super table and sub tables 3. Create streams with state_window trigger mode 4. Insert data into source tables 5. Check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_state_disorder_update_new.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_state_new.TestStreamStateTrigger.test_stream_state_trigger","title":"","text":"Options: state window stable 1. create 14 streams, each stream has 1 source tables 2. write data to source tables 3. check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_state_new.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_state_window_close.TestWindowCloseStateWindow.test_window_close_state_window","title":"","text":"Options: state window close Test window close trigger mode with state window windows 1. create streams with state window windows 2. write data to source tables with state window gaps 3. check stream results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_state_window_close.py"},{"location":"case_list_docs/StreamProcessing/TriggerMode/#18-StreamProcessing.03-TriggerMode.test_ts_7622.TestTS_7622.test_ts_7622","title":"","text":"Stream event window Description:     - Create a stream for a virtual table with an event window trigger mode     - Map table d1.t1.a to a data column of the virtual table     - Write data to d1.t1 and verify the stream calculation results     - Map table d2.t2.b to a data column of the virtual table     - Write data to d2.t2 and verify the stream calculation results                      path:                                            cases/18-StreamProcessing/03-TriggerMode/test_ts_7622.py"},{"location":"case_list_docs/StreamProcessing/UseCase/","title":"20-UseCase","text":""},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.big_press.Test_BigPress.test_stream_usecase_em","title":"","text":"Nevados Refer: https://taosdata.feishu.cn/wiki/Zkb2wNkHDihARVkGHYEcbNhmnxb                      path:                                            cases/18-StreamProcessing/20-UseCase/big_press.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.nevados_dbg.Test_Nevados.test_stream_usecase_nevados","title":"","text":"IDMP nevados Refer: https://taosdata.feishu.cn/wiki/XaqbweV96iZVRnkgHLJcx2ZCnQf                      path:                                            cases/18-StreamProcessing/20-UseCase/nevados_dbg.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.sdny_2.TestSdnyStream.test_sdny_case2","title":"","text":"Stream sdny test 1. test sdny stream                       path:                                            cases/18-StreamProcessing/20-UseCase/sdny_2.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_meters.Test_IDMP_Meters.test_stream_usecase_em","title":"","text":"IDMP: meters scenario 1. IDMP trigger table is super vtable 2. IDMP trigger table is vtable 3. IDMP trigger mode: period, sliding, event, session, interval, count, state 4. IDMP trigger group: partition by tbname, tag column, tbname and columns 5. IDMP trigger condition: on window open, on window close, on event 6. IDMP trigger action: notify, calc, calc and notify 7. IDMP notify on: window open, window close, both open and close 8. IDMP output table: super table , normal table 9. IDMP stream Options: IGNORE_DISORDER, CALC_NOTIF_ONLY, LOW_LATENCY_CALC,PRE_FILTER, FORCE_OUTPUT, IGNORE_NODATA_TRIGGER Refer: https://taosdata.feishu.cn/wiki/Zkb2wNkHDihARVkGHYEcbNhmnxb                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_meters.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_public.Test_IDMP_Meters_TD36808.test_td36808","title":"","text":"IDMP: public utility scenario Reproduce the scenario where IDMP generates a core: create 2 streams, STOP STREAM, START STREAM, DROP STREAM                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_public.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_pv.TestIdmpPhotovoltaic.test_pv","title":"","text":"IDMP: photovoltaic scenario 1. Test the analysis generated by AI recommendations, create a Stream, and verify the correctness of the stream. 2. Test different trigger types:     1. Sliding window: Calculate aggregates over an m-hour period every n minutes.     2. Event window: Starts from the start_condition and ends at the stop_condition for a field.     3. Session window: No data reported for more than n minutes.     4. Count window: Collect data n times consecutively. 3. Different types of aggregate functions:     1. AVG: Average value     2. LAST: Latest value     3. SUM: Summation     4. MAX: Maximum value Refer: https://taosdata.feishu.cn/wiki/Zkb2wNkHDihARVkGHYEcbNhmnxb#share-Ygqld907hoMESmx04GBcRlaVnZz                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_pv.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_tobacco.TestIdmpTobacco.test_idmp_tobacco","title":"","text":"IDMP: tobacco scenario 1. Test the analysis generated by AI recommendations, create a Stream, and verify the correctness of the stream. 2. Test manually created analysis and verify the correctness of the stream.   2.1. Trigger types:     - Timed window: Specify different window sizes and window offsets.     - State window: Specify the field for the state.     - Session window: Specify the time interval for the session.   2.2. Time window aggregation:     - Window start time: _tprev_localtime / _twstart / _tprev_ts     - Window end time: _tlocaltime / _twend / _tcurrent_ts   2.3. Output attributes:     - AVG: Average value     - LAST: Latest value     - SUM: Summation     - MAX: Maximum value     - STDDEV: Standard deviation     - SPREAD: Range     - SPREAD/FIRST: Rate of change Refer: https://taosdata.feishu.cn/wiki/Zkb2wNkHDihARVkGHYEcbNhmnxb#share-I9GwdF26PoWk6uxx2zJcxZYrn1d                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_tobacco.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_vehicle.Test_IDMP_Vehicle.test_stream_usecase_em","title":"","text":"IDMP: vehicle scenario 1. IDMP stream option with EVENT_TYPE 2. IDMP stream option with MAX_DELAY 3. IDMP stream option with WATERMARK 4. IDMP stream option with EXPIRED_TIME 5. IDMP stream option with IGNORE_DISORDER 6. IDMP write data with ordered and disordered data 7. IDMP write NULL data 8. IDMP calc with trows and select sql Refer: https://taosdata.feishu.cn/wiki/Zkb2wNkHDihARVkGHYEcbNhmnxb                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_vehicle.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_idmp_yuxi.Test_IDMP_Meters.test_stream_usecase_em","title":"","text":"IDMP: YuXi scenario Refer: https://taosdata.feishu.cn/wiki/G8mSwPK20iLpPrk9MmOc9g95nLe                      path:                                            cases/18-StreamProcessing/20-UseCase/test_idmp_yuxi.py"},{"location":"case_list_docs/StreamProcessing/UseCase/#18-StreamProcessing.20-UseCase.test_nevados.Test_Nevados.test_stream_usecase_nevados","title":"","text":"Nevados Refer: https://taosdata.feishu.cn/wiki/XaqbweV96iZVRnkgHLJcx2ZCnQf                      path:                                            cases/18-StreamProcessing/20-UseCase/test_nevados.py"},{"location":"case_list_docs/SuperTables/Alter/","title":"03-Alter","text":""},{"location":"case_list_docs/SuperTables/Alter/#04-SuperTables.03-Alter.test_stable_alter_basic.TestStableAlterBasic.test_stable_alter_basic","title":"","text":"Alter basic 1. Add Modify Drop Column 2. Add Modify Drop Rename Tag 3. Alter Comment 4. Alter add/modify/drop columns for all datatype 5. Alter modify varchar column to 390001 length 6. Alter add/modify tag/column with multi threads                      path:                                            cases/04-SuperTables/03-Alter/test_stable_alter_basic.py"},{"location":"case_list_docs/SuperTables/Alter/#04-SuperTables.03-Alter.test_stable_alter_overall.TestAlterTable.test_alter_table","title":"","text":"Alter super/normal table 1. Alter super  table add/modify/drop columns and set tags for all datatypes 2. Alter normal table add/modify/drop columns for all datatypes                      path:                                            cases/04-SuperTables/03-Alter/test_stable_alter_overall.py"},{"location":"case_list_docs/SuperTables/Alter/#04-SuperTables.03-Alter.test_stable_alter_tag.TestStableAlterTag.test_stable_alter_tag","title":"","text":"Alter tags 1. Create a super table 2. Create a child table and insert data 3. Add a tag column and verify that it takes effect 4. Query using the newly added tag value 5. Repeat the same operations for Drop, Modify, and Rename Tag 6. Restart and verify that all modifications remain effective                      path:                                            cases/04-SuperTables/03-Alter/test_stable_alter_tag.py"},{"location":"case_list_docs/SuperTables/Alter/#04-SuperTables.03-Alter.test_stable_alter_write_data.TestStableAlterThenWriteData.test_stable_alter_then_write_data","title":"","text":"Alter then write data 1. Create a table and insert data 2. Alter the table and insert data 3. Alter the table and insert expired data 4. Repeat the above operations 5. Restart and verify that all data remains intact                      path:                                            cases/04-SuperTables/03-Alter/test_stable_alter_write_data.py"},{"location":"case_list_docs/SuperTables/Create/","title":"01-Create","text":""},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_basic.TestStableCreateMt.test_stable_create_mt","title":"","text":"Stable name basic 1. Attempt to create stables with invalid table names, column names, and invalid data types 2. Create a super table containing multiple tag types 3. Create child tables and insert data 4. Query using tags                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_basic.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_keep.TestCreateStbKeep.test_create_stb_keep","title":"","text":"Stable keep options 1. prepare database 2. check create stb with keep 3. check create stb with err keep duration 4. check alter stb with keep 5. check alter stb with keep err 6. check child table with keep 7. check normal table with keep 8. check stb keep show create 9. check stb keep ins_stables                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_keep.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_presuf.TestDatabasePreSuf.test_stable_create_presuf","title":"","text":"Stable prefix &amp; suffix 1. Create Database with random vgroups 2. Create Super Table with random prefix and suffix 3. Create Sub Tables with random prefix and suffix 4. Insert data into Sub Tables 5. Check data in Sub Tables and Super Table                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_presuf.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_rowlength64k.TestRowlength64k.test_stable_create_rowlength64k","title":"","text":"Stable max row length alter 1. Create stable with max columns to test limit 2. Create stable with max tags to test limit 3. Alter stable to test column and tag limit 4. Insert data to test max columns and tags 5. Query data to test max columns and tags                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_rowlength64k.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_rowlength64k_benchmark.TestRowlength64kBenchmark.test_rowlength64k_benchmark","title":"","text":"Stable max row length benchmark 1. taosBenchmark create table with column 1023 2. taosBenchmark create table with column 4095 3. taosBenchmark create table with column 1021 4. taosBenchmark create table with column 4093 5. taosBenchmark run with rowlength64k.json 6. verify result is ok                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_rowlength64k_benchmark.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_create_rowlength64k_call.TestRowlength64k1.test_stable_create_rowlength64k","title":"","text":"Stable max row length 1. Call Table Max Columns Case with Different queryPolicy (-Q 1 to 4) 2. Call Table Max Columns Case with restful                      path:                                            cases/04-SuperTables/01-Create/test_stable_create_rowlength64k_call.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_stable_keep_compact.TestStbKeepCompact.test_super_table_keep_compact","title":"","text":"Stable keep options 1. Super table keep parameter only takes effect during compaction 2. Before compaction, all historical data is visible regardless of keep settings 3. After compaction, data older than the keep period is removed 4. Different combinations of database keep and super table keep behave as expected                      path:                                            cases/04-SuperTables/01-Create/test_stable_keep_compact.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_table_comment.TestTableComment.test_table_comment","title":"","text":"Stable comment options 1. Create normal table, stable and child table with/without comment 2. Alter table comment 3. Verify comment info in information_schema.ins_tables and information_schema.ins_stables 4. Verify error when comment length &gt; 1024                      path:                                            cases/04-SuperTables/01-Create/test_table_comment.py"},{"location":"case_list_docs/SuperTables/Create/#04-SuperTables.01-Create.test_table_param_ttl.TestTableParamTtl.test_table_param_ttl","title":"","text":"Stable ttl options 1. Create normal table with ttl param 2. Create stable and child table with ttl param 3. Insert data into child table with ttl param 4. Verify ttl param is ok                      path:                                            cases/04-SuperTables/01-Create/test_table_param_ttl.py"},{"location":"case_list_docs/SuperTables/Drop/","title":"02-Drop","text":""},{"location":"case_list_docs/SuperTables/Drop/#04-SuperTables.02-Drop.test_stable_drop_basic.TestStableDropBasic.test_stable_drop_basic","title":"","text":"Drop: basic 1. Create a super table 2. Create a child table 3. Create a normal table 4. Insert data 5. Drop the super table                      path:                                            cases/04-SuperTables/02-Drop/test_stable_drop_basic.py"},{"location":"case_list_docs/SuperTables/Drop/#04-SuperTables.02-Drop.test_stable_drop_delfile.TestDeleteCheck.test_delete_check","title":"","text":"Delete files after drop stable 1. Create database and stable  2. Insert data into child tables 3. Drop stable 4. Compact database 5. Check tsdb files are deleted 6. Repeat above steps for 3 times                      path:                                            cases/04-SuperTables/02-Drop/test_stable_drop_delfile.py"},{"location":"case_list_docs/SuperTables/Drop/#04-SuperTables.02-Drop.test_stable_drop_repeat.TestStableDropRepeat.test_stable_drop_repeat","title":"","text":"Drop: repeatedly 1. Create a super table. 2. Create child tables and insert data. 3. Drop the super table. 4. Repeat the above 30 times with the same super-table name.                      path:                                            cases/04-SuperTables/02-Drop/test_stable_drop_repeat.py"},{"location":"case_list_docs/SuperTables/Query/","title":"04-Query","text":""},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_column_datatypes.TestStableQueryColumnDatatypes.test_stable_query_column_datatypes","title":"","text":"Query: column datatypes 1. Create a super table containing 1 data column and 1 tag column 2. With data column data types: bool, smallint, tinyint, int, bigint, unsigned bigint, float, double, binary 3. Create child tables and insert data 4. Execute queries on the super table with filtering conditions based on regular data columns, including: Projection queries, Aggregate queries, Group-by queries                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_column_datatypes.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_column_filter.TestStableQueryColumnFilter.test_stable_query_column_filter","title":"","text":"Query: column filter 1. Create a super table containing multiple data columns and tags (2-6 fields) 2. Create child tables and insert data 3. Execute queries on the super table with filtering conditions based on regular data columns, including:     Projection queries     Aggregate queries     Group-by queries 4.                       path:                                            cases/04-SuperTables/04-Query/test_stable_query_column_filter.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_during_leader_election.TestSelectDuringLeaderElection.test_select_during_leader_election","title":"","text":"Query: during leader election 1. Create 3 dnodes 2. Create db with 10 vgroups 3 replications 2. Create supper table and sub table 3. Stop one of the dnodes with leader vnode on it 4. Select data from super table, it should be success                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_during_leader_election.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_from_dnodes.TestStableQueryFromDnodes.test_stable_query_from_dnodes","title":"","text":"Query: from dnodes 1. Create a super table distributed across multiple dnodes and vnodes 2. Insert data and query the results 3. Perform partitioned queries using PARTITION BY 4. Check query results when data is distributed across different vnodes, memory, and disk 5. Restart all nodes and verify the computation results                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_from_dnodes.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_tag.TestTagScan.test_tag_scan","title":"","text":"Query: tag scan 1. Create super table with tags 2. Create multiple child tables with different tag values 3. Insert data into child tables 4. Query tag with order by, limit, slimit, group by, distinct, partition by 5. Query tag with sub-queries 6. Query tag with single vgroup and multi vgroups 7. Query tag with different data types 8. Query tag with various combinations of clauses                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_tag.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_tag_datatypes.TestStableQueryTagDatatypes.test_stable_query_tag_datatypes","title":"","text":"Query: tag datatypes 1. Create a super table containing 1 data column and 1 tag column 2. With tag column data types: bool, smallint, tinyint, int, bigint, unsigned bigint, float, double, binary 3. Create child tables and insert data 4. Execute queries on the super table with filtering conditions based on regular data columns, including: Projection queries, Aggregate queries, Group-by queries                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_tag_datatypes.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_tag_filter.TestStableQueryTagFilter.test_query_tag_filter","title":"","text":"Query: tag filter 1. Create a super table containing multiple data columns and tags (1-6 fields) 2. Create child tables and insert data 3. Execute queries on the super table with filtering conditions based on regular data columns, including:     Projection queries     Aggregate queries     Group-by queries 4. Jira TS-4421                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_tag_filter.py"},{"location":"case_list_docs/SuperTables/Query/#04-SuperTables.04-Query.test_stable_query_tbname_filter.TestStableQueryTbnameFilter.test_stable_query_tbname_filter","title":"","text":"Query: tbname filter 1. Create a super table 2. Create child tables and insert data 3. Execute the following query operations on the super table using tbname INconditions:\u2022 Projection queries (column selection)\u2022 Aggregate queries (COUNT/SUM/AVG/MIN/MAX)\u2022 Grouping queries (GROUP BY with HAVING)                      path:                                            cases/04-SuperTables/04-Query/test_stable_query_tbname_filter.py"},{"location":"case_list_docs/Tables/NormalTables/","title":"01-NormalTables","text":""},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_100w.TestTb100wDataOrder.test_tb_100w_data_order","title":"","text":"Normal table create 100w 1. Create 100w normal tables 2. Query table order by col 3. flush database                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_100w.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_alter_1.TestNormalTableAlter1.test_normal_table_alter_1","title":"","text":"Alter: then desc 1. ALTER TABLE \u2026 ADD/DROP/MODIFY columns 2. DESCRIBE each change to confirm 3. Restart the database 4. Resume ADD/DROP/MODIFY operations and verify again                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_alter_1.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_alter_2.TestNormalTableAlter2.test_normal_table_alter_2","title":"","text":"Alter: then insert 1. Execute ADD COLUMN, DROP COLUMN, MODIFY COLUMN operations. 2. Insert data and run SELECT COUNT queries to verify. 3. Restart the database. 4. Continue modifying columns and verify the changes.                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_alter_2.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_alter_3.TestNormalTableAlter3.test_normal_table_alter_3","title":"","text":"Alter: import old data 1. Add column 2. Insert out-of-order data 3. Query data                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_alter_3.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_alter_4.TestNormalTableAlter4.test_normal_table_alter_4","title":"","text":"Alter: repeatedly add 1. Add column 2. Insert data 3. Project query 4. Loop for 7 times 5. Kill then restart                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_alter_4.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_alter_5.TestNormalTableAlter5.test_normal_table_alter_5","title":"","text":"Alter: repeatedly drop 1. Drop column 2. Insert data 3. Project query 4. Loop for 7 times 5. Kill then restart                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_alter_5.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_column_limit.TestNormalTableColumnNumLimit.test_normal_table_column_num_limit","title":"","text":"Column num limit 1. Create normal table 2. Add or delete columns 3. Check column count, the count should not exceed 4096                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_column_limit.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_datatypes.TestNormalTableDatatypes.test_normal_table_datatypes","title":"","text":"Normal table data types 1. Create a normal table containing bigint, binary, bool, double, float, int, smallint, tinyint types 2. Write data 3. Perform a projection query, including an order by condition 4. Perform a filter query, including various comparison conditions                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_datatypes.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_delete_reuse1.TestNormalTableDeleteReuse2.test_normal_table_delete_reuse2","title":"","text":"Repeatedly drop same name 1. Create a normal table (same name) 2. Insert data  3. Query data 4. Repeat 20 timeses                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_delete_reuse1.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_delete_reuse2.TestNormalTableDeleteReuse2.test_normal_table_delete_reuse2","title":"","text":"Repeatedly drop new name 1. Create a normal table (new name) 2. Insert data  3. Query data 4. Repeat 20 timeses                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_delete_reuse2.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_delete_writing.TestNormalTableDeleteWriting.test_normal_table_delete_writing","title":"","text":"Normal table drop while writing 1. Create a background process that continuously writes data 2. Create a normal table 3. Insert data  4. Query data 5. Repeat 20 timeses                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_delete_writing.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_query_after_drop.TestNormalTableDrop.test_normal_table_drop","title":"","text":"Normal table after drop 1. Create a table \u2192 insert one record \u2192 query that record \u2192 repeat this sequence 8 times 2. Drop all created tables 3. Repeat 1 times                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_query_after_drop.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_query_aggregate.TestNormalTableAggregate.test_normal_table_aggregate","title":"","text":"Normal table aggregate 1. Create a table with 256 columns 2. Insert data 3. Execute projection queries 4. Execute filter queries 5. Execute aggregate queries 6. Kill the process and restart the database                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_query_aggregate.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_query_composite.TestCompositeKeyLoad.test_composite_key_load","title":"","text":"Normal table composite key Error Reading Composite Key Data from Memory and STT Files Root Cause: The minKeyused a shallow copy. During backward iteration in STT, this accidentally modified the minKeyvalue. When merging keys from memory and STT, inconsistent key states caused data corruption. Reproduction Steps: 1. Create table with timestamp column and composite key string column. Insert 4 records into STT files and 1 record into memory. 2. Execute query \u2192 Trigger failure                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_query_composite.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_query_filter.TestNormalTableQuery.test_normal_table_query","title":"","text":"Normal table filter 1. Create a normal table 2. Insert data 3. Execute projection queries 4. Execute aggregate queries 5. Execute field filtering queries                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_query_filter.py"},{"location":"case_list_docs/Tables/NormalTables/#03-Tables.01-NormalTables.test_normaltable_synatx.TestNormalTableSynatx.test_normal_table_synatx","title":"","text":"Normal table syntax 1. Attempt to create tables with invalid table names 2. Attempt to create tables with invalid column names 3. Attempt to create tables with invalid data types 4. Create normal tables with valid and invalid names                      path:                                            cases/03-Tables/01-NormalTables/test_normaltable_synatx.py"},{"location":"case_list_docs/Tables/SubTables/","title":"02-SubTables","text":""},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_autocreate.TestSubTableAutoCreate.test_subtable_auto_create","title":"","text":"Auto create child table 1. Automatically create child tables by inserting data, query data, and query tag values 2. Delete some of the created child tables and repeat the auto-creation 3. When automatically creating child tables, use some Chinese tag values 4. When automatically creating child tables, specify partial tag values 5. Insert table auto insert with cache 6. Check duplicate table with err tag 7. Check table with another stb name 8. Check table with same name 9. Check same table same timestamp 10. Check some error cases                      path:                                            cases/03-Tables/02-SubTables/test_subtable_autocreate.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_batchcreate.TestSubTableBatchCreate.test_sub_table_batch_create","title":"","text":"Batch create 1. Create super table 2. Batch-create multiple child tables 3. Insert data 4. Query results 5. Create a normal table 6. Batch-insert data 7. Query results                      path:                                            cases/03-Tables/02-SubTables/test_subtable_batchcreate.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_create_using_csv.TestCreateCtbUsingCsvFile.test_subtable_create_using_csv","title":"","text":"Child table create using csv 1. Create database with vgroups 20 stt_trigger 1 2. Create super table according to csvfile format 3. Create child table using csv file 4. Check created child table number                      path:                                            cases/03-Tables/02-SubTables/test_subtable_create_using_csv.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_drop.TestSubtableDrop.test_subtable_drop","title":"","text":"Drop then query 1. Repeatedly create and drop 2. Query tags after deleting child tables                      path:                                            cases/03-Tables/02-SubTables/test_subtable_drop.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_query.TestSubTableQuery.test_subtable_query","title":"","text":"Query 1. Create super tables and child tables 2. Check results from:     SHOW TABLES     SELECT * FROM ins_tables     SELECT * FROM ins_stables                      path:                                            cases/03-Tables/02-SubTables/test_subtable_query.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_set_tag_vals.TestSubTableSetTagVals.test_set_subtable_set_tag_vals","title":"","text":"Set tag vals 1. Modify tag values and insert data, including setting tags with NULL values 2. Perform filtered queries on the super table using the modified tag values 3. Modify multiple tag values simultaneously                      path:                                            cases/03-Tables/02-SubTables/test_subtable_set_tag_vals.py"},{"location":"case_list_docs/Tables/SubTables/#03-Tables.02-SubTables.test_subtable_ttl.TestTtl.test_subtable_ttl","title":"","text":"Subtable ttl 1. Create 100 subtables with TTL 2. flush database and wait for TTL to take effect 3. Verify that the correct number of subtables have been dropped 4. Create 2 subtables, one with TTL and one without 5. Insert data into the subtable with TTL before it expires 6. Verify that the subtable with TTL is not dropped after the TTL period, 7. While the subtable without TTL remains unaffected. 8. Create/Alter ttl/comment on normal/child table 9. Verify ttl/comment in information_schema                      path:                                            cases/03-Tables/02-SubTables/test_subtable_ttl.py"},{"location":"case_list_docs/TimeSeriesExt/CountWindow/","title":"07-CountWindow","text":""},{"location":"case_list_docs/TimeSeriesExt/CountWindow/#13-TimeSeriesExt.07-CountWindow.test_count.TestCount.test_count","title":"","text":"Count basic 1. Count + sliding window queries 2. Specified column queries 3. Combined use with PARTITION BY and ORDER BY 4. Some illegal value checks                      path:                                            cases/13-TimeSeriesExt/07-CountWindow/test_count.py"},{"location":"case_list_docs/TimeSeriesExt/EventWindow/","title":"05-EventWindow","text":""},{"location":"case_list_docs/TimeSeriesExt/EventWindow/#13-TimeSeriesExt.05-EventWindow.test_event.TestEvent.test_event","title":"","text":"Event: basic test 1. Test the usage of event window, including various start/end conditions, combination with PARTITION BY and GROUP BY, usage as subqueries, etc. 2. Test some illegal statements                      path:                                            cases/13-TimeSeriesExt/05-EventWindow/test_event.py"},{"location":"case_list_docs/TimeSeriesExt/EventWindow/#13-TimeSeriesExt.05-EventWindow.test_ts_event_bugs.TestTsEventBugs.test_ts_event_bugs","title":"","text":"Meta bugs 1. Verify bug TD-31660                      path:                                            cases/13-TimeSeriesExt/05-EventWindow/test_ts_event_bugs.py"},{"location":"case_list_docs/TimeSeriesExt/Fill/","title":"02-Fill","text":""},{"location":"case_list_docs/TimeSeriesExt/Fill/#13-TimeSeriesExt.02-Fill.test_ts_fill.TestFill.test_ts_fill","title":"","text":"Fill: basic test 1. Test fill + value, while generating multiple columns simultaneously 2. Test various methods such as prev, NULL, none, next, linear, null, null_f, and more 3. Test insert two rows and check fill(value, 0, 0) and fill(value, 1000, 10)                      path:                                            cases/13-TimeSeriesExt/02-Fill/test_ts_fill.py"},{"location":"case_list_docs/TimeSeriesExt/Fill/#13-TimeSeriesExt.02-Fill.test_ts_fill.TestFill.test_fill_sliding_duration","title":"","text":"Fill with sliding 1. Check the correctness of duration when filling null for sliding interval window 2. Use first and last function to verify the window range 3. Sliding window with duration overlapping 4. Fill with null method 5. Verify the correctness of _wstart, _wduration, _wend columns                      path:                                            cases/13-TimeSeriesExt/02-Fill/test_ts_fill.py"},{"location":"case_list_docs/TimeSeriesExt/Fill/#13-TimeSeriesExt.02-Fill.test_ts_fill_datatype.TestFill2.test_ts_fill_datatype","title":"","text":"Fill datatype 1. Create normal/super tables with various decimal/decimal64 and other data types 2. Insert data into the tables 3. Run fill queries with different fill methods (PREV, NEXT, NULL, LINEAR, NULL_F) 4. Validate the results to ensure correctness of the fill operation                              path:                                            cases/13-TimeSeriesExt/02-Fill/test_ts_fill_datatype.py"},{"location":"case_list_docs/TimeSeriesExt/Fill/#13-TimeSeriesExt.02-Fill.test_ts_fill_method.TestFill.test_ts_fill_method","title":"","text":"Fill method 1. Create database with ns precision 2. Create table with different data types 3. Insert data with nulls 4. Perform fill queries with different data types and methods (value, null, prev, next) 5. Query with multi-threaded fill range 6. Validate the filled results for each data type 7. Fill with group by queries 8. Fill with complex expressions                      path:                                            cases/13-TimeSeriesExt/02-Fill/test_ts_fill_method.py"},{"location":"case_list_docs/TimeSeriesExt/PartitionBy/","title":"01-PartitionBy","text":""},{"location":"case_list_docs/TimeSeriesExt/PartitionBy/#13-TimeSeriesExt.01-PartitionBy.test_ts_partitonby.TestPartitonBy.test_ts_partitionby","title":"","text":"Time series partition by 1. Create stable with multiple tags 2. Create multiple subtables using the stable with different tags 3. Insert data into the subtables 4. Query with partition by on different tags and verify the results 5. Query various aggregate functions with partition by clause 6. Query interval and sliding window with partition by clause 7. Query edge cases and error handling for partition by queries                      path:                                            cases/13-TimeSeriesExt/01-PartitionBy/test_ts_partitonby.py"},{"location":"case_list_docs/TimeSeriesExt/SessionWindow/","title":"06-SessionWindow","text":""},{"location":"case_list_docs/TimeSeriesExt/SessionWindow/#13-TimeSeriesExt.06-SessionWindow.test_session.TestSession.test_session","title":"","text":"Session basic 1. Test the basic usage of session window 2. Test some illegal statements                      path:                                            cases/13-TimeSeriesExt/06-SessionWindow/test_session.py"},{"location":"case_list_docs/TimeSeriesExt/TimeWindow/","title":"03-TimeWindow","text":""},{"location":"case_list_docs/TimeSeriesExt/TimeWindow/#13-TimeSeriesExt.03-TimeWindow.test_interval_auto.TestIntervalMore.test_query_interval","title":"","text":"Interval: auto 1. Testing the mixed use of interval and auto 2. Combined with LIMIT, ts filtering conditions 3. Combined with sliding                      path:                                            cases/13-TimeSeriesExt/03-TimeWindow/test_interval_auto.py"},{"location":"case_list_docs/TimeSeriesExt/TimeWindow/#13-TimeSeriesExt.03-TimeWindow.test_interval_basic.TestInterval.test_interval_basic","title":"","text":"Interval: basic test 1. Testing the use of interval, offset, and sliding 2. Testing their use with GROUP BY, ORDER BY, and PARTITION BY 3. Testing different fill methods, such as NULL, prev, next 4. Testing mixed use with functions such as count, sum, max, min, count, stddev, last, spread 5. Testing unit interval:     - percision ms/us/ns     - different interval/sliding/offset units: a/s/m/h/d/w/M/y     - invalid unit handling 6. Testing explain plan for interval/sliding/offset 7. Testing limit/offset with interval queries                      path:                                            cases/13-TimeSeriesExt/03-TimeWindow/test_interval_basic.py"},{"location":"case_list_docs/TimeSeriesExt/TimeWindow/#13-TimeSeriesExt.03-TimeWindow.test_interval_bugfix.TestIntervalBugFix.test_interval_bugfix","title":"","text":"Interval: bug fixed 1. Jira TS-5400 2. Jira TS-7676                        path:                                            cases/13-TimeSeriesExt/03-TimeWindow/test_interval_bugfix.py"},{"location":"case_list_docs/TimeSeriesExt/TimeWindow/#13-TimeSeriesExt.03-TimeWindow.test_interval_timezone.TestIntervalDiffTz.test_interval_diff_tz","title":"","text":"Interval: timezone test interval with client and server using different timezone                      path:                                            cases/13-TimeSeriesExt/03-TimeWindow/test_interval_timezone.py"},{"location":"case_list_docs/Tools/Benchmark/","title":"03-Benchmark","text":""},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_basic.TestBenchmarkBasic.test_benchmark_basic","title":"","text":"taosBenchmark basic 1. Insert data with different json files 2. Check data correct depends on json file 3. Check taosBenchmark options 4. Check custom column and tags 5. Check default json file 6. Check demo mode 7. Check from to continue insert 8. Check from to insert 9. Check insert auto create table json 10.Check insert bind vgroup 11.Check json tag 12.Check limit offset json 13.Check insert precision 14. Check insert with mix mode() 15. Check insert correctly with different stt options 16. Check taos config is correctedly set                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_basic.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_bugs.TestBugs.test_benchmark_bugs","title":"","text":"taosBenchmark bugs 1. Verify bug TD-32913 2. Verify bug TD-31575 3. Verify bug TD-31490 4. Verify bug TS-5846 5. Verify bug TS-5234 6. Verify bug TD-22190                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_bugs.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_commandline.TestBenchmarkCommandline.test_benchmark_commandline","title":"","text":"taosBenchmark command line 1. Verify -c with different config path 2. Verify -I with taosc, rest, stmt, stmt2, sml, sml-line, sml-telnet, sml-json, sml-taosjson 3. Verify -b with all data types 4. Verify -v with support vgroups 5. Verify -A with all data types 6. Verify -S to set start time 7. Verify -U to do supplement insert 8. Verify -V to check version info 9. Verify other command line options -ntyNxGrTiFM 10. Verify JIRA TD-11510/TD-19387/TD-19985/TD-21063/TD-22334/TD-21932/TD-19352/TD-21806 11. Verify invalid command line options                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_commandline.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_commandline.TestBenchmarkCommandline.test_benchmark_disorder","title":"","text":"Benchmark disorder data 1. Prepare disorder data with taosBenchmark -O option 2. Run sql to verify the data correctness 3. Run sql again after flush database 4. Verify sub table data correctness 5. Run sql again after flush database 6. Verify sub table data correctness again 7. Repeat the above steps with different parameters                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_commandline.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_conn_mode.TestConnMode.test_benchmark_conn_mode","title":"","text":"taosBenchmark connect with Native and WebSocket 1. Verify \"-Z native -X http://127.0.0.1:6041\" 2. Verify \"-Z websocket -X http://127.0.0.1:6042\" 3. Verify command line connection mode priority over json and env 4. Verify env connection mode priority over json 5. Verify except command line connection mode 6. Verify host and port in command line and json                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_conn_mode.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_datatypes.TestBenchmarkDatatypes.test_benchmark_datatypes","title":"","text":"taosBenchmark datatypes 1. Check decimal data type                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_datatypes.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_except.TestBenchmarkExcept.test_benchmark_except","title":"","text":"taosBenchmark exception 1. Insert operator be canceled check expect 2. Insert operator be forced exit check expect 3. Insert operator meet dnode exit check expect                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_except.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_mix.TestTaoscInsertMix.test_taosc_insert_mix","title":"","text":"taosBenchmark insert mix mode 1. Insert data with mix mode json file 2. Generate data rate: disorder_ratio 10%, update_ratio 5%, delete_ratio 1% 3. Verify generate rows is less than 95% (except delete rows)                       path:                                            cases/81-Tools/03-Benchmark/test_benchmark_mix.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_query_main.TestBenchmarkQueryMain.test_query_main","title":"","text":"taosBenchmark query basic 1. Insert test data into benchmark tables. 2. Run taosBenchmark in three query modes:     1) specified table query     2) specified table mixed query     3) super table query 3. Validate the output of each query mode to ensure correct execution. 4. Perform exception tests to verify error handling.                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_query_main.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_query_rest.TestBenchmarkQueryRest.test_benchmark_basic","title":"","text":"taosBenchmark query with json 1. Create database and super table 2. Create sub-tables and insert data 3. taosBenchmark run with taosc_query.json 4. taosBenchmark run with rest_query.json 5. taosBenchmark run with taosc_query_mixed_query.json 6. taosBenchmark run with rest_query_mixed_query.json 7. Verify query result correct 8. Verify query times correct 9. Verify query with times less than or equal to 100 10. Verify query result print QPS 11. Use illegal or out of range parameters query json file                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_query_rest.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_query_sqlfile.TestQueryJsonWithSqlfile.test_benchmark_query_json","title":"","text":"taosBenchmark query with json 1. taosBenchmark run with query sqlfile 2. Verify data correct after query sqlfile 3. taosBenchmark run with query error sqlfile 4. Verify handling of error sqlfile                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_query_sqlfile.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_rest.TestCommandlineSmlRest.test_commandline_sml_rest","title":"","text":"taosBenchmark run with rest connect 1. Verify \"-I sml-rest -t 1 -n 1 -y\" 2. Verify \"-I sml-rest-line -t 1 -n 1 -y\" 3. Verify \"-I sml-rest-telnet -t 1 -n 1 -y\" 4. Verify \"-I sml-rest-json -t 1 -n 1 -y\" 5. Verify \"-I sml-rest-taosjson -t 1 -n 1 -y\" 6. Verify \"-N -I sml-rest -y\" negative case 7. Run with rest insert all data-types 8. Connect with telnet_tcp protocol 9. Verify taosadapter with sml rest json/line/telnet                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_rest.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_sml.TestBenchmarkSml.test_benchmark_sml","title":"","text":"taosBenchmark schemaless insert 1. sml auto create table with json 2. sml insert alltypes with json 3. sml interlace 4. sml json alltypes interlace 5. sml json alltypes 6. sml json insert alltypes same min max 7. sml taosjson alltypes 8. sml taosjson insert alltypes same min max 9. sml telnet alltypes 10.sml telnet insert alltypes same min max                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_sml.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_stmt.TestBenchmarkStmt.test_benchmark_stmt","title":"","text":"taosBenchmark stmt &amp; stmt2 insert 1. Stmt auto create table with json 2. Stmt insert alltypes with json 3. Stmt insert alltypes same min max 4. Stmt offset with json 5. Stmt2 restart dnode during insert with json 6. Stmt2 insert with auto-create-table(yes or no), interlace or batch, csv or not 7. Old case (taosdemo) for insert with stmt other parameters                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_stmt.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_tag_order_sml.TestInsertTagOrderSml.test_benchmark_tag_order_sml","title":"","text":"taosBenchmark tag order sml 1. Sml insert with tag order and interlace 1 2. Sml insert with tag order and interlace 0 3. Check tag value is ordered after insert                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_tag_order_sml.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_tag_order_sql.TestInsertTagOrderSql.test_benchmark_tag_order_sql","title":"","text":"taosBenchmark tag order sql 1. Sql insert with tag order and interlace 1 2. Sql insert with tag order and interlace 0  3. Check tag value is ordered after insert                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_tag_order_sql.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_tag_order_stmt.TestInsertTagOrderStmt.test_benchmark_tag_order_stmt","title":"","text":"taosBenchmark tag order stmt 1. Stmt insert with tag order and interlace 1 2. Stmt insert with tag order and interlace 0 3. Check tag value is ordered after insert                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_tag_order_stmt.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_tag_order_stmt2.TestInsertTagOrderStmt2.test_insert_tag_order_stmt2","title":"","text":"taosBenchmark tag order stmt2 1. Stmt2 insert with tag order and interlace 1 2. Stmt2 insert with tag order and interlace 0 3. Check tag value is ordered after insert                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_tag_order_stmt2.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_taosc.TestTaoscAutoCreateTableJson.test_benchmark_taosc","title":"","text":"taosBenchmark taosc insert 1. Taosc insert auto create table with json 2. Taosc insert alltypes with json partial col 3. Taosc insert alltypes with json 4. Taosc insert alltypes same min max 5. Taosc insert mix 6. Taosc insert retry global with json 7. Taosc insert retry stb with json 8. Taosc insert with table creating interval                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_taosc.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_tmq.TestBenchmarkTmq.test_benchmark_tmq","title":"","text":"taosBenchmark tmq 1. Check tmq basic insert data, tmq sequ, tmq parallel 2. Check tmq case for different options 3. Check coredump do restart taosd during consume data                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_tmq.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_website.TestBenchmarkWebsite.test_benchmark_website","title":"","text":"taosBenchmark official website 1. Check official website example case run successfully 2. example files: insert.json/query.json/queryStb.json/tmq.json                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_website.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_websocket.TestWebsocket.test_benchmark_websocket","title":"","text":"taosBenchmark websocket 1. Check option -W http://localhost:6041 2. Check option --driver='WebSocket' 3. Check option --cloud_dsn='http://localhost:6041'                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_websocket.py"},{"location":"case_list_docs/Tools/Benchmark/#81-Tools.03-Benchmark.test_benchmark_with_csv.TestBenchmarkWithCsv.test_benchmark_with_csv","title":"","text":"taosBenchmark json with csv 1. Create table tags from csv file 2. Create table with keywords 3. Export data to csv files 4. Insert data from json and csv files 5. Stmt sample with csv and json 6. Stmt sample with csv and json doesnt use ts 7. Stmt sample with csv and json subtable 8. Taosc sample with csv and json 9. Taosc sample with csv and json subtable                      path:                                            cases/81-Tools/03-Benchmark/test_benchmark_with_csv.py"},{"location":"case_list_docs/Tools/Check/","title":"01-Check","text":""},{"location":"case_list_docs/Tools/Check/#81-Tools.01-Check.test_check_error_code.TestCheckErrorCode.test_check_error_code","title":"","text":"Check the consistency of error codes between header file and doc files. 1. Read all error codes from include/util/taoserror.h 2. Read all error codes from docs/zh/14-reference/09-error-code.md 3. Read all error codes from docs/en/14-reference/09-error-code.md 4. Check whether all error codes in header file are documented in both doc files 5. Check whether the description, possible cause and suggested actions are provided in both doc files                      path:                                            cases/81-Tools/01-Check/test_check_error_code.py"},{"location":"case_list_docs/Tools/Check/#81-Tools.01-Check.test_check_scan.TestScan.test_check_scan","title":"","text":"Scan database &amp; vgroups 1. Preapare 3 dnode cluster environment 2. Check scan database command correctness 3. Check scan vgroups command correctness 4. Check show scans command correctness 5. Check show scan &lt;scan_id&gt; command correctness 6. Check kill scan &lt;scan_id&gt; command correctness 7. Check error cases of scan vgroups command   - invalid sql   - error without using database   - error with duplicate vgroup   - error with invalid vgroup id   - error to scan vgroups not in the same database   - error with vgroup ids not in the same data node 8. Check success cases of scan vgroups command 9. Check scan vgroups in multiple databases command correctness 10. Check scan vgroups command after using database                      path:                                            cases/81-Tools/01-Check/test_check_scan.py"},{"location":"case_list_docs/Tools/Check/#81-Tools.01-Check.test_check_systb_inspect.TestTaosinspect.test_taosinspect","title":"","text":"Tool system tables inspect 1. Check columns completeness on information_schema tables: 2. information_schema.ins_stables 3. information_schema.ins_dnode_variables 4. information_schema.ins_dnodes 5. information_schema.ins_mnodes 6. information_schema.ins_vnodes 7. information_schema.ins_users 8. information_schema.ins_user_privileges 9. information_schema.ins_grants 10. information_schema.ins_databases 11. information_schema.ins_tables 12. information_schema.ins_streams 13. information_schema.ins_topics 14. information_schema.ins_subscriptions 15. information_schema.ins_vgroups 16. information_schema.ins_stream_tasks                      path:                                            cases/81-Tools/01-Check/test_check_systb_inspect.py"},{"location":"case_list_docs/Tools/Taos/","title":"02-Taos","text":""},{"location":"case_list_docs/Tools/Taos/#81-Tools.02-Taos.test_tool_cmdline.TestFullopt.test_tools_cmdline","title":"","text":"taos-CLI command line test 1. Insert data with taosBenchmark json format 2. Check taos-CLI all command lines                      path:                                            cases/81-Tools/02-Taos/test_tool_cmdline.py"},{"location":"case_list_docs/Tools/Taos/#81-Tools.02-Taos.test_tool_taos_cli.TestTaosCli.test_tool_taos_cli","title":"","text":"taos-CLI basic test 1. Insert data with taosBenchmark json format 2. Check describe show full 3. Check basic command in different conn mode 4. Check version and help 5. Check command options 6. Check data dump in/out 7. Check conn mode priority and except cmd 8. Check max password length                      path:                                            cases/81-Tools/02-Taos/test_tool_taos_cli.py"},{"location":"case_list_docs/Tools/Taos/#81-Tools.02-Taos.test_tool_taos_shell.TestTaosShell.test_tool_taos_shell","title":"","text":"taos-CLI command line 1. taos-CLI connect with different parameters 2. taos-CLI execute sql with different parameters 3. taos-CLI verify execute result with system database 4. taos-CLI parameters include: -h, -P, -u, -p, -a, -A, -c, -C, -s, -r, -f, -t, -n, -l, -N, -V, -d, -w 5. taos-CLI test -k repeatly 6. taos-CLI test environment: taosd with cluster mode                      path:                                            cases/81-Tools/02-Taos/test_tool_taos_shell.py"},{"location":"case_list_docs/Tools/Taos/#81-Tools.02-Taos.test_tool_taos_shell_error.TestTaosShellError.test_tool_taos_shell_error","title":"","text":"taos-CLI except 1. taos-CLI connect with different error parameters 2. taos-CLI execute sql with different error parameters 3. taos-CLI expect connect or execute error 4. taos-CLI different parameters include: -h, -P, -u, -p, -a, -f                      path:                                            cases/81-Tools/02-Taos/test_tool_taos_shell_error.py"},{"location":"case_list_docs/Tools/Taos/#81-Tools.02-Taos.test_tool_taos_shell_net_chk.TestTaosShellNetChk.test_tool_taos_shell_net_chk","title":"","text":"taos-CLI net check 1. taosd normal running 2. taos-CLI -k expect 2: service ok 3. taosd stop 4. taos-CLI -k expect 0: unavailable 5. taos-CLI -n server start 6. taos-CLI -n client expect response is received 7. taosd restart 8. taos-CLI -k expect 2: service ok                              path:                                            cases/81-Tools/02-Taos/test_tool_taos_shell_net_chk.py"},{"location":"case_list_docs/Tools/Taosdump/","title":"04-Taosdump","text":""},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_basic.TestTaosdumpBasic.test_taosdump_basic","title":"","text":"taosdump basic 1. Create database and tables with various data types 2. Insert data with special values 3. Use taosdump to export the database 4. Drop the original database 5. Use taosdump to import the database back with different options 6. Verify the imported database, tables, and data 7. Boundary value testing for database and table names 8. Check large data insertion and export/import 9. Check taosdump with different configurations 10. Check taosdump export/import with chinese string value 11. Inspect avro files generated with -I argument 12. Dump/restore a specific normal table in a database 13. Dump/restore some super/child tables in a database 14. Dump/restore database with escaped argument -e 15. Dump/restore into different data types 16. Dump/restore table with many columns(MAX 300 columns)                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_basic.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_bugs.TestTaosdumpStartEndTime.test_taosdump_bugs","title":"","text":"taosdump bugs 1. Verify bug TS-2769 (start-time end-time) 2. Verify bug TS-7053 (start-time end-time + precision) 3. Verify bug TS-3072 (database name case sensitivity)                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_bugs.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_commandline.TestTaosdumpCommandline.test_taosdump_commandline","title":"","text":"taosdump commandline 1. Insert data with taosBenchmark 2. Test taosdump commandline arguments:     - dump in/out with Native/Rest/WebSocket modes     - basic commandline arguments     - except commandline arguments     - check connMode priority cmd &gt; env 3. Verify dump and import data is correctly. 4. Check long password support. 5. Inspect avro files generated with -I argument 6. Dump/restore database with escaped argument -e                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_commandline.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_compa.TestTaosdumpCompa.test_taosdump_compa","title":"","text":"taosdump compatible  1. Backup data come from v3.1.0.0 2. Restore data with taosdump 3. Verify data correctness     - compare sum value for numeric type      - compare last value for string/boolean type                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_compa.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_datatypes.TestTaosdumpDataTypes.test_taosdump_datatypes","title":"","text":"taosdump data types 1. taosdump type big int 2. taosdump type binary 3. taosdump type bool 4. taosdump type double 5. taosdump type float 6. taosdump type json 7. taosdump type small int 8. taosdump type int 9. taosdump type tiny int 10. taosdump type unsigned big int 11. taosdump type unsigned int 12. taosdump type unsigned small int 13. taosdump type unsigned tiny int 14. taosdump type geometry 15. taosdump type varbinary                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_datatypes.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_except.TestTaosdumpRetry.test_taosdump_retry","title":"","text":"taosdump except 1. taosBenchmark prepare data with super table and normal table 2. taosdump start dump out database 3. Create except with kill -9 taosadapter during dump out 4. Start taosadapter again 5. taosdump dump in database 6. Verify data correctness with sum aggregation 7. Verify data correctness with row by row comparison on some data                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_except.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_precision.TestTaosdumpPrecision.test_taosdump_precision","title":"","text":"taosdump precision 1.  Create a database with nanosecond precision and multiple tables 2.  Insert data into the tables with nanosecond timestamps 3.  Use taosdump to export the entire database 4.  Use taosdump to export data within specific time ranges using -S and -E 5.  Drop the original database 6.  Use taosdump to import the exported data back into the database 7.  Verify that the imported data matches the original data for all exports                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_precision.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_primarykey.TestTaosdumpPrimaryKey.test_taosdump_primarykey","title":"","text":"taosdump primary key 1. Prepare database with primary key using taosBenchmark 2. Dump out database using taosdump 3. Dump in database using taosdump 4. Verify data correctness with sum aggregation 5. Verify meta correctness with taosBenchmark json file                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_primarykey.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_privilege.TestTaosdumpNonRoot.test_taosdump_non_root","title":"","text":"taosdump privilege 1. Create database and tables with various data types 2. Insert data with non-null and null values 3. Use taosdump to export the database with a non-root user 4. Drop the original database 5. Use taosdump to import the database back with a non-root user 6. Verify the imported database, tables, and data                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_privilege.py"},{"location":"case_list_docs/Tools/Taosdump/#81-Tools.04-Taosdump.test_taosdump_schema_change.TestTaosdumpSchemaChange.test_taosdump_schema_change","title":"","text":"taosdump precision 1.  Prepare data with taosBenchmark -f schemaChange.json/schemaChangeNew.json 2.  Use taosdump to export the entire database 3.  Use taosdump to import the exported data back into a new database 4.  Verify that the imported data matches the original data 5.  Use taosdump to export specific tables from the original database 6.  Use taosdump to import the exported data back into another new database 7.  Verify that the imported data matches the original data for the specified tables 8.  Drop old super tables and recreate new ones with schema changes (e.g., missing columns or tags) 9. Use taosdump to import the previously exported data into the modified tables 10. Verify that the data import handles the schema changes correctly 11.  Test exception handling when the target tables have schema changes (e.g., missing columns or tags)                      path:                                            cases/81-Tools/04-Taosdump/test_taosdump_schema_change.py"},{"location":"util_funcs_docs/new_test_framework/utils/","title":"Utils","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__","title":"<code>__init__</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.BeforeTest","title":"<code>BeforeTest</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.BeforeTest.create_database","title":"create_database(request, db_name, host, port)","text":"<p>\u521b\u5efamodule\u7ea7\u522b\u7684\u6570\u636e\u5e93</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.BeforeTest.deploy_taos","title":"deploy_taos(yaml_file, mnodes_num=1, clean=False)","text":"<p>get env directory from request; use yaml file for taostest run;</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ClusterComCheck","title":"<code>ClusterComCheck</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ClusterComCheck.check_vgroups_status","title":"check_vgroups_status(vgroup_numbers=2, db_replica=3, count_number=10, db_name='db')","text":"<p>check vgroups status in 10s after db vgroups status is changed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ClusterComCheck.check_vgroups_status_with_offline","title":"check_vgroups_status_with_offline(vgroup_numbers=2, db_replica=3, count_number=10, db_name='db')","text":"<p>n nodes cluster, 3 replica database return 1, n leaders, stable status return 2, 0 &lt; num of leader &lt; n, stable status return 0, no leader, stable status return -1, Elections not yet completed, unstable status</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ClusterDnodes","title":"<code>ClusterDnodes</code>","text":"<p>rewrite TDDnodes and make MyDdnodes as TDDnodes child class</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ColorFormatter","title":"<code>ColorFormatter</code>","text":"<p>\u81ea\u5b9a\u4e49\u5e26\u989c\u8272\u7684\u65e5\u5fd7\u683c\u5f0f\u5316\u5668</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.CompatibilityBase","title":"<code>CompatibilityBase</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.CompatibilityBase.alter_string_in_file","title":"alter_string_in_file(file, old_str, new_str)","text":"<p>replace str in file :param file :param old_str :param new_str :return:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.CompatibilityBase.version_compare","title":"version_compare(version1, version2)","text":"<p>Compare two version strings. Returns 1 if version1 &gt; version2, -1 if version1 &lt; version2, 0 if equal</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.ConfigureyCluster","title":"<code>ConfigureyCluster</code>","text":"<p>This will create defined number of dnodes and create a cluster. at the same time, it will return TDDnodes list:  dnodes,</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil","title":"<code>MqttUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil.checkEqual","title":"checkEqual(elm, expect_elm, show=False)","text":"<p>Checks if the given element is equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element does not match the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil.checkNotEqual","title":"checkNotEqual(elm, expect_elm)","text":"<p>Checks if the given element is not equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element matches the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil.checkQos","title":"checkQos(expectedQos, show=False)","text":"<p>Checks if the qos fetched by the last subscription matches the expected qos.</p> <p>Parameters:</p> Name Type Description Default <code>expectedQos</code> <code>int</code> <p>The expected qos.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the qos matches the expected qos, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of qos does not match the expected qos.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil.checkRows","title":"checkRows(expectedRows, show=False)","text":"<p>Checks if the number of rows fetched by the last subscription matches the expected number of rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <code>int</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows matches the expected number, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.MqttUtil.getRows","title":"getRows()","text":"<p>Retrieves the number of rows fetched by the last sub.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched by the last sub.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem","title":"<code>StreamItem</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem.addQuerySqlCase","title":"addQuerySqlCase(query_sql_case)","text":"<p>\u6dfb\u52a0\u67e5\u8be2SQL\u7528\u4f8b</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem.awaitResultHasRows","title":"awaitResultHasRows(waitSeconds=60)","text":"<p>\u786e\u4fdd\u6d41\u5904\u7406\u5df2\u6709\u7ed3\u679c\uff0c\u4e0d\u786e\u8ba4\u6700\u7ec8\u7ed3\u679c\u884c\u6570\u65f6\u4f7f\u7528</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem.awaitRowStability","title":"awaitRowStability(stable_rows, waitSeconds=300)","text":"<p>\u786e\u4fdd\u6d41\u5904\u7406\u7ed3\u679c\u7684\u884c\u6570\u4e0e\u9884\u671f\u7684\u7a33\u5b9a\u884c\u6570\u4e00\u81f4 :param stable_rows: int, \u9884\u671f\u7684\u7a33\u5b9a\u884c\u6570</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem.setResultFile","title":"setResultFile(file)","text":"<p>\u8bbe\u7f6e\u7ed3\u679c\u6587\u4ef6\u8def\u5f84</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamItem.set_exp_query_param_mapping","title":"set_exp_query_param_mapping(mapping)","text":"<p>\u8bbe\u7f6e\u53c2\u6570\u540d\u4e0e\u5217\u7d22\u5f15\u7684\u6620\u5c04\uff0c\u4f8b\u5982 {\"_wstart\": 0, \"_wend\": 1}</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable","title":"<code>StreamTable</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.__delete_data","title":"__delete_data(full_table_name, start_row, end_row)","text":"<p>\u5220\u9664\u6307\u5b9a\u8303\u56f4\u5185\u7684\u6570\u636e</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.appendSubTables","title":"appendSubTables(startTbIndex, endTbIndex)","text":"<p>\u5411\u8d85\u7ea7\u8868\u4e2d\u8ffd\u52a0\u5b50\u8868 :param startTbIndex: int, \u8d77\u59cb\u5b50\u8868\u7d22\u5f15 :param endTbIndex: int, \u7ed3\u675f\u5b50\u8868\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.append_data","title":"append_data(start_row, end_row)","text":"<p>\u5411\u8868\u4e2d\u8ffd\u52a0\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.append_subtable_data","title":"append_subtable_data(tbName, start_row, end_row)","text":"<p>\u5411\u6307\u5b9a\u5b50\u8868\u8ffd\u52a0\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.delete_data","title":"delete_data(start_row, end_row)","text":"<p>\u5220\u9664\u8868\u4e2d\u7684\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.delete_subtable_data","title":"delete_subtable_data(tbName, start_row, end_row)","text":"<p>\u5220\u9664\u6307\u5b9a\u5b50\u8868\u4e2d\u7684\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.register_column_generator","title":"register_column_generator(column_name, generator_func)","text":"<p>\u6ce8\u518c\u67d0\u4e2a\u5217\u540d\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u751f\u6210\u51fd\u6570 :param column_name: str, \u5217\u540d :param generator_func: function(row_index: int, timestamp: int) -&gt; str</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.reset_columns","title":"reset_columns()","text":"<p>\u91cd\u7f6e\u4e3a\u9ed8\u8ba4\u5217\u5b9a\u4e49</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.setInterval","title":"setInterval(interval)","text":"<p>\u8bbe\u7f6e\u65f6\u95f4\u95f4\u9694 :param interval: int, \u65f6\u95f4\u95f4\u9694\uff0c\u5355\u4f4d\u4e3a\u79d2</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.setLogOpen","title":"setLogOpen(logOpen)","text":"<p>\u8bbe\u7f6e\u65e5\u5fd7\u5f00\u5173 :param logOpen: bool, \u662f\u5426\u5f00\u542f\u65e5\u5fd7</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.setPrecision","title":"setPrecision(precision)","text":"<p>\u8bbe\u7f6e\u65f6\u95f4\u7cbe\u5ea6 :param precision: str, \u65f6\u95f4\u7cbe\u5ea6\uff0c\u652f\u6301 \"ms\", \"us\", \"ns\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.setStart","title":"setStart(start)","text":"<p>\u8bbe\u7f6e\u8d77\u59cb\u65f6\u95f4 :param start: str, \u8d77\u59cb\u65f6\u95f4\uff0c\u683c\u5f0f\u4e3a \"YYYY-MM-DD HH.MM.SS\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.set_columns","title":"set_columns(column_def)","text":"<p>\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u5217\u5b9a\u4e49 :param column_def: str\uff0c\u4f8b\u5982 \"ts timestamp, val int\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.update_data","title":"update_data(start_row, end_row)","text":"<p>\u66f4\u65b0\u8868\u4e2d\u7684\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.StreamTable.update_subtable_data","title":"update_subtable_data(tbName, start_row, end_row)","text":"<p>\u66f4\u65b0\u6307\u5b9a\u5b50\u8868\u4e2d\u7684\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom","title":"<code>TDCom</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.cal_watermark_window_close_interval_endts","title":"cal_watermark_window_close_interval_endts(start_ts, interval, watermark=None)","text":"<p>cal endts for close window</p> <p>Parameters:</p> Name Type Description Default <code>start_ts</code> <code>epoch time</code> <p>self.date_time</p> required <code>interval</code> <code>int</code> <p>[s]</p> required <code>watermark</code> <code>int</code> <p>[s]. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.cal_watermark_window_close_session_endts","title":"cal_watermark_window_close_session_endts(start_ts, watermark=None, session=None)","text":"<p>cal endts for close window</p> <p>Parameters:</p> Name Type Description Default <code>start_ts</code> <code>epoch time</code> <p>self.date_time</p> required <code>watermark</code> <code>int</code> <p>session. Defaults to None.</p> <code>None</code> <code>session</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <p>as followed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.cast_query_data","title":"cast_query_data(query_data)","text":"<p>cast query-result for existed-stb</p> <p>Parameters:</p> Name Type Description Default <code>query_data</code> <code>list</code> <p>query data list</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>new list after cast</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.check_query_data","title":"check_query_data(sql1, sql2, sorted=False, fill_value=None, tag_value_list=None, defined_tag_count=None, partition=True, use_exist_stb=False, subtable=None, reverse_check=False)","text":"<p>confirm query result</p> <p>Parameters:</p> Name Type Description Default <code>sql1</code> <code>str</code> <p>select ....</p> required <code>sql2</code> <code>str</code> <p>select ....</p> required <code>sorted</code> <code>bool</code> <p>if sort result list. Defaults to False.</p> <code>False</code> <code>fill_value</code> <code>str</code> <p>fill. Defaults to None.</p> <code>None</code> <code>tag_value_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>defined_tag_count</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>partition</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>use_exist_stb</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code> <code>subtable</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>reverse_check</code> <code>bool</code> <p>not equal. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>False if failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.check_stream","title":"check_stream(sql1, sql2, expected_count, max_delay=None)","text":"<p>confirm stream</p> <p>Parameters:</p> Name Type Description Default <code>sql1</code> <code>str</code> <p>select ...</p> required <code>sql2</code> <code>str</code> <p>select ...</p> required <code>expected_count</code> <code>int</code> <p>expected_count</p> required <code>max_delay</code> <code>int</code> <p>max_delay value. Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.check_stream_field_type","title":"check_stream_field_type(sql, input_function)","text":"<p>confirm stream field</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>input sql</p> required <code>input_function</code> <code>str</code> <p>scalar</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.check_stream_res","title":"check_stream_res(sql, expected_res, max_delay)","text":"<p>confirm stream result</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>select ...</p> required <code>expected_res</code> <code>str</code> <p>expected result</p> required <code>max_delay</code> <code>int</code> <p>max_delay value</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>False if failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.check_stream_task_status","title":"check_stream_task_status(stream_name, vgroups, stream_timeout=0, check_wal_info=True)","text":"<p>check stream status</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>vgroups</code> <code>int</code> <p>vgroups</p> required <p>Returns:     str: status</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.cleanTb","title":"cleanTb(type='taosc', dbname='db')","text":"<p>type is taosc or restful</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.clean_env","title":"clean_env()","text":"<p>drop all streams and databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.create_old_stream","title":"create_old_stream(stream_name, des_table, source_sql, trigger_mode=None, watermark=None, max_delay=None, ignore_expired=None, ignore_update=None, subtable_value=None, fill_value=None, fill_history_value=None, stb_field_name_value=None, tag_value=None, use_exist_stb=False, use_except=False)","text":"<p>create_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>des_table</code> <code>str</code> <p>target stable</p> required <code>source_sql</code> <code>str</code> <p>stream sql</p> required <code>trigger_mode</code> <code>str</code> <p>at_once/window_close/max_delay. Defaults to None.</p> <code>None</code> <code>watermark</code> <code>str</code> <p>watermark time. Defaults to None.</p> <code>None</code> <code>max_delay</code> <code>str</code> <p>max_delay time. Defaults to None.</p> <code>None</code> <code>ignore_expired</code> <code>int</code> <p>ignore expired data. Defaults to None.</p> <code>None</code> <code>ignore_update</code> <code>int</code> <p>ignore update data. Defaults to None.</p> <code>None</code> <code>subtable_value</code> <code>str</code> <p>subtable. Defaults to None.</p> <code>None</code> <code>fill_value</code> <code>str</code> <p>fill. Defaults to None.</p> <code>None</code> <code>fill_history_value</code> <code>int</code> <p>0/1. Defaults to None.</p> <code>None</code> <code>stb_field_name_value</code> <code>str</code> <p>existed stb. Defaults to None.</p> <code>None</code> <code>tag_value</code> <code>str</code> <p>custom tag. Defaults to None.</p> <code>None</code> <code>use_exist_stb</code> <code>bool</code> <p>use existed stb tag. Defaults to False.</p> <code>False</code> <code>use_except</code> <code>bool</code> <p>Exception tag. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>stream</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.create_snode_if_not_exists","title":"create_snode_if_not_exists(dnode_id=1)","text":"<p>Create snode if not exists</p> <p>Parameters:</p> Name Type Description Default <code>dnode_id</code> <code>int</code> <p>The dnode ID to create snode on. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if snode exists or created successfully, False if creation failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.create_stream","title":"create_stream(stream_name, des_table=None, source_sql=None, trigger_table=None, trigger_type=None, from_table=None, partition_by=None, stream_options=None, notification_definition=None, output_subtable=None, columns=None, tags=None, if_not_exists=True, db_name=None, use_except=False)","text":"<p>create_stream with new syntax</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>des_table</code> <code>str</code> <p>target table. Defaults to None.</p> <code>None</code> <code>source_sql</code> <code>str</code> <p>subquery. Defaults to None.</p> <code>None</code> <code>trigger_table</code> <code>str</code> <p>trigger table name. Defaults to None.</p> <code>None</code> <code>trigger_type</code> <code>str</code> <p>SESSION/STATE_WINDOW/INTERVAL/EVENT_WINDOW/COUNT_WINDOW/PERIOD. Defaults to None.</p> <code>None</code> <code>from_table</code> <code>str</code> <p>source table name. Defaults to None.</p> <code>None</code> <code>partition_by</code> <code>str</code> <p>partition columns. Defaults to None.</p> <code>None</code> <code>stream_options</code> <code>str</code> <p>stream options. Defaults to None.</p> <code>None</code> <code>notification_definition</code> <code>str</code> <p>notification settings. Defaults to None.</p> <code>None</code> <code>output_subtable</code> <code>str</code> <p>subtable expression. Defaults to None.</p> <code>None</code> <code>columns</code> <code>str</code> <p>column definitions. Defaults to None.</p> <code>None</code> <code>tags</code> <code>str</code> <p>tag definitions. Defaults to None.</p> <code>None</code> <code>if_not_exists</code> <code>bool</code> <p>if not exists flag. Defaults to True.</p> <code>True</code> <code>db_name</code> <code>str</code> <p>database name. Defaults to None.</p> <code>None</code> <code>use_except</code> <code>bool</code> <p>Exception tag. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>stream SQL if use_except=True, None otherwise</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.drop_all_db","title":"drop_all_db()","text":"<p>drop all databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.drop_all_streams","title":"drop_all_streams()","text":"<p>drop all streams from all user databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.drop_db","title":"drop_db(dbname='test')","text":"<p>drop a db</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to \"test\".</p> <code>'test'</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.drop_snode","title":"drop_snode(snode_id=None)","text":"<p>Drop snode</p> <p>Parameters:</p> Name Type Description Default <code>snode_id</code> <code>int</code> <p>Specific snode ID to drop. If None, drops all snodes.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if successful, False otherwise</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.ensure_snode_ready","title":"ensure_snode_ready(dnode_id=1, timeout=30)","text":"<p>Ensure snode is created and ready</p> <p>Parameters:</p> Name Type Description Default <code>dnode_id</code> <code>int</code> <p>The dnode ID to create snode on. Defaults to 1.</p> <code>1</code> <code>timeout</code> <code>int</code> <p>Maximum wait time in seconds. Defaults to 30.</p> <code>30</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if snode is ready, False if timeout or creation failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.float_handle","title":"float_handle(input_list)","text":"<p>float list elem</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>input value list</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>float list</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.genTs","title":"genTs(precision='ms', ts='', protype='taosc', ns_tag=None)","text":"<p>generate ts</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>str</code> <p>db precision. Defaults to \"ms\".</p> <code>'ms'</code> <code>ts</code> <code>str</code> <p>input ts. Defaults to \"\".</p> <code>''</code> <code>protype</code> <code>str</code> <p>\"taosc\" or \"restful\". Defaults to \"taosc\".</p> <code>'taosc'</code> <code>ns_tag</code> <code>_type_</code> <p>use ns. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>timestamp, datetime: timestamp and datetime</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.gen_tag_col_str","title":"gen_tag_col_str(gen_type, data_type, count)","text":"<p>gen multi tags or cols by gen_type</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.getLongName","title":"getLongName(len, mode='mixed')","text":"<p>generate long name mode could be numbers/letters/letters_mixed/mixed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.get_long_name","title":"get_long_name(length=10, mode='letters')","text":"<p>generate long name mode could be numbers/letters/letters_mixed/mixed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.get_timestamp_n_days_later","title":"get_timestamp_n_days_later(n=30)","text":"<p>Get the timestamp of a date n days later from the current date.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of days to add to the current date. Default is 30.</p> <code>30</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Timestamp of the date n days later, in milliseconds.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.pause_stream","title":"pause_stream(stream_name, if_exist=True, if_not_exist=False)","text":"<p>pause_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>if_exist</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>if_not_exist</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.prepare_data","title":"prepare_data(interval=None, watermark=None, session=None, state_window=None, state_window_max=127, interation=3, range_count=None, precision='ms', fill_history_value=0, ext_stb=None, custom_col_index=None, col_value_type='random')","text":"<p>prepare stream data</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>watermark</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>session</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>state_window</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>state_window_max</code> <code>int</code> <p>Defaults to 127.</p> <code>127</code> <code>interation</code> <code>int</code> <p>Defaults to 3.</p> <code>3</code> <code>range_count</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>precision</code> <code>str</code> <p>Defaults to \"ms\".</p> <code>'ms'</code> <code>fill_history_value</code> <code>int</code> <p>Defaults to 0.</p> <code>0</code> <code>ext_stb</code> <code>bool</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.resume_stream","title":"resume_stream(stream_name, if_exist=True, if_not_exist=False, ignore_untreated=False)","text":"<p>resume_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>if_exist</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>if_not_exist</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code> <code>ignore_untreated</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.round_handle","title":"round_handle(input_list)","text":"<p>round list elem</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>input value list</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>round list</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.screateDb","title":"screateDb(dbname='test', drop_db=True, **kwargs)","text":"<p>create database</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to \"test\".</p> <code>'test'</code> <code>drop_db</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.screate_ctable","title":"screate_ctable(dbname=None, stbname=None, ctbname='ctb', use_name='table', tag_elm_list=None, ts_value=None, count=1, default_varchar_datatype='letters', default_nchar_datatype='letters', default_ctbname_prefix='ctb', default_ctbname_index_start_num=1, **kwargs)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>stbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>ctbname</code> <code>str</code> <p>Defaults to \"ctb\".</p> <code>'ctb'</code> <code>use_name</code> <code>str</code> <p>Defaults to \"table\".</p> <code>'table'</code> <code>tag_elm_list</code> <code>list</code> <p>use for sgen_tag_type_str(), Defaults to None.</p> <code>None</code> <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>ctb count, Defaults to 1.</p> <code>1</code> <code>default_varchar_datatype</code> <code>str</code> <p>Defaults to \"letters\".</p> <code>'letters'</code> <code>default_nchar_datatype</code> <code>str</code> <p>Defaults to \"letters\".</p> <code>'letters'</code> <code>default_ctbname_prefix</code> <code>str</code> <p>Defaults to \"ctb\".</p> <code>'ctb'</code> <code>default_ctbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.screate_stable","title":"screate_stable(dbname=None, stbname='stb', use_name='table', column_elm_list=None, tag_elm_list=None, need_tagts=False, count=1, default_stbname_prefix='stb', default_stbname_index_start_num=1, default_column_index_start_num=1, default_tag_index_start_num=1, **kwargs)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>stbname</code> <code>str</code> <p>Defaults to \"stb\".</p> <code>'stb'</code> <code>use_name</code> <code>str</code> <p>stable/table, Defaults to \"table\".</p> <code>'table'</code> <code>column_elm_list</code> <code>list</code> <p>use for sgen_column_type_str(), Defaults to None.</p> <code>None</code> <code>tag_elm_list</code> <code>list</code> <p>use for sgen_tag_type_str(), Defaults to None.</p> <code>None</code> <code>need_tagts</code> <code>bool</code> <p>tag use timestamp, Defaults to False.</p> <code>False</code> <code>count</code> <code>int</code> <p>stable count, Defaults to 1.</p> <code>1</code> <code>default_stbname_prefix</code> <code>str</code> <p>Defaults to \"stb\".</p> <code>'stb'</code> <code>default_stbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_column_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_tag_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.screate_table","title":"screate_table(dbname=None, tbname='tb', use_name='table', column_elm_list=None, count=1, default_tbname_prefix='tb', default_tbname_index_start_num=1, default_column_index_start_num=1, **kwargs)","text":"<p>create ctable</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to \"tb\".</p> <code>'tb'</code> <code>use_name</code> <code>str</code> <p>Defaults to \"table\".</p> <code>'table'</code> <code>column_elm_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_tbname_prefix</code> <code>str</code> <p>Defaults to \"tb\".</p> <code>'tb'</code> <code>default_tbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_column_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sdelete_rows","title":"sdelete_rows(dbname=None, tbname=None, start_ts=None, end_ts=None, ts_key=None)","text":"<p>delete rows</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>start_ts</code> <code>timestamp</code> <p>range start. Defaults to None.</p> <code>None</code> <code>end_ts</code> <code>timestamp</code> <p>range end. Defaults to None.</p> <code>None</code> <code>ts_key</code> <code>str</code> <p>timestamp column name. Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sgen_column_type_str","title":"sgen_column_type_str(column_elm_list)","text":"<p>generage column type str</p> <p>Parameters:</p> Name Type Description Default <code>column_elm_list</code> <code>list</code> <p>column_elm_list</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sgen_column_value_list","title":"sgen_column_value_list(column_elm_list, need_null, ts_value=None, additional_ts=None, custom_col_index=None, col_value_type=None, force_pk_val=None)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>column_elm_list</code> <code>list</code> <p>gen_random_type_value()</p> required <code>need_null</code> <code>bool</code> <p>if insert null</p> required <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sgen_tag_type_str","title":"sgen_tag_type_str(tag_elm_list)","text":"<p>generage tag type str</p> <p>Parameters:</p> Name Type Description Default <code>tag_elm_list</code> <code>list</code> <p>tag_elm_list</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sgen_tag_value_list","title":"sgen_tag_value_list(tag_elm_list, ts_value=None)","text":"<p>generage tag value str</p> <p>Parameters:</p> Name Type Description Default <code>tag_elm_list</code> <code>list</code> <p>description</p> required <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.sinsert_rows","title":"sinsert_rows(dbname=None, tbname=None, column_ele_list=None, ts_value=None, count=1, need_null=False, custom_col_index=None, col_value_type='random')","text":"<p>insert rows</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>column_ele_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>need_null</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.str_ts_trans_bigint","title":"str_ts_trans_bigint(str_ts)","text":"<p>trans str ts to bigint</p> <p>Parameters:</p> Name Type Description Default <code>str_ts</code> <code>str</code> <p>human-date</p> required <p>Returns:</p> Name Type Description <code>bigint</code> <p>bigint-ts</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.time_cast","title":"time_cast(time_value, split_symbol='+')","text":"<p>cast bigint to timestamp</p> <p>Parameters:</p> Name Type Description Default <code>time_value</code> <code>bigint</code> <p>ts</p> required <code>split_symbol</code> <code>str</code> <p>split sympol. Defaults to \"+\".</p> <code>'+'</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>timestamp</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.trans_time_to_s","title":"trans_time_to_s(runtime)","text":"<p>trans time to s</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>str</code> <p>1d/1h/1m...</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>second</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.update_delete_history_data","title":"update_delete_history_data(delete)","text":"<p>update and delete history data</p> <p>Parameters:</p> Name Type Description Default <code>delete</code> <code>bool</code> <p>True/False</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDCom.update_json_file_replica","title":"update_json_file_replica(json_file_path, new_replica_value, output_file_path=None)","text":"<p>Read a JSON file, update the 'replica' value, and write the result back to a file.</p> <p>Parameters: json_file_path (str): The path to the original JSON file. new_replica_value (int): The new 'replica' value to be set. output_file_path (str, optional): The path to the output file where the updated JSON will be saved. If not provided, the original file will be overwritten.</p> <p>Returns: None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDDnode","title":"<code>TDDnode</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDDnode.dnodeClearData","title":"dnodeClearData()","text":"<p>Clear dnode's data (Remove all data files).</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was cleared successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDDnodes","title":"<code>TDDnodes</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDDnodes.dnodeClearData","title":"dnodeClearData(index)","text":"<p>Clear dnode's data (Remove all data files).</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode to clear.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was cleared successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDFindPath","title":"<code>TDFindPath</code>","text":"<p>This class is for finding path within TDengine</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDFindPath.getTDenginePath","title":"getTDenginePath()","text":"<p>for finding the root path of TDengine</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the root path of TDengine</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDFindPath.getTaosdemoPath","title":"getTaosdemoPath()","text":"<p>for finding the path of directory containing taosdemo</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the path to directory containing taosdemo</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDFindPath.init","title":"init(file)","text":"<p>[summary]</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>the file location you want to start the query. Generally using file</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql","title":"<code>TDSql</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkAffectedRows","title":"checkAffectedRows(expectAffectedRows)","text":"<p>Checks if the number of affected rows from the last executed SQL statement matches the expected number of affected rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectAffectedRows</code> <code>int</code> <p>The expected number of affected rows.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of affected rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkAgg","title":"checkAgg(sql, expectCnt)","text":"<p>Executes an aggregate SQL query and checks if the result matches the expected count.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The aggregate SQL query to be executed.</p> required <code>expectCnt</code> <code>int</code> <p>The expected count from the aggregate query.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the result of the aggregate query does not match the expected count.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkAssert","title":"checkAssert(assertVal, show=False)","text":"<p>Checks if the assertVal is true.</p> <p>Parameters:</p> Name Type Description Default <code>assertVal</code> <p>The value to be assert</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data of the specified key does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkColNameList","title":"checkColNameList(col_name_list, expect_col_name_list)","text":"<p>Checks if the column names from the last query match the expected column names.</p> <p>Parameters:</p> Name Type Description Default <code>col_name_list</code> <code>list</code> <p>The list of column names from the last query.</p> required <code>expect_col_name_list</code> <code>list</code> <p>The list of expected column names.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the column names do not match the expected column names.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkCols","title":"checkCols(expectCols)","text":"<p>Checks if the number of columns fetched by the last query matches the expected number of columns.</p> <p>Parameters:</p> Name Type Description Default <code>expectCols</code> <code>int</code> <p>The expected number of columns.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of columns does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkData","title":"checkData(row, col, data, show=False, exit=True, dbPrecision='', tolerance=0.0)","text":"<p>Checks if the data at the specified row and column matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data at the specified row and column does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataCsv","title":"checkDataCsv(sql, csvfilePath)","text":"<p>Executes a SQL query and checks if the result matches the expected data from a CSV file.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>csvfilePath</code> <code>str</code> <p>The path to the CSV file containing the expected data.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the CSV file path is invalid, the file is not found, there is an error reading the file, or if the sql result does not match the expected data from CSV file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataCsvByLine","title":"checkDataCsvByLine(sql, csvfilePath)","text":"<p>Executes a SQL query and checks if the result matches the expected data from a CSV file line by line.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>csvfilePath</code> <code>str</code> <p>The path to the CSV file containing the expected data.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the CSV file path is invalid, the file is not found, there is an error reading the file,         or if the SQL result does not match the expected data from the CSV file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataLoop","title":"checkDataLoop(row, col, data, sql, loopCount=10, waitTime=1)","text":"<p>Executes a SQL query in a loop and checks if the data at the specified row and column matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>loopCount</code> <code>int</code> <p>The number of times to execute the SQL query.</p> <code>10</code> <code>waitTime</code> <code>int</code> <p>The time to wait (in seconds) between each execution.</p> <code>1</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the data at the specified row and column does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataMem","title":"checkDataMem(sql, mem)","text":"<p>Executes a SQL query and checks if the result matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataMemByLine","title":"checkDataMemByLine(sql, mem)","text":"<p>Executes a SQL query and checks if the result matches the expected data (Same as checkDataMem).</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataMemLoop","title":"checkDataMemLoop(sql, mem, loopCount=120, waitTime=1)","text":"<p>Loop executes a SQL query and checks if the result matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataNoExist","title":"checkDataNoExist(row, col, data)","text":"<p>Checks if the data at the specified row and column matches the expected data without exiting the program.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the data matches the expected data, otherwise False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataType","title":"checkDataType(row, col, dataType)","text":"<p>Checks if the data type at the specified row and column matches the expected data type.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>dataType</code> <code>str</code> <p>The expected data type.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the data type matches the expected data type, otherwise False.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column index is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkDataV2","title":"checkDataV2(row, col, data, show=False, operator='==')","text":"<p>Compare the data at the specified row and column with the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to compare against.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <code>operator</code> <code>str</code> <p>The operator to use for comparison. Defaults to \"==\".</p> <code>'=='</code> <p>Returns:     bool: True if the comparison is successful, False otherwise. Usage:     assert self.checkDataV2(row, col, data, show=True, operator=\"==\")     assert self.checkDataV2(row, col, data, show=True, operator=\"&lt;\") # means actual value is less than data</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkEqual","title":"checkEqual(elm, expect_elm, show=False)","text":"<p>Checks if the given element is equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element does not match the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkFirstValue","title":"checkFirstValue(sql, expect)","text":"<p>Executes a SQL query and checks if the first value in the result matches the expected value.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>expect</code> <p>The expected value of the first result.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the first value in the result does not match the expected value.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkGreater","title":"checkGreater(elm, expect_elm)","text":"<p>Verifies that the first element is greater than the second element.</p> <p>This method compares two values and ensures that the first value (elm) is  strictly greater than the second value (expect_elm). It's commonly used for validating query results, performance metrics, or any numeric comparisons in test cases.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The actual value to be compared. Can be any comparable type  (int, float, string, etc.).</p> required <code>expect_elm</code> <p>The expected threshold value that elm should exceed.     Must be the same comparable type as elm.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if elm &gt; expect_elm, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkKeyData","title":"checkKeyData(key, col, data, show=False)","text":"<p>Checks if the data at the specified key matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>The first column to be compared with.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data of the specified key does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkNotEqual","title":"checkNotEqual(elm, expect_elm)","text":"<p>Checks if the given element is not equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element matches the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRowCol","title":"checkRowCol(row, col, exit=True)","text":"<p>Checks if the specified row and column indices are within the range of the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index to be checked.</p> required <code>col</code> <code>int</code> <p>The column index to be checked.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column index is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRowColNoExist","title":"checkRowColNoExist(row, col)","text":"<p>Checks if the specified row and column indices are within the range of the last query result without exiting the program.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index to be checked.</p> required <code>col</code> <code>int</code> <p>The column index to be checked.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the specified row and column indices are within the range, otherwise False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRows","title":"checkRows(expectedRows, show=False)","text":"<p>Checks if the number of rows fetched by the last query matches the expected number of rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <code>int</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows matches the expected number, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRowsNotExited","title":"checkRowsNotExited(expectedRows)","text":"<pre><code>Check if the query rows is equal to the expected rows\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Returns True if the actual number of rows matches the expected number, otherwise returns False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRowsRange","title":"checkRowsRange(excepte_row_list)","text":"<p>Checks if the number of rows fetched by the last query is within the expected range.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>excepte_row_list</code> <code>list</code> <p>A list of expected row counts.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows is within the expected range, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows is not within the expected range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkRowsV2","title":"checkRowsV2(expectedRows, operator='==', show=True)","text":"<p>Verify if the number of rows returned by SQL query meets the expected condition.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows </code> <p>int The expected number of rows to compare against</p> required <code>operator </code> <p>str, optional Comparison operator ('&lt;', '&lt;=', '&gt;', '&gt;=', '==', '!='), defaults to '&lt;'</p> required <code>show </code> <p>bool, optional Whether to print the verification result, defaults to True</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool True if the actual row count meets the expected condition, False otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid operator is provided</p> Usage <p>assert checker.checkRows(15, operator=\"&lt;\")  # Verify if less than 15 rows</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.checkSameColumn","title":"checkSameColumn(c1, c2)","text":"<p>Checks if the values in two specified columns are the same for all rows in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>c1</code> <code>int</code> <p>The index of the first column to be checked.</p> required <code>c2</code> <code>int</code> <p>The index of the second column to be checked.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the values in the specified columns are not the same for any row.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.close","title":"close()","text":"<p>Closes the cursor.</p> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.connect","title":"connect(username='root', passwd='taosdata', **kwargs)","text":"<p>Reconnect</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>The username used to log in to the cluster.</p> <code>'root'</code> <code>passwd</code> <code>str</code> <p>The password used to log in to the cluster.</p> <code>'taosdata'</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.deleteRows","title":"deleteRows(table, where=None)","text":"<p>Deletes rows from the specified table based on the given condition.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table from which rows are to be deleted.</p> required <code>where</code> <code>str</code> <p>The condition for deleting rows. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the delete operation fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.error","title":"error(sql, expectedErrno=None, expectErrInfo=None, fullMatched=True, show=False)","text":"<p>Executes a SQL statement and checks for expected errors.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>expectedErrno</code> <code>int</code> <p>The expected error number. Defaults to None.</p> <code>None</code> <code>expectErrInfo</code> <code>str</code> <p>The expected error information. Defaults to None.</p> <code>None</code> <code>fullMatched</code> <code>bool</code> <p>If True, checks for exact matches of the expected error information. Defaults to True.</p> <code>True</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The error information if an error occurs.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected error does not occur or if the error information does not match the expected information.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.errors","title":"errors(sql_list, expected_error_id_list=None, expected_error_info_list=None)","text":"<p>Executes a list of SQL queries and checks for expected errors.</p> <p>Parameters:</p> Name Type Description Default <code>sql_list</code> <code>list</code> <p>The list of SQL queries to be executed.</p> required <code>expected_error_id_list</code> <code>list</code> <p>The list of expected error numbers corresponding to each SQL query. Defaults to None.</p> <code>None</code> <code>expected_error_info_list</code> <code>list</code> <p>The list of expected error information corresponding to each SQL query. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the SQL list is empty, if the execution of any SQL query fails, if the expected error does not occur, or if the error information does not match the expected information.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.execute","title":"execute(sql, queryTimes=10, show=False)","text":"<p>Executes a SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the execution in case of failure. Defaults to 10.</p> <code>10</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of affected rows.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.executeTimes","title":"executeTimes(sql, times)","text":"<p>Executes a SQL statement a specified number of times.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>times</code> <code>int</code> <p>The number of times to execute the SQL statement.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The number of affected rows from the last execution.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.executes","title":"executes(sqls, queryTimes=30, show=False)","text":"<p>Executes a list of SQL statements.</p> <p>Parameters:</p> Name Type Description Default <code>sqls</code> <code>list</code> <p>The list of SQL statements to be executed.</p> required <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the execution in case of failure. Defaults to 30.</p> <code>30</code> <code>show</code> <code>bool</code> <p>If True, each SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution of any SQL statement fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.expectKeyData","title":"expectKeyData(key, col, data, show=False)","text":"<p>Whether the data at the specified key matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>The first column to be compared with.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>Bool</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getColData","title":"getColData(col)","text":"<p>Retrieves all data from the specified column in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>int</code> <p>The column index of the data to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing all data from the specified column.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getColNameList","title":"getColNameList(sql, col_tag=None)","text":"<p>Executes a SQL query and retrieves the column names and optionally the column types.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>col_tag</code> <code>optional</code> <p>If provided, the method will return both column names and column types. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing the column names.</p> <code>tuple</code> <p>A tuple containing two lists - the column names and the column types, if col_tag is provided.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getCols","title":"getCols()","text":"<p>Retrieves the number of cols fetched by the last query.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of cols fetched by the last query.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getData","title":"getData(row, col)","text":"<p>Retrieves the data at the specified row and column from the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be retrieved.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be retrieved.</p> required <p>Returns:</p> Type Description <p>The data at the specified row and column.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getDataWithOutCheck","title":"getDataWithOutCheck(row, col)","text":"<p>Retrieves the data at the specified row and column from the last query result. Args:     row (int): The row index of the data to be retrieved.     col (int): The column index of the data to be retrieved. Returns:     The data at the specified row and column. Raises:     IndexError: If the specified row or column is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getFirstValue","title":"getFirstValue(sql)","text":"<p>Executes a SQL query and retrieves the first value in the result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <p>Returns:</p> Type Description <p>The first value in the result.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getResult","title":"getResult(sql, exit=True)","text":"<p>Executes a SQL query and fetches the results.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>The fetched results.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getRowData","title":"getRowData(row)","text":"<p>Retrieves all data from the specified row in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing all data from the specified row.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getRows","title":"getRows()","text":"<p>Retrieves the number of rows fetched by the last query.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched by the last query.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getTimes","title":"getTimes(time_str, precision='ms')","text":"<p>Converts a time string to a timestamp based on the specified precision.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>time_str</code> <code>str</code> <p>The time string to be converted. The string should end with a character indicating the time unit (e.g., 's' for seconds, 'm' for minutes).</p> required <code>precision</code> <code>str</code> <p>The precision of the timestamp. Can be \"ms\" (milliseconds), \"us\" (microseconds), or \"ns\" (nanoseconds). Defaults to \"ms\".</p> <code>'ms'</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The timestamp in the specified precision.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the time string does not end with a valid time unit character or if the precision is not valid.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getType","title":"getType(col)","text":"<p>Retrieves the data type of the specified column in the last query result.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>int</code> <p>The column index for which the data type is to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The data type of the specified column.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.getVariable","title":"getVariable(search_attr)","text":"<p>Retrieves the value of a specified variable from the database.</p> <p>Parameters:</p> Name Type Description Default <code>search_attr</code> <code>str</code> <p>The name of the variable to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the value of the specified variable and the list of all variables.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.init","title":"init(cursor, log=False)","text":"<p>Initializes the TDSql instance with a database cursor and optionally enables logging.</p> <p>Parameters:</p> Name Type Description Default <code>cursor</code> <p>The database cursor to be used for executing SQL queries.</p> required <code>log</code> <code>bool</code> <p>If True, enables logging of SQL statements to a file. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.isErrorSql","title":"isErrorSql(sql)","text":"<p>Executes a SQL statement and checks if it results in an error.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the SQL statement results in an error, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.is_err_sql","title":"is_err_sql(sql)","text":"<p>Checks if a SQL statement will result in an error when executed.</p> <p>This method executes the provided SQL statement and determines whether it  causes an exception. It's useful for testing error conditions and validating that certain SQL statements should fail.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be tested for errors.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>False if the SQL statement executes successfully without errors, True if the SQL statement results in an error/exception.</p> <p>Raises:</p> Type Description <code>None</code> <p>This method catches all exceptions internally and returns a boolean result instead of raising exceptions.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.no_error","title":"no_error(sql)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>_type_</code> <p>description</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.pause","title":"pause()","text":"<p>Pause the execution of the program and wait for enter key. Used for debugging. Args:     None Returns:     None Raises:     None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.prepare","title":"prepare(dbname='db', drop=True, **kwargs)","text":"<p>Prepares the database by optionally dropping it if it exists, creating it, and setting it as the active database.</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>The name of the database to be prepared. Defaults to \"db\".</p> <code>'db'</code> <code>drop</code> <code>bool</code> <p>If True, drops the database if it exists before creating it. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to be included in the database creation statement. If duration is not provided, it defaults to 100.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.query","title":"query(sql, row_tag=None, queryTimes=10, count_expected_res=None, show=False, exit=True)","text":"<p>Executes a SQL query and fetches the results.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>row_tag</code> <code>optional</code> <p>If provided, the method will return the fetched results. Defaults to None.</p> <code>None</code> <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the query in case of failure. Defaults to 10.</p> <code>10</code> <code>count_expected_res</code> <code>optional</code> <p>If provided, the method will repeatedly execute the query until the first result matches this value or the queryTimes limit is reached. Defaults to None.</p> <code>None</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched if row_tag is not provided.</p> <code>list</code> <p>The fetched results if row_tag is provided.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.queryAndCheckResult","title":"queryAndCheckResult(sql_list, expect_result_list, dbPrecision='')","text":"<p>Executes a list of SQL queries and checks the results against the expected results.</p> <p>Parameters:</p> Name Type Description Default <code>sql_list</code> <code>list</code> <p>The list of SQL queries to be executed.</p> required <code>expect_result_list</code> <code>list</code> <p>The list of expected results corresponding to each SQL query.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution of any SQL query fails or if the results do not match the expected results.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.query_success_failed","title":"query_success_failed(sql, row_tag=None, queryTimes=10, count_expected_res=None, expectErrInfo=None, fullMatched=True)","text":"<p>Executes a SQL query with retry mechanism and handles both successful and failed scenarios.</p> <p>This method attempts to execute a SQL query multiple times, handling both successful executions and expected error conditions. It's particularly useful for testing scenarios where queries might initially fail but eventually succeed, or for validating specific error conditions.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query statement to be executed.</p> required <code>row_tag</code> <code>optional</code> <p>If provided, the method will return the fetched results              instead of just the row count. Defaults to None.</p> <code>None</code> <code>queryTimes</code> <code>int</code> <p>Maximum number of retry attempts if the query fails.                     Defaults to 10.</p> <code>10</code> <code>count_expected_res</code> <code>optional</code> <p>If provided, the method will repeatedly execute                          the query until the first result matches this value                          or retry limit is reached. Defaults to None.</p> <code>None</code> <code>expectErrInfo</code> <code>str</code> <p>Expected error message to validate against when                          query fails. If None, any error is acceptable.                          Defaults to None.</p> <code>None</code> <code>fullMatched</code> <code>bool</code> <p>If True, performs exact string matching for error                          messages. If False, performs partial string matching                          (contains). Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Error information string if an expected error occurs and query fails within retry attempts.</p> <code>None</code> <p>If query succeeds or if unexpected error occurs and reaches retry limit.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If query fails after all retry attempts and the error is not expected     or doesn't match the expected error pattern.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.setConnMode","title":"setConnMode(mode=0, value=1)","text":"<p>Set Conn Mode</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>int</code> <p>connect mode options.</p> <code>0</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TDSql.waitedQuery","title":"waitedQuery(sql, expectedRows, timeout)","text":"<p>Executes a SQL query and waits until the expected number of rows is retrieved or the timeout is reached.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>expectedRows</code> <code>int</code> <p>The expected number of rows to be retrieved.</p> required <code>timeout</code> <code>int</code> <p>The maximum time to wait (in seconds) for the expected number of rows to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the number of rows retrieved and the time taken (in seconds).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TaosKeeper","title":"<code>TaosKeeper</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TaosKeeper.cfg","title":"cfg(option, value)","text":"<p>add param option and value to cfg file</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <p>str, param name</p> required <code>value</code> <p>str, param value</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TaosKeeper.start","title":"start()","text":"<p>start taoskeeper process.</p> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TaosKeeper.stop","title":"stop(force_kill=False)","text":"<p>stop taoskeeper process.</p> <p>Parameters:</p> Name Type Description Default <code>force_kill</code> <p>bool, whether to force kill the process default: False if True, use kill -9 if False, use kill -15</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.TaosKeeper.update_cfg","title":"update_cfg(update_dict)","text":"<p>update taoskeeper cfg file</p> <p>Parameters:</p> Name Type Description Default <code>update_dict</code> <code>dict</code> <p>dict, update dict example: {\"log\": {\"path\": \"/var/log/taos\"}}</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#__init__.findTaosdThread","title":"findTaosdThread(threadName)","text":"<p>Find the first process named 'taosd' and count the number of threads  that contain the specified thread name.</p> <p>Parameters:</p> Name Type Description Default <code>threadName</code> <code>str</code> <p>Thread name to search for (supports partial matching)</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Number of matching threads in the first taosd process found,   returns 0 if no taosd process is found or no threads match.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#before_test","title":"<code>before_test</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#before_test.BeforeTest","title":"<code>BeforeTest</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#before_test.BeforeTest.create_database","title":"create_database(request, db_name, host, port)","text":"<p>\u521b\u5efamodule\u7ea7\u522b\u7684\u6570\u636e\u5e93</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#before_test.BeforeTest.deploy_taos","title":"deploy_taos(yaml_file, mnodes_num=1, clean=False)","text":"<p>get env directory from request; use yaml file for taostest run;</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#boundary","title":"<code>boundary</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#clusterCommonCheck","title":"<code>clusterCommonCheck</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#clusterCommonCheck.ClusterComCheck","title":"<code>ClusterComCheck</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#clusterCommonCheck.ClusterComCheck.check_vgroups_status","title":"check_vgroups_status(vgroup_numbers=2, db_replica=3, count_number=10, db_name='db')","text":"<p>check vgroups status in 10s after db vgroups status is changed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#clusterCommonCheck.ClusterComCheck.check_vgroups_status_with_offline","title":"check_vgroups_status_with_offline(vgroup_numbers=2, db_replica=3, count_number=10, db_name='db')","text":"<p>n nodes cluster, 3 replica database return 1, n leaders, stable status return 2, 0 &lt; num of leader &lt; n, stable status return 0, no leader, stable status return -1, Elections not yet completed, unstable status</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common","title":"<code>common</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom","title":"<code>TDCom</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.cal_watermark_window_close_interval_endts","title":"cal_watermark_window_close_interval_endts(start_ts, interval, watermark=None)","text":"<p>cal endts for close window</p> <p>Parameters:</p> Name Type Description Default <code>start_ts</code> <code>epoch time</code> <p>self.date_time</p> required <code>interval</code> <code>int</code> <p>[s]</p> required <code>watermark</code> <code>int</code> <p>[s]. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>description</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.cal_watermark_window_close_session_endts","title":"cal_watermark_window_close_session_endts(start_ts, watermark=None, session=None)","text":"<p>cal endts for close window</p> <p>Parameters:</p> Name Type Description Default <code>start_ts</code> <code>epoch time</code> <p>self.date_time</p> required <code>watermark</code> <code>int</code> <p>session. Defaults to None.</p> <code>None</code> <code>session</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>int</code> <p>as followed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.cast_query_data","title":"cast_query_data(query_data)","text":"<p>cast query-result for existed-stb</p> <p>Parameters:</p> Name Type Description Default <code>query_data</code> <code>list</code> <p>query data list</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>new list after cast</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.check_query_data","title":"check_query_data(sql1, sql2, sorted=False, fill_value=None, tag_value_list=None, defined_tag_count=None, partition=True, use_exist_stb=False, subtable=None, reverse_check=False)","text":"<p>confirm query result</p> <p>Parameters:</p> Name Type Description Default <code>sql1</code> <code>str</code> <p>select ....</p> required <code>sql2</code> <code>str</code> <p>select ....</p> required <code>sorted</code> <code>bool</code> <p>if sort result list. Defaults to False.</p> <code>False</code> <code>fill_value</code> <code>str</code> <p>fill. Defaults to None.</p> <code>None</code> <code>tag_value_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>defined_tag_count</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>partition</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>use_exist_stb</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code> <code>subtable</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>reverse_check</code> <code>bool</code> <p>not equal. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>False if failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.check_stream","title":"check_stream(sql1, sql2, expected_count, max_delay=None)","text":"<p>confirm stream</p> <p>Parameters:</p> Name Type Description Default <code>sql1</code> <code>str</code> <p>select ...</p> required <code>sql2</code> <code>str</code> <p>select ...</p> required <code>expected_count</code> <code>int</code> <p>expected_count</p> required <code>max_delay</code> <code>int</code> <p>max_delay value. Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.check_stream_field_type","title":"check_stream_field_type(sql, input_function)","text":"<p>confirm stream field</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>input sql</p> required <code>input_function</code> <code>str</code> <p>scalar</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.check_stream_res","title":"check_stream_res(sql, expected_res, max_delay)","text":"<p>confirm stream result</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>select ...</p> required <code>expected_res</code> <code>str</code> <p>expected result</p> required <code>max_delay</code> <code>int</code> <p>max_delay value</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>False if failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.check_stream_task_status","title":"check_stream_task_status(stream_name, vgroups, stream_timeout=0, check_wal_info=True)","text":"<p>check stream status</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>vgroups</code> <code>int</code> <p>vgroups</p> required <p>Returns:     str: status</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.cleanTb","title":"cleanTb(type='taosc', dbname='db')","text":"<p>type is taosc or restful</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.clean_env","title":"clean_env()","text":"<p>drop all streams and databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.create_old_stream","title":"create_old_stream(stream_name, des_table, source_sql, trigger_mode=None, watermark=None, max_delay=None, ignore_expired=None, ignore_update=None, subtable_value=None, fill_value=None, fill_history_value=None, stb_field_name_value=None, tag_value=None, use_exist_stb=False, use_except=False)","text":"<p>create_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>des_table</code> <code>str</code> <p>target stable</p> required <code>source_sql</code> <code>str</code> <p>stream sql</p> required <code>trigger_mode</code> <code>str</code> <p>at_once/window_close/max_delay. Defaults to None.</p> <code>None</code> <code>watermark</code> <code>str</code> <p>watermark time. Defaults to None.</p> <code>None</code> <code>max_delay</code> <code>str</code> <p>max_delay time. Defaults to None.</p> <code>None</code> <code>ignore_expired</code> <code>int</code> <p>ignore expired data. Defaults to None.</p> <code>None</code> <code>ignore_update</code> <code>int</code> <p>ignore update data. Defaults to None.</p> <code>None</code> <code>subtable_value</code> <code>str</code> <p>subtable. Defaults to None.</p> <code>None</code> <code>fill_value</code> <code>str</code> <p>fill. Defaults to None.</p> <code>None</code> <code>fill_history_value</code> <code>int</code> <p>0/1. Defaults to None.</p> <code>None</code> <code>stb_field_name_value</code> <code>str</code> <p>existed stb. Defaults to None.</p> <code>None</code> <code>tag_value</code> <code>str</code> <p>custom tag. Defaults to None.</p> <code>None</code> <code>use_exist_stb</code> <code>bool</code> <p>use existed stb tag. Defaults to False.</p> <code>False</code> <code>use_except</code> <code>bool</code> <p>Exception tag. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>stream</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.create_snode_if_not_exists","title":"create_snode_if_not_exists(dnode_id=1)","text":"<p>Create snode if not exists</p> <p>Parameters:</p> Name Type Description Default <code>dnode_id</code> <code>int</code> <p>The dnode ID to create snode on. Defaults to 1.</p> <code>1</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if snode exists or created successfully, False if creation failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.create_stream","title":"create_stream(stream_name, des_table=None, source_sql=None, trigger_table=None, trigger_type=None, from_table=None, partition_by=None, stream_options=None, notification_definition=None, output_subtable=None, columns=None, tags=None, if_not_exists=True, db_name=None, use_except=False)","text":"<p>create_stream with new syntax</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>des_table</code> <code>str</code> <p>target table. Defaults to None.</p> <code>None</code> <code>source_sql</code> <code>str</code> <p>subquery. Defaults to None.</p> <code>None</code> <code>trigger_table</code> <code>str</code> <p>trigger table name. Defaults to None.</p> <code>None</code> <code>trigger_type</code> <code>str</code> <p>SESSION/STATE_WINDOW/INTERVAL/EVENT_WINDOW/COUNT_WINDOW/PERIOD. Defaults to None.</p> <code>None</code> <code>from_table</code> <code>str</code> <p>source table name. Defaults to None.</p> <code>None</code> <code>partition_by</code> <code>str</code> <p>partition columns. Defaults to None.</p> <code>None</code> <code>stream_options</code> <code>str</code> <p>stream options. Defaults to None.</p> <code>None</code> <code>notification_definition</code> <code>str</code> <p>notification settings. Defaults to None.</p> <code>None</code> <code>output_subtable</code> <code>str</code> <p>subtable expression. Defaults to None.</p> <code>None</code> <code>columns</code> <code>str</code> <p>column definitions. Defaults to None.</p> <code>None</code> <code>tags</code> <code>str</code> <p>tag definitions. Defaults to None.</p> <code>None</code> <code>if_not_exists</code> <code>bool</code> <p>if not exists flag. Defaults to True.</p> <code>True</code> <code>db_name</code> <code>str</code> <p>database name. Defaults to None.</p> <code>None</code> <code>use_except</code> <code>bool</code> <p>Exception tag. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>stream SQL if use_except=True, None otherwise</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.drop_all_db","title":"drop_all_db()","text":"<p>drop all databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.drop_all_streams","title":"drop_all_streams()","text":"<p>drop all streams from all user databases</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.drop_db","title":"drop_db(dbname='test')","text":"<p>drop a db</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to \"test\".</p> <code>'test'</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.drop_snode","title":"drop_snode(snode_id=None)","text":"<p>Drop snode</p> <p>Parameters:</p> Name Type Description Default <code>snode_id</code> <code>int</code> <p>Specific snode ID to drop. If None, drops all snodes.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if successful, False otherwise</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.ensure_snode_ready","title":"ensure_snode_ready(dnode_id=1, timeout=30)","text":"<p>Ensure snode is created and ready</p> <p>Parameters:</p> Name Type Description Default <code>dnode_id</code> <code>int</code> <p>The dnode ID to create snode on. Defaults to 1.</p> <code>1</code> <code>timeout</code> <code>int</code> <p>Maximum wait time in seconds. Defaults to 30.</p> <code>30</code> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if snode is ready, False if timeout or creation failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.float_handle","title":"float_handle(input_list)","text":"<p>float list elem</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>input value list</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>float list</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.genTs","title":"genTs(precision='ms', ts='', protype='taosc', ns_tag=None)","text":"<p>generate ts</p> <p>Parameters:</p> Name Type Description Default <code>precision</code> <code>str</code> <p>db precision. Defaults to \"ms\".</p> <code>'ms'</code> <code>ts</code> <code>str</code> <p>input ts. Defaults to \"\".</p> <code>''</code> <code>protype</code> <code>str</code> <p>\"taosc\" or \"restful\". Defaults to \"taosc\".</p> <code>'taosc'</code> <code>ns_tag</code> <code>_type_</code> <p>use ns. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>timestamp, datetime: timestamp and datetime</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.gen_tag_col_str","title":"gen_tag_col_str(gen_type, data_type, count)","text":"<p>gen multi tags or cols by gen_type</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.getLongName","title":"getLongName(len, mode='mixed')","text":"<p>generate long name mode could be numbers/letters/letters_mixed/mixed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.get_long_name","title":"get_long_name(length=10, mode='letters')","text":"<p>generate long name mode could be numbers/letters/letters_mixed/mixed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.get_timestamp_n_days_later","title":"get_timestamp_n_days_later(n=30)","text":"<p>Get the timestamp of a date n days later from the current date.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Number of days to add to the current date. Default is 30.</p> <code>30</code> <p>Returns:</p> Name Type Description <code>int</code> <p>Timestamp of the date n days later, in milliseconds.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.pause_stream","title":"pause_stream(stream_name, if_exist=True, if_not_exist=False)","text":"<p>pause_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>if_exist</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>if_not_exist</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.prepare_data","title":"prepare_data(interval=None, watermark=None, session=None, state_window=None, state_window_max=127, interation=3, range_count=None, precision='ms', fill_history_value=0, ext_stb=None, custom_col_index=None, col_value_type='random')","text":"<p>prepare stream data</p> <p>Parameters:</p> Name Type Description Default <code>interval</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>watermark</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>session</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>state_window</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>state_window_max</code> <code>int</code> <p>Defaults to 127.</p> <code>127</code> <code>interation</code> <code>int</code> <p>Defaults to 3.</p> <code>3</code> <code>range_count</code> <code>int</code> <p>Defaults to None.</p> <code>None</code> <code>precision</code> <code>str</code> <p>Defaults to \"ms\".</p> <code>'ms'</code> <code>fill_history_value</code> <code>int</code> <p>Defaults to 0.</p> <code>0</code> <code>ext_stb</code> <code>bool</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.resume_stream","title":"resume_stream(stream_name, if_exist=True, if_not_exist=False, ignore_untreated=False)","text":"<p>resume_stream</p> <p>Parameters:</p> Name Type Description Default <code>stream_name</code> <code>str</code> <p>stream_name</p> required <code>if_exist</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code> <code>if_not_exist</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code> <code>ignore_untreated</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.round_handle","title":"round_handle(input_list)","text":"<p>round list elem</p> <p>Parameters:</p> Name Type Description Default <code>input_list</code> <code>list</code> <p>input value list</p> required <p>Returns:</p> Name Type Description <code>_type_</code> <p>round list</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.screateDb","title":"screateDb(dbname='test', drop_db=True, **kwargs)","text":"<p>create database</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to \"test\".</p> <code>'test'</code> <code>drop_db</code> <code>bool</code> <p>Defaults to True.</p> <code>True</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.screate_ctable","title":"screate_ctable(dbname=None, stbname=None, ctbname='ctb', use_name='table', tag_elm_list=None, ts_value=None, count=1, default_varchar_datatype='letters', default_nchar_datatype='letters', default_ctbname_prefix='ctb', default_ctbname_index_start_num=1, **kwargs)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>stbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>ctbname</code> <code>str</code> <p>Defaults to \"ctb\".</p> <code>'ctb'</code> <code>use_name</code> <code>str</code> <p>Defaults to \"table\".</p> <code>'table'</code> <code>tag_elm_list</code> <code>list</code> <p>use for sgen_tag_type_str(), Defaults to None.</p> <code>None</code> <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>ctb count, Defaults to 1.</p> <code>1</code> <code>default_varchar_datatype</code> <code>str</code> <p>Defaults to \"letters\".</p> <code>'letters'</code> <code>default_nchar_datatype</code> <code>str</code> <p>Defaults to \"letters\".</p> <code>'letters'</code> <code>default_ctbname_prefix</code> <code>str</code> <p>Defaults to \"ctb\".</p> <code>'ctb'</code> <code>default_ctbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.screate_stable","title":"screate_stable(dbname=None, stbname='stb', use_name='table', column_elm_list=None, tag_elm_list=None, need_tagts=False, count=1, default_stbname_prefix='stb', default_stbname_index_start_num=1, default_column_index_start_num=1, default_tag_index_start_num=1, **kwargs)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>stbname</code> <code>str</code> <p>Defaults to \"stb\".</p> <code>'stb'</code> <code>use_name</code> <code>str</code> <p>stable/table, Defaults to \"table\".</p> <code>'table'</code> <code>column_elm_list</code> <code>list</code> <p>use for sgen_column_type_str(), Defaults to None.</p> <code>None</code> <code>tag_elm_list</code> <code>list</code> <p>use for sgen_tag_type_str(), Defaults to None.</p> <code>None</code> <code>need_tagts</code> <code>bool</code> <p>tag use timestamp, Defaults to False.</p> <code>False</code> <code>count</code> <code>int</code> <p>stable count, Defaults to 1.</p> <code>1</code> <code>default_stbname_prefix</code> <code>str</code> <p>Defaults to \"stb\".</p> <code>'stb'</code> <code>default_stbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_column_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_tag_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.screate_table","title":"screate_table(dbname=None, tbname='tb', use_name='table', column_elm_list=None, count=1, default_tbname_prefix='tb', default_tbname_index_start_num=1, default_column_index_start_num=1, **kwargs)","text":"<p>create ctable</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to \"tb\".</p> <code>'tb'</code> <code>use_name</code> <code>str</code> <p>Defaults to \"table\".</p> <code>'table'</code> <code>column_elm_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_tbname_prefix</code> <code>str</code> <p>Defaults to \"tb\".</p> <code>'tb'</code> <code>default_tbname_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>default_column_index_start_num</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sdelete_rows","title":"sdelete_rows(dbname=None, tbname=None, start_ts=None, end_ts=None, ts_key=None)","text":"<p>delete rows</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>start_ts</code> <code>timestamp</code> <p>range start. Defaults to None.</p> <code>None</code> <code>end_ts</code> <code>timestamp</code> <p>range end. Defaults to None.</p> <code>None</code> <code>ts_key</code> <code>str</code> <p>timestamp column name. Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sgen_column_type_str","title":"sgen_column_type_str(column_elm_list)","text":"<p>generage column type str</p> <p>Parameters:</p> Name Type Description Default <code>column_elm_list</code> <code>list</code> <p>column_elm_list</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sgen_column_value_list","title":"sgen_column_value_list(column_elm_list, need_null, ts_value=None, additional_ts=None, custom_col_index=None, col_value_type=None, force_pk_val=None)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>column_elm_list</code> <code>list</code> <p>gen_random_type_value()</p> required <code>need_null</code> <code>bool</code> <p>if insert null</p> required <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sgen_tag_type_str","title":"sgen_tag_type_str(tag_elm_list)","text":"<p>generage tag type str</p> <p>Parameters:</p> Name Type Description Default <code>tag_elm_list</code> <code>list</code> <p>tag_elm_list</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sgen_tag_value_list","title":"sgen_tag_value_list(tag_elm_list, ts_value=None)","text":"<p>generage tag value str</p> <p>Parameters:</p> Name Type Description Default <code>tag_elm_list</code> <code>list</code> <p>description</p> required <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.sinsert_rows","title":"sinsert_rows(dbname=None, tbname=None, column_ele_list=None, ts_value=None, count=1, need_null=False, custom_col_index=None, col_value_type='random')","text":"<p>insert rows</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>tbname</code> <code>str</code> <p>Defaults to None.</p> <code>None</code> <code>column_ele_list</code> <code>list</code> <p>Defaults to None.</p> <code>None</code> <code>ts_value</code> <code>timestamp</code> <p>Defaults to None.</p> <code>None</code> <code>count</code> <code>int</code> <p>Defaults to 1.</p> <code>1</code> <code>need_null</code> <code>bool</code> <p>Defaults to False.</p> <code>False</code>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.str_ts_trans_bigint","title":"str_ts_trans_bigint(str_ts)","text":"<p>trans str ts to bigint</p> <p>Parameters:</p> Name Type Description Default <code>str_ts</code> <code>str</code> <p>human-date</p> required <p>Returns:</p> Name Type Description <code>bigint</code> <p>bigint-ts</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.time_cast","title":"time_cast(time_value, split_symbol='+')","text":"<p>cast bigint to timestamp</p> <p>Parameters:</p> Name Type Description Default <code>time_value</code> <code>bigint</code> <p>ts</p> required <code>split_symbol</code> <code>str</code> <p>split sympol. Defaults to \"+\".</p> <code>'+'</code> <p>Returns:</p> Name Type Description <code>_type_</code> <p>timestamp</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.trans_time_to_s","title":"trans_time_to_s(runtime)","text":"<p>trans time to s</p> <p>Parameters:</p> Name Type Description Default <code>runtime</code> <code>str</code> <p>1d/1h/1m...</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>second</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.update_delete_history_data","title":"update_delete_history_data(delete)","text":"<p>update and delete history data</p> <p>Parameters:</p> Name Type Description Default <code>delete</code> <code>bool</code> <p>True/False</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#common.TDCom.update_json_file_replica","title":"update_json_file_replica(json_file_path, new_replica_value, output_file_path=None)","text":"<p>Read a JSON file, update the 'replica' value, and write the result back to a file.</p> <p>Parameters: json_file_path (str): The path to the original JSON file. new_replica_value (int): The new 'replica' value to be set. output_file_path (str, optional): The path to the output file where the updated JSON will be saved. If not provided, the original file will be overwritten.</p> <p>Returns: None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#constant","title":"<code>constant</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#eos","title":"<code>eos</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#epath","title":"<code>epath</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#etime","title":"<code>etime</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#etool","title":"<code>etool</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#etool.benchMark","title":"benchMark(command='', json='')","text":"<p>Run the <code>taosBenchmark</code> binary with a command or JSON file.</p> <p>Parameters:</p> Name Type Description Default <code>command</code> <code>str</code> <p>The command to execute. Defaults to an empty string.</p> <code>''</code> <code>json</code> <code>str</code> <p>The path to a JSON file for execution. Defaults to an empty string.</p> <code>''</code> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the execution of the JSON file fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.benchMarkFile","title":"benchMarkFile()","text":"<p>Get the path to the <code>taosBenchmark</code> binary file.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the <code>taosBenchmark</code> binary file, with <code>.exe</code> appended if on Windows.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.curFile","title":"curFile(fullPath, filename)","text":"<p>Get the full path to a file in the current directory.</p> <p>Parameters:</p> Name Type Description Default <code>fullPath</code> <code>str</code> <p>The full path to the current directory.</p> required <code>filename</code> <code>str</code> <p>The name of the file.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the file in the current directory.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.exeBinFile","title":"exeBinFile(fname, command, wait=True, show=True)","text":"<p>Execute a binary file with the specified command.</p> <p>This method uses <code>utils.army.frame.eos.exe</code> or <code>utils.army.frame.eos.exeNoWait</code>  to execute the binary file. The <code>exe</code> function waits for the command to finish,  while <code>exeNoWait</code> runs the command in the background and returns immediately.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>The name of the binary file.</p> required <code>command</code> <code>str</code> <p>The command to execute.</p> required <code>wait</code> <code>bool</code> <p>Whether to wait for the command to finish. Defaults to True. - If True, uses <code>utils.army.frame.eos.exe</code>. - If False, uses <code>utils.army.frame.eos.exeNoWait</code>.</p> <code>True</code> <code>show</code> <code>bool</code> <p>Whether to log the command. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The exit status of the command execution. A return value of <code>0</code> indicates success,   while a non-zero value indicates failure.  - If <code>wait</code> is False, the return value is the exit status of the <code>nohup</code> or <code>mintty</code> command.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.getFilePath","title":"getFilePath(base_dir, *parts)","text":"<p>Get the full path to a file, ensuring compatibility with Windows paths.</p> <p>Parameters:</p> Name Type Description Default <code>*parts</code> <code>str</code> <p>The parts of the file path.</p> <code>()</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.runBinFile","title":"runBinFile(fname, command, show=True, checkRun=False, retFail=False)","text":"<p>Run a binary file with the specified command.</p> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>str</code> <p>The name of the binary file.</p> required <code>command</code> <code>str</code> <p>The command to execute.</p> required <code>show</code> <code>bool</code> <p>Whether to log the command. Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>list</code> <p>The output of the command as a list of strings.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.taosAdapterFile","title":"taosAdapterFile()","text":"<p>Get the path to the <code>taosAdapter</code> binary file.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the <code>taosAdapter</code> binary file, with <code>.exe</code> appended if on Windows.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.taosDumpFile","title":"taosDumpFile()","text":"<p>Get the path to the <code>taosdump</code> binary file.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the <code>taosdump</code> binary file, with <code>.exe</code> appended if on Windows.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#etool.taosFile","title":"taosFile()","text":"<p>Get the path to the <code>taos</code> binary file.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The full path to the <code>taos</code> binary file, with <code>.exe</code> appended if on Windows.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#eutil","title":"<code>eutil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#eutil.findTaosdThread","title":"findTaosdThread(threadName)","text":"<p>Find the first process named 'taosd' and count the number of threads  that contain the specified thread name.</p> <p>Parameters:</p> Name Type Description Default <code>threadName</code> <code>str</code> <p>Thread name to search for (supports partial matching)</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>Number of matching threads in the first taosd process found,   returns 0 if no taosd process is found or no threads match.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#gettime","title":"<code>gettime</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#log","title":"<code>log</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#log.ColorFormatter","title":"<code>ColorFormatter</code>","text":"<p>\u81ea\u5b9a\u4e49\u5e26\u989c\u8272\u7684\u65e5\u5fd7\u683c\u5f0f\u5316\u5668</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#pathFinding","title":"<code>pathFinding</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#pathFinding.TDFindPath","title":"<code>TDFindPath</code>","text":"<p>This class is for finding path within TDengine</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#pathFinding.TDFindPath.getTDenginePath","title":"getTDenginePath()","text":"<p>for finding the root path of TDengine</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the root path of TDengine</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#pathFinding.TDFindPath.getTaosdemoPath","title":"getTaosdemoPath()","text":"<p>for finding the path of directory containing taosdemo</p> <p>Returns:</p> Name Type Description <code>str</code> <p>the path to directory containing taosdemo</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#pathFinding.TDFindPath.init","title":"init(file)","text":"<p>[summary]</p> <p>Parameters:</p> Name Type Description Default <code>file</code> <code>str</code> <p>the file location you want to start the query. Generally using file</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#sql","title":"<code>sql</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql","title":"<code>TDSql</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkAffectedRows","title":"checkAffectedRows(expectAffectedRows)","text":"<p>Checks if the number of affected rows from the last executed SQL statement matches the expected number of affected rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectAffectedRows</code> <code>int</code> <p>The expected number of affected rows.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of affected rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkAgg","title":"checkAgg(sql, expectCnt)","text":"<p>Executes an aggregate SQL query and checks if the result matches the expected count.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The aggregate SQL query to be executed.</p> required <code>expectCnt</code> <code>int</code> <p>The expected count from the aggregate query.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the result of the aggregate query does not match the expected count.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkAssert","title":"checkAssert(assertVal, show=False)","text":"<p>Checks if the assertVal is true.</p> <p>Parameters:</p> Name Type Description Default <code>assertVal</code> <p>The value to be assert</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data of the specified key does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkColNameList","title":"checkColNameList(col_name_list, expect_col_name_list)","text":"<p>Checks if the column names from the last query match the expected column names.</p> <p>Parameters:</p> Name Type Description Default <code>col_name_list</code> <code>list</code> <p>The list of column names from the last query.</p> required <code>expect_col_name_list</code> <code>list</code> <p>The list of expected column names.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the column names do not match the expected column names.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkCols","title":"checkCols(expectCols)","text":"<p>Checks if the number of columns fetched by the last query matches the expected number of columns.</p> <p>Parameters:</p> Name Type Description Default <code>expectCols</code> <code>int</code> <p>The expected number of columns.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of columns does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkData","title":"checkData(row, col, data, show=False, exit=True, dbPrecision='', tolerance=0.0)","text":"<p>Checks if the data at the specified row and column matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data at the specified row and column does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataCsv","title":"checkDataCsv(sql, csvfilePath)","text":"<p>Executes a SQL query and checks if the result matches the expected data from a CSV file.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>csvfilePath</code> <code>str</code> <p>The path to the CSV file containing the expected data.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the CSV file path is invalid, the file is not found, there is an error reading the file, or if the sql result does not match the expected data from CSV file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataCsvByLine","title":"checkDataCsvByLine(sql, csvfilePath)","text":"<p>Executes a SQL query and checks if the result matches the expected data from a CSV file line by line.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>csvfilePath</code> <code>str</code> <p>The path to the CSV file containing the expected data.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the CSV file path is invalid, the file is not found, there is an error reading the file,         or if the SQL result does not match the expected data from the CSV file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataLoop","title":"checkDataLoop(row, col, data, sql, loopCount=10, waitTime=1)","text":"<p>Executes a SQL query in a loop and checks if the data at the specified row and column matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>loopCount</code> <code>int</code> <p>The number of times to execute the SQL query.</p> <code>10</code> <code>waitTime</code> <code>int</code> <p>The time to wait (in seconds) between each execution.</p> <code>1</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the data at the specified row and column does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataMem","title":"checkDataMem(sql, mem)","text":"<p>Executes a SQL query and checks if the result matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataMemByLine","title":"checkDataMemByLine(sql, mem)","text":"<p>Executes a SQL query and checks if the result matches the expected data (Same as checkDataMem).</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataMemLoop","title":"checkDataMemLoop(sql, mem, loopCount=120, waitTime=1)","text":"<p>Loop executes a SQL query and checks if the result matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>mem</code> <code>list</code> <p>The expected data, represented as a list of lists.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected data is not a list of lists, or if the SQL result does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataNoExist","title":"checkDataNoExist(row, col, data)","text":"<p>Checks if the data at the specified row and column matches the expected data without exiting the program.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the data matches the expected data, otherwise False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataType","title":"checkDataType(row, col, dataType)","text":"<p>Checks if the data type at the specified row and column matches the expected data type.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>dataType</code> <code>str</code> <p>The expected data type.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the data type matches the expected data type, otherwise False.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column index is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkDataV2","title":"checkDataV2(row, col, data, show=False, operator='==')","text":"<p>Compare the data at the specified row and column with the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be checked.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to compare against.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <code>operator</code> <code>str</code> <p>The operator to use for comparison. Defaults to \"==\".</p> <code>'=='</code> <p>Returns:     bool: True if the comparison is successful, False otherwise. Usage:     assert self.checkDataV2(row, col, data, show=True, operator=\"==\")     assert self.checkDataV2(row, col, data, show=True, operator=\"&lt;\") # means actual value is less than data</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkEqual","title":"checkEqual(elm, expect_elm, show=False)","text":"<p>Checks if the given element is equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element does not match the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkFirstValue","title":"checkFirstValue(sql, expect)","text":"<p>Executes a SQL query and checks if the first value in the result matches the expected value.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>expect</code> <p>The expected value of the first result.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p> <code>SystemExit</code> <p>If the first value in the result does not match the expected value.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkGreater","title":"checkGreater(elm, expect_elm)","text":"<p>Verifies that the first element is greater than the second element.</p> <p>This method compares two values and ensures that the first value (elm) is  strictly greater than the second value (expect_elm). It's commonly used for validating query results, performance metrics, or any numeric comparisons in test cases.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The actual value to be compared. Can be any comparable type  (int, float, string, etc.).</p> required <code>expect_elm</code> <p>The expected threshold value that elm should exceed.     Must be the same comparable type as elm.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if elm &gt; expect_elm, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkKeyData","title":"checkKeyData(key, col, data, show=False)","text":"<p>Checks if the data at the specified key matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>The first column to be compared with.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the data of the specified key does not match the expected data.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkNotEqual","title":"checkNotEqual(elm, expect_elm)","text":"<p>Checks if the given element is not equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element matches the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRowCol","title":"checkRowCol(row, col, exit=True)","text":"<p>Checks if the specified row and column indices are within the range of the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index to be checked.</p> required <code>col</code> <code>int</code> <p>The column index to be checked.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column index is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRowColNoExist","title":"checkRowColNoExist(row, col)","text":"<p>Checks if the specified row and column indices are within the range of the last query result without exiting the program.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index to be checked.</p> required <code>col</code> <code>int</code> <p>The column index to be checked.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the specified row and column indices are within the range, otherwise False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRows","title":"checkRows(expectedRows, show=False)","text":"<p>Checks if the number of rows fetched by the last query matches the expected number of rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <code>int</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows matches the expected number, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRowsNotExited","title":"checkRowsNotExited(expectedRows)","text":"<pre><code>Check if the query rows is equal to the expected rows\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>Returns True if the actual number of rows matches the expected number, otherwise returns False.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRowsRange","title":"checkRowsRange(excepte_row_list)","text":"<p>Checks if the number of rows fetched by the last query is within the expected range.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>excepte_row_list</code> <code>list</code> <p>A list of expected row counts.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows is within the expected range, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows is not within the expected range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkRowsV2","title":"checkRowsV2(expectedRows, operator='==', show=True)","text":"<p>Verify if the number of rows returned by SQL query meets the expected condition.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows </code> <p>int The expected number of rows to compare against</p> required <code>operator </code> <p>str, optional Comparison operator ('&lt;', '&lt;=', '&gt;', '&gt;=', '==', '!='), defaults to '&lt;'</p> required <code>show </code> <p>bool, optional Whether to print the verification result, defaults to True</p> required <p>Returns:</p> Type Description <code>bool</code> <p>bool True if the actual row count meets the expected condition, False otherwise</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If invalid operator is provided</p> Usage <p>assert checker.checkRows(15, operator=\"&lt;\")  # Verify if less than 15 rows</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.checkSameColumn","title":"checkSameColumn(c1, c2)","text":"<p>Checks if the values in two specified columns are the same for all rows in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>c1</code> <code>int</code> <p>The index of the first column to be checked.</p> required <code>c2</code> <code>int</code> <p>The index of the second column to be checked.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the values in the specified columns are not the same for any row.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.close","title":"close()","text":"<p>Closes the cursor.</p> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.connect","title":"connect(username='root', passwd='taosdata', **kwargs)","text":"<p>Reconnect</p> <p>Parameters:</p> Name Type Description Default <code>username</code> <code>str</code> <p>The username used to log in to the cluster.</p> <code>'root'</code> <code>passwd</code> <code>str</code> <p>The password used to log in to the cluster.</p> <code>'taosdata'</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.deleteRows","title":"deleteRows(table, where=None)","text":"<p>Deletes rows from the specified table based on the given condition.</p> <p>Parameters:</p> Name Type Description Default <code>table</code> <code>str</code> <p>The name of the table from which rows are to be deleted.</p> required <code>where</code> <code>str</code> <p>The condition for deleting rows. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the delete operation fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.error","title":"error(sql, expectedErrno=None, expectErrInfo=None, fullMatched=True, show=False)","text":"<p>Executes a SQL statement and checks for expected errors.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>expectedErrno</code> <code>int</code> <p>The expected error number. Defaults to None.</p> <code>None</code> <code>expectErrInfo</code> <code>str</code> <p>The expected error information. Defaults to None.</p> <code>None</code> <code>fullMatched</code> <code>bool</code> <p>If True, checks for exact matches of the expected error information. Defaults to True.</p> <code>True</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>str</code> <p>The error information if an error occurs.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the expected error does not occur or if the error information does not match the expected information.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.errors","title":"errors(sql_list, expected_error_id_list=None, expected_error_info_list=None)","text":"<p>Executes a list of SQL queries and checks for expected errors.</p> <p>Parameters:</p> Name Type Description Default <code>sql_list</code> <code>list</code> <p>The list of SQL queries to be executed.</p> required <code>expected_error_id_list</code> <code>list</code> <p>The list of expected error numbers corresponding to each SQL query. Defaults to None.</p> <code>None</code> <code>expected_error_info_list</code> <code>list</code> <p>The list of expected error information corresponding to each SQL query. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the SQL list is empty, if the execution of any SQL query fails, if the expected error does not occur, or if the error information does not match the expected information.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.execute","title":"execute(sql, queryTimes=10, show=False)","text":"<p>Executes a SQL statement.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the execution in case of failure. Defaults to 10.</p> <code>10</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of affected rows.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.executeTimes","title":"executeTimes(sql, times)","text":"<p>Executes a SQL statement a specified number of times.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <code>times</code> <code>int</code> <p>The number of times to execute the SQL statement.</p> required <p>Returns:</p> Name Type Description <code>int</code> <p>The number of affected rows from the last execution.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.executes","title":"executes(sqls, queryTimes=30, show=False)","text":"<p>Executes a list of SQL statements.</p> <p>Parameters:</p> Name Type Description Default <code>sqls</code> <code>list</code> <p>The list of SQL statements to be executed.</p> required <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the execution in case of failure. Defaults to 30.</p> <code>30</code> <code>show</code> <code>bool</code> <p>If True, each SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution of any SQL statement fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.expectKeyData","title":"expectKeyData(key, col, data, show=False)","text":"<p>Whether the data at the specified key matches the expected data.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <p>The first column to be compared with.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be checked.</p> required <code>data</code> <p>The expected data to be compared with.</p> required <code>show</code> <code>bool</code> <p>If True, logs a message when the check is successful. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>Bool</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getColData","title":"getColData(col)","text":"<p>Retrieves all data from the specified column in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>int</code> <p>The column index of the data to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing all data from the specified column.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getColNameList","title":"getColNameList(sql, col_tag=None)","text":"<p>Executes a SQL query and retrieves the column names and optionally the column types.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>col_tag</code> <code>optional</code> <p>If provided, the method will return both column names and column types. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing the column names.</p> <code>tuple</code> <p>A tuple containing two lists - the column names and the column types, if col_tag is provided.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getCols","title":"getCols()","text":"<p>Retrieves the number of cols fetched by the last query.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of cols fetched by the last query.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getData","title":"getData(row, col)","text":"<p>Retrieves the data at the specified row and column from the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be retrieved.</p> required <code>col</code> <code>int</code> <p>The column index of the data to be retrieved.</p> required <p>Returns:</p> Type Description <p>The data at the specified row and column.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row or column is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getDataWithOutCheck","title":"getDataWithOutCheck(row, col)","text":"<p>Retrieves the data at the specified row and column from the last query result. Args:     row (int): The row index of the data to be retrieved.     col (int): The column index of the data to be retrieved. Returns:     The data at the specified row and column. Raises:     IndexError: If the specified row or column is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getFirstValue","title":"getFirstValue(sql)","text":"<p>Executes a SQL query and retrieves the first value in the result.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <p>Returns:</p> Type Description <p>The first value in the result.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getResult","title":"getResult(sql, exit=True)","text":"<p>Executes a SQL query and fetches the results.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>The fetched results.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getRowData","title":"getRowData(row)","text":"<p>Retrieves all data from the specified row in the last query result.</p> <p>Parameters:</p> Name Type Description Default <code>row</code> <code>int</code> <p>The row index of the data to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list containing all data from the specified row.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the specified row is out of range.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getRows","title":"getRows()","text":"<p>Retrieves the number of rows fetched by the last query.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched by the last query.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getTimes","title":"getTimes(time_str, precision='ms')","text":"<p>Converts a time string to a timestamp based on the specified precision.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>time_str</code> <code>str</code> <p>The time string to be converted. The string should end with a character indicating the time unit (e.g., 's' for seconds, 'm' for minutes).</p> required <code>precision</code> <code>str</code> <p>The precision of the timestamp. Can be \"ms\" (milliseconds), \"us\" (microseconds), or \"ns\" (nanoseconds). Defaults to \"ms\".</p> <code>'ms'</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The timestamp in the specified precision.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the time string does not end with a valid time unit character or if the precision is not valid.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getType","title":"getType(col)","text":"<p>Retrieves the data type of the specified column in the last query result.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>col</code> <code>int</code> <p>The column index for which the data type is to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The data type of the specified column.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.getVariable","title":"getVariable(search_attr)","text":"<p>Retrieves the value of a specified variable from the database.</p> <p>Parameters:</p> Name Type Description Default <code>search_attr</code> <code>str</code> <p>The name of the variable to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the value of the specified variable and the list of all variables.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.init","title":"init(cursor, log=False)","text":"<p>Initializes the TDSql instance with a database cursor and optionally enables logging.</p> <p>Parameters:</p> Name Type Description Default <code>cursor</code> <p>The database cursor to be used for executing SQL queries.</p> required <code>log</code> <code>bool</code> <p>If True, enables logging of SQL statements to a file. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.isErrorSql","title":"isErrorSql(sql)","text":"<p>Executes a SQL statement and checks if it results in an error.(Not used)</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be executed.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the SQL statement results in an error, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.is_err_sql","title":"is_err_sql(sql)","text":"<p>Checks if a SQL statement will result in an error when executed.</p> <p>This method executes the provided SQL statement and determines whether it  causes an exception. It's useful for testing error conditions and validating that certain SQL statements should fail.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL statement to be tested for errors.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>False if the SQL statement executes successfully without errors, True if the SQL statement results in an error/exception.</p> <p>Raises:</p> Type Description <code>None</code> <p>This method catches all exceptions internally and returns a boolean result instead of raising exceptions.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.no_error","title":"no_error(sql)","text":"<p>summary</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>_type_</code> <p>description</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.pause","title":"pause()","text":"<p>Pause the execution of the program and wait for enter key. Used for debugging. Args:     None Returns:     None Raises:     None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.prepare","title":"prepare(dbname='db', drop=True, **kwargs)","text":"<p>Prepares the database by optionally dropping it if it exists, creating it, and setting it as the active database.</p> <p>Parameters:</p> Name Type Description Default <code>dbname</code> <code>str</code> <p>The name of the database to be prepared. Defaults to \"db\".</p> <code>'db'</code> <code>drop</code> <code>bool</code> <p>If True, drops the database if it exists before creating it. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <p>Additional keyword arguments to be included in the database creation statement. If duration is not provided, it defaults to 100.</p> <code>{}</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.query","title":"query(sql, row_tag=None, queryTimes=10, count_expected_res=None, show=False, exit=True)","text":"<p>Executes a SQL query and fetches the results.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>row_tag</code> <code>optional</code> <p>If provided, the method will return the fetched results. Defaults to None.</p> <code>None</code> <code>queryTimes</code> <code>int</code> <p>The number of times to attempt the query in case of failure. Defaults to 10.</p> <code>10</code> <code>count_expected_res</code> <code>optional</code> <p>If provided, the method will repeatedly execute the query until the first result matches this value or the queryTimes limit is reached. Defaults to None.</p> <code>None</code> <code>show</code> <code>bool</code> <p>If True, the SQL statement will be logged before execution. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched if row_tag is not provided.</p> <code>list</code> <p>The fetched results if row_tag is provided.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query fails after the specified number of attempts.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.queryAndCheckResult","title":"queryAndCheckResult(sql_list, expect_result_list, dbPrecision='')","text":"<p>Executes a list of SQL queries and checks the results against the expected results.</p> <p>Parameters:</p> Name Type Description Default <code>sql_list</code> <code>list</code> <p>The list of SQL queries to be executed.</p> required <code>expect_result_list</code> <code>list</code> <p>The list of expected results corresponding to each SQL query.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the execution of any SQL query fails or if the results do not match the expected results.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.query_success_failed","title":"query_success_failed(sql, row_tag=None, queryTimes=10, count_expected_res=None, expectErrInfo=None, fullMatched=True)","text":"<p>Executes a SQL query with retry mechanism and handles both successful and failed scenarios.</p> <p>This method attempts to execute a SQL query multiple times, handling both successful executions and expected error conditions. It's particularly useful for testing scenarios where queries might initially fail but eventually succeed, or for validating specific error conditions.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query statement to be executed.</p> required <code>row_tag</code> <code>optional</code> <p>If provided, the method will return the fetched results              instead of just the row count. Defaults to None.</p> <code>None</code> <code>queryTimes</code> <code>int</code> <p>Maximum number of retry attempts if the query fails.                     Defaults to 10.</p> <code>10</code> <code>count_expected_res</code> <code>optional</code> <p>If provided, the method will repeatedly execute                          the query until the first result matches this value                          or retry limit is reached. Defaults to None.</p> <code>None</code> <code>expectErrInfo</code> <code>str</code> <p>Expected error message to validate against when                          query fails. If None, any error is acceptable.                          Defaults to None.</p> <code>None</code> <code>fullMatched</code> <code>bool</code> <p>If True, performs exact string matching for error                          messages. If False, performs partial string matching                          (contains). Defaults to True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>str</code> <p>Error information string if an expected error occurs and query fails within retry attempts.</p> <code>None</code> <p>If query succeeds or if unexpected error occurs and reaches retry limit.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If query fails after all retry attempts and the error is not expected     or doesn't match the expected error pattern.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.setConnMode","title":"setConnMode(mode=0, value=1)","text":"<p>Set Conn Mode</p> <p>Parameters:</p> Name Type Description Default <code>mode</code> <code>int</code> <p>connect mode options.</p> <code>0</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sql.TDSql.waitedQuery","title":"waitedQuery(sql, expectedRows, timeout)","text":"<p>Executes a SQL query and waits until the expected number of rows is retrieved or the timeout is reached.</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>The SQL query to be executed.</p> required <code>expectedRows</code> <code>int</code> <p>The expected number of rows to be retrieved.</p> required <code>timeout</code> <code>int</code> <p>The maximum time to wait (in seconds) for the expected number of rows to be retrieved.</p> required <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the number of rows retrieved and the time taken (in seconds).</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the query execution fails.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sqlset","title":"<code>sqlset</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl","title":"<code>srvCtl</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl","title":"<code>srvCtl</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.addSimExtraCfg","title":"addSimExtraCfg(option, value)","text":"<p>add new option to taos.cfg Args:     option (string): option key     value  (string): option value Returns:     bool: True if add ok, False if failed</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.clusterRootPath","title":"clusterRootPath()","text":"<p>Gets the root path of the cluster.</p> <p>Returns:</p> Name Type Description <code>str</code> <p>The root path of the cluster.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeCfgPath","title":"dnodeCfgPath(idx)","text":"<p>Gets the configuration path for a specific dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The configuration path for the dnode.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeClearData","title":"dnodeClearData(idx)","text":"<p>Clear dnode's data (Remove all data files).</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode to clear.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was cleared successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeDataFiles","title":"dnodeDataFiles(idx)","text":"<p>Gets the data files for a specific dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode.</p> required <p>Returns:</p> Name Type Description <code>list</code> <p>A list of data files for the dnode.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeForceStop","title":"dnodeForceStop(idx)","text":"<p>Force Stops a dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode to stop.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was stopped successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeLogPath","title":"dnodeLogPath(idx)","text":"<p>Gets the log path for a specific dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The log path for the dnode.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeRestartAll","title":"dnodeRestartAll()","text":"<p>Restarts all dnodes.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all dnodes were restarted successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeStart","title":"dnodeStart(idx)","text":"<p>Starts a dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode to start.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was started successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeStartAll","title":"dnodeStartAll()","text":"<p>Starts all dnodes.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all dnodes were started successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeStop","title":"dnodeStop(idx)","text":"<p>Stops a dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode to stop.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the dnode was stopped successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.dnodeStopAll","title":"dnodeStopAll()","text":"<p>Stops all dnodes.</p> <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all dnodes were stopped successfully, False otherwise.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#srvCtl.srvCtl.taosdFile","title":"taosdFile(idx)","text":"<p>Gets the path to the taosd file for a specific dnode.</p> <p>Parameters:</p> Name Type Description Default <code>idx</code> <code>int</code> <p>The index of the dnode.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>The path to the taosd file.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#sub","title":"<code>sub</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taosadapter","title":"<code>taosadapter</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taosadapter.TAdapter","title":"<code>TAdapter</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taosadapter.TAdapter.start_taosadapter","title":"start_taosadapter()","text":"<p>use this method, must deploy taosadapter</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg","title":"<code>taosdemoCfg</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg","title":"<code>TDTaosdemoCfg</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg.append_sql_stb","title":"append_sql_stb(target, value)","text":"<p>for appending sql dict into specific sql list</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>the target append list format: 'fileType_tableType' fileType: query, sub tableType: table, stable unique: 'insert_stbs'</p> required <code>value</code> <code>dict</code> <p>the sql dict going to be appended</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg.get_sql","title":"get_sql(target)","text":"<p>general get function for all sql lists</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>the sql list want to get format: 'fileType_tableType' fileType: query, sub tableType: table, stable unique: 'insert_stbs'</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg.get_template","title":"get_template(target)","text":"<p>general get function for the default sql template</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>the sql list want to get format: 'fileType_tableType' fileType: query, sub tableType: table, stable unique: 'insert_stbs'</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg.import_sql","title":"import_sql(Sql_in, mode)","text":"<p>used for importing the sql later used</p> <p>Parameters:</p> Name Type Description Default <code>Sql_in</code> <code>dict</code> <p>the imported sql dict</p> required <code>mode</code> <code>str</code> <p>the sql storing location within TDTaosdemoCfg format: 'fileType_tableType' fileType: query, sub tableType: table, stable</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#taosdemoCfg.TDTaosdemoCfg.pop_sql_stb","title":"pop_sql_stb(target, index)","text":"<p>for poping a sql dict from specific sql list</p> <p>Parameters:</p> Name Type Description Default <code>target</code> <code>str</code> <p>the target append list format: 'fileType_tableType' fileType: query, sub tableType: table, stable unique: 'insert_stbs'</p> required <code>index</code> <code>int</code> <p>the sql dict that is going to be popped</p> required"},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper","title":"<code>taoskeeper</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper.TaosKeeper","title":"<code>TaosKeeper</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper.TaosKeeper.cfg","title":"cfg(option, value)","text":"<p>add param option and value to cfg file</p> <p>Parameters:</p> Name Type Description Default <code>option</code> <p>str, param name</p> required <code>value</code> <p>str, param value</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper.TaosKeeper.start","title":"start()","text":"<p>start taoskeeper process.</p> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper.TaosKeeper.stop","title":"stop(force_kill=False)","text":"<p>stop taoskeeper process.</p> <p>Parameters:</p> Name Type Description Default <code>force_kill</code> <p>bool, whether to force kill the process default: False if True, use kill -9 if False, use kill -15</p> <code>False</code> <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#taoskeeper.TaosKeeper.update_cfg","title":"update_cfg(update_dict)","text":"<p>update taoskeeper cfg file</p> <p>Parameters:</p> Name Type Description Default <code>update_dict</code> <code>dict</code> <p>dict, update dict example: {\"log\": {\"path\": \"/var/log/taos\"}}</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#tserror","title":"<code>tserror</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#types","title":"<code>types</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#types.TDSmlProtocolType","title":"<code>TDSmlProtocolType</code>","text":"<p>Schemaless Protocol types 0 - unknown 1 - InfluxDB Line Protocol 2 - OpenTSDB Telnet Protocl 3 - OpenTSDB JSON Protocol</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil","title":"<code>streamUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem","title":"<code>StreamItem</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem.addQuerySqlCase","title":"addQuerySqlCase(query_sql_case)","text":"<p>\u6dfb\u52a0\u67e5\u8be2SQL\u7528\u4f8b</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem.awaitResultHasRows","title":"awaitResultHasRows(waitSeconds=60)","text":"<p>\u786e\u4fdd\u6d41\u5904\u7406\u5df2\u6709\u7ed3\u679c\uff0c\u4e0d\u786e\u8ba4\u6700\u7ec8\u7ed3\u679c\u884c\u6570\u65f6\u4f7f\u7528</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem.awaitRowStability","title":"awaitRowStability(stable_rows, waitSeconds=300)","text":"<p>\u786e\u4fdd\u6d41\u5904\u7406\u7ed3\u679c\u7684\u884c\u6570\u4e0e\u9884\u671f\u7684\u7a33\u5b9a\u884c\u6570\u4e00\u81f4 :param stable_rows: int, \u9884\u671f\u7684\u7a33\u5b9a\u884c\u6570</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem.setResultFile","title":"setResultFile(file)","text":"<p>\u8bbe\u7f6e\u7ed3\u679c\u6587\u4ef6\u8def\u5f84</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamItem.set_exp_query_param_mapping","title":"set_exp_query_param_mapping(mapping)","text":"<p>\u8bbe\u7f6e\u53c2\u6570\u540d\u4e0e\u5217\u7d22\u5f15\u7684\u6620\u5c04\uff0c\u4f8b\u5982 {\"_wstart\": 0, \"_wend\": 1}</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable","title":"<code>StreamTable</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.__delete_data","title":"__delete_data(full_table_name, start_row, end_row)","text":"<p>\u5220\u9664\u6307\u5b9a\u8303\u56f4\u5185\u7684\u6570\u636e</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.appendSubTables","title":"appendSubTables(startTbIndex, endTbIndex)","text":"<p>\u5411\u8d85\u7ea7\u8868\u4e2d\u8ffd\u52a0\u5b50\u8868 :param startTbIndex: int, \u8d77\u59cb\u5b50\u8868\u7d22\u5f15 :param endTbIndex: int, \u7ed3\u675f\u5b50\u8868\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.append_data","title":"append_data(start_row, end_row)","text":"<p>\u5411\u8868\u4e2d\u8ffd\u52a0\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.append_subtable_data","title":"append_subtable_data(tbName, start_row, end_row)","text":"<p>\u5411\u6307\u5b9a\u5b50\u8868\u8ffd\u52a0\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.delete_data","title":"delete_data(start_row, end_row)","text":"<p>\u5220\u9664\u8868\u4e2d\u7684\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.delete_subtable_data","title":"delete_subtable_data(tbName, start_row, end_row)","text":"<p>\u5220\u9664\u6307\u5b9a\u5b50\u8868\u4e2d\u7684\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.register_column_generator","title":"register_column_generator(column_name, generator_func)","text":"<p>\u6ce8\u518c\u67d0\u4e2a\u5217\u540d\u7684\u81ea\u5b9a\u4e49\u6570\u636e\u751f\u6210\u51fd\u6570 :param column_name: str, \u5217\u540d :param generator_func: function(row_index: int, timestamp: int) -&gt; str</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.reset_columns","title":"reset_columns()","text":"<p>\u91cd\u7f6e\u4e3a\u9ed8\u8ba4\u5217\u5b9a\u4e49</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.setInterval","title":"setInterval(interval)","text":"<p>\u8bbe\u7f6e\u65f6\u95f4\u95f4\u9694 :param interval: int, \u65f6\u95f4\u95f4\u9694\uff0c\u5355\u4f4d\u4e3a\u79d2</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.setLogOpen","title":"setLogOpen(logOpen)","text":"<p>\u8bbe\u7f6e\u65e5\u5fd7\u5f00\u5173 :param logOpen: bool, \u662f\u5426\u5f00\u542f\u65e5\u5fd7</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.setPrecision","title":"setPrecision(precision)","text":"<p>\u8bbe\u7f6e\u65f6\u95f4\u7cbe\u5ea6 :param precision: str, \u65f6\u95f4\u7cbe\u5ea6\uff0c\u652f\u6301 \"ms\", \"us\", \"ns\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.setStart","title":"setStart(start)","text":"<p>\u8bbe\u7f6e\u8d77\u59cb\u65f6\u95f4 :param start: str, \u8d77\u59cb\u65f6\u95f4\uff0c\u683c\u5f0f\u4e3a \"YYYY-MM-DD HH.MM.SS\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.set_columns","title":"set_columns(column_def)","text":"<p>\u5141\u8bb8\u7528\u6237\u81ea\u5b9a\u4e49\u5217\u5b9a\u4e49 :param column_def: str\uff0c\u4f8b\u5982 \"ts timestamp, val int\"</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.update_data","title":"update_data(start_row, end_row)","text":"<p>\u66f4\u65b0\u8868\u4e2d\u7684\u6570\u636e :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#streamUtil.StreamTable.update_subtable_data","title":"update_subtable_data(tbName, start_row, end_row)","text":"<p>\u66f4\u65b0\u6307\u5b9a\u5b50\u8868\u4e2d\u7684\u6570\u636e :param tbName: str, \u5b50\u8868\u540d\u79f0 :param start_row: int, \u8d77\u59cb\u884c\u7d22\u5f15 :param end_row: int, \u7ed3\u675f\u884c\u7d22\u5f15</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#autogen","title":"<code>autogen</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#rawblock","title":"<code>rawblock</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil","title":"<code>mqttUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil","title":"<code>MqttUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil.checkEqual","title":"checkEqual(elm, expect_elm, show=False)","text":"<p>Checks if the given element is equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element does not match the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil.checkNotEqual","title":"checkNotEqual(elm, expect_elm)","text":"<p>Checks if the given element is not equal to the expected element.</p> <p>Parameters:</p> Name Type Description Default <code>elm</code> <p>The element to be checked.</p> required <code>expect_elm</code> <p>The expected element to be compared with.</p> required <p>Returns:</p> Type Description <p>None</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the element matches the expected element.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil.checkQos","title":"checkQos(expectedQos, show=False)","text":"<p>Checks if the qos fetched by the last subscription matches the expected qos.</p> <p>Parameters:</p> Name Type Description Default <code>expectedQos</code> <code>int</code> <p>The expected qos.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the qos matches the expected qos, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of qos does not match the expected qos.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil.checkRows","title":"checkRows(expectedRows, show=False)","text":"<p>Checks if the number of rows fetched by the last subscription matches the expected number of rows.</p> <p>Parameters:</p> Name Type Description Default <code>expectedRows</code> <code>int</code> <p>The expected number of rows.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the number of rows matches the expected number, otherwise it exits the program.</p> <p>Raises:</p> Type Description <code>SystemExit</code> <p>If the number of rows does not match the expected number.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#mqttUtil.MqttUtil.getRows","title":"getRows()","text":"<p>Retrieves the number of rows fetched by the last sub.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The number of rows fetched by the last sub.</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#compatibilityUtil","title":"<code>compatibilityUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#compatibilityUtil.CompatibilityBase","title":"<code>CompatibilityBase</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#compatibilityUtil.CompatibilityBase.alter_string_in_file","title":"alter_string_in_file(file, old_str, new_str)","text":"<p>replace str in file :param file :param old_str :param new_str :return:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#compatibilityUtil.CompatibilityBase.version_compare","title":"version_compare(version1, version2)","text":"<p>Compare two version strings. Returns 1 if version1 &gt; version2, -1 if version1 &lt; version2, 0 if equal</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#tmqUtil","title":"<code>tmqUtil</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2","title":"<code>stmt2</code>","text":""},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2","title":"<code>TDStmt2</code>","text":"<p>TDengine Stmt2 utility class</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.affect_rows","title":"affect_rows()","text":"<p>Get affected rows count</p> <p>Returns:</p> Type Description <p>Number of affected rows</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.bind_batch_params","title":"bind_batch_params(params)","text":"<p>Bind batch parameters to statement</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <p>List of parameter batches (list of lists)     Example: [[ts1, temp1, hum1, loc1], [ts2, temp2, hum2, loc2], ...]</p> required <p>Returns:</p> Type Description <p>self for method chaining</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.bind_params","title":"bind_params(params)","text":"<p>Bind parameters to statement for simple INSERT</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <p>List of parameter values for a single row</p> required <p>Returns:</p> Type Description <p>self for method chaining</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.bind_super_table_data","title":"bind_super_table_data(tbnames, tags, datas)","text":"<p>Bind data for super table operations </p> <p>Parameters:</p> Name Type Description Default <code>tbnames</code> <p>List of sub-table names</p> required <code>tags</code> <p>List of tag values for each table </p> required <code>datas</code> <p>List of row-oriented data for each table</p> required <p>Returns:</p> Type Description <p>self for method chaining</p> Example"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.bind_super_table_data--row-oriented-data-format-easier-to-use","title":"Row-oriented data format (easier to use)","text":"<p>tbnames = [\"d_bind_0\", \"d_bind_1\"] tags = [[0, \"location_0\"], [1, \"location_1\"]] datas = [     # table 0 data: 2 rows, 4 columns each     [         [ts1, curr1, volt1, phase1],  # row 1         [ts2, curr2, volt2, phase2]   # row 2     ],     # table 1 data: 2 rows, 4 columns each     [         [ts3, curr3, volt3, phase3],  # row 1         [ts4, curr4, volt4, phase4]   # row 2     ] ]</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.close","title":"close()","text":"<p>Close the statement</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute","title":"execute()","text":"<p>Execute the prepared statement</p> <p>Returns:</p> Type Description <p>Number of affected rows</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_batch","title":"execute_batch(sql, batch_params, check_affected=True, expected_rows=None)","text":"<p>Convenience method for batch insert</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL statement</p> required <code>batch_params</code> <code>list</code> <p>Batch parameters (list of lists)</p> required <code>check_affected</code> <code>bool</code> <p>Whether to check affected rows</p> <code>True</code> <code>expected_rows</code> <code>int</code> <p>Expected number of affected rows</p> <code>None</code> <p>Returns:</p> Type Description <p>Number of affected rows if check_affected=True</p> <p>Examples:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_batch--batch-insert-with-expected-rows-validation","title":"Batch insert with expected rows validation","text":"<p>batch_data = [[ts1, v1], [ts2, v2], [ts3, v3]] affected = stmt.execute_batch(     \"INSERT INTO table VALUES (?, ?)\",     batch_data,     expected_rows=3 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_single","title":"execute_single(sql, params, check_affected=True, expected_rows=None)","text":"<p>Convenience method for single row insert</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL statement </p> required <code>params</code> <code>list</code> <p>Single row parameters</p> required <code>check_affected</code> <code>bool</code> <p>Whether to check affected rows</p> <code>True</code> <code>expected_rows</code> <code>int</code> <p>Expected number of affected rows</p> <code>None</code> <p>Returns:</p> Type Description <p>Number of affected rows if check_affected=True</p> <p>Examples:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_single--insert-with-expected-rows-validation","title":"Insert with expected rows validation","text":"<p>affected = stmt.execute_single(     \"INSERT INTO sensor_data VALUES (?, ?, ?, ?)\",     [timestamp, temp, humidity, location],     expected_rows=1 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_stmt","title":"execute_stmt(sql, params=None, batch_params=None, tbnames=None, tags=None, datas=None, check_affected=True, expected_rows=None)","text":"<p>Execute a complete statement with prepare, bind, execute and affect_rows check</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL statement with ? placeholders</p> required <code>params</code> <code>list</code> <p>Parameters for single row insert</p> <code>None</code> <code>batch_params</code> <code>list</code> <p>Parameters for batch insert</p> <code>None</code> <code>tbnames</code> <code>list</code> <p>Table names for super table operations</p> <code>None</code> <code>tags</code> <code>list</code> <p>Tag values for super table operations  </p> <code>None</code> <code>datas</code> <code>list</code> <p>Column data for super table operations</p> <code>None</code> <code>check_affected</code> <code>bool</code> <p>Whether to check and return affected rows</p> <code>True</code> <code>expected_rows</code> <code>int</code> <p>Expected number of affected rows for validation</p> <code>None</code> <p>Returns:</p> Type Description <p>Number of affected rows if check_affected=True, otherwise None</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>When expected_rows is provided and doesn't match actual affected rows</p> <p>Examples:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_stmt--single-row-insert-with-expected-rows-check","title":"Single row insert with expected rows check","text":"<p>affected = stmt.execute_stmt(     \"INSERT INTO sensor_data VALUES (?, ?, ?, ?)\",     params=[timestamp, temp, humidity, location],     expected_rows=1 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_stmt--batch-insert-with-expected-rows-check","title":"Batch insert with expected rows check","text":"<p>affected = stmt.execute_stmt(     \"INSERT INTO sensor_data VALUES (?, ?, ?, ?)\",     batch_params=[[ts1, temp1, hum1, loc1], [ts2, temp2, hum2, loc2]],     expected_rows=2 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_stmt--super-table-insert-with-expected-rows-check","title":"Super table insert with expected rows check","text":"<p>affected = stmt.execute_stmt(     \"INSERT INTO ? USING device_metrics TAGS(?, ?, ?) VALUES (?, ?, ?)\",     tbnames=[\"device_001\"],      tags=[[\"device_001\", 1, \"Building_A\"],[\"device_002\", 2, \"Building_B\"]],      datas=datas = [[[ts1,100.1, 1]],[[ts2, 200.1, 2],[ts3, 200.2, 2]]],     expected_rows=3 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_super_table","title":"execute_super_table(sql, tbnames, tags, datas, check_affected=True, expected_rows=None)","text":"<p>Convenience method for super table operations</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <code>str</code> <p>SQL statement</p> required <code>tbnames</code> <code>list</code> <p>Table names</p> required <code>tags</code> <code>list</code> <p>Tag values</p> required <code>datas</code> <code>list</code> <p>Column data</p> required <code>check_affected</code> <code>bool</code> <p>Whether to check affected rows</p> <code>True</code> <code>expected_rows</code> <code>int</code> <p>Expected number of affected rows</p> <code>None</code> <p>Returns:</p> Type Description <p>Number of affected rows if check_affected=True</p> <p>Examples:</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.execute_super_table--super-table-insert-with-expected-rows-check","title":"Super table insert with expected rows check","text":"<p>affected = stmt.execute_stmt(     \"INSERT INTO ? USING device_metrics TAGS(?, ?, ?) VALUES (?, ?, ?)\",     tbnames=[\"device_001\"],      tags=[[\"device_001\", 1, \"Building_A\"],[\"device_002\", 2, \"Building_B\"]],      datas=datas = [[[ts1,100.1, 1]],[[ts2, 200.1, 2],[ts3, 200.2, 2]]],     expected_rows=3 )</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.init","title":"init(conn)","text":"<p>Initialize stmt2 with connection</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.prepare","title":"prepare(sql)","text":"<p>Prepare a statement using stmt2 API</p> <p>Parameters:</p> Name Type Description Default <code>sql</code> <p>SQL statement with ? placeholders</p> required <p>Returns:</p> Type Description <p>self for method chaining</p>"},{"location":"util_funcs_docs/new_test_framework/utils/#stmt2.TDStmt2.reconnect","title":"reconnect(**kwargs)","text":"<p>Reconnect to the database with new parameters</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Connection parameters like host, user, password, etc.</p> <code>{}</code> <p>Returns:</p> Type Description <p>self for method chaining</p>"}]}