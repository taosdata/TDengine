import json
import subprocess
import threading
import psutil
import time
import taos
import shutil
import argparse
import os
import signal
import sys
import datetime
import itertools
import re 
import traceback
import uuid
import gc

"""TDengine New Stream Computing Performance Test
TDengine æ–°æ•°æ®æµè®¡ç®—æ€§èƒ½æµ‹è¯•å·¥å…·

Purpose/ç”¨é€”:
    TDengine æµè®¡ç®—æ€§èƒ½æµ‹è¯•å·¥å…·ï¼Œæ”¯æŒå¤šç§æµ‹è¯•æ¨¡å¼å’Œæµè®¡ç®—ç±»å‹ã€‚
    æä¾›å®Œæ•´çš„æ•°æ®ç”Ÿæˆã€æµè®¡ç®—åˆ›å»ºã€æ€§èƒ½ç›‘æ§ã€å»¶è¿Ÿæ£€æµ‹ç­‰åŠŸèƒ½ã€‚
    é€‚ç”¨äºæµè®¡ç®—æ€§èƒ½åŸºå‡†æµ‹è¯•ã€ç³»ç»Ÿè°ƒä¼˜ã€å‹åŠ›æµ‹è¯•ç­‰åœºæ™¯ã€‚

Catalog/ç›®å½•:
    - Performance Testing / æ€§èƒ½æµ‹è¯•
    - Stream Computing / æµè®¡ç®—  
    - Real-time Analytics / å®æ—¶åˆ†æ
    - Benchmarking / åŸºå‡†æµ‹è¯•

Features/åŠŸèƒ½:
    âœ¨ æµè®¡ç®—æ€§èƒ½æµ‹è¯•
        - æ”¯æŒæ—¶é—´çª—å£ã€æ»‘åŠ¨çª—å£ã€ä¼šè¯çª—å£ã€è®¡æ•°çª—å£ã€äº‹ä»¶çª—å£ã€çŠ¶æ€çª—å£ã€å®šæ—¶è§¦å‘ç­‰7ç§çª—å£ç±»å‹
        - æ”¯æŒè¶…çº§è¡¨å’Œå­è¡¨æ•°æ®æºï¼Œæ”¯æŒæŒ‰å­è¡¨åå’Œtagåˆ†ç»„
        - æ”¯æŒèšåˆæŸ¥è¯¢å’ŒæŠ•å½±æŸ¥è¯¢ä¸¤ç§è®¡ç®—æ¨¡å¼
        - æ”¯æŒå•æµå’Œå¤šæµå¹¶å‘æµ‹è¯•
        
    ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§
        - ç³»ç»Ÿèµ„æºç›‘æ§ï¼šCPUã€å†…å­˜ã€ç£ç›˜I/Oå®æ—¶ç›‘æ§
        - æµè®¡ç®—å»¶è¿Ÿç›‘æ§ï¼šæºè¡¨ä¸ç›®æ ‡è¡¨æ•°æ®å»¶è¿Ÿæ£€æµ‹
        - åŠ¨æ€é˜ˆå€¼å‘Šè­¦ï¼šåŸºäºæ£€æŸ¥é—´éš”çš„æ™ºèƒ½å»¶è¿Ÿåˆ†çº§
        - è¯¦ç»†æ€§èƒ½æŠ¥å‘Šï¼šå›¾è¡¨åŒ–å±•ç¤ºå’Œé—®é¢˜åˆ†æå»ºè®®
        
    ğŸ—„ï¸ æ•°æ®ç®¡ç†
        - è‡ªåŠ¨æ•°æ®ç”Ÿæˆï¼šæ”¯æŒå¯é…ç½®çš„è¡¨æ•°é‡ã€è®°å½•æ•°ã€ä¹±åºç‡
        - æ•°æ®å¤‡ä»½æ¢å¤ï¼šæ”¯æŒå®Œæ•´çš„æ•°æ®å¤‡ä»½å’Œå¿«é€Ÿæ¢å¤
        - å†å²æ•°æ®æµ‹è¯•ï¼šåŸºäºå·²æœ‰æ•°æ®è¿›è¡Œæµè®¡ç®—æ€§èƒ½æµ‹è¯•
        - å¢é‡æ•°æ®å†™å…¥ï¼šæ¨¡æ‹Ÿå®æ—¶æ•°æ®æµåœºæ™¯
        
    ğŸ—ï¸ éƒ¨ç½²æ¶æ„
        - å•èŠ‚ç‚¹æ¨¡å¼ï¼šé€‚ç”¨äºå¼€å‘æµ‹è¯•å’Œå°è§„æ¨¡éªŒè¯
        - é›†ç¾¤æ¨¡å¼ï¼šæ”¯æŒ3èŠ‚ç‚¹é›†ç¾¤çš„é«˜å¯ç”¨æµ‹è¯•
        - è‡ªåŠ¨ç¯å¢ƒå‡†å¤‡ï¼šè‡ªåŠ¨é…ç½®TDengineé›†ç¾¤ç¯å¢ƒ
        - çµæ´»å‚æ•°è°ƒä¼˜ï¼šæ”¯æŒvgroupsã€è°ƒè¯•çº§åˆ«ç­‰å‚æ•°è°ƒæ•´
        
Test Scenarios/æµ‹è¯•åœºæ™¯:
    ğŸš€ åŸºç¡€æµè®¡ç®—æµ‹è¯•
        - åˆ›å»ºæµ‹è¯•æ•°æ®å¹¶æ‰§è¡Œå®æ—¶æµè®¡ç®—
        - æŒç»­æ•°æ®å†™å…¥ï¼Œè§‚å¯Ÿæµè®¡ç®—å»¶è¿Ÿå˜åŒ–
        - é€‚ç”¨äºéªŒè¯æµè®¡ç®—åŸºæœ¬åŠŸèƒ½å’Œæ€§èƒ½
        
    ğŸ“ˆ å‹åŠ›æµ‹è¯•
        - å¤§æ•°æ®é‡ä¸‹çš„æµè®¡ç®—æ€§èƒ½æµ‹è¯•
        - å¤šæµå¹¶å‘å¤„ç†èƒ½åŠ›æµ‹è¯•  
        - ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µåˆ†æ
        
    ğŸ” å»¶è¿Ÿæµ‹è¯•
        - æµè®¡ç®—å®æ—¶æ€§éªŒè¯
        - å»¶è¿Ÿåˆ†å¸ƒç»Ÿè®¡å’Œåˆ†æ
        - å»¶è¿Ÿé˜ˆå€¼å‘Šè­¦æµ‹è¯•
        
    ğŸ‹ï¸ å†å²æ•°æ®æµ‹è¯•
        - åŸºäºå·²æœ‰å¤§æ•°æ®é›†çš„æµè®¡ç®—æµ‹è¯•
        - é¿å…é‡å¤æ•°æ®ç”Ÿæˆï¼Œå¿«é€ŸéªŒè¯ä¸åŒæµSQL
        - é€‚ç”¨äºç®—æ³•éªŒè¯å’Œæ€§èƒ½å¯¹æ¯”

Window Types/çª—å£ç±»å‹:
    ğŸ“Š æ—¶é—´çª—å£ (INTERVAL SLIDING WINDOW)
        - å›ºå®šæ—¶é—´é—´éš”çš„è®¡ç®—
        - é€‚ç”¨äºè¿ç»­æ•°æ®çš„å¹³æ»‘ç»Ÿè®¡
        
    ğŸ“Š æ»‘åŠ¨çª—å£ (SLIDING WINDOW)
        - å›ºå®šæ—¶é—´é—´éš”çš„æ»‘åŠ¨è®¡ç®—
        - é€‚ç”¨äºè¿ç»­æ•°æ®çš„å¹³æ»‘ç»Ÿè®¡
        
    ğŸ”— ä¼šè¯çª—å£ (SESSION WINDOW)  
        - åŸºäºæ•°æ®é—´éš”çš„åŠ¨æ€çª—å£
        - é€‚ç”¨äºç”¨æˆ·ä¼šè¯åˆ†æ
        
    ğŸ“ è®¡æ•°çª—å£ (COUNT WINDOW)
        - åŸºäºè®°å½•æ•°é‡çš„å›ºå®šçª—å£
        - é€‚ç”¨äºæ‰¹é‡æ•°æ®å¤„ç†
        
    âš¡ äº‹ä»¶çª—å£ (EVENT WINDOW)
        - åŸºäºäº‹ä»¶æ¡ä»¶çš„åŠ¨æ€çª—å£
        - é€‚ç”¨äºå¼‚å¸¸æ£€æµ‹å’Œæ¨¡å¼è¯†åˆ«
        
    ğŸ“ çŠ¶æ€çª—å£ (STATE WINDOW)
        - åŸºäºçŠ¶æ€å˜åŒ–çš„çª—å£åˆ’åˆ†
        - é€‚ç”¨äºçŠ¶æ€æœºåˆ†æ
        
    â° å®šæ—¶è§¦å‘ (PERIOD TRIGGER)
        - å®šæ—¶æ‰§è¡Œçš„è®¡ç®—è§¦å‘
        - é€‚ç”¨äºå®šæœŸæŠ¥è¡¨ç”Ÿæˆ

Query Types/æŸ¥è¯¢ç±»å‹:
    ğŸ“Š èšåˆæŸ¥è¯¢ (AGG): avg(), max(), min() ç­‰ç»Ÿè®¡å‡½æ•°
    ğŸ“‹ æŠ•å½±æŸ¥è¯¢ (SELECT): å­—æ®µé€‰æ‹©å’ŒæŠ•å½±æ“ä½œ

Data Sources/æ•°æ®æº:
    ğŸ¢ è¶…çº§è¡¨ (STB): stream_from.stb - é€‚ç”¨äºå¤§è§„æ¨¡æ•°æ®æŸ¥è¯¢
    ğŸ“„ å­è¡¨ (TB): stream_from.ctb0_X - é€‚ç”¨äºå•è¡¨æ€§èƒ½æµ‹è¯•

Partitioning/åˆ†ç»„æ–¹å¼:
    ğŸ“‚ æ— åˆ†ç»„ (NONE): å…¨è¡¨ç»Ÿè®¡
    ğŸ·ï¸ æŒ‰å­è¡¨å (BY_TBNAME): partition by tbname
    ğŸ”– æŒ‰æ ‡ç­¾ (BY_TAG): partition by tag

Performance Monitoring/æ€§èƒ½ç›‘æ§:
    ğŸ’» ç³»ç»Ÿèµ„æº: CPUä½¿ç”¨ç‡ã€å†…å­˜å ç”¨ã€ç£ç›˜I/O
    â±ï¸ å»¶è¿Ÿç›‘æ§: æºè¡¨ä¸ç›®æ ‡è¡¨çš„æ—¶é—´å·®åˆ†æ
    ğŸ“ˆ å®æ—¶ç»Ÿè®¡: æµè®¡ç®—å¤„ç†é€Ÿåº¦å’Œæ•ˆç‡
    ğŸš¨ æ™ºèƒ½å‘Šè­¦: å»¶è¿Ÿé˜ˆå€¼å‘Šè­¦å’Œæ€§èƒ½å»ºè®®

Requirements/ç³»ç»Ÿè¦æ±‚:
    TDengine: v3.3.7.0+
    Python: 3.7+
    ä¾èµ–åŒ…: taos, psutil, json

Authors/ä½œè€…:
    Guo Xiangyang / éƒ­å‘é˜³

Labels/æ ‡ç­¾: 
    performance, stream, testing

History/å†å²:
    - 2025-08-15 Initial commit
                 é¦–æ¬¡æäº¤

Usage Examples/ä½¿ç”¨ç¤ºä¾‹:

    # å¿«é€Ÿå¼€å§‹ - åŸºç¡€æµè®¡ç®—æµ‹è¯•
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 1 --table-count 1000 --time 30
    
    # åˆ›å»ºå¹¶å¤‡ä»½æµ‹è¯•æ•°æ®  
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir --create-data --table-count 5000 --histroy-rows 1000
    
    # æ¢å¤æ•°æ®å¹¶æµ‹è¯•ç‰¹å®šæµè®¡ç®—
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 3 --sql-type intervalsliding_stb_partition_by_tbname --time 60
    
    # å¤šæµå¹¶å‘æµ‹è¯•
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 1 --sql-type intervalsliding_stb --stream-num 100 --time 30
    
    # å»¶è¿Ÿç›‘æ§æµ‹è¯•
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 1 --check-stream-delay --delay-check-interval 5 --time 60
    
    # é›†ç¾¤æ¨¡å¼æµ‹è¯•
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 1 --deployment-mode cluster --vgroups 20 --time 30
    
    # å‹åŠ›æ§åˆ¶æµ‹è¯•
    python3 stream_perf_test.py --stream-perf-test-dir /home/stream_perf_test_dir -m 1 --real-time-batch-sleep 10 --real-time-batch-rows 500


"""

# ========== å…¨å±€é¢œè‰²å®šä¹‰ ==========
class Colors:
    """ç»ˆç«¯é¢œè‰²å¸¸é‡å®šä¹‰"""
    # åŸºç¡€é¢œè‰²
    RED = '\033[91m'        # çº¢è‰² - é”™è¯¯ã€ä¸¥é‡è­¦å‘Š
    GREEN = '\033[92m'      # ç»¿è‰² - æˆåŠŸã€æ­£å¸¸çŠ¶æ€
    YELLOW = '\033[93m'     # é»„è‰² - è­¦å‘Šã€æ³¨æ„
    BLUE = '\033[94m'       # è“è‰² - ä¿¡æ¯ã€è¯¦æƒ…
    PURPLE = '\033[95m'     # ç´«è‰² - æ ‡é¢˜ã€é‡è¦ä¿¡æ¯
    CYAN = '\033[96m'       # é’è‰² - æ—¶é—´æˆ³ã€æ•°æ®
    WHITE = '\033[97m'      # ç™½è‰² - æ™®é€šæ–‡æœ¬
    
    # ç‰¹æ®Šæ ¼å¼
    BOLD = '\033[1m'        # ç²—ä½“
    UNDERLINE = '\033[4m'   # ä¸‹åˆ’çº¿
    BLINK = '\033[5m'       # é—ªçƒ
    REVERSE = '\033[7m'     # åè‰²
    
    # èƒŒæ™¯è‰²
    BG_RED = '\033[41m'     # çº¢è‰²èƒŒæ™¯
    BG_GREEN = '\033[42m'   # ç»¿è‰²èƒŒæ™¯
    BG_YELLOW = '\033[43m'  # é»„è‰²èƒŒæ™¯
    BG_BLUE = '\033[44m'    # è“è‰²èƒŒæ™¯
    
    # ç»“æŸç¬¦
    END = '\033[0m'         # é‡ç½®æ‰€æœ‰æ ¼å¼
    
    @staticmethod
    def supports_color():
        """æ£€æµ‹ç»ˆç«¯æ˜¯å¦æ”¯æŒé¢œè‰²è¾“å‡º"""
        return (
            hasattr(os.sys.stdout, 'isatty') and os.sys.stdout.isatty() and
            os.environ.get('TERM') != 'dumb' and
            os.environ.get('NO_COLOR') is None
        )
    
    @staticmethod
    def get_colors():
        """è·å–é¢œè‰²å¯¹è±¡ï¼Œå¦‚æœä¸æ”¯æŒé¢œè‰²åˆ™è¿”å›ç©ºå­—ç¬¦ä¸²"""
        if Colors.supports_color():
            return Colors
        else:
            # åˆ›å»ºä¸€ä¸ªæ‰€æœ‰é¢œè‰²éƒ½ä¸ºç©ºå­—ç¬¦ä¸²çš„ç±»
            class NoColors:
                RED = GREEN = YELLOW = BLUE = PURPLE = CYAN = WHITE = ''
                BOLD = UNDERLINE = BLINK = REVERSE = ''
                BG_RED = BG_GREEN = BG_YELLOW = BG_BLUE = ''
                END = ''
            return NoColors


# ========== é¢œè‰²æ‰“å°è¾…åŠ©å‡½æ•° ==========
def print_success(message):
    """æ‰“å°æˆåŠŸæ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.GREEN}âœ“ {message}{c.END}")

def print_warning(message):
    """æ‰“å°è­¦å‘Šæ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.YELLOW}âš  {message}{c.END}")

def print_error(message):
    """æ‰“å°é”™è¯¯æ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.RED}âœ— {message}{c.END}")

def print_info(message):
    """æ‰“å°ä¿¡æ¯æ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.BLUE}â„¹ {message}{c.END}")

def print_title(message):
    """æ‰“å°æ ‡é¢˜æ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.BOLD}{c.PURPLE}{message}{c.END}")

def print_subtitle(message):
    """æ‰“å°å‰¯æ ‡é¢˜æ¶ˆæ¯"""
    c = Colors.get_colors()
    print(f"{c.CYAN}{message}{c.END}")

def print_timestamp(message):
    """æ‰“å°å¸¦æ—¶é—´æˆ³çš„æ¶ˆæ¯"""
    c = Colors.get_colors()
    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
    print(f"{c.CYAN}[{timestamp}]{c.END} {message}")

def print_separator(char='-', length=80, color=None):
    """æ‰“å°åˆ†éš”çº¿"""
    c = Colors.get_colors()
    if color:
        print(f"{getattr(c, color.upper(), '')}{char * length}{c.END}")
    else:
        print(char * length)
        
        
class MonitorSystemLoad:

    def __init__(self, name_pattern, count, perf_file='/tmp/perf.log', use_signal=True, interval=1, deployment_mode='cluster', warm_up_time=0) -> None:
        """åˆå§‹åŒ–ç³»ç»Ÿè´Ÿè½½ç›‘æ§
        
        Args:
            name_pattern: è¿›ç¨‹åæ¨¡å¼,ä¾‹å¦‚ 'taosd.*dnode1/conf'
            count: ç›‘æ§æ¬¡æ•°
            perf_file: æ€§èƒ½æ•°æ®è¾“å‡ºæ–‡ä»¶
            interval: æ€§èƒ½é‡‡é›†é—´éš”(ç§’),é»˜è®¤1ç§’
            deployment_mode: éƒ¨ç½²æ¨¡å¼ 'single' æˆ– 'cluster'
            warm_up_time: é¢„çƒ­æ—¶é—´(ç§’),åœ¨æ­¤æœŸé—´æ”¶é›†æ•°æ®ä½†ä¸æ‰“å°,é»˜è®¤0ç§’
        """
        self.name_pattern = name_pattern  # ä¿å­˜è¿›ç¨‹åæ¨¡å¼
        self.count = count
        self.perf_file = perf_file
        self.interval = interval
        self.deployment_mode = deployment_mode
        self.warm_up_time = warm_up_time
        
        # æ·»åŠ å”¯ä¸€æ ‡è¯†ç¬¦
        import uuid
        self.instance_id = str(uuid.uuid4())[:8]
        self.thread_name = f"MonitorSystemLoad-{self.instance_id}"
        
        print(f"è°ƒè¯•: MonitorSystemLoad åˆå§‹åŒ–ï¼Œå®ä¾‹ID = {self.instance_id}ï¼Œperf_file = {perf_file}")
        print(f"è°ƒè¯•: é¢„çƒ­ç­‰å¾…æ—¶é—´ = {warm_up_time}ç§’")        
        
        self.stop_monitoring = False
        self._should_stop = False
        self._is_running = False
        self._force_stop = False
        self._stop_event = threading.Event()
        
        # æ ¹æ®éƒ¨ç½²æ¨¡å¼ç¡®å®šéœ€è¦ç›‘æ§çš„èŠ‚ç‚¹
        if deployment_mode == 'single':
            self.monitor_nodes = ['dnode1']
            print(f"å•èŠ‚ç‚¹æ¨¡å¼: ä»…ç›‘æ§ dnode1")
        else:
            self.monitor_nodes = ['dnode1', 'dnode2', 'dnode3']
            print(f"é›†ç¾¤æ¨¡å¼: ç›‘æ§ dnode1, dnode2, dnode3")
        
        # ä¸ºæ¯ä¸ªdnodeåˆ›å»ºå¯¹åº”çš„æ€§èƒ½æ–‡ä»¶å¥æŸ„
        self.perf_files = {}
        for dnode in self.monitor_nodes:
            # åŸºäºä¼ å…¥çš„perf_fileè·¯å¾„ç”Ÿæˆæ¯ä¸ªèŠ‚ç‚¹çš„æ–‡ä»¶è·¯å¾„
            base_dir = os.path.dirname(perf_file)
            base_name = os.path.splitext(os.path.basename(perf_file))[0]
            file_path = os.path.join(base_dir, f"{base_name}-{dnode}.log")
            
            try:
                # ç¡®ä¿ç›®å½•å­˜åœ¨
                os.makedirs(base_dir, exist_ok=True)
                self.perf_files[dnode] = open(file_path, 'w+')
                print(f"åˆ›å»ºæ€§èƒ½æ—¥å¿—æ–‡ä»¶: {file_path}")
            except Exception as e:
                print(f"åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
                
        # åˆ›å»ºæ±‡æ€»æ—¥å¿—æ–‡ä»¶
        try:
            base_dir = os.path.dirname(perf_file)
            base_name = os.path.splitext(os.path.basename(perf_file))[0]
            all_file = os.path.join(base_dir, f"{base_name}-all.log")
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(base_dir, exist_ok=True)
            self.perf_files['all'] = open(all_file, 'w+')
            print(f"åˆ›å»ºæ±‡æ€»æ—¥å¿—æ–‡ä»¶: {all_file}")
        except Exception as e:
            print(f"åˆ›å»ºæ±‡æ€»æ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
            
        # è·å–è¿›ç¨‹ID
        self.pids = self.get_pids_by_pattern()
        self.processes = {}
        
        # ä¿®å¤CPUç›‘æ§é—®é¢˜ï¼šæ­£ç¡®åˆå§‹åŒ–è¿›ç¨‹å¯¹è±¡å¹¶è¿›è¡Œç¬¬ä¸€æ¬¡CPUé‡‡æ ·
        for dnode, pid in self.pids.items():
            if pid:
                try:
                    process = psutil.Process(pid)
                    process.cpu_percent()
                    self.processes[dnode] = process
                    print(f"åˆå§‹åŒ–è¿›ç¨‹å¯¹è±¡: {dnode}, PID: {pid}")
                except Exception as e:
                    print(f"åˆå§‹åŒ–è¿›ç¨‹å¯¹è±¡å¤±è´¥ {dnode} (PID: {pid}): {str(e)}")
                    self.processes[dnode] = None
            else:
                self.processes[dnode] = None
                
        self.stop_monitoring = False
        self._should_stop = False
        if use_signal and threading.current_thread() is threading.main_thread():
            signal.signal(signal.SIGINT, self.signal_handler)
            signal.signal(signal.SIGTERM, self.signal_handler)

    def __del__(self):
        """ç¡®ä¿æ‰€æœ‰æ–‡ä»¶éƒ½è¢«æ­£ç¡®å…³é—­"""
        try:
            if hasattr(self, '_is_running') and self._is_running:
                print(f"è°ƒè¯•: MonitorSystemLoadå®ä¾‹ {getattr(self, 'instance_id', 'unknown')} æ­£åœ¨ææ„ï¼Œå¼ºåˆ¶åœæ­¢")
                self.stop()
        except:
            pass
        
        # å…³é—­æ–‡ä»¶å¥æŸ„
        if hasattr(self, 'perf_files'):
            for f in self.perf_files.values():
                try:
                    if not f.closed:
                        f.close()
                except:
                    pass
            
    def stop(self):
        """æä¾›å¤–éƒ¨åœæ­¢ç›‘æ§çš„æ–¹æ³•"""
        print(f"è°ƒè¯•: åœæ­¢ç›‘æ§å®ä¾‹ {getattr(self, 'instance_id', 'unknown')}")
        self.stop_monitoring = True
        self._should_stop = True
        self._force_stop = True 
        self._is_running = False
        self._stop_event.set() 
        
        print("\nåœæ­¢æ€§èƒ½ç›‘æ§...")
        # ç­‰å¾…æ‰€æœ‰æ–‡ä»¶å†™å…¥å®Œæˆ
        if hasattr(self, 'perf_files'):
            for f in self.perf_files.values():
                try:
                    if not f.closed:
                        f.flush()
                except:
                    pass
            

    def _should_continue_monitoring(self):
        """ç»Ÿä¸€çš„åœæ­¢æ£€æŸ¥æ–¹æ³•"""
        return (not self.stop_monitoring and 
                not self._should_stop and 
                not self._force_stop and 
                not self._stop_event.is_set())
        
    def signal_handler(self, signum, frame):
        """å¤„ç†ä¸­æ–­ä¿¡å·"""
        print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢ç›‘æ§...")
        self.stop_monitoring = True
        time.sleep(1)
        # å…³é—­æ‰€æœ‰æ–‡ä»¶
        for f in self.perf_files.values():
            try:
                f.close()
            except:
                pass
        # é€€å‡ºç›‘æ§ä½†ä¸å½±å“taosdè¿›ç¨‹
        print("\nç›‘æ§å·²åœæ­¢ï¼Œtaosdè¿›ç¨‹ç»§ç»­è¿è¡Œ")
        os._exit(0)
            
    def get_pid_by_name(self, name):
        for proc in psutil.process_iter(['pid', 'name']):
            if proc.info['name'] == name:
                return proc.info['pid']
        return None
    
    def write_metrics(self, dnode, status, timestamp=None, print_to_console=True):
        """å†™å…¥æ€§èƒ½æŒ‡æ ‡
        
        Args:
            dnode: èŠ‚ç‚¹åç§°
            status: æ€§èƒ½æ•°æ®
            timestamp: æ—¶é—´æˆ³(å¯é€‰)
            print_to_console: æ˜¯å¦æ‰“å°åˆ°æ§åˆ¶å°
        """
        # å†™å…¥å•ä¸ªèŠ‚ç‚¹çš„æ—¥å¿—æ–‡ä»¶
        self.perf_files[dnode].write(status + '\n')
        
        # åŒæ—¶å†™å…¥æ±‡æ€»æ—¥å¿—æ–‡ä»¶
        self.perf_files['all'].write(status + '\n')
        
        # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦è¾“å‡ºåˆ°æ§åˆ¶å°
        if print_to_console:
            print(status)

    def get_pids_by_pattern(self):
        """æ ¹æ®è¿›ç¨‹åæ¨¡å¼è·å–æ‰€æœ‰åŒ¹é…çš„è¿›ç¨‹ID"""
        pids = {}
        # ä½¿ç”¨ ps å‘½ä»¤è·å–è¯¦ç»†è¿›ç¨‹ä¿¡æ¯
        result = subprocess.run(
            'ps -ef | grep taosd | grep -v grep', 
            shell=True, 
            capture_output=True, 
            text=True
        )
        
        for line in result.stdout.splitlines():
            if self.name_pattern in line:
                parts = line.split()
                pid = int(parts[1])
                # ä»é…ç½®æ–‡ä»¶è·¯å¾„ä¸­æå–dnodeä¿¡æ¯
                cfg_path = next((p for p in parts if '/conf/taos.cfg' in p), None)
                if cfg_path:
                    # ä»è·¯å¾„ä¸­æå–dnodeåç§°
                    dnode = next((part for part in cfg_path.split('/') if part.startswith('dnode')), None)
                    if dnode and dnode in self.monitor_nodes:
                        pids[dnode] = pid
                        print(f"æ‰¾åˆ° {dnode} è¿›ç¨‹, PID: {pid}, é…ç½®æ–‡ä»¶: {cfg_path}")
        
        if not pids:
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°åŒ¹é…æ¨¡å¼ '{self.name_pattern}' çš„è¿›ç¨‹")
        else:
            print(f"å…±æ‰¾åˆ° {len(pids)} ä¸ªtaosdè¿›ç¨‹")
        
        # æ— è®ºæ˜¯å¦æ‰¾åˆ°è¿›ç¨‹,éƒ½åˆå§‹åŒ–æ‰€æœ‰dnodeçš„æ–‡ä»¶å¥æŸ„
        for dnode in self.monitor_nodes:
            if dnode not in self.perf_files:
                file_path = f"{os.path.splitext(self.perf_file)[0]}-{dnode}.log"
                try:
                    self.perf_files[dnode] = open(file_path, 'w+')
                    print(f"åˆ›å»ºæ€§èƒ½æ—¥å¿—æ–‡ä»¶: {file_path}")
                except Exception as e:
                    print(f"åˆ›å»ºæ—¥å¿—æ–‡ä»¶å¤±è´¥ {file_path}: {str(e)}")
        
        return pids
    
    def write_zero_metrics(self, dnode, timestamp, is_warm_up=False, instance_id=None):
        """å†™å…¥é›¶å€¼æŒ‡æ ‡
        
        Args:
            dnode: èŠ‚ç‚¹åç§°
            timestamp: æ—¶é—´æˆ³
            is_warm_up: æ˜¯å¦ä¸ºé¢„çƒ­æœŸ
        """
        status = (
            f"{timestamp} [{dnode}] "
            f"CPU: 0.0%, "
            f"Memory: 0.00MB (0.00%), "
            f"Read: 0.00MB (0), "
            f"Write: 0.00MB (0)"
        )
        
        if is_warm_up:
            status += " [é¢„çƒ­æœŸæ•°æ®]"
        if instance_id:
            status += f" (å®ä¾‹ID: {instance_id})"
        
        try:
            if hasattr(self, 'perf_files') and dnode in self.perf_files:
                if not self.perf_files[dnode].closed:
                    self.perf_files[dnode].write(status + '\n')
        except:
            pass
        
        # é¢„çƒ­æœŸä¸æ‰“å°åˆ°æ§åˆ¶å°
        if not is_warm_up:
            print(status)
        
    def get_proc_status_old(self):
        """ç›‘æ§æ‰€æœ‰åŒ¹é…è¿›ç¨‹çš„çŠ¶æ€"""
        try:
            processes = {
                dnode: psutil.Process(pid) if pid else None
                for dnode, pid in self.pids.items()
            }
            
            while self.count > 0 and not self.stop_monitoring:
                try:
                    sys_load = psutil.getloadavg()
                    timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
                    
                    # è®°å½•ç³»ç»Ÿæ•´ä½“è´Ÿè½½
                    load_info = f"\n{timestamp} System Load: {sys_load[0]:.2f}\n"
                    for dnode in self.perf_files.keys():
                        self.perf_files[dnode].write(load_info)
                    print(load_info)
                    
                    # è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„çŠ¶æ€
                    for dnode in ['dnode1', 'dnode2', 'dnode3']:
                        process = processes.get(dnode)
                        try:
                            if process and process.is_running():
                                cpu_percent = process.cpu_percent(interval=self.interval)
                                memory_info = process.memory_info()
                                memory_percent = process.memory_percent()
                                io_counters = process.io_counters()

                                status = (
                                    f"{timestamp} [{dnode}] "
                                    f"CPU: {cpu_percent:.1f}%, "
                                    f"Memory: {memory_info.rss/1048576.0:.2f}MB ({memory_percent:.2f}%), "
                                    f"Read: {io_counters.read_bytes/1048576.0:.2f}MB ({io_counters.read_count}), "
                                    f"Write: {io_counters.write_bytes/1048576.0:.2f}MB ({io_counters.write_count})"
                                )
                                self.write_metrics(dnode, status)
                            else:
                                # è¿›ç¨‹ä¸å­˜åœ¨æ—¶å†™å…¥é›¶å€¼
                                self.write_zero_metrics(dnode, timestamp)
                                
                        except (psutil.NoSuchProcess, psutil.AccessDenied):
                            # è¿›ç¨‹å·²ç»ˆæ­¢æˆ–æ— æ³•è®¿é—®æ—¶å†™å…¥é›¶å€¼
                            self.write_zero_metrics(dnode, timestamp)
                            processes[dnode] = None
                        except Exception as e:
                            print(f"ç›‘æ§ {dnode} å‡ºé”™: {str(e)}")
                            self.write_zero_metrics(dnode, timestamp)
                    
                    # æ·»åŠ åˆ†éš”çº¿
                    separator = "-" * 80 + "\n"
                    for f in self.perf_files.values():
                        f.write(separator)
                        f.flush()
                    print(separator.strip())
                        
                    time.sleep(self.interval)
                    self.count -= 1
                    
                    if self.stop_monitoring:
                        print("æ­£åœ¨å®Œæˆæœ€åçš„ç›‘æ§è®°å½•...")
                        break
                    
                except Exception as e:
                    print(f"ç›‘æ§å‡ºé”™: {str(e)}")
                    if not self.stop_monitoring:  # åªæœ‰åœ¨éä¸»åŠ¨åœæ­¢æ—¶æ‰è·³å‡º
                            break
                
            print("\nç›‘æ§å·²åœæ­¢")
        
        finally:
            # å…³é—­æ‰€æœ‰æ–‡ä»¶
            for f in self.perf_files.values():
                try:
                    f.close()
                except:
                    pass

    def get_proc_status(self):
        """ç›‘æ§æ‰€æœ‰åŒ¹é…è¿›ç¨‹çš„çŠ¶æ€"""
        # æ ‡è®°å®ä¾‹æ­£åœ¨è¿è¡Œ
        self._is_running = True
        instance_id = getattr(self, 'instance_id', 'unknown')
        
        print(f"è°ƒè¯•: ç›‘æ§çº¿ç¨‹å¼€å§‹è¿è¡Œï¼Œå®ä¾‹ID = {instance_id}")
        
        try:
            # è®¡ç®—é¢„çƒ­æœŸé—´çš„æ•°æ®ç‚¹æ•°é‡
            warm_up_cycles = int(self.warm_up_time / self.interval) if self.warm_up_time > 0 else 0
            
            if warm_up_cycles > 0:
                print(f"\n=== å¼€å§‹æ€§èƒ½ç›‘æ§é¢„çƒ­æœŸ ===")
                print(f"é¢„çƒ­æ—¶é—´: {self.warm_up_time}ç§’ ({warm_up_cycles}ä¸ªå‘¨æœŸ)")
                print(f"é¢„çƒ­æœŸé—´æ”¶é›†æ•°æ®ä½†ä¸æ‰“å°ï¼Œç­‰å¾…ç³»ç»Ÿç¨³å®š...")
                
                # å†™å…¥é¢„çƒ­è¯´æ˜åˆ°æ—¥å¿—æ–‡ä»¶
                for f in self.perf_files.values():
                    f.write(f"=== æ€§èƒ½ç›‘æ§é¢„çƒ­æœŸå¼€å§‹ ===\n")
                    f.write(f"é¢„çƒ­æ—¶é—´: {self.warm_up_time}ç§’\n")
                    f.write(f"é¢„çƒ­æœŸé—´çš„æ•°æ®ä»…ç”¨äºç³»ç»Ÿç¨³å®šï¼Œä¸ä½œä¸ºæ€§èƒ½è¯„ä¼°ä¾æ®\n")
                    f.write(f"{'='*60}\n")
            
            cycle_count = 0
            
            while self.count > 0 and self._should_continue_monitoring():
                start_time = time.time()
                cycle_count += 1
                
                # åœ¨æ¯ä¸ªå¾ªç¯å¼€å§‹æ—¶æ£€æŸ¥åœæ­¢æ ‡å¿—
                if not self._should_continue_monitoring():
                    print(f"è°ƒè¯•: ç›‘æ§å®ä¾‹ {instance_id} æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œç¬¬{cycle_count}æ¬¡å¾ªç¯")
                    break
                
                sys_load = psutil.getloadavg()
                timestamp = time.strftime('%Y-%m-%d %H:%M:%S')
                
                # åˆ¤æ–­æ˜¯å¦åœ¨é¢„çƒ­æœŸ
                is_warm_up = cycle_count <= warm_up_cycles
                
                # è®°å½•ç³»ç»Ÿè´Ÿè½½
                load_info = f"\n{timestamp} System Load: {sys_load[0]:.2f}\n"
                if is_warm_up:
                    load_info += f" [é¢„çƒ­æœŸ {cycle_count}/{warm_up_cycles}] (å®ä¾‹ID: {instance_id})"
                else:
                    load_info += f" [æ­£å¼ç›‘æ§] (å®ä¾‹ID: {instance_id})"
                load_info += "\n"
                
                # å†™å…¥æ–‡ä»¶ï¼ˆåŒ…æ‹¬é¢„çƒ­æœŸæ•°æ®ï¼‰
                for f in self.perf_files.values():
                    try:
                        if not f.closed:
                            f.write(load_info)
                    except:
                        pass
                                
                # æ§åˆ¶å°è¾“å‡ºï¼ˆé¢„çƒ­æœŸé™é»˜ï¼‰
                if not is_warm_up:
                    print(load_info.strip()) 
                elif cycle_count == 1:
                    print(f"é¢„çƒ­å¼€å§‹: {timestamp}(å®ä¾‹ID: {instance_id})")
                elif cycle_count % 10 == 0:  # æ¯10ä¸ªå‘¨æœŸæ˜¾ç¤ºä¸€æ¬¡é¢„çƒ­è¿›åº¦
                    print(f"é¢„çƒ­è¿›åº¦: {cycle_count}/{warm_up_cycles} ({(cycle_count/warm_up_cycles)*100:.1f}%)(å®ä¾‹ID: {instance_id})")
                
                current_pids = self.get_pids_by_pattern()
                
                # æ›´æ–°è¿›ç¨‹å¯¹è±¡ï¼šæ£€æŸ¥PIDæ˜¯å¦å˜åŒ–ï¼Œå¦‚æœå˜åŒ–åˆ™é‡æ–°åˆå§‹åŒ–
                for dnode in self.monitor_nodes:
                    current_pid = current_pids.get(dnode)
                    existing_process = self.processes.get(dnode)
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°è¿›ç¨‹å¯¹è±¡
                    need_update = False
                    if current_pid is None:
                        # è¿›ç¨‹ä¸å­˜åœ¨äº†
                        if existing_process is not None:
                            need_update = True
                            self.processes[dnode] = None
                    elif existing_process is None:
                        # æ–°å‘ç°çš„è¿›ç¨‹
                        need_update = True
                    elif existing_process.pid != current_pid:
                        # PIDå˜åŒ–äº†ï¼Œè¿›ç¨‹é‡å¯äº†
                        need_update = True
                    
                    if need_update and current_pid:
                        try:
                            new_process = psutil.Process(current_pid)
                            new_process.cpu_percent()
                            self.processes[dnode] = new_process
                            print(f"è°ƒè¯•: æ›´æ–°è¿›ç¨‹å¯¹è±¡ {dnode}, æ–°PID: {current_pid}")
                        except Exception as e:
                            print(f"è°ƒè¯•: åˆå§‹åŒ–æ–°è¿›ç¨‹å¯¹è±¡å¤±è´¥ {dnode} (PID: {current_pid}): {str(e)}")
                            self.processes[dnode] = None
                            
                # æ”¶é›†è¿›ç¨‹æŒ‡æ ‡
                for dnode in self.monitor_nodes:
                    try:
                        process = self.processes.get(dnode)
                        
                        if process and process.is_running():
                            try:
                                cpu_percent = process.cpu_percent(interval=None)
                                memory_info = process.memory_info()
                                memory_percent = process.memory_percent()
                                io_counters = process.io_counters()

                                status = (
                                    f"{timestamp} [{dnode}] "
                                    f"CPU: {cpu_percent:.1f}%, "
                                    f"Memory: {memory_info.rss/1048576.0:.2f}MB ({memory_percent:.2f}%), "
                                    f"Read: {io_counters.read_bytes/1048576.0:.2f}MB ({io_counters.read_count}), "
                                    f"Write: {io_counters.write_bytes/1048576.0:.2f}MB ({io_counters.write_count})"
                                )
                                
                                if is_warm_up:
                                    status += f" [é¢„çƒ­æœŸæ•°æ®] (å®ä¾‹ID: {instance_id})"
                                else:
                                    status += f" (å®ä¾‹ID: {instance_id})"
                                
                                # å†™å…¥æ—¥å¿—æ–‡ä»¶
                                self.write_metrics(dnode, status, print_to_console=(not is_warm_up))
                                # âœ… è°ƒè¯•è¾“å‡ºCPUé‡‡æ ·ä¿¡æ¯
                                if cycle_count <= 3 or (cycle_count % 20 == 0):  # å‰3æ¬¡æˆ–æ¯20æ¬¡æ‰“å°è°ƒè¯•ä¿¡æ¯
                                    print(f"è°ƒè¯•: {dnode} CPUé‡‡æ · - å‘¨æœŸ{cycle_count}, CPU: {cpu_percent:.1f}%")
                                    
                            except (psutil.NoSuchProcess, psutil.AccessDenied) as e:
                                print(f"è°ƒè¯•: è¿›ç¨‹{dnode}è®¿é—®å¤±è´¥: {str(e)}")
                                self.write_zero_metrics(dnode, timestamp, is_warm_up, instance_id)
                                self.processes[dnode] = None  # æ¸…ç†æ— æ•ˆçš„è¿›ç¨‹å¯¹è±¡
                        else:
                            # å¦‚æœé…ç½®è¦æ±‚ç›‘æ§æ­¤èŠ‚ç‚¹ä½†æ‰¾ä¸åˆ°è¿›ç¨‹
                            if dnode in self.monitor_nodes:
                                self.write_zero_metrics(dnode, timestamp, is_warm_up, instance_id)
                            
                    except Exception as e:
                        if not is_warm_up:
                            print(f"ç›‘æ§ {dnode} å‡ºé”™: {str(e)} (å®ä¾‹ID: {instance_id})")
                        self.write_zero_metrics(dnode, timestamp, is_warm_up, instance_id)
                
                # æ·»åŠ åˆ†éš”çº¿
                separator = f"---------------- (å®ä¾‹ID: {instance_id}) ----------------\n"
                for f in self.perf_files.values():
                    try:
                        if not f.closed:
                            f.write(separator)
                            f.flush()
                    except:
                        pass
                
                if not is_warm_up:
                    print(separator.strip())
                    
                # é¢„çƒ­æœŸç»“æŸæç¤º
                if is_warm_up and cycle_count == warm_up_cycles:
                    print(f"\n=== é¢„çƒ­æœŸç»“æŸï¼Œå¼€å§‹æ­£å¼æ€§èƒ½ç›‘æ§ (å®ä¾‹ID: {instance_id}) ===")
                    
                    # å†™å…¥é¢„çƒ­ç»“æŸæ ‡è®°
                    for f in self.perf_files.values():
                        try:
                            if not f.closed:
                                f.write(f"\n=== é¢„çƒ­æœŸç»“æŸï¼Œæ­£å¼ç›‘æ§å¼€å§‹ (å®ä¾‹ID: {instance_id}) ===\n")
                                f.write(f"{'='*60}\n")
                                f.flush()
                                print(f"è°ƒè¯•: å·²å†™å…¥é¢„çƒ­æœŸç»“æŸæ ‡è®°åˆ°æ€§èƒ½æ–‡ä»¶")
                        except Exception as e:
                            print(f"è°ƒè¯•: å†™å…¥é¢„çƒ­æœŸç»“æŸæ ‡è®°å¤±è´¥: {str(e)}")
                            pass
                
                # ç²¾ç¡®æ§åˆ¶é—´éš”æ—¶é—´
                elapsed = time.time() - start_time
                if elapsed < self.interval:
                    remaining_time = self.interval - elapsed
                    
                    # ä½¿ç”¨Event.wait()æ›¿ä»£sleepï¼Œèƒ½ç«‹å³å“åº”åœæ­¢ä¿¡å·
                    if self._stop_event.wait(timeout=remaining_time):
                        print(f"è°ƒè¯•: ç›‘æ§å®ä¾‹ {instance_id} åœ¨waitæœŸé—´æ”¶åˆ°åœæ­¢ä¿¡å·")
                        break
                
                self.count -= 1
                
                # æœ€ç»ˆæ£€æŸ¥æ˜¯å¦éœ€è¦åœæ­¢
                if not self._should_continue_monitoring():
                    print(f"è°ƒè¯•: ç›‘æ§å®ä¾‹ {instance_id} æ­£å¸¸ç»“æŸå¾ªç¯")
                    break
                
        except Exception as e:
            print(f"ç›‘æ§å‡ºé”™ (å®ä¾‹ID: {instance_id}): {str(e)}")  
        finally:
            self._is_running = False
            print(f"è°ƒè¯•: ç›‘æ§çº¿ç¨‹æ­£åœ¨æ¸…ç†èµ„æº (å®ä¾‹ID: {instance_id})...")
            
            # âœ… ç¡®ä¿æ‰€æœ‰æ–‡ä»¶å¥æŸ„éƒ½è¢«å…³é—­
            if hasattr(self, 'perf_files'):
                for f in self.perf_files.values():
                    try:
                        if not f.closed:
                            f.close()
                    except:
                        pass
                        
            print(f"è°ƒè¯•: ç›‘æ§çº¿ç¨‹å·²ç»“æŸ (å®ä¾‹ID: {instance_id})")
                   

def do_monitor(runtime, perf_file, deployment_mode='cluster', warm_up_time=0):
    """ç›‘æ§çº¿ç¨‹å‡½æ•°"""
    try:
        # ä¸åœ¨å­çº¿ç¨‹ä¸­ä½¿ç”¨ä¿¡å·å¤„ç†
        loader = MonitorSystemLoad(
            'taosd -c', 
            runtime, 
            perf_file, 
            use_signal=False,
            deployment_mode=deployment_mode,
            warm_up_time=warm_up_time 
        )
        loader.get_proc_status()
    except Exception as e:
        print(f"ç›‘æ§çº¿ç¨‹å‡ºé”™: {str(e)}")
    finally:
        print("ç›‘æ§çº¿ç¨‹ç»“æŸ")

def get_table_list(cursor):
    cursor.execute('use stream_from')

    sql = "select table_name from information_schema.ins_tables where db_name = 'stream_from' and stable_name='stb' order by table_name"
    cursor.execute(sql)

    res = cursor.fetchall()
    return res

def do_multi_insert(index, total, host, user, passwd, conf, tz):
    conn = taos.connect(
        host=host, user=user, password=passwd, config=conf, timezone=tz
    )

    cursor = conn.cursor()
    cursor.execute('use stream_from')

    start_ts = 1609430400000
    step = 5

    cursor.execute("create stable if not exists stb_result(wstart timestamp, minx float, maxx float, countx bigint) tags(gid bigint unsigned)")

    list = get_table_list(cursor)

    list = list[index*total: (index+1)*total]

    print("there are %d tables" % len(list))

    for index, n in enumerate(list):
        cursor.execute(f"create table if not exists {n[0]}_1 using stb_result tags(1)")
        count = 1
        while True:
            sql = (f"select cast({start_ts + step * 1000 * (count - 1)} as timestamp), min(c1), max(c2), count(c3) from stream_from.{n[0]} "
                   f"where ts >= {start_ts + step * 1000 * (count - 1)} and ts < {start_ts + step * 1000 * count}")
            cursor.execute(sql)

            res = cursor.fetchall()
            if res[0][3] == 0:
                break

            insert = f"insert into {n[0]}_1 values ({start_ts + step * 1000 * (count - 1)}, {res[0][1]}, {res[0][2]}, {res[0][3]})"
            cursor.execute(insert)
            count += 1
    conn.close()


'''
class StreamSQLTemplates_bak_for_phase1:
    """æµè®¡ç®— SQL æ¨¡æ¿é›†åˆ"""
    
    s2_2 = """
    create stream s2_2 trigger at_once 
        ignore expired 0 ignore update 0 into stream_to.stb2_2 
        as select _wstart as wstart,
        avg(c0), avg(c1),avg(c2), avg(c3),
        max(c0), max(c1), max(c2), max(c3),
        min(c0), min(c1), min(c2), min(c3)
        from stream_from.stb partition by tbname interval(15s);
    """
    
    s2_3 = """
    create stream s2_3 trigger window_close 
        ignore expired 0 ignore update 0 into stream_to.stb2_3 
        as select _wstart as wstart,
        avg(c0), avg(c1),avg(c2), avg(c3),
        max(c0), max(c1), max(c2), max(c3),
        min(c0), min(c1), min(c2), min(c3)
        from stream_from.stb partition by tbname interval(15s);
    """
    
    s2_4 = """
    create stream s2_4 trigger max_delay 5s 
        ignore expired 0 ignore update 0 into stream_to.stb2_4 
        as select _wstart as wstart,
        avg(c0), avg(c1),avg(c2), avg(c3),
        max(c0), max(c1), max(c2), max(c3),
        min(c0), min(c1), min(c2), min(c3)
        from stream_from.stb partition by tbname interval(15s);
    """
    
    s2_5 = """
    create stream s2_5 trigger FORCE_WINDOW_CLOSE into stream_to.stb2_5 
        as select _wstart as wstart,
        avg(c0), avg(c1),avg(c2), avg(c3),
        max(c0), max(c1), max(c2), max(c3),
        min(c0), min(c1), min(c2), min(c3)
        from stream_from.stb partition by tbname interval(15s);
    """
    
    s2_6 = """
    create stream s2_6 trigger CONTINUOUS_WINDOW_CLOSE 
        ignore expired 0 ignore update 0 into stream_to.stb2_6 
        as select _wstart as wstart,
        avg(c0), avg(c1),avg(c2), avg(c3),
        max(c0), max(c1), max(c2), max(c3),
        min(c0), min(c1), min(c2), min(c3)
        from stream_from.stb partition by tbname interval(15s);
    """
    
    s2_7 = """
    create stream stream_from.s2_7 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb 
            partition by tbname 
            into stream_to.stb2_7
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts < _twend;
    """
    
    s2_8 = """
    create stream stream_from.s2_8 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb 
            partition by tbname 
            into stream_to.stb2_8
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%trows ;
    """
    
    s2_9 = """
    create stream stream_from.s2_9 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb partition by tbname 
            STREAM_OPTIONS(MAX_DELAY(5s)) 
            into stream_to.stb2_9
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts < _twend;
    """
    
    s2_10 = """
    create stream stream_from.s2_10 INTERVAL(15s) SLIDING(15s) 
            from stream_from.stb 
            STREAM_OPTIONS(MAX_DELAY(5s))
            into stream_to.stb2_10
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%trows ;
    """
    
    s2_11 = """
    create stream stream_from.s2_11 period(15s) 
            from stream_from.stb partition by tbname  
            into stream_to.stb2_11
            as select cast(_tlocaltime/1000000 as timestamp) ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname ;
    """    
    
    s2_12 = """
    create stream stream_from.s2_12 session(ts,10a)
            from stream_from.stb partition by tbname 
            into stream_to.stb2_12
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts <= _twend;
    """
    
    s2_13 = """
    create stream stream_from.s2_13 COUNT_WINDOW(1000)
            from stream_from.stb partition by tbname 
            into stream_to.stb2_13
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts <= _twend;
    """
    
    s2_14 = """
    create stream stream_from.s2_14 EVENT_WINDOW(START WITH c0 > 5 END WITH c0 < 5) 
            from stream_from.stb partition by tbname 
            into stream_to.stb2_14
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts <= _twend;
    """
    
    s2_15 = """
    create stream stream_from.s2_15 STATE_WINDOW(c0) 
            from stream_from.stb partition by tbname 
            into stream_to.stb2_15
            as select _twstart ts, avg(c0), avg(c1), avg(c2), avg(c3),
            max(c0), max(c1), max(c2), max(c3),
            min(c0), min(c1), min(c2), min(c3)
            from %%tbname where ts >= _twstart and ts <= _twend;
    """
    
    @classmethod
    def get_sql(cls, sql_type):
        """
        è·å–æŒ‡å®šç±»å‹çš„ SQL æ¨¡æ¿
        Args:
            sql_type: SQL ç±»å‹æ ‡è¯†ç¬¦ (case_id)
        Returns:
            å¯¹åº”çš„ SQL æ¨¡æ¿
        """
        sql_map = {
            's2_2': cls.s2_2,
            's2_3': cls.s2_3,
            's2_4': cls.s2_4,
            's2_5': cls.s2_5,
            's2_6': cls.s2_6,
            's2_7': cls.s2_7,
            's2_8': cls.s2_8,
            's2_9': cls.s2_9,
            's2_10': cls.s2_10,
            's2_11': cls.s2_11,
            's2_12': cls.s2_12,
            's2_13': cls.s2_13,
            's2_14': cls.s2_14,
            's2_15': cls.s2_15,
        }
        
        # å®šä¹‰æ‰¹é‡ SQL ç»„åˆ
        batch_map = {
            'all': {
                's2_7': cls.s2_7,
                's2_8': cls.s2_8,
                's2_9': cls.s2_9,
                's2_10': cls.s2_10,
                's2_11': cls.s2_11,
                's2_12': cls.s2_12,
                's2_13': cls.s2_13,
                's2_14': cls.s2_14,
                's2_15': cls.s2_15,
            }
        }
        # å¦‚æœè¯·æ±‚æ‰¹é‡ SQL
        if sql_type in batch_map:
            return batch_map[sql_type]
        
        # è¿”å›å•ä¸ª SQLï¼Œé»˜è®¤è¿”å› s2_7
        return sql_map.get(sql_type, cls.s2_7)  
'''


class StreamSQLTemplates:
    """æµè®¡ç®— SQL æ¨¡æ¿é›†åˆ - é‡æ„ç‰ˆæœ¬"""
    
    def __init__(self):
        # å®šä¹‰é»˜è®¤çš„èšåˆå‡½æ•°ç»„åˆ
        self.default_agg_columns = [
                "avg(c0), avg(c1), avg(c2), avg(c3)",
                "max(c0), max(c1), max(c2), max(c3)", 
                "min(c0), min(c1), min(c2), min(c3)"
        ]
        
        # å®šä¹‰é»˜è®¤çš„æŠ•å½±åˆ—
        self.default_select_columns = ["c0", "c1", "c2", "c3"]
        
    def get_select_stream(self, **kwargs):
        """æŸ¥è¯¢æ‰€æœ‰æµä¿¡æ¯"""
        return "select * from information_schema.ins_streams;"
    
    def _build_columns(self, agg_or_select='agg', custom_columns=None):
        """æ„å»ºæŸ¥è¯¢åˆ—
        
        Args:
            agg_or_select: 'agg' è¡¨ç¤ºèšåˆæŸ¥è¯¢, 'select' è¡¨ç¤ºæŠ•å½±æŸ¥è¯¢
            custom_columns: è‡ªå®šä¹‰åˆ—ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è‡ªå®šä¹‰åˆ—
            
        Returns:
            str: æ„å»ºå¥½çš„åˆ—å­—ç¬¦ä¸²
        """
        if custom_columns:
            if isinstance(custom_columns, list):
                return ", ".join(custom_columns)
            return custom_columns
            
        if agg_or_select == 'agg':
            return ",\n        ".join(self.default_agg_columns)
        else:  
            return ", ".join(self.default_select_columns)
    
    def _build_from_clause(self, tbname_or_trows_or_sourcetable='sourcetable', is_period=False, is_sliding=False, partition_type='none'):
        """æ„å»º FROM å­å¥
        
        Args:
            tbname_or_trows_or_sourcetable: FROM å­å¥ç±»å‹
                - 'tbname': %%tbname where ts >= _twstart and ts <= _twend  
                - 'trows': %%trows
                - 'sourcetable': æ˜ç¡®æŒ‡å®šæºè¡¨å where ts >= _twstart and ts <= _twend
            is_period: æ˜¯å¦ä¸º period ç±»å‹çš„æµè®¡ç®—
            is_sliding: æ˜¯å¦ä¸º sliding ç±»å‹çš„æµè®¡ç®—
            partition_type: åˆ†åŒºç±»å‹ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
            
        Returns:
            str: FROM å­å¥å­—ç¬¦ä¸²
        """
        # æ ¹æ® partition_type ç¡®å®šæ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
        tag_filter = " and t0=%%1" if partition_type == 'tag' else ""
    
        if tbname_or_trows_or_sourcetable == 'trows':
            return "%%trows "
        elif tbname_or_trows_or_sourcetable == 'sourcetable':
            # è¿”å›å ä½ç¬¦ï¼Œåœ¨å…·ä½“æ¨¡æ¿ä¸­ä¼šè¢«æ›¿æ¢ä¸ºå®é™…çš„è¡¨å
            if is_sliding:
                return "SOURCE_TABLE_PLACEHOLDER where ts >= _tprev_ts and ts <= _tnext_ts"
            elif is_period:
                return "SOURCE_TABLE_PLACEHOLDER where ts >= cast(_tprev_localtime/1000000 as timestamp) and ts <= cast(_tnext_localtime/1000000 as timestamp)"
            else:
                return "SOURCE_TABLE_PLACEHOLDER where ts >= _twstart and ts <= _twend"
        else:  # 'tbname' and çº³ç§’
            if is_sliding:
                return f"%%tbname where ts >= _tprev_ts and ts <= _tnext_ts{tag_filter}"
            elif is_period:
                return f"%%tbname where ts >= cast(_tprev_localtime/1000000 as timestamp) and ts <= cast(_tnext_localtime/1000000 as timestamp){tag_filter}"
            else:
                return f"%%tbname where ts >= _twstart and ts <= _twend{tag_filter}"

    
    def _build_from_source_and_clause(self, source_type='stb', stream_index=None, tbname_or_trows_or_sourcetable='sourcetable', is_period=False, is_sliding=False, partition_type='none'):
        """æ„å»ºæ•°æ®æºå’ŒFROMå­å¥çš„ç»„åˆ
        
        Args:
            source_type: æ•°æ®æºç±»å‹ ('stb', 'tb')
            stream_index: æµçš„ç´¢å¼•ç¼–å·
            tbname_or_trows_or_sourcetable: FROMå­å¥ç±»å‹
            is_period: æ˜¯å¦ä¸º period ç±»å‹çš„æµè®¡ç®—
            is_sliding: æ˜¯å¦ä¸º sliding ç±»å‹çš„æµè®¡ç®—
            partition_type: åˆ†åŒºç±»å‹ï¼Œç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
                
        Returns:
            tuple: (from_source, from_clause)
        """
        from_source = self._build_from_source(source_type, stream_index)
        
    
        if tbname_or_trows_or_sourcetable == 'sourcetable':
            # å¯¹äºsourcetableæ¨¡å¼ï¼ŒFROMå­å¥ç›´æ¥ä½¿ç”¨å…·ä½“çš„è¡¨å
            
            # æ ¹æ® partition_type ç¡®å®šæ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
            tag_filter = " and t0=%%1" if partition_type == 'tag' else ""
            
            if source_type == 'tb':
                # å­è¡¨æƒ…å†µï¼šä½¿ç”¨å…·ä½“çš„å­è¡¨å
                if stream_index is not None:
                    table_name = f"stream_from.ctb0_{stream_index}"
                else:
                    table_name = "stream_from.ctb0_0"
            else:  # 'stb'
                # è¶…çº§è¡¨æƒ…å†µï¼šä½¿ç”¨è¶…çº§è¡¨å
                table_name = "stream_from.stb"
                
            # period ç±»å‹ä½¿ç”¨ä¸åŒçš„æ—¶é—´å˜é‡
            if is_sliding:
                from_clause = f"{table_name} where ts >= _tprev_ts and ts <= _tnext_ts{tag_filter}"
            elif is_period:
                from_clause = f"{table_name} where ts >= cast(_tprev_localtime/1000000 as timestamp) and ts <= cast(_tnext_localtime/1000000 as timestamp){tag_filter}"
            else:
                from_clause = f"{table_name} where ts >= _twstart and ts <= _twend{tag_filter}"
        else:
            # å…¶ä»–æ¨¡å¼ä½¿ç”¨åŸæœ‰é€»è¾‘
            from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable, is_period, is_sliding)
            
        return from_source, from_clause        
    
    def _build_partition_clause(self, partition_type='none'):
        """æ„å»ºåˆ†åŒºå­å¥
        
        Args:
            partition_type: åˆ†åŒºç±»å‹
                - 'none': ä¸åˆ†ç»„
                - 'tbname': æŒ‰å­è¡¨ååˆ†ç»„  
                - 'tag': æŒ‰tagåˆ†ç»„
                
        Returns:
            str: åˆ†åŒºå­å¥å­—ç¬¦ä¸²
        """
        if partition_type == 'tbname':
            return "partition by tbname"
        elif partition_type == 'tag':
            return "partition by t0"  # å‡è®¾ç¬¬ä¸€ä¸ªtagå­—æ®µåä¸ºt0
        else:  # 'none'
            return ""
    
    def _build_from_source(self, source_type='stb', stream_index=None):
        """æ„å»ºæ•°æ®æº
        
        Args:
            source_type: æ•°æ®æºç±»å‹
                - 'stb': è¶…çº§è¡¨ stream_from.stb
                - 'tb': å­è¡¨ stream_from.ctb0_X
            stream_index: æµçš„ç´¢å¼•ç¼–å·ï¼ˆç”¨äºå¤šæµæ—¶é€‰æ‹©ä¸åŒå­è¡¨ï¼‰
                
        Returns:
            str: æ•°æ®æºå­—ç¬¦ä¸²
        """
        if source_type == 'tb':
            # å¦‚æœæœ‰æµç´¢å¼•ï¼Œä½¿ç”¨å¯¹åº”çš„å­è¡¨ï¼›å¦åˆ™ä½¿ç”¨é»˜è®¤çš„ctb0_0
            if stream_index is not None:
                # å­è¡¨ç¼–å·ä»1å¼€å§‹
                table_index = stream_index 
                #print(f"è°ƒè¯•: ç”Ÿæˆå­è¡¨å stream_from.ctb0_{table_index}")
                return f"stream_from.ctb0_{table_index}"
            else:
                #print(f"è°ƒè¯•: ä½¿ç”¨é»˜è®¤å­è¡¨ stream_from.ctb0_0")
                return "stream_from.ctb0_0"  # é»˜è®¤å­è¡¨
        else:  # 'stb'
            return "stream_from.stb"
    
    def _generate_stream_name(self, base_type, source_type, partition_type, agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', stream_index=None):
        """ç”Ÿæˆæµåç§°
        
        Args:
            base_type: åŸºç¡€ç±»å‹ (å¦‚ 's2_7', 'intervalsliding')
            source_type: æ•°æ®æºç±»å‹ ('stb', 'tb') 
            partition_type: åˆ†åŒºç±»å‹ ('none', 'tbname', 'tag')
            agg_or_select: æŸ¥è¯¢ç±»å‹ ('agg', 'select')
            tbname_or_trows_or_sourcetable: FROMå­å¥ç±»å‹ ('tbname', 'trows', 'sourcetable')
            stream_index: æµç´¢å¼•ç¼–å·ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: ç”Ÿæˆçš„æµåç§°
        """
        # æ„å»ºåç§°ç»„ä»¶
        source_part = "stb" if source_type == "stb" else "tb"
        
        if partition_type == 'none':
            partition_part = ""
        elif partition_type == 'tbname':
            partition_part = "_partition_by_tbname" 
        elif partition_type == 'tag':
            partition_part = "_partition_by_tag"
        else:
            partition_part = ""
            
        # æŸ¥è¯¢ç±»å‹éƒ¨åˆ†
        query_part = f"_{agg_or_select}"
        
        # FROMå­å¥ç±»å‹éƒ¨åˆ†
        if tbname_or_trows_or_sourcetable == 'sourcetable':
            if source_type == 'stb':
                # è¶…çº§è¡¨æƒ…å†µï¼šåŠ ä¸Š stb åç¼€
                from_part = "_sourcetable_stb"
            else:  # 'tb'
                # å­è¡¨æƒ…å†µï¼šåŠ ä¸Šå…·ä½“çš„å­è¡¨å
                if stream_index is not None:
                    from_part = f"_sourcetable_ctb0_{stream_index}"
                else:
                    from_part = "_sourcetable_ctb0_0"
        else:
            from_part = f"_{tbname_or_trows_or_sourcetable}"
        
        # åŸºç¡€åç§°ç»„åˆ
        stream_name = f"stream_from.{base_type}_{source_part}{partition_part}{query_part}{from_part}"
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œæ·»åŠ åˆ°æœ«å°¾
        if stream_index is not None and not (tbname_or_trows_or_sourcetable == 'sourcetable' and source_type == 'tb'):
            stream_name += f"_{stream_index}"
            
        return stream_name
    
    def _generate_target_table(self, base_type, source_type, partition_type, agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', stream_index=None):
        """ç”Ÿæˆç›®æ ‡è¡¨åç§°"""
        source_part = "stb" if source_type == "stb" else "tb"
        
        if partition_type == 'none':
            partition_part = ""
        elif partition_type == 'tbname':
            partition_part = "_partition_by_tbname"
        elif partition_type == 'tag':
            partition_part = "_partition_by_tag"
        else:
            partition_part = ""
        
        # æŸ¥è¯¢ç±»å‹éƒ¨åˆ†
        query_part = f"_{agg_or_select}"
        
        # FROMå­å¥ç±»å‹éƒ¨åˆ†
        if tbname_or_trows_or_sourcetable == 'sourcetable':
            if source_type == 'stb':
                # è¶…çº§è¡¨æƒ…å†µï¼šåŠ ä¸Š stb åç¼€
                from_part = "_sourcetable_stb"
            else:  # 'tb'
                # å­è¡¨æƒ…å†µï¼šåŠ ä¸Šå…·ä½“çš„å­è¡¨å
                if stream_index is not None:
                    from_part = f"_sourcetable_ctb0_{stream_index}"
                else:
                    from_part = "_sourcetable_ctb0_0"
        else:
            from_part = f"_{tbname_or_trows_or_sourcetable}"
        
        # åŸºç¡€åç§°ç»„åˆ
        target_table = f"stream_to.{base_type}_{source_part}{partition_part}{query_part}{from_part}"
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œæ·»åŠ åˆ°æœ«å°¾
        if stream_index is not None and not (tbname_or_trows_or_sourcetable == 'sourcetable' and source_type == 'tb'):
            target_table += f"_{stream_index}"
            
        return target_table
    
        
    # ========== é€šç”¨æ¨¡æ¿ç”Ÿæˆæ–¹æ³• ==========
    def get_intervalsliding_template(self, source_type='stb', partition_type='tbname', 
                           agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆæ»‘åŠ¨çª—å£æ¨¡æ¿
        
        Args:
            source_type: 'stb'(è¶…çº§è¡¨) æˆ– 'tb'(å­è¡¨)
            partition_type: 'none'(ä¸åˆ†ç»„), 'tbname'(æŒ‰å­è¡¨å), 'tag'(æŒ‰tag)
            agg_or_select: 'agg' æˆ– 'select'
            tbname_or_trows_or_sourcetable: 'tbname' æˆ– 'trows' æˆ– 'sourcetable'
            custom_columns: è‡ªå®šä¹‰åˆ—
        """
        columns = self._build_columns(agg_or_select, custom_columns)
        from_source, from_clause = self._build_from_source_and_clause(source_type, stream_index, tbname_or_trows_or_sourcetable, is_period=False, is_sliding=False, partition_type=partition_type)
        partition_clause = self._build_partition_clause(partition_type)
        
        stream_name = self._generate_stream_name('intervalsliding', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('intervalsliding', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        # æ„å»ºå®Œæ•´çš„SQL
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        return f"""
    create stream {stream_name} INTERVAL(15s) SLIDING(15s)
            from {from_source}{partition_line}
            into {target_table}
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_session_template(self, source_type='stb', partition_type='tbname',
                           agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆä¼šè¯çª—å£æ¨¡æ¿"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_source, from_clause = self._build_from_source_and_clause(source_type, stream_index, tbname_or_trows_or_sourcetable, is_period=False, is_sliding=False, partition_type=partition_type)
        partition_clause = self._build_partition_clause(partition_type)
         
        stream_name = self._generate_stream_name('session', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('session', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        return f"""
    create stream {stream_name} session(ts,10a)
            from {from_source}{partition_line}
            into {target_table}
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_count_template(self, source_type='stb', partition_type='tbname',
                         agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆè®¡æ•°çª—å£æ¨¡æ¿"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_source, from_clause = self._build_from_source_and_clause(source_type, stream_index, tbname_or_trows_or_sourcetable, is_period=False, is_sliding=False, partition_type=partition_type)
        partition_clause = self._build_partition_clause(partition_type)
        
        stream_name = self._generate_stream_name('count', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('count', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        return f"""
    create stream {stream_name} COUNT_WINDOW(1000)
            from {from_source}{partition_line}
            into {target_table}
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_event_template(self, source_type='stb', partition_type='tbname',
                         agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆäº‹ä»¶çª—å£æ¨¡æ¿"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_source, from_clause = self._build_from_source_and_clause(source_type, stream_index, tbname_or_trows_or_sourcetable, is_period=False, is_sliding=False, partition_type=partition_type)
        partition_clause = self._build_partition_clause(partition_type)
        
        stream_name = self._generate_stream_name('event', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('event', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        return f"""
    create stream {stream_name} EVENT_WINDOW(START WITH c0 > 5 END WITH c0 < 5)
            from {from_source}{partition_line}
            into {target_table}
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_state_template(self, source_type='stb', partition_type='tbname',
                         agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”ŸæˆçŠ¶æ€çª—å£æ¨¡æ¿"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_source, from_clause = self._build_from_source_and_clause(source_type, stream_index, tbname_or_trows_or_sourcetable, is_period=False, is_sliding=False, partition_type=partition_type)
        partition_clause = self._build_partition_clause(partition_type)
         
        stream_name = self._generate_stream_name('state', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('state', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        return f"""
    create stream {stream_name} STATE_WINDOW(c0)
            from {from_source}{partition_line}
            into {target_table}
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_period_template(self, source_type='stb', partition_type='tbname',
                          agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆå®šæ—¶è§¦å‘æ¨¡æ¿ """
        columns = self._build_columns(agg_or_select, custom_columns)
        partition_clause = self._build_partition_clause(partition_type)
        
        # period ç±»å‹ç‰¹æ®Šå¤„ç†ï¼šä½¿ç”¨ä¸“é—¨çš„æ—¶é—´å˜é‡
        from_source = self._build_from_source(source_type, stream_index)
        # æ ¹æ® partition_type ç¡®å®šæ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
        tag_filter = " and t0=%%1" if partition_type == 'tag' else ""
    
        
        # period ç±»å‹çš„ FROM å­å¥å¤„ç†
        if tbname_or_trows_or_sourcetable == 'trows':
            # period + trows çš„ç»„åˆï¼šç›´æ¥ä½¿ç”¨ %%trowsï¼ˆä¸æ”¯æŒæ—¶é—´æ¡ä»¶ï¼‰
            from_clause = "%%trows"
        elif tbname_or_trows_or_sourcetable == 'sourcetable':
            # period + sourcetableï¼šä½¿ç”¨å…·ä½“è¡¨å + period ä¸“ç”¨æ—¶é—´å˜é‡
        
            if source_type == 'tb':
                if stream_index is not None:
                    table_name = f"stream_from.ctb0_{stream_index}"
                else:
                    table_name = "stream_from.ctb0_0"
            else:  # 'stb'
                table_name = "stream_from.stb"
            from_clause = f"{table_name} where ts >= cast(_tprev_localtime/1000000 as timestamp) and ts <= cast(_tnext_localtime/1000000 as timestamp){tag_filter}"
        else:  # 'tbname'
            # period + tbnameï¼šä½¿ç”¨ %%tbname + period ä¸“ç”¨æ—¶é—´å˜é‡
            from_clause = f"%%tbname where ts >= cast(_tprev_localtime/1000000 as timestamp) and ts <= cast(_tnext_localtime/1000000 as timestamp){tag_filter}"
         
        stream_name = self._generate_stream_name('period', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('period', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        # å¦‚æœæœ‰æµç´¢å¼•ï¼Œåœ¨æµåç§°å’Œç›®æ ‡è¡¨ä¸­æ·»åŠ ç´¢å¼•
        if stream_index is not None:
            stream_name += f"_{stream_index}"
            target_table += f"_{stream_index}"
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        #select cast(_tlocaltime/1000000 as timestamp) ts --> select cast(_tprev_localtime/1000000 as timestamp) ts
        return f"""
    create stream {stream_name} period(15s)
            from {from_source}{partition_line}
            into {target_table}
            as select cast(_tprev_localtime/1000000 as timestamp) ts, {columns}
            from {from_clause};
    """


    def get_sliding_template(self, source_type='stb', partition_type='tbname',
                           agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None, stream_index=None):
        """ç”Ÿæˆ sliding çª—å£æ¨¡æ¿ - æ–°å¢çª—å£ç±»å‹"""
        columns = self._build_columns(agg_or_select, custom_columns)
        partition_clause = self._build_partition_clause(partition_type)
        
        # sliding ç±»å‹ç‰¹æ®Šå¤„ç†ï¼šä½¿ç”¨ä¸“é—¨çš„æ—¶é—´å˜é‡
        from_source = self._build_from_source(source_type, stream_index)
        # æ ¹æ® partition_type ç¡®å®šæ˜¯å¦éœ€è¦æ·»åŠ  tag è¿‡æ»¤æ¡ä»¶
        tag_filter = " and t0=%%1" if partition_type == 'tag' else ""
    
        
        # sliding ç±»å‹çš„ FROM å­å¥å¤„ç†
        if tbname_or_trows_or_sourcetable == 'trows':
            # sliding + trows çš„ç»„åˆï¼šç›´æ¥ä½¿ç”¨ %%trowsï¼ˆä¸æ”¯æŒæ—¶é—´æ¡ä»¶ï¼‰
            from_clause = "%%trows"
        elif tbname_or_trows_or_sourcetable == 'sourcetable':
            # sliding + sourcetableï¼šä½¿ç”¨å…·ä½“è¡¨å + sliding ä¸“ç”¨æ—¶é—´å˜é‡
            if source_type == 'tb':
                if stream_index is not None:
                    table_name = f"stream_from.ctb0_{stream_index}"
                else:
                    table_name = "stream_from.ctb0_0"
            else:  # 'stb'
                table_name = "stream_from.stb"
            from_clause = f"{table_name} where ts >= _tprev_ts and ts <= _tnext_ts{tag_filter}"
        else:  # 'tbname'
            # sliding + tbnameï¼šä½¿ç”¨ %%tbname + sliding ä¸“ç”¨æ—¶é—´å˜é‡
            from_clause = f"%%tbname where ts >= _tprev_ts and ts <= _tnext_ts{tag_filter}"
         
        stream_name = self._generate_stream_name('sliding', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        target_table = self._generate_target_table('sliding', source_type, partition_type, agg_or_select, tbname_or_trows_or_sourcetable, stream_index)
        
        partition_line = f"\n            {partition_clause}" if partition_clause else ""
        
        #select _tcurrent_ts ts, --> select _tprev_ts ts,
        return f"""
    create stream {stream_name} sliding(15s)
            from {from_source}{partition_line}
            into {target_table}
            as select _tprev_ts ts, {columns}
            from {from_clause};
    """
       
    # ========== ç»„åˆç”Ÿæˆæ–¹æ³• ==========
    def get_intervalsliding_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„æ»‘åŠ¨çª—å£ç»„åˆ (4ç§ç»„åˆ)"""
        return {
            'intervalsliding_stb': self.get_intervalsliding_template(source_type='stb', partition_type='none', **kwargs),
            'intervalsliding_stb_partition_by_tbname': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **kwargs),
            'intervalsliding_stb_partition_by_tag': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **kwargs),
            'intervalsliding_tb': self.get_intervalsliding_template(source_type='tb', partition_type='none', **kwargs)
        }

    def get_sliding_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„ sliding çª—å£ç»„åˆ"""
        return {
            'sliding_stb': self.get_sliding_template(source_type='stb', partition_type='none', **kwargs),
            'sliding_stb_partition_by_tbname': self.get_sliding_template(source_type='stb', partition_type='tbname', **kwargs),
            'sliding_stb_partition_by_tag': self.get_sliding_template(source_type='stb', partition_type='tag', **kwargs),
            'sliding_tb': self.get_sliding_template(source_type='tb', partition_type='none', **kwargs)
        }
            
    def get_session_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„ä¼šè¯çª—å£ç»„åˆ"""
        return {
            'session_stb': self.get_session_template(source_type='stb', partition_type='none', **kwargs),
            'session_stb_partition_by_tbname': self.get_session_template(source_type='stb', partition_type='tbname', **kwargs),
            'session_stb_partition_by_tag': self.get_session_template(source_type='stb', partition_type='tag', **kwargs),
            'session_tb': self.get_session_template(source_type='tb', partition_type='none', **kwargs)
        }
    
    def get_count_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„è®¡æ•°çª—å£ç»„åˆ"""
        return {
            'count_stb': self.get_count_template(source_type='stb', partition_type='none', **kwargs),
            'count_stb_partition_by_tbname': self.get_count_template(source_type='stb', partition_type='tbname', **kwargs),
            'count_stb_partition_by_tag': self.get_count_template(source_type='stb', partition_type='tag', **kwargs),
            'count_tb': self.get_count_template(source_type='tb', partition_type='none', **kwargs)
        }
    
    def get_event_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„äº‹ä»¶çª—å£ç»„åˆ"""
        return {
            'event_stb': self.get_event_template(source_type='stb', partition_type='none', **kwargs),
            'event_stb_partition_by_tbname': self.get_event_template(source_type='stb', partition_type='tbname', **kwargs),
            'event_stb_partition_by_tag': self.get_event_template(source_type='stb', partition_type='tag', **kwargs),
            'event_tb': self.get_event_template(source_type='tb', partition_type='none', **kwargs)
        }
    
    def get_state_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„çŠ¶æ€çª—å£ç»„åˆ"""
        return {
            'state_stb': self.get_state_template(source_type='stb', partition_type='none', **kwargs),
            'state_stb_partition_by_tbname': self.get_state_template(source_type='stb', partition_type='tbname', **kwargs),
            'state_stb_partition_by_tag': self.get_state_template(source_type='stb', partition_type='tag', **kwargs),
            'state_tb': self.get_state_template(source_type='tb', partition_type='none', **kwargs)
        }
    
    def get_period_group_detailed(self, **kwargs):
        """è·å–è¯¦ç»†çš„å®šæ—¶è§¦å‘ç»„åˆ"""
        # period ä¸æ”¯æŒ tbname_or_trows_or_sourcetable å‚æ•°
        filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}
        return {
            'period_stb': self.get_period_template(source_type='stb', partition_type='none', **filtered_kwargs),
            'period_stb_partition_by_tbname': self.get_period_template(source_type='stb', partition_type='tbname', **filtered_kwargs),
            'period_stb_partition_by_tag': self.get_period_template(source_type='stb', partition_type='tag', **filtered_kwargs),
            'period_tb': self.get_period_template(source_type='tb', partition_type='none', **filtered_kwargs)
        }
        
    def get_tbname_agg_group(self, **kwargs):
        """è·å– tbname + agg ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='tbname', agg_or_select='agg'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'tbname',
            'agg_or_select': 'agg'
        })
        
        return {
            # intervalsliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_tbname_agg': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_agg': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_tbname_agg': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_agg': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_agg': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_agg': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                        
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_tbname_agg': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_agg': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_agg': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_agg': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_tbname_agg': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_agg': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_agg': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_agg': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_tbname_agg': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_agg': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_agg': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_agg': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_tbname_agg': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_agg': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_agg': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_agg': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ
            'period_stb_tbname_agg': self.get_period_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'period_stb_partition_by_tbname_agg': self.get_period_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'period_stb_partition_by_tag_agg': self.get_period_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'period_tb_agg': self.get_period_template(source_type='tb', partition_type='none', **fixed_kwargs),
        }

    def get_tbname_select_group(self, **kwargs):
        """è·å– tbname + select ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='tbname', agg_or_select='select'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'tbname',
            'agg_or_select': 'select'
        })
        
        return {
            # intervalslidingçª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_tbname_select': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_select': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_select': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_select': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_tbname_select': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_select': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_select': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_select': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                        
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_tbname_select': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_select': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_select': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_select': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_tbname_select': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_select': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_select': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_select': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_tbname_select': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_select': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_select': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_select': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_tbname_select': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_select': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_select': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_select': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ
            'period_stb_tbname_select': self.get_period_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'period_stb_partition_by_tbname_select': self.get_period_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'period_stb_partition_by_tag_select': self.get_period_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'period_tb_select': self.get_period_template(source_type='tb', partition_type='none', **fixed_kwargs),
        }

    def get_trows_agg_group(self, **kwargs):
        """è·å– trows + agg ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='trows', agg_or_select='agg'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'trows',
            'agg_or_select': 'agg'
        })
        
        return {
            # intervalsliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_trows_agg': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_trows_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_trows_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_trows_agg': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_trows_agg': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_trows_agg': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_trows_agg': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_trows_agg': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                     
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_trows_agg': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_trows_agg': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_trows_agg': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_trows_agg': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_trows_agg': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_trows_agg': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_trows_agg': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_trows_agg': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_trows_agg': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_trows_agg': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_trows_agg': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_trows_agg': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_trows_agg': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_trows_agg': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_trows_agg': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_trows_agg': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ (æ³¨æ„: periodä¸æ”¯æŒtrowsï¼Œæ‰€ä»¥è¿™é‡Œå®é™…ä¸Šä»ç„¶ä½¿ç”¨tbname)
            'period_stb_trows_agg': self.get_period_template(source_type='stb', partition_type='none', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_stb_partition_by_tbname_trows_agg': self.get_period_template(source_type='stb', partition_type='tbname', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_stb_partition_by_tag_trows_agg': self.get_period_template(source_type='stb', partition_type='tag', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_tb_trows_agg': self.get_period_template(source_type='tb', partition_type='none', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
        }

    def get_trows_select_group(self, **kwargs):
        """è·å– trows + select ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='trows', agg_or_select='select'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'trows',
            'agg_or_select': 'select'
        })
        
        return {
            # intervalsliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_trows_select': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_trows_select': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_trows_select': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_trows_select': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
             
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_trows_select': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_trows_select': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_trows_select': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_trows_select': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                       
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_trows_select': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_trows_select': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_trows_select': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_trows_select': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_trows_select': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_trows_select': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_trows_select': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_trows_select': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_trows_select': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_trows_select': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_trows_select': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_trows_select': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_trows_select': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_trows_select': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_trows_select': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_trows_select': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ (æ³¨æ„: periodä¸æ”¯æŒtrowsï¼Œæ‰€ä»¥è¿™é‡Œå®é™…ä¸Šä»ç„¶ä½¿ç”¨tbname)
            'period_stb_trows_select': self.get_period_template(source_type='stb', partition_type='none', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_stb_partition_by_tbname_trows_select': self.get_period_template(source_type='stb', partition_type='tbname', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_stb_partition_by_tag_trows_select': self.get_period_template(source_type='stb', partition_type='tag', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
            'period_tb_trows_select': self.get_period_template(source_type='tb', partition_type='none', **{k: v for k, v in fixed_kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}),
        }
        
    def get_sourcetable_agg_group(self, **kwargs):
        """è·å– sourcetable + agg ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='sourcetable', agg_or_select='agg'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'sourcetable',
            'agg_or_select': 'agg'
        })
        
        return {
            # intervalsliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_sourcetable_agg': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_sourcetable_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_sourcetable_agg': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_sourcetable_agg': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_sourcetable_agg': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_sourcetable_agg': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_sourcetable_agg': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_sourcetable_agg': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                        
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_sourcetable_agg': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_sourcetable_agg': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_sourcetable_agg': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_sourcetable_agg': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_sourcetable_agg': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_sourcetable_agg': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_sourcetable_agg': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_sourcetable_agg': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_sourcetable_agg': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_sourcetable_agg': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_sourcetable_agg': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_sourcetable_agg': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_sourcetable_agg': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_sourcetable_agg': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_sourcetable_agg': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_sourcetable_agg': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ (æ³¨æ„: periodæ”¯æŒsourcetable)
            'period_stb_sourcetable_agg': self.get_period_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'period_stb_partition_by_tbname_sourcetable_agg': self.get_period_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'period_stb_partition_by_tag_sourcetable_agg': self.get_period_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'period_tb_sourcetable_agg': self.get_period_template(source_type='tb', partition_type='none', **fixed_kwargs),
        }


    def get_sourcetable_select_group(self, **kwargs):
        """è·å– sourcetable + select ç»„åˆçš„æ‰€æœ‰çª—å£ç±»å‹
        
        å›ºå®šå‚æ•°: tbname_or_trows_or_sourcetable='sourcetable', agg_or_select='select'
        å¿½ç•¥å‘½ä»¤è¡Œä¼ å…¥çš„è¿™ä¸¤ä¸ªå‚æ•°
        """
        # å›ºå®šå‚æ•°ï¼Œå¿½ç•¥ä¼ å…¥çš„å‚æ•°
        fixed_kwargs = {k: v for k, v in kwargs.items() if k not in ['tbname_or_trows_or_sourcetable', 'agg_or_select']}
        fixed_kwargs.update({
            'tbname_or_trows_or_sourcetable': 'sourcetable',
            'agg_or_select': 'select'
        })
        
        return {
            # intervalsliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'intervalsliding_stb_sourcetable_select': self.get_intervalsliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tbname_sourcetable_select': self.get_intervalsliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'intervalsliding_stb_partition_by_tag_sourcetable_select': self.get_intervalsliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'intervalsliding_tb_sourcetable_select': self.get_intervalsliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # sliding çª—å£ - æ‰€æœ‰ç»„åˆ
            'sliding_stb_sourcetable_select': self.get_sliding_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'sliding_stb_partition_by_tbname_sourcetable_select': self.get_sliding_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'sliding_stb_partition_by_tag_sourcetable_select': self.get_sliding_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'sliding_tb_sourcetable_select': self.get_sliding_template(source_type='tb', partition_type='none', **fixed_kwargs),
                        
            # ä¼šè¯çª—å£ - æ‰€æœ‰ç»„åˆ
            'session_stb_sourcetable_select': self.get_session_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'session_stb_partition_by_tbname_sourcetable_select': self.get_session_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'session_stb_partition_by_tag_sourcetable_select': self.get_session_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'session_tb_sourcetable_select': self.get_session_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # è®¡æ•°çª—å£ - æ‰€æœ‰ç»„åˆ
            'count_stb_sourcetable_select': self.get_count_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'count_stb_partition_by_tbname_sourcetable_select': self.get_count_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'count_stb_partition_by_tag_sourcetable_select': self.get_count_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'count_tb_sourcetable_select': self.get_count_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # äº‹ä»¶çª—å£ - æ‰€æœ‰ç»„åˆ
            'event_stb_sourcetable_select': self.get_event_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'event_stb_partition_by_tbname_sourcetable_select': self.get_event_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'event_stb_partition_by_tag_sourcetable_select': self.get_event_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'event_tb_sourcetable_select': self.get_event_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # çŠ¶æ€çª—å£ - æ‰€æœ‰ç»„åˆ
            'state_stb_sourcetable_select': self.get_state_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'state_stb_partition_by_tbname_sourcetable_select': self.get_state_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'state_stb_partition_by_tag_sourcetable_select': self.get_state_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'state_tb_sourcetable_select': self.get_state_template(source_type='tb', partition_type='none', **fixed_kwargs),
            
            # å®šæ—¶è§¦å‘ - æ‰€æœ‰ç»„åˆ (æ³¨æ„: periodæ”¯æŒsourcetable)
            'period_stb_sourcetable_select': self.get_period_template(source_type='stb', partition_type='none', **fixed_kwargs),
            'period_stb_partition_by_tbname_sourcetable_select': self.get_period_template(source_type='stb', partition_type='tbname', **fixed_kwargs),
            'period_stb_partition_by_tag_sourcetable_select': self.get_period_template(source_type='stb', partition_type='tag', **fixed_kwargs),
            'period_tb_sourcetable_select': self.get_period_template(source_type='tb', partition_type='none', **fixed_kwargs),
        }

        
    def generate_multiple_streams(self, base_sql, stream_num=1):
        """æ ¹æ®åŸºç¡€SQLæ¨¡æ¿ç”Ÿæˆå¤šä¸ªç¼–å·çš„æµ
        
        Args:
            base_sql: åŸºç¡€SQLæ¨¡æ¿
            stream_num: è¦ç”Ÿæˆçš„æµæ•°é‡
            
        Returns:
            dict: åŒ…å«å¤šä¸ªæµSQLçš„å­—å…¸ï¼Œkeyä¸ºæµåç§°ï¼Œvalueä¸ºSQL
        """
        if stream_num <= 1:
            return {'stream_1': base_sql}
        
        result = {}
        
        if isinstance(base_sql, str):
            for i in range(1, stream_num + 1):
                modified_sql = self._modify_sql_for_multiple_streams(base_sql, i)
                result[f'stream_{i}'] = modified_sql
        else:
            # å¦‚æœéœ€è¦é‡æ–°ç”Ÿæˆï¼ˆç”¨äºæ”¯æŒä¸åŒå­è¡¨çš„æƒ…å†µï¼‰
            # è¿™ç§æƒ…å†µä¸‹base_sqlåº”è¯¥åŒ…å«ç”Ÿæˆå‡½æ•°å’Œå‚æ•°ä¿¡æ¯
            # æš‚æ—¶ä¿æŒåŸæœ‰é€»è¾‘ï¼Œè¿™ä¸ªåˆ†æ”¯ä¸»è¦ç”¨äºå‘åå…¼å®¹
            for i in range(1, stream_num + 1):
                modified_sql = self._modify_sql_for_multiple_streams(base_sql, i)
                result[f'stream_{i}'] = modified_sql
            
        return result

    def _modify_sql_for_multiple_streams(self, sql, stream_index):
        """ä¿®æ”¹SQLä»¥æ”¯æŒå¤šæµåˆ›å»º
        
        Args:
            sql: åŸå§‹SQL
            stream_index: æµç¼–å·
            
        Returns:
            str: ä¿®æ”¹åçš„SQL
        """
        import re
        
        # 1. ä¿®æ”¹æµåç§°ï¼Œæ·»åŠ ç¼–å·åç¼€
        # åŒ¹é… "create stream xxx" æ¨¡å¼
        sql = re.sub(
            r'(create\s+stream\s+)([^\s]+)',
            rf'\1\2_{stream_index}',
            sql,
            flags=re.IGNORECASE
        )
        
        # 2. ä¿®æ”¹ç›®æ ‡è¡¨åç§°ï¼Œæ·»åŠ ç¼–å·åç¼€
        # åŒ¹é… "into stream_to.xxx" æ¨¡å¼
        sql = re.sub(
            r'(into\s+)(stream_to\.)([^\s]+)',
            rf'\1\2\3_{stream_index}',
            sql,
            flags=re.IGNORECASE
        )
        
        return sql
        
    '''                    
    # ========== oldæµæ¨¡æ¿ï¼Œä»ç„¶æ”¯æŒï¼Œä½œä¸ºç¬¬ä¸€è½®çš„æ‘¸åº•æµ‹è¯•ï¼Œä½†ä¸æ¨èä½¿ç”¨äº†ï¼Œä½¿ç”¨ä¸Šé¢çš„å»ºæµæ¨¡ç‰ˆè¿›è¡Œç¬¬äºŒè½®æµ‹è¯• (s2_2 åˆ° s2_6) ==========
    def get_s2_2(self, agg_or_select='agg', custom_columns=None):
        """trigger at_once"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream s2_2 trigger at_once 
        ignore expired 0 ignore update 0 into stream_to.stb2_2 
        as select _wstart as wstart,
        {columns}
        from stream_from.stb partition by tbname interval(15s);
    """
    
    def get_s2_3(self, agg_or_select='agg', custom_columns=None):
        """trigger window_close"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream s2_3 trigger window_close 
        ignore expired 0 ignore update 0 into stream_to.stb2_3 
        as select _wstart as wstart,
        {columns}
        from stream_from.stb partition by tbname interval(15s);
    """
    
    def get_s2_4(self, agg_or_select='agg', custom_columns=None):
        """trigger max_delay 5s"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream s2_4 trigger max_delay 5s 
        ignore expired 0 ignore update 0 into stream_to.stb2_4 
        as select _wstart as wstart,
        {columns}
        from stream_from.stb partition by tbname interval(15s);
    """
    
    def get_s2_5(self, agg_or_select='agg', custom_columns=None):
        """trigger FORCE_WINDOW_CLOSE"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream s2_5 trigger FORCE_WINDOW_CLOSE into stream_to.stb2_5 
        as select _wstart as wstart,
        {columns}
        from stream_from.stb partition by tbname interval(15s);
    """
    
    def get_s2_6(self, agg_or_select='agg', custom_columns=None):
        """trigger CONTINUOUS_WINDOW_CLOSE"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream s2_6 trigger CONTINUOUS_WINDOW_CLOSE 
        ignore expired 0 ignore update 0 into stream_to.stb2_6 
        as select _wstart as wstart,
        {columns}
        from stream_from.stb partition by tbname interval(15s);
    """
    
    # ========== newæµæ¨¡æ¿ï¼Œä»ç„¶æ”¯æŒï¼Œä½œä¸ºç¬¬ä¸€è½®çš„æ‘¸åº•æµ‹è¯•ï¼Œä½†ä¸æ¨èä½¿ç”¨äº†ï¼Œä½¿ç”¨ä¸Šé¢çš„å»ºæµæ¨¡ç‰ˆè¿›è¡Œç¬¬äºŒè½®æµ‹è¯•  (s2_7 åˆ° s2_15) ==========
    def get_s2_7(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """INTERVAL(15s) çª—å£"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_7 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb 
            partition by tbname 
            into stream_to.stb2_7
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_8(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='trows', custom_columns=None):
        """INTERVAL with %%trows"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_8 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb 
            partition by tbname 
            into stream_to.stb2_8
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_9(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """INTERVAL with MAX_DELAY"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_9 INTERVAL(15s) SLIDING(15s)
            from stream_from.stb partition by tbname 
            STREAM_OPTIONS(MAX_DELAY(5s)) 
            into stream_to.stb2_9
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_10(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='trows', custom_columns=None):
        """INTERVAL with MAX_DELAY and %%trows"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_10 INTERVAL(15s) SLIDING(15s) 
            from stream_from.stb 
            STREAM_OPTIONS(MAX_DELAY(5s))
            into stream_to.stb2_10
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_11(self, agg_or_select='agg', custom_columns=None):
        """PERIOD(15s) å®šæ—¶è§¦å‘"""
        columns = self._build_columns(agg_or_select, custom_columns)
        return f"""
    create stream stream_from.s2_11 period(15s) 
            from stream_from.stb partition by tbname  
            into stream_to.stb2_11
            as select cast(_tlocaltime/1000000 as timestamp) ts, {columns}
            from %%tbname;
    """
    
    def get_s2_12(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """SESSION(ts,10a) ä¼šè¯çª—å£"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_12 session(ts,10a)
            from stream_from.stb partition by tbname 
            into stream_to.stb2_12
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_13(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """COUNT_WINDOW(1000) è®¡æ•°çª—å£"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_13 COUNT_WINDOW(1000)
            from stream_from.stb partition by tbname 
            into stream_to.stb2_13
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_14(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """EVENT_WINDOW äº‹ä»¶çª—å£"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_14 EVENT_WINDOW(START WITH c0 > 5 END WITH c0 < 5) 
            from stream_from.stb partition by tbname 
            into stream_to.stb2_14
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    def get_s2_15(self, agg_or_select='agg', tbname_or_trows_or_sourcetable='tbname', custom_columns=None):
        """STATE_WINDOW çŠ¶æ€çª—å£"""
        columns = self._build_columns(agg_or_select, custom_columns)
        from_clause = self._build_from_clause(tbname_or_trows_or_sourcetable)
        return f"""
    create stream stream_from.s2_15 STATE_WINDOW(c0) 
            from stream_from.stb partition by tbname 
            into stream_to.stb2_15
            as select _twstart ts, {columns}
            from {from_clause};
    """
    
    # ========== åˆ†ç»„å’Œæ‰¹é‡è·å–æ–¹æ³• ==========
    def get_intervalsliding_group(self, **kwargs):
        """è·å–æ»‘åŠ¨çª—å£ç»„ (s2_7, s2_8, s2_9, s2_10)"""
        return {
            's2_7': self.get_s2_7(**kwargs),
            's2_8': self.get_s2_8(**kwargs),
            's2_9': self.get_s2_9(**kwargs),
            's2_10': self.get_s2_10(**kwargs)
        }
    
    def get_count_group(self, **kwargs):
        """è·å–è®¡æ•°çª—å£ç»„ (s2_13)"""
        return {
            's2_13': self.get_s2_13(**kwargs)
        }
    
    def get_session_group(self, **kwargs):
        """è·å–ä¼šè¯çª—å£ç»„ (s2_12)"""
        return {
            's2_12': self.get_s2_12(**kwargs)
        }
    
    def get_period_group(self, **kwargs):
        """è·å–å®šæ—¶è§¦å‘ç»„ (s2_11)"""
        # period ç±»å‹ä¸æ”¯æŒ tbname_or_trows_or_sourcetable å‚æ•°
        filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}
        return {
            's2_11': self.get_s2_11(**filtered_kwargs)
        }
    
    def get_event_group(self, **kwargs):
        """è·å–äº‹ä»¶çª—å£ç»„ (s2_14)"""
        return {
            's2_14': self.get_s2_14(**kwargs)
        }
    
    def get_state_group(self, **kwargs):
        """è·å–çŠ¶æ€çª—å£ç»„ (s2_15)"""
        return {
            's2_15': self.get_s2_15(**kwargs)
        }
    
    def get_basic_group(self, **kwargs):
        """è·å–åŸºç¡€è§¦å‘ç»„ (s2_2 åˆ° s2_6)"""
        # åŸºç¡€ç»„ä¸æ”¯æŒ tbname_or_trows_or_sourcetable å‚æ•°
        filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}
        return {
            's2_2': self.get_s2_2(**filtered_kwargs),
            's2_3': self.get_s2_3(**filtered_kwargs),
            's2_4': self.get_s2_4(**filtered_kwargs),
            's2_5': self.get_s2_5(**filtered_kwargs),
            's2_6': self.get_s2_6(**filtered_kwargs)
        }
    
    def get_all_advanced(self, **kwargs):
        """è·å–æ‰€æœ‰é«˜çº§æµ (s2_7 åˆ° s2_15)"""
        result = {}
        result.update(self.get_intervalsliding_group(**kwargs))
        result.update(self.get_period_group(**kwargs))
        result.update(self.get_session_group(**kwargs))
        result.update(self.get_count_group(**kwargs))
        result.update(self.get_event_group(**kwargs))
        result.update(self.get_state_group(**kwargs))
        return result
    
    def get_all(self, **kwargs):
        """è·å–æ‰€æœ‰æµæ¨¡æ¿"""
        result = {}
        result.update(self.get_basic_group(**kwargs))
        result.update(self.get_all_advanced(**kwargs))
        return result
    
    # @classmethod
    # def get_sql_bak(cls, sql_type, **kwargs):
    #     """
    #     è·å–æŒ‡å®šç±»å‹çš„ SQL æ¨¡æ¿ - ä¸»è¦å…¥å£æ–¹æ³•
        
    #     Args:
    #         sql_type: SQL ç±»å‹æ ‡è¯†ç¬¦æˆ–åˆ†ç»„å
    #         **kwargs: å¯é€‰å‚æ•°
    #             - agg_or_select: 'agg'(é»˜è®¤) æˆ– 'select'ï¼Œæ§åˆ¶èšåˆè¿˜æ˜¯æŠ•å½±æŸ¥è¯¢
    #             - tbname_or_trows_or_sourcetable: 'tbname'(é»˜è®¤) æˆ– 'trows'ï¼Œæ§åˆ¶FROMå­å¥
    #             - custom_columns: è‡ªå®šä¹‰åˆ—ï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨è‡ªå®šä¹‰åˆ—
                
    #     Returns:
    #         str or dict: å•ä¸ªSQLå­—ç¬¦ä¸²æˆ–SQLå­—å…¸
            
    #     Usage Examples:
    #         # è·å–å•ä¸ªæ¨¡æ¿
    #         sql = StreamSQLTemplates.get_sql('s2_7')
            
    #         # ä½¿ç”¨æŠ•å½±æŸ¥è¯¢
    #         sql = StreamSQLTemplates.get_sql('s2_7', agg_or_select='select')
            
    #         # ä½¿ç”¨trows
    #         sql = StreamSQLTemplates.get_sql('s2_8', tbname_or_trows_or_sourcetable='trows')
            
    #         # è‡ªå®šä¹‰åˆ—
    #         sql = StreamSQLTemplates.get_sql('s2_7', custom_columns=['sum(c0)', 'count(*)'])
            
    #         # è·å–åˆ†ç»„
    #         sqls = StreamSQLTemplates.get_sql('intervalsliding')  # æ»‘åŠ¨çª—å£ç»„
    #         sqls = StreamSQLTemplates.get_sql('all')      # æ‰€æœ‰æ¨¡æ¿
    #     """
    #     instance = cls()
        
    #     # å•ä¸ªæ¨¡æ¿æ˜ å°„
    #     single_templates = {
    #         's2_2': instance.get_s2_2,
    #         's2_3': instance.get_s2_3,
    #         's2_4': instance.get_s2_4,
    #         's2_5': instance.get_s2_5,
    #         's2_6': instance.get_s2_6,
    #         's2_7': instance.get_s2_7,
    #         's2_8': instance.get_s2_8,
    #         's2_9': instance.get_s2_9,
    #         's2_10': instance.get_s2_10,
    #         's2_11': instance.get_s2_11,
    #         's2_12': instance.get_s2_12,
    #         's2_13': instance.get_s2_13,
    #         's2_14': instance.get_s2_14,
    #         's2_15': instance.get_s2_15,
    #     }
        
    #     # åˆ†ç»„æ¨¡æ¿æ˜ å°„
    #     group_templates = {
    #         'basic': instance.get_basic_group,
    #         'intervalsliding': instance.get_intervalsliding_group,
    #         'count': instance.get_count_group,
    #         'session': instance.get_session_group,
    #         'period': instance.get_period_group,
    #         'event': instance.get_event_group,
    #         'state': instance.get_state_group,
    #         'advanced': instance.get_all_advanced,
    #         'all': instance.get_all,
    #     }
        
    #     # å¤„ç†å•ä¸ªæ¨¡æ¿
    #     if sql_type in single_templates:
    #         method = single_templates[sql_type]
    #         # ä¸ºä¸åŒç±»å‹çš„æ¨¡æ¿è¿‡æ»¤å‚æ•°
    #         if sql_type in ['s2_2', 's2_3', 's2_4', 's2_5', 's2_6', 's2_11']:
    #             # åŸºç¡€æ¨¡æ¿å’Œperiodæ¨¡æ¿ä¸æ”¯æŒ tbname_or_trows_or_sourcetable
    #             filtered_kwargs = {k: v for k, v in kwargs.items() if k != 'tbname_or_trows_or_sourcetable'}
    #             return method(**filtered_kwargs)
    #         else:
    #             return method(**kwargs)
        
    #     # å¤„ç†åˆ†ç»„æ¨¡æ¿
    #     if sql_type in group_templates:
    #         return group_templates[sql_type](**kwargs)
        
    #     # é»˜è®¤è¿”å› s2_7
    #     print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¨¡æ¿ '{sql_type}'ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿ 's2_7'")
    #     return instance.get_s2_7(**kwargs)
    
    '''
    
    @classmethod
    def get_sql(cls, sql_type, stream_num=1, auto_combine=False, **kwargs):
        """
        è·å–æŒ‡å®šç±»å‹çš„ SQL æ¨¡æ¿ - ä¸»è¦å…¥å£æ–¹æ³•
        
        Args:
            sql_type: SQL ç±»å‹æ ‡è¯†ç¬¦æˆ–åˆ†ç»„å
                å•ä¸ªæ¨¡æ¿: 'intervalsliding_stb', 'intervalsliding_stb_partition_by_tbname' ç­‰
                ç»„åˆæ¨¡æ¿: 'intervalsliding_detailed', 'session_detailed' ç­‰
            stream_num: æµæ•°é‡ï¼ˆä»…å¯¹å•ä¸ªæµç±»å‹æœ‰æ•ˆï¼‰
            auto_combine: æ˜¯å¦è‡ªåŠ¨ç”Ÿæˆ6ç§å‚æ•°ç»„åˆ
            **kwargs: å¯é€‰å‚æ•°
                
        Returns:
            str or dict: å•ä¸ªSQLå­—ç¬¦ä¸²æˆ–SQLå­—å…¸
            
        Usage Examples:
            # è·å–å•ä¸ªè¯¦ç»†æ¨¡æ¿
            sql = StreamSQLTemplates.get_sql('intervalsliding_stb_partition_by_tbname')
            
            # è·å–è¯¦ç»†ç»„åˆ
            sqls = StreamSQLTemplates.get_sql('intervalsliding_detailed')
            
            # è·å–æ‰€æœ‰çª—å£ç±»å‹çš„è¯¦ç»†ç»„åˆ
            sqls = StreamSQLTemplates.get_sql('all_detailed')
        """
        instance = cls()
        
        # å¤„ç†ç‰¹æ®Šçš„æŸ¥è¯¢è¯­å¥
        if sql_type == 'select_stream':
            return instance.get_select_stream(**kwargs)
        
        if sql_type == 'tbname_agg':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_tbname_agg_group(**kwargs)
        elif sql_type == 'tbname_select':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_tbname_select_group(**kwargs)
        elif sql_type == 'trows_agg':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_trows_agg_group(**kwargs)
        elif sql_type == 'trows_select':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_trows_select_group(**kwargs)
        elif sql_type == 'sourcetable_agg':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_sourcetable_agg_group(**kwargs)
        elif sql_type == 'sourcetable_select':
            if stream_num > 1:
                print("è­¦å‘Š: å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --stream-num å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
            return instance.get_sourcetable_select_group(**kwargs)
        
        # å•ä¸ªè¯¦ç»†æ¨¡æ¿æ˜ å°„
        detailed_templates = {
            'intervalsliding_stb': lambda stream_index=None, **kw: instance.get_intervalsliding_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'intervalsliding_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_intervalsliding_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'intervalsliding_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_intervalsliding_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'intervalsliding_tb': lambda stream_index=None, **kw: instance.get_intervalsliding_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
            
            'sliding_stb': lambda stream_index=None, **kw: instance.get_sliding_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'sliding_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_sliding_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'sliding_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_sliding_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'sliding_tb': lambda stream_index=None, **kw: instance.get_sliding_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
                       
            'session_stb': lambda stream_index=None, **kw: instance.get_session_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'session_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_session_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'session_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_session_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'session_tb': lambda stream_index=None, **kw: instance.get_session_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
            
            'count_stb': lambda stream_index=None, **kw: instance.get_count_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'count_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_count_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'count_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_count_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'count_tb': lambda stream_index=None, **kw: instance.get_count_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
            
            'event_stb': lambda stream_index=None, **kw: instance.get_event_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'event_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_event_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'event_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_event_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'event_tb': lambda stream_index=None, **kw: instance.get_event_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
            
            'state_stb': lambda stream_index=None, **kw: instance.get_state_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'state_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_state_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'state_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_state_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'state_tb': lambda stream_index=None, **kw: instance.get_state_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
            
            'period_stb': lambda stream_index=None, **kw: instance.get_period_template(source_type='stb', partition_type='none', stream_index=stream_index, **kw),
            'period_stb_partition_by_tbname': lambda stream_index=None, **kw: instance.get_period_template(source_type='stb', partition_type='tbname', stream_index=stream_index, **kw),
            'period_stb_partition_by_tag': lambda stream_index=None, **kw: instance.get_period_template(source_type='stb', partition_type='tag', stream_index=stream_index, **kw),
            'period_tb': lambda stream_index=None, **kw: instance.get_period_template(source_type='tb', partition_type='none', stream_index=stream_index, **kw),
        }
        
        # ç»„åˆæ¨¡æ¿æ˜ å°„
        group_templates = {
            'intervalsliding_detailed': instance.get_intervalsliding_group_detailed,
            'sliding_detailed': instance.get_sliding_group_detailed, 
            'session_detailed': instance.get_session_group_detailed,
            'count_detailed': instance.get_count_group_detailed,
            'event_detailed': instance.get_event_group_detailed,
            'state_detailed': instance.get_state_group_detailed,
            'period_detailed': instance.get_period_group_detailed,
        }
        
        # å¤„ç†å•ä¸ªè¯¦ç»†æ¨¡æ¿æ—¶
        if sql_type in detailed_templates:
            # æ£€æŸ¥æ˜¯å¦å¯ç”¨è‡ªåŠ¨ç»„åˆ
            if auto_combine:
                print(f"è‡ªåŠ¨ç”Ÿæˆ {sql_type} çš„6ç§å‚æ•°ç»„åˆ (å¿½ç•¥ --agg-or-select å’Œ --tbname-or-trows-or-sourcetable å‚æ•°)")
                
                if stream_num > 1:
                    print("è­¦å‘Š: --auto-combine æ¨¡å¼ä¸‹ --stream-num å‚æ•°æ— æ•ˆï¼Œå°†å¿½ç•¥")
                
                # ç”Ÿæˆ6ç§ç»„åˆ
                combinations = [
                    ('tbname', 'agg'),
                    ('tbname', 'select'),
                    ('trows', 'agg'),
                    ('trows', 'select'),
                    ('sourcetable', 'agg'),
                    ('sourcetable', 'select')
                ]
                
                result = {}
                for tbname_param, agg_param in combinations:
                    # åˆ›å»ºå‚æ•°å‰¯æœ¬ï¼Œè¦†ç›–æŒ‡å®šå‚æ•°
                    combo_kwargs = kwargs.copy()
                    combo_kwargs['tbname_or_trows_or_sourcetable'] = tbname_param
                    combo_kwargs['agg_or_select'] = agg_param
                    
                    # ç”Ÿæˆç»„åˆåç§°
                    combo_name = f"{sql_type}_{agg_param}_{tbname_param}"
                    
                    # ç”ŸæˆSQL
                    combo_sql = detailed_templates[sql_type](**combo_kwargs)
                    result[combo_name] = combo_sql
                    
                    print(f"  ç”Ÿæˆç»„åˆ: {combo_name}")
                
                return result
                
            else:
                # åŸæœ‰é€»è¾‘ï¼šæ ¹æ® stream_num å¤„ç†
                if stream_num > 1:
                    print(f"ç”Ÿæˆ {stream_num} ä¸ª {sql_type} ç±»å‹çš„æµ")
                    result = {}
                    
                    for i in range(1, stream_num + 1):
                        stream_sql = detailed_templates[sql_type](stream_index=i, **kwargs)
                        result[f'stream_{i}'] = stream_sql
                        
                    return result
                else:
                    return detailed_templates[sql_type](**kwargs)
        
        # å¤„ç†ç»„åˆæ¨¡æ¿ï¼ˆæ”¯æŒ stream_numï¼‰ï¼ˆä¸å— auto_combine å½±å“ï¼‰
        if sql_type in group_templates:
            if auto_combine:
                print("è­¦å‘Š: ç»„åˆæ¨¡æ¿ä¸æ”¯æŒ --auto-combine å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
                
            base_sqls = group_templates[sql_type](**kwargs)
            
            # å¦‚æœstream_num > 1ï¼Œä¸ºæ¯ä¸ªç»„åˆä¸­çš„æ¯ä¸ªæµç”Ÿæˆå¤šä¸ªå‰¯æœ¬
            if stream_num > 1:
                print(f"ç”Ÿæˆ {sql_type} ç»„åˆï¼Œæ¯ç§æµç±»å‹åˆ›å»º {stream_num} ä¸ªæµ")
                result = {}
                
                for base_name, base_sql in base_sqls.items():
                    # ä¸ºæ¯ä¸ªåŸºç¡€æµç”Ÿæˆå¤šä¸ªç¼–å·å‰¯æœ¬
                    multiple_streams = instance.generate_multiple_streams(base_sql, stream_num)
                    
                    # é‡å‘½åé”®å€¼ä»¥é¿å…å†²çª
                    for stream_key, stream_sql in multiple_streams.items():
                        # ä¾‹å¦‚: intervalsliding_stb_1, intervalsliding_stb_2, intervalsliding_stb_partition_by_tbname_1, etc.
                        new_key = f"{base_name}_{stream_key.split('_')[-1]}"  # æå–ç¼–å·
                        result[new_key] = stream_sql
                
                return result
            else:
                return base_sqls
        
        # å¤„ç†ç‰¹æ®Šç»„åˆ
        if sql_type == 'all_detailed':
            if auto_combine:
                print("è­¦å‘Š: all_detailed æ¨¡æ¿ä¸æ”¯æŒ --auto-combine å‚æ•°ï¼Œå°†å¿½ç•¥è¯¥å‚æ•°")
                
            result = {}
            for group_type in ['intervalsliding_detailed', 'sliding_detailed', 'session_detailed', 'count_detailed', 
                            'event_detailed', 'state_detailed', 'period_detailed']:
                group_sqls = group_templates[group_type](**kwargs)
                
                # å¦‚æœstream_num > 1ï¼Œä¸ºæ¯ä¸ªæµç”Ÿæˆå¤šä¸ªå‰¯æœ¬
                if stream_num > 1:
                    for base_name, base_sql in group_sqls.items():
                        multiple_streams = instance.generate_multiple_streams(base_sql, stream_num)
                        
                        for stream_key, stream_sql in multiple_streams.items():
                            new_key = f"{base_name}_{stream_key.split('_')[-1]}"
                            result[new_key] = stream_sql
                else:
                    result.update(group_sqls)
                    
            if stream_num > 1:
                print(f"ç”Ÿæˆ all_detailed ç»„åˆï¼Œæ¯ç§æµç±»å‹åˆ›å»º {stream_num} ä¸ªæµ")
                
            return result
        
        # é»˜è®¤è¿”å› select_stream
        print(f"è­¦å‘Š: æœªæ‰¾åˆ°æ¨¡æ¿ '{sql_type}'ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿ 'select_stream'")
        return instance.get_select_stream(**kwargs)

            
def format_delay_time(delay_ms):
    """å°†å»¶è¿Ÿæ¯«ç§’æ•°æ ¼å¼åŒ–ä¸ºæ˜“è¯»çš„æ—¶é—´æ ¼å¼
    
    Args:
        delay_ms: å»¶è¿Ÿæ¯«ç§’æ•°
        
    Returns:
        str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²
    """
    if delay_ms is None:
        return "N/A"
    
    if delay_ms < 1000:  # å°äº1ç§’ï¼Œæ˜¾ç¤ºæ¯«ç§’
        return f"{delay_ms}ms"
    elif delay_ms < 60000:  # å°äº1åˆ†é’Ÿï¼Œæ˜¾ç¤ºç§’
        seconds = delay_ms / 1000.0
        return f"{seconds:.1f}s"
    elif delay_ms < 3600000:  # å°äº1å°æ—¶ï¼Œæ˜¾ç¤ºåˆ†é’Ÿå’Œç§’
        minutes = delay_ms // 60000
        seconds = (delay_ms % 60000) / 1000.0
        if seconds >= 1:
            return f"{minutes}m{seconds:.1f}s"
        else:
            return f"{minutes}m"
    else:  # 1å°æ—¶ä»¥ä¸Šï¼Œæ˜¾ç¤ºå°æ—¶ã€åˆ†é’Ÿã€ç§’
        hours = delay_ms // 3600000
        minutes = (delay_ms % 3600000) // 60000
        seconds = (delay_ms % 60000) / 1000.0
        
        parts = [f"{hours}h"]
        if minutes > 0:
            parts.append(f"{minutes}m")
        if seconds >= 1:
            parts.append(f"{seconds:.1f}s")
        
        return "".join(parts)
    
def extract_stream_creation_error(error_message):
    """ä»æµåˆ›å»ºé”™è¯¯ä¿¡æ¯ä¸­æå–TDengineçš„å…·ä½“é”™è¯¯
    
    Args:
        error_message: å®Œæ•´çš„å¼‚å¸¸é”™è¯¯ä¿¡æ¯
        
    Returns:
        str: æå–çš„TDengineé”™è¯¯ä¿¡æ¯
    """
    #print(f"è°ƒè¯• extract_stream_creation_error: è¾“å…¥å‚æ•°ç±»å‹={type(error_message)}, é•¿åº¦={len(str(error_message))}")
    
    try:
        # ç®€å•å¤„ç†ï¼šç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯ï¼ŒåªåšåŸºæœ¬æ¸…ç†
        if not error_message:
            print(f"è°ƒè¯•: é”™è¯¯ä¿¡æ¯ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯")
            return ""
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²
        error_str = str(error_message).strip()
        #print(f"è°ƒè¯•: è½¬æ¢åå­—ç¬¦ä¸²é•¿åº¦: {len(error_str)}")
        
    
        if not error_str:
            print(f"è°ƒè¯•: è½¬æ¢åå­—ç¬¦ä¸²ä¸ºç©ºï¼Œè¿”å›é»˜è®¤æ¶ˆæ¯")
            return "é”™è¯¯ä¿¡æ¯ä¸ºç©º"
        
        # å¦‚æœå¤ªé•¿å°±æˆªæ–­
        if len(error_str) > 500:
            error_str = error_str[:500] + "..."
        
        # æ¸…ç†æ¢è¡Œç¬¦ï¼Œä¿æŒå•è¡Œæ˜¾ç¤º
        error_str = error_str.replace('\n', ' ').replace('\r', ' ')
        
        # æ¸…ç†HTMLç‰¹æ®Šå­—ç¬¦
        error_str = error_str.replace('<', '&lt;').replace('>', '&gt;')
        
        return error_str
        
    except Exception as e:
        return f"é”™è¯¯ä¿¡æ¯å¤„ç†å¤±è´¥: {str(e)}"

  
def extract_tdengine_error(error_message):
    """ä»é”™è¯¯ä¿¡æ¯ä¸­æå–TDengineçš„å…·ä½“é”™è¯¯
    
    Args:
        error_message: å®Œæ•´çš„é”™è¯¯ä¿¡æ¯
        
    Returns:
        str: æå–çš„TDengineé”™è¯¯ä¿¡æ¯
    """
    try:
        # ç®€åŒ–å¤„ç†ï¼šç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯ï¼ŒåªåšåŸºæœ¬çš„é•¿åº¦æ§åˆ¶
        if not error_message:
            return ""
        
        # è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼ˆé˜²æ­¢ä¼ å…¥éå­—ç¬¦ä¸²ç±»å‹ï¼‰
        error_str = str(error_message).strip()
        #print(f"è°ƒè¯•: è½¬æ¢åå­—ç¬¦ä¸²é•¿åº¦: {len(error_str)}")
        print(f"è°ƒè¯•: åŸå§‹é”™è¯¯ä¿¡æ¯å‰300ä¸ªå­—ç¬¦: {error_str[:300]}")
        
        # å¦‚æœé”™è¯¯ä¿¡æ¯å¤ªé•¿ï¼Œæˆªæ–­åˆ°åˆç†é•¿åº¦
        max_length = 500
        if len(error_str) > max_length:
            error_str = error_str[:max_length] + "..."
        
        # æ¸…ç†ä¸€äº›å¯èƒ½å½±å“HTMLæ˜¾ç¤ºçš„å­—ç¬¦
        error_str = error_str.replace('<', '&lt;').replace('>', '&gt;')
        error_str = error_str.replace('\n', ' ').replace('\r', ' ')
        print(f"è°ƒè¯•: æ¸…ç†åé”™è¯¯ä¿¡æ¯é•¿åº¦: {len(error_str)}")
        print(f"è°ƒè¯•: æœ€ç»ˆè¿”å›çš„é”™è¯¯ä¿¡æ¯: {error_str[:200]}...")
        
        return error_str
        
    except Exception as e:
        # å¦‚æœå¤„ç†å‡ºé”™ï¼Œè¿”å›ç®€å•çš„é”™è¯¯ä¿¡æ¯
        return f"é”™è¯¯ä¿¡æ¯å¤„ç†å¤±è´¥: {str(e)}"
    

def format_sql_for_display(sql_text):
    """æ ¼å¼åŒ–SQLç”¨äºæ˜¾ç¤ºï¼Œå»æ‰å¤šä½™çš„ç©ºç™½å’Œæ¢è¡Œ
    
    Args:
        sql_text: åŸå§‹SQLæ–‡æœ¬
        
    Returns:
        str: æ ¼å¼åŒ–åçš„SQL
    """
    try:
        import re
        
        # 1. å»æ‰å‰åçš„ç©ºç™½
        sql = sql_text.strip()
        
        # 2. å°†å¤šä¸ªè¿ç»­çš„ç©ºç™½å­—ç¬¦ï¼ˆåŒ…æ‹¬æ¢è¡Œã€åˆ¶è¡¨ç¬¦ã€ç©ºæ ¼ï¼‰æ›¿æ¢ä¸ºå•ä¸ªç©ºæ ¼
        sql = re.sub(r'\s+', ' ', sql)
        
        # 3. åœ¨ä¸»è¦çš„SQLå…³é”®å­—å‰åæ·»åŠ é€‚å½“çš„æ¢è¡Œï¼Œä½¿ç»“æ„æ›´æ¸…æ™°
        # ä½†ä¿æŒæ•´ä½“ç´§å‡‘
        keywords = [
            'create stream', 'from', 'partition by', 'into', 'as select', 
            'where', 'interval\\(', 'sliding\\(', 'session\\(', 'period\\(', 
            'count_window\\(', 'event_window\\(', 'state_window\\('
        ]
        
        for keyword in keywords:
            # åœ¨å…³é”®å­—å‰æ·»åŠ æ¢è¡Œï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªcreate streamï¼‰
            if keyword != 'create stream':
                sql = re.sub(f'\\s+({keyword})', r' \1', sql, flags=re.IGNORECASE)
        
        # 4. ç‰¹æ®Šå¤„ç†ï¼šåœ¨ä¸»è¦å­å¥ä¹‹é—´æ·»åŠ åˆ†éš”
        # ä½†ä¸æ·»åŠ å®é™…æ¢è¡Œï¼Œè€Œæ˜¯ç”¨ | ç¬¦å·åˆ†éš”å¢å¼ºå¯è¯»æ€§
        sql = re.sub(r'\s+(from\s+)', r' | \1', sql, flags=re.IGNORECASE)
        sql = re.sub(r'\s+(partition\s+by)', r' | \1', sql, flags=re.IGNORECASE)
        sql = re.sub(r'\s+(into\s+)', r' | \1', sql, flags=re.IGNORECASE)
        sql = re.sub(r'\s+(as\s+select)', r' | \1', sql, flags=re.IGNORECASE)
        
        return sql
        
    except Exception as e:
        # å¦‚æœæ ¼å¼åŒ–å‡ºé”™ï¼Œè¿”å›ç®€å•æ¸…ç†åçš„ç‰ˆæœ¬
        return ' '.join(sql_text.split())



class StreamBatchTester:
    """æµè®¡ç®—æ‰¹é‡æµ‹è¯•å™¨ - è‡ªåŠ¨æ‰§è¡Œå¤šç§å‚æ•°ç»„åˆæµ‹è¯•"""
    
    def __init__(self, base_args=None, specified_sql_types=None, filter_mode='all', single_template_mode='default', perf_node='dnode1'):
        """åˆå§‹åŒ–æ‰¹é‡æµ‹è¯•å™¨
        
        Args:
            base_args: åŸºç¡€å‚æ•°å­—å…¸ï¼ŒåŒ…å«ä¸å˜çš„å‚æ•°
            specified_sql_types: æŒ‡å®šçš„SQLç±»å‹åˆ—è¡¨ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤çš„å…¨éƒ¨ç»„åˆ
            filter_mode: è¿‡æ»¤æ¨¡å¼ ('all', 'skip-known-failures', 'only-known-failures', 'skip-known-case')
        """
        self.base_args = base_args or {}
        self.test_results = []
        self.failed_tests = []
        self.current_test_index = 0
        self.total_tests = 0
        self.start_time = None
        self.specified_sql_types = specified_sql_types or []
        self.filter_mode = filter_mode
        self.single_template_mode = single_template_mode
        self.perf_node = perf_node
        self.realtime_report_file = None
        
        # ç¼“å­˜å·²çŸ¥å¤±è´¥æµ‹è¯•åˆ—è¡¨ï¼Œé¿å…é‡å¤è°ƒç”¨å’Œæ‰“å°
        self._known_failure_tests = None
        # ç¼“å­˜å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åˆ—è¡¨
        self._known_poor_performance_tests = None
        
        self.delay_trends_analysis =  base_args.get('delay_trends_analysis', True)
        
        # é»˜è®¤çš„å›ºå®šå‚æ•°
        self.fixed_params = {
            'mode': 1,  # å®æ—¶æµè®¡ç®—æµ‹è¯•
            'check_stream_delay': True,
            'stream_num': 1,
            'real_time_batch_sleep': 0,
            'monitor_interval': 30,
            'delay_check_interval': 30,
            'max_delay_threshold': 30000,
            'deployment_mode': 'single',
            'table_count': 2000,
            'histroy_rows': 1,
            'real_time_batch_rows': 200,
            'disorder_ratio': 0,
            'vgroups': 10,
            'debug_flag': 131,
            'num_of_log_lines': 500000,
            'perf_node': 'dnode1'
        }
        
        # æ›´æ–°å›ºå®šå‚æ•°
        self.fixed_params.update(self.base_args)       
        
        # æ‰¹é‡æµ‹è¯•ä¸­å¼ºåˆ¶å¯ç”¨æµå»¶è¿Ÿæ£€æŸ¥
        self.fixed_params['check_stream_delay'] = True
        
        # âœ… ç¡®ä¿ use_virtual_table å‚æ•°è¢«æ­£ç¡®ä¼ é€’
        use_virtual_table = self.base_args.get('use_virtual_table', False)
        self.fixed_params['use_virtual_table'] = use_virtual_table
        
        print(f"æ‰¹é‡æµ‹è¯•å™¨åˆå§‹åŒ–å®Œæˆ:")
        if self.specified_sql_types:
            print(f"  æŒ‡å®šSQLç±»å‹: {', '.join(self.specified_sql_types)}")
        else:
            print(f"  SQLç±»å‹: å…¨éƒ¨ç»„åˆ")
            
        
        print(f"  è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
        if self.filter_mode == 'skip-known-failures':
            failure_count = len(self.get_known_failure_tests())
            print(f"  å·²çŸ¥å¤±è´¥æµ‹è¯•: {failure_count} ä¸ª")
            print(f"  å°†è·³è¿‡å·²çŸ¥å¤±è´¥çš„æµ‹è¯•åœºæ™¯ï¼Œä¸“æ³¨äºæˆåŠŸåœºæ™¯")
        elif self.filter_mode == 'only-known-failures':
            failure_count = len(self.get_known_failure_tests())
            print(f"  å·²çŸ¥å¤±è´¥æµ‹è¯•: {failure_count} ä¸ª")
            print(f"  ä»…è¿è¡Œå·²çŸ¥å¤±è´¥çš„æµ‹è¯•åœºæ™¯ï¼Œç”¨äºè°ƒè¯•å¤±è´¥åŸå› ")
        elif self.filter_mode == 'skip-known-case':
            failure_count = len(self.get_known_failure_tests())
            poor_performance_count = len(self.get_known_poor_performance_tests())
            total_skip_count = failure_count + poor_performance_count
            print(f"  å·²çŸ¥å¤±è´¥æµ‹è¯•: {failure_count} ä¸ª")
            print(f"  å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰æµ‹è¯•: {poor_performance_count} ä¸ª")
            print(f"  æ€»è·³è¿‡æµ‹è¯•: {total_skip_count} ä¸ª")
            print(f"  å°†è·³è¿‡å·²çŸ¥å¤±è´¥å’Œæ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åœºæ™¯ï¼Œä¸“æ³¨äºä¼˜è´¨åœºæ™¯")
        elif self.filter_mode != 'all':
            failure_count = len(self.get_known_failure_tests())
            print(f"  å·²çŸ¥å¤±è´¥æµ‹è¯•: {failure_count} ä¸ª")
                
        print(f"  æµå»¶è¿Ÿæ£€æŸ¥: {'å¯ç”¨' if self.fixed_params['check_stream_delay'] else 'ç¦ç”¨'} (æ‰¹é‡æµ‹è¯•å¼ºåˆ¶å¯ç”¨)")
        print(f"  å»¶è¿Ÿæ£€æŸ¥é—´éš”: {self.fixed_params['delay_check_interval']}ç§’")
        print(f"  æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {self.fixed_params['max_delay_threshold']}ms")
        print(f"  æµæ•°é‡: {self.fixed_params['stream_num']}") 


    def get_known_failure_tests(self):
        """è·å–å·²çŸ¥å¤±è´¥çš„æµ‹è¯•åœºæ™¯åˆ—è¡¨
        
        è¿™é‡Œç»´æŠ¤æ‰€æœ‰å·²çŸ¥ä¼šå¤±è´¥çš„æµ‹è¯•åœºæ™¯åç§°
        æ‚¨å¯ä»¥ç›´æ¥åœ¨è¿™é‡Œæ·»åŠ æˆ–åˆ é™¤å¤±è´¥çš„æµ‹è¯•åç§°
        
        Returns:
            set: å·²çŸ¥å¤±è´¥çš„æµ‹è¯•åç§°é›†åˆ
        """
        # ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åˆ›å»ºå’Œæ‰“å°
        if self._known_failure_tests is not None:
            return self._known_failure_tests
        
        # åœ¨è¿™é‡Œç»´æŠ¤å·²çŸ¥å¤±è´¥çš„æµ‹è¯•åç§°åˆ—è¡¨
        known_failures = {
            # period 
            'period_stb_agg_tbname',
            'period_stb_select_tbname', 
            'period_stb_partition_by_tag_agg_tbname',
            'period_stb_partition_by_tag_select_tbname',
            'period_tb_agg_tbname',
            'period_tb_select_tbname',
            
            # count 
            'count_stb_agg_tbname',
            'count_stb_select_tbname',
            'count_stb_agg_trows', 
            'count_stb_select_trows',
            'count_stb_agg_sourcetable_stb',
            'count_stb_select_sourcetable_stb',
            'count_stb_partition_by_tag_agg_tbname',
            'count_stb_partition_by_tag_select_tbname',
            'count_stb_partition_by_tag_agg_trows', 
            'count_stb_partition_by_tag_select_trows',
            'count_stb_partition_by_tag_agg_sourcetable_stb',
            'count_stb_partition_by_tag_select_sourcetable_stb',
            'count_tb_agg_tbname',
            'count_tb_select_tbname',
            
            # event 
            'event_stb_agg_tbname',
            'event_stb_select_tbname',
            'event_stb_agg_trows',
            'event_stb_select_trows',
            'event_stb_agg_sourcetable_stb', 
            'event_stb_select_sourcetable_stb',
            'event_stb_partition_by_tag_agg_tbname',
            'event_stb_partition_by_tag_select_tbname',
            'event_stb_partition_by_tag_agg_trows',
            'event_stb_partition_by_tag_select_trows',
            'event_stb_partition_by_tag_agg_sourcetable_stb', 
            'event_stb_partition_by_tag_select_sourcetable_stb',
            'event_tb_agg_tbname',
            'event_tb_select_tbname',
            
            # state 
            'state_stb_agg_tbname',
            'state_stb_select_tbname',
            'state_stb_agg_trows',
            'state_stb_select_trows',
            'state_stb_agg_sourcetable_stb', 
            'state_stb_select_sourcetable_stb',
            'state_stb_partition_by_tag_agg_tbname',
            'state_stb_partition_by_tag_select_tbname',
            'state_stb_partition_by_tag_agg_trows',
            'state_stb_partition_by_tag_select_trows',
            'state_stb_partition_by_tag_agg_sourcetable_stb', 
            'state_stb_partition_by_tag_select_sourcetable_stb',
            'state_tb_agg_tbname',
            'state_tb_select_tbname',
            
            # intervalsliding
            'intervalsliding_stb_agg_tbname',
            'intervalsliding_stb_select_tbname',
            'intervalsliding_stb_partition_by_tag_agg_tbname',
            'intervalsliding_stb_partition_by_tag_select_tbname',
            'intervalsliding_tb_agg_tbname',
            'intervalsliding_tb_select_tbname',
            
            # session            
            'session_stb_agg_tbname',
            'session_stb_select_tbname',
            'session_stb_partition_by_tag_agg_tbname',
            'session_stb_partition_by_tag_select_tbname',
            'session_tb_agg_tbname',
            'session_tb_select_tbname',
            
            # sliding
            'sliding_stb_agg_tbname',
            'sliding_stb_select_tbname',
            'sliding_stb_partition_by_tag_agg_tbname',
            'sliding_stb_partition_by_tag_select_tbname',
            'sliding_tb_agg_tbname',
            'sliding_tb_select_tbname',
            
        }
        
        # ç¼“å­˜ç»“æœå¹¶åªæ‰“å°ä¸€æ¬¡
        self._known_failure_tests = known_failures
        print(f"ç»´æŠ¤çš„å·²çŸ¥å¤±è´¥æµ‹è¯•åˆ—è¡¨åŒ…å« {len(known_failures)} ä¸ªåœºæ™¯")
        return self._known_failure_tests
    
    
    def get_known_poor_performance_tests(self):
        """è·å–å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åœºæ™¯åˆ—è¡¨
        
        è¿™é‡Œç»´æŠ¤æ‰€æœ‰å·²çŸ¥æ€§èƒ½è¡¨ç°ä¸ä½³çš„æµ‹è¯•åœºæ™¯åç§°
        è¿™äº›åœºæ™¯è™½ç„¶å¯ä»¥æˆåŠŸè¿è¡Œï¼Œä½†æ€§èƒ½è¡¨ç°ä¸ç†æƒ³
        æ‚¨å¯ä»¥ç›´æ¥åœ¨è¿™é‡Œæ·»åŠ æˆ–åˆ é™¤æ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åç§°
        
        Returns:
            set: å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åç§°é›†åˆ
        """
        # ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤åˆ›å»ºå’Œæ‰“å°
        if self._known_poor_performance_tests is not None:
            return self._known_poor_performance_tests
        
        # åœ¨è¿™é‡Œç»´æŠ¤å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„æµ‹è¯•åç§°åˆ—è¡¨
        # è¿™äº›æµ‹è¯•å¯ä»¥è¿è¡ŒæˆåŠŸï¼Œä½†æ€§èƒ½è¡¨ç°ä¸ç†æƒ³ï¼Œéœ€è¦åæœŸä¼˜åŒ–
        poor_performance_cases = set({
            # ç¤ºä¾‹: ä»¥ä¸‹æ˜¯ä¸€äº›å¯èƒ½æ²¡æœ‰å®é™…æ„ä¹‰çš„åœºæ™¯ï¼Œå¯ä»¥æ ¹æ®å®é™…æµ‹è¯•ç»“æœæ·»åŠ 
            # æŸäº›å¤§è¡¨åˆ†åŒºæŸ¥è¯¢æ€§èƒ½ä¸ä½³çš„åœºæ™¯ï¼Œé€šè¿‡%%tbnameæ›¿ä»£
            'intervalsliding_stb_partition_by_tbname_agg_sourcetable_stb',
            'sliding_stb_partition_by_tbname_agg_sourcetable_stb',
            'session_stb_partition_by_tbname_agg_sourcetable_stb',            
            'count_stb_partition_by_tbname_agg_sourcetable_stb',
            'event_stb_partition_by_tbname_agg_sourcetable_stb',
            'state_stb_partition_by_tbname_agg_sourcetable_stb',
            'period_stb_partition_by_tbname_agg_sourcetable_stb',
            'intervalsliding_stb_partition_by_tbname_select_sourcetable_stb',
            'sliding_stb_partition_by_tbname_select_sourcetable_stb',
            'session_stb_partition_by_tbname_select_sourcetable_stb',
            'count_stb_partition_by_tbname_select_sourcetable_stb',
            'event_stb_partition_by_tbname_select_sourcetable_stb',
            'state_stb_partition_by_tbname_select_sourcetable_stb',
            'period_stb_partition_by_tbname_select_sourcetable_stb',
            
            # æŸäº›trowsç›¸å…³çš„æ€§èƒ½é—®é¢˜åœºæ™¯  
            'intervalsliding_stb_agg_trows',
            'intervalsliding_stb_partition_by_tbname_agg_trows',
            'intervalsliding_stb_partition_by_tag_agg_trows',
            'intervalsliding_tb_agg_trows',
            'sliding_stb_agg_trows',
            'sliding_stb_partition_by_tbname_agg_trows',
            'sliding_stb_partition_by_tag_agg_trows',
            'sliding_tb_agg_trows',
            'session_stb_agg_trows',
            'session_stb_partition_by_tbname_agg_trows',
            'session_stb_partition_by_tag_agg_trows',
            'session_tb_agg_trows',
            'count_stb_partition_by_tbname_agg_trows',
            'count_tb_agg_trows',
            'event_stb_partition_by_tbname_agg_trows',
            'event_tb_agg_trows',
            'state_stb_partition_by_tbname_agg_trows',
            'state_tb_agg_trows',
            'period_stb_agg_trows',
            'period_stb_partition_by_tbname_agg_trows',
            'period_stb_partition_by_tag_agg_trows',
            'period_tb_agg_trows',
            'intervalsliding_stb_select_trows',
            'intervalsliding_stb_partition_by_tbname_select_trows',
            'intervalsliding_stb_partition_by_tag_select_trows',
            'intervalsliding_tb_select_trows',
            'sliding_stb_select_trows',
            'sliding_stb_partition_by_tbname_select_trows',
            'sliding_stb_partition_by_tag_select_trows',
            'sliding_tb_select_trows',
            'session_stb_select_trows',
            'session_stb_partition_by_tbname_select_trows',
            'session_stb_partition_by_tag_select_trows',
            'session_tb_select_trows',
            'count_stb_partition_by_tbname_select_trows',
            'count_tb_select_trows',
            'event_stb_partition_by_tbname_select_trows',
            'event_tb_select_trows',
            'state_stb_partition_by_tbname_select_trows',
            'state_tb_select_trows',
            'period_stb_select_trows',
            'period_stb_partition_by_tbname_select_trows',
            'period_stb_partition_by_tag_select_trows',
            'period_tb_select_trows',
            
            
            # æ³¨æ„: è¿™é‡Œåªæ˜¯ç¤ºä¾‹ï¼Œå®é™…çš„æ²¡æœ‰å®é™…æ„ä¹‰çš„åœºæ™¯éœ€è¦æ ¹æ®æµ‹è¯•ç»“æœæ¥æ·»åŠ 
            # å¯ä»¥åœ¨æ‰¹é‡æµ‹è¯•å®Œæˆåï¼Œæ ¹æ®æ€§èƒ½æŠ¥å‘Šä¸­çš„CPU/å†…å­˜ä½¿ç”¨æƒ…å†µæ¥è¯†åˆ«
        })
        
        # ç¼“å­˜ç»“æœå¹¶åªæ‰“å°ä¸€æ¬¡
        self._known_poor_performance_tests = poor_performance_cases
        print(f"ç»´æŠ¤çš„å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰æµ‹è¯•åˆ—è¡¨åŒ…å« {len(poor_performance_cases)} ä¸ªåœºæ™¯")
        if poor_performance_cases:
            print(f"å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„åœºæ™¯: {', '.join(list(poor_performance_cases)[:5])}{'...' if len(poor_performance_cases) > 5 else ''}")
        return self._known_poor_performance_tests
    
    def extract_stream_names_from_sql(self, sql_templates):
        """ä»SQLæ¨¡æ¿ä¸­æå–æµåç§°
        
        Args:
            sql_templates: SQLæ¨¡æ¿å­—ç¬¦ä¸²æˆ–å­—å…¸
            
        Returns:
            set: æµåç§°é›†åˆ
        """
        import re
        stream_names = set()
        
        try:
            if isinstance(sql_templates, dict):
                for sql_template in sql_templates.values():
                    match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                    if match:
                        full_stream_name = match.group(1)
                        # å»æ‰æ•°æ®åº“å‰ç¼€ï¼Œåªä¿ç•™æµåç§°éƒ¨åˆ†
                        if '.' in full_stream_name:
                            stream_name = full_stream_name.split('.')[-1]
                        else:
                            stream_name = full_stream_name
                        stream_names.add(stream_name)
                        print(f"è°ƒè¯•: ä»SQLä¸­æå–æµåç§°: {full_stream_name} -> {stream_name}")
            else:
                match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                if match:
                    full_stream_name = match.group(1)
                    # å»æ‰æ•°æ®åº“å‰ç¼€ï¼Œåªä¿ç•™æµåç§°éƒ¨åˆ†
                    if '.' in full_stream_name:
                        stream_name = full_stream_name.split('.')[-1]
                    else:
                        stream_name = full_stream_name
                    stream_names.add(stream_name)
                    print(f"è°ƒè¯•: ä»SQLä¸­æå–æµåç§°: {full_stream_name} -> {stream_name}")
        except Exception as e:
            print(f"æå–æµåç§°æ—¶å‡ºé”™: {str(e)}")
        
        return stream_names

    def should_skip_test_by_stream_names(self, stream_names):
        """æ ¹æ®æµåç§°åˆ¤æ–­æ˜¯å¦è·³è¿‡æµ‹è¯•
        
        Args:
            stream_names: å½“å‰æµ‹è¯•è¦åˆ›å»ºçš„æµåç§°é›†åˆ
            
        Returns:
            tuple: (æ˜¯å¦è·³è¿‡, åŸå› )
        """
        if self.filter_mode == 'all':
            return False, ""
        
        print(f"è°ƒè¯•è¿‡æ»¤: å½“å‰æµåç§°é›†åˆ: {stream_names}")
        print(f"è°ƒè¯•è¿‡æ»¤: è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
        
        known_failures = self.get_known_failure_tests()
        known_poor_performance = self.get_known_poor_performance_tests()
        print(f"è°ƒè¯•è¿‡æ»¤: å·²çŸ¥å¤±è´¥æµæ•°é‡: {len(known_failures)}")
        print(f"è°ƒè¯•è¿‡æ»¤: å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰æµæ•°é‡: {len(known_poor_performance)}")
        
        failed_streams = stream_names.intersection(known_failures)
        poor_performance_streams = stream_names.intersection(known_poor_performance)
        success_streams = stream_names - known_failures - known_poor_performance
        
        print(f"è°ƒè¯•è¿‡æ»¤: åŒ¹é…åˆ°çš„å¤±è´¥æµ: {failed_streams}")
        print(f"è°ƒè¯•è¿‡æ»¤: åŒ¹é…åˆ°çš„æ²¡æœ‰å®é™…æ„ä¹‰æµ: {poor_performance_streams}")
        print(f"è°ƒè¯•è¿‡æ»¤: æˆåŠŸæµ: {success_streams}")
        
        if self.filter_mode == 'skip-known-failures':
            # å¦‚æœåŒ…å«å·²çŸ¥å¤±è´¥çš„æµï¼Œè·³è¿‡
            if failed_streams:
                return True, f"åŒ…å«å·²çŸ¥å¤±è´¥æµ: {', '.join(failed_streams)}"
            return False, ""
            
        elif self.filter_mode == 'only-known-failures':
            # å¦‚æœä¸åŒ…å«å·²çŸ¥å¤±è´¥çš„æµï¼Œè·³è¿‡
            if not failed_streams:
                return True, f"ä¸åŒ…å«å·²çŸ¥å¤±è´¥æµï¼Œè·³è¿‡æµ‹è¯•"
            return False, ""
            
        elif self.filter_mode == 'skip-known-case':
            # å¦‚æœåŒ…å«å·²çŸ¥å¤±è´¥çš„æµæˆ–å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„æµï¼Œè·³è¿‡
            if failed_streams:
                return True, f"åŒ…å«å·²çŸ¥å¤±è´¥æµ: {', '.join(failed_streams)}"
            elif poor_performance_streams:
                return True, f"åŒ…å«å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰æµ: {', '.join(poor_performance_streams)} (å¾…åæœŸä¼˜åŒ–ï¼Œè·³è¿‡æµ‹è¯•)"
            return False, ""
            
        return False, ""
        
    def get_test_combinations(self):
        """è·å–æ‰€æœ‰æµ‹è¯•ç»„åˆ
        
        Returns:
            list: åŒ…å«æ‰€æœ‰å‚æ•°ç»„åˆçš„åˆ—è¡¨
        """
        if self.specified_sql_types:
            # å¦‚æœæŒ‡å®šäº†SQLç±»å‹ï¼Œä½¿ç”¨æŒ‡å®šçš„ç±»å‹è¿›è¡Œç»„åˆ
            return self.get_combinations_for_specified_types()
        else:
            # ä½¿ç”¨é»˜è®¤çš„å…¨éƒ¨ç»„åˆ
            return self.get_default_combinations()
    
    def get_default_combinations(self):
        """è·å–é»˜è®¤çš„å…¨éƒ¨æµ‹è¯•ç»„åˆ """
        # å®šä¹‰å˜åŒ–çš„å‚æ•°
        variable_params = {
            'tbname_or_trows_or_sourcetable': ['tbname', 'trows', 'sourcetable'],
            'agg_or_select': ['agg', 'select'],
            'sql_type': [
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - é—´éš”æ»‘åŠ¨çª—å£
                'intervalsliding_stb', 'intervalsliding_stb_partition_by_tbname', 
                'intervalsliding_stb_partition_by_tag', 'intervalsliding_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - æ»‘åŠ¨çª—å£  
                'sliding_stb', 'sliding_stb_partition_by_tbname',
                'sliding_stb_partition_by_tag', 'sliding_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - ä¼šè¯çª—å£
                'session_stb', 'session_stb_partition_by_tbname',
                'session_stb_partition_by_tag', 'session_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - è®¡æ•°çª—å£
                'count_stb', 'count_stb_partition_by_tbname',
                'count_stb_partition_by_tag', 'count_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - äº‹ä»¶çª—å£
                'event_stb', 'event_stb_partition_by_tbname',
                'event_stb_partition_by_tag', 'event_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - çŠ¶æ€çª—å£
                'state_stb', 'state_stb_partition_by_tbname',
                'state_stb_partition_by_tag', 'state_tb',
                # å•ä¸ªè¯¦ç»†æ¨¡æ¿ - å®šæ—¶è§¦å‘
                'period_stb', 'period_stb_partition_by_tbname',
                'period_stb_partition_by_tag', 'period_tb'
            ]
        }
        
        # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
        combinations = []
        keys = list(variable_params.keys())
        values = list(variable_params.values())
        
        for combination in itertools.product(*values):
            param_dict = dict(zip(keys, combination))
            combinations.append(param_dict)
            
        return combinations
    
    def get_combinations_for_specified_types(self):
        """ä¸ºæŒ‡å®šçš„SQLç±»å‹ç”Ÿæˆæµ‹è¯•ç»„åˆ"""
        combinations = []
        
        # è§£ææŒ‡å®šçš„SQLç±»å‹å¹¶ç”Ÿæˆå¯¹åº”çš„ç»„åˆ
        for sql_type in self.specified_sql_types:
            type_combinations = self.get_combinations_for_single_type(sql_type)
            combinations.extend(type_combinations)
        
        return combinations
    
    def get_combinations_for_single_type(self, sql_type):
        """ä¸ºå•ä¸ªSQLç±»å‹ç”Ÿæˆæµ‹è¯•ç»„åˆ"""
        combinations = []
        
        # å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿ - è¿™äº›å¿½ç•¥å‘½ä»¤è¡Œçš„ tbname_or_trows_or_sourcetable å’Œ agg_or_select
        fixed_param_templates = {
            'tbname_agg': [
                ('tbname', 'agg', 'intervalsliding_stb'), ('tbname', 'agg', 'intervalsliding_stb_partition_by_tbname'),
                ('tbname', 'agg', 'intervalsliding_stb_partition_by_tag'), ('tbname', 'agg', 'intervalsliding_tb'),
                ('tbname', 'agg', 'sliding_stb'), ('tbname', 'agg', 'sliding_stb_partition_by_tbname'),
                ('tbname', 'agg', 'sliding_stb_partition_by_tag'), ('tbname', 'agg', 'sliding_tb'),
                ('tbname', 'agg', 'session_stb'), ('tbname', 'agg', 'session_stb_partition_by_tbname'),
                ('tbname', 'agg', 'session_stb_partition_by_tag'), ('tbname', 'agg', 'session_tb'),
                ('tbname', 'agg', 'count_stb'), ('tbname', 'agg', 'count_stb_partition_by_tbname'),
                ('tbname', 'agg', 'count_stb_partition_by_tag'), ('tbname', 'agg', 'count_tb'),
                ('tbname', 'agg', 'event_stb'), ('tbname', 'agg', 'event_stb_partition_by_tbname'),
                ('tbname', 'agg', 'event_stb_partition_by_tag'), ('tbname', 'agg', 'event_tb'),
                ('tbname', 'agg', 'state_stb'), ('tbname', 'agg', 'state_stb_partition_by_tbname'),
                ('tbname', 'agg', 'state_stb_partition_by_tag'), ('tbname', 'agg', 'state_tb'),
                ('tbname', 'agg', 'period_stb'), ('tbname', 'agg', 'period_stb_partition_by_tbname'),
                ('tbname', 'agg', 'period_stb_partition_by_tag'), ('tbname', 'agg', 'period_tb')
            ],
            'tbname_select': [
                ('tbname', 'select', 'intervalsliding_stb'), ('tbname', 'select', 'intervalsliding_stb_partition_by_tbname'),
                ('tbname', 'select', 'intervalsliding_stb_partition_by_tag'), ('tbname', 'select', 'intervalsliding_tb'),
                ('tbname', 'select', 'sliding_stb'), ('tbname', 'select', 'sliding_stb_partition_by_tbname'),
                ('tbname', 'select', 'sliding_stb_partition_by_tag'), ('tbname', 'select', 'sliding_tb'),
                ('tbname', 'select', 'session_stb'), ('tbname', 'select', 'session_stb_partition_by_tbname'),
                ('tbname', 'select', 'session_stb_partition_by_tag'), ('tbname', 'select', 'session_tb'),
                ('tbname', 'select', 'count_stb'), ('tbname', 'select', 'count_stb_partition_by_tbname'),
                ('tbname', 'select', 'count_stb_partition_by_tag'), ('tbname', 'select', 'count_tb'),
                ('tbname', 'select', 'event_stb'), ('tbname', 'select', 'event_stb_partition_by_tbname'),
                ('tbname', 'select', 'event_stb_partition_by_tag'), ('tbname', 'select', 'event_tb'),
                ('tbname', 'select', 'state_stb'), ('tbname', 'select', 'state_stb_partition_by_tbname'),
                ('tbname', 'select', 'state_stb_partition_by_tag'), ('tbname', 'select', 'state_tb'),
                ('tbname', 'select', 'period_stb'), ('tbname', 'select', 'period_stb_partition_by_tbname'),
                ('tbname', 'select', 'period_stb_partition_by_tag'), ('tbname', 'select', 'period_tb')
            ],
            'trows_agg': [
                ('trows', 'agg', 'intervalsliding_stb'), ('trows', 'agg', 'intervalsliding_stb_partition_by_tbname'),
                ('trows', 'agg', 'intervalsliding_stb_partition_by_tag'), ('trows', 'agg', 'intervalsliding_tb'),
                ('trows', 'agg', 'sliding_stb'), ('trows', 'agg', 'sliding_stb_partition_by_tbname'),
                ('trows', 'agg', 'sliding_stb_partition_by_tag'), ('trows', 'agg', 'sliding_tb'),
                ('trows', 'agg', 'session_stb'), ('trows', 'agg', 'session_stb_partition_by_tbname'),
                ('trows', 'agg', 'session_stb_partition_by_tag'), ('trows', 'agg', 'session_tb'),
                ('trows', 'agg', 'count_stb'), ('trows', 'agg', 'count_stb_partition_by_tbname'),
                ('trows', 'agg', 'count_stb_partition_by_tag'), ('trows', 'agg', 'count_tb'),
                ('trows', 'agg', 'event_stb'), ('trows', 'agg', 'event_stb_partition_by_tbname'),
                ('trows', 'agg', 'event_stb_partition_by_tag'), ('trows', 'agg', 'event_tb'),
                ('trows', 'agg', 'state_stb'), ('trows', 'agg', 'state_stb_partition_by_tbname'),
                ('trows', 'agg', 'state_stb_partition_by_tag'), ('trows', 'agg', 'state_tb'),
                ('trows', 'agg', 'period_stb'), ('trows', 'agg', 'period_stb_partition_by_tbname'),
                ('trows', 'agg', 'period_stb_partition_by_tag'), ('trows', 'agg', 'period_tb')
            ],
            'trows_select': [
                ('trows', 'select', 'intervalsliding_stb'), ('trows', 'select', 'intervalsliding_stb_partition_by_tbname'),
                ('trows', 'select', 'intervalsliding_stb_partition_by_tag'), ('trows', 'select', 'intervalsliding_tb'),
                ('trows', 'select', 'sliding_stb'), ('trows', 'select', 'sliding_stb_partition_by_tbname'),
                ('trows', 'select', 'sliding_stb_partition_by_tag'), ('trows', 'select', 'sliding_tb'),
                ('trows', 'select', 'session_stb'), ('trows', 'select', 'session_stb_partition_by_tbname'),
                ('trows', 'select', 'session_stb_partition_by_tag'), ('trows', 'select', 'session_tb'),
                ('trows', 'select', 'count_stb'), ('trows', 'select', 'count_stb_partition_by_tbname'),
                ('trows', 'select', 'count_stb_partition_by_tag'), ('trows', 'select', 'count_tb'),
                ('trows', 'select', 'event_stb'), ('trows', 'select', 'event_stb_partition_by_tbname'),
                ('trows', 'select', 'event_stb_partition_by_tag'), ('trows', 'select', 'event_tb'),
                ('trows', 'select', 'state_stb'), ('trows', 'select', 'state_stb_partition_by_tbname'),
                ('trows', 'select', 'state_stb_partition_by_tag'), ('trows', 'select', 'state_tb'),
                ('trows', 'select', 'period_stb'), ('trows', 'select', 'period_stb_partition_by_tbname'),
                ('trows', 'select', 'period_stb_partition_by_tag'), ('trows', 'select', 'period_tb')
            ],
            'sourcetable_agg': [
                ('sourcetable', 'agg', 'intervalsliding_stb'), ('sourcetable', 'agg', 'intervalsliding_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'intervalsliding_stb_partition_by_tag'), ('sourcetable', 'agg', 'intervalsliding_tb'),
                ('sourcetable', 'agg', 'sliding_stb'), ('sourcetable', 'agg', 'sliding_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'sliding_stb_partition_by_tag'), ('sourcetable', 'agg', 'sliding_tb'),
                ('sourcetable', 'agg', 'session_stb'), ('sourcetable', 'agg', 'session_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'session_stb_partition_by_tag'), ('sourcetable', 'agg', 'session_tb'),
                ('sourcetable', 'agg', 'count_stb'), ('sourcetable', 'agg', 'count_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'count_stb_partition_by_tag'), ('sourcetable', 'agg', 'count_tb'),
                ('sourcetable', 'agg', 'event_stb'), ('sourcetable', 'agg', 'event_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'event_stb_partition_by_tag'), ('sourcetable', 'agg', 'event_tb'),
                ('sourcetable', 'agg', 'state_stb'), ('sourcetable', 'agg', 'state_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'state_stb_partition_by_tag'), ('sourcetable', 'agg', 'state_tb'),
                ('sourcetable', 'agg', 'period_stb'), ('sourcetable', 'agg', 'period_stb_partition_by_tbname'),
                ('sourcetable', 'agg', 'period_stb_partition_by_tag'), ('sourcetable', 'agg', 'period_tb')
            ],
            'sourcetable_select': [
                ('sourcetable', 'select', 'intervalsliding_stb'), ('sourcetable', 'select', 'intervalsliding_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'intervalsliding_stb_partition_by_tag'), ('sourcetable', 'select', 'intervalsliding_tb'),
                ('sourcetable', 'select', 'sliding_stb'), ('sourcetable', 'select', 'sliding_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'sliding_stb_partition_by_tag'), ('sourcetable', 'select', 'sliding_tb'),
                ('sourcetable', 'select', 'session_stb'), ('sourcetable', 'select', 'session_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'session_stb_partition_by_tag'), ('sourcetable', 'select', 'session_tb'),
                ('sourcetable', 'select', 'count_stb'), ('sourcetable', 'select', 'count_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'count_stb_partition_by_tag'), ('sourcetable', 'select', 'count_tb'),
                ('sourcetable', 'select', 'event_stb'), ('sourcetable', 'select', 'event_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'event_stb_partition_by_tag'), ('sourcetable', 'select', 'event_tb'),
                ('sourcetable', 'select', 'state_stb'), ('sourcetable', 'select', 'state_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'state_stb_partition_by_tag'), ('sourcetable', 'select', 'state_tb'),
                ('sourcetable', 'select', 'period_stb'), ('sourcetable', 'select', 'period_stb_partition_by_tbname'),
                ('sourcetable', 'select', 'period_stb_partition_by_tag'), ('sourcetable', 'select', 'period_tb')
            ]
        }
        
        # ç»„åˆæ¨¡æ¿ - æ¯ç»„åŒ…å«4ç§ç»„åˆï¼Œä½¿ç”¨æ‰€æœ‰çš„ tbname_or_trows_or_sourcetable å’Œ agg_or_select ç»„åˆ
        detailed_templates = {
            'intervalsliding_detailed': [
                'intervalsliding_stb', 'intervalsliding_stb_partition_by_tbname',
                'intervalsliding_stb_partition_by_tag', 'intervalsliding_tb'
            ],
            'sliding_detailed': [
                'sliding_stb', 'sliding_stb_partition_by_tbname',
                'sliding_stb_partition_by_tag', 'sliding_tb'
            ],
            'session_detailed': [
                'session_stb', 'session_stb_partition_by_tbname',
                'session_stb_partition_by_tag', 'session_tb'
            ],
            'count_detailed': [
                'count_stb', 'count_stb_partition_by_tbname',
                'count_stb_partition_by_tag', 'count_tb'
            ],
            'event_detailed': [
                'event_stb', 'event_stb_partition_by_tbname',
                'event_stb_partition_by_tag', 'event_tb'
            ],
            'state_detailed': [
                'state_stb', 'state_stb_partition_by_tbname',
                'state_stb_partition_by_tag', 'state_tb'
            ],
            'period_detailed': [
                'period_stb', 'period_stb_partition_by_tbname',
                'period_stb_partition_by_tag', 'period_tb'
            ]
        }
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿
        if sql_type in fixed_param_templates:
            for tbname_param, agg_param, actual_sql_type in fixed_param_templates[sql_type]:
                combinations.append({
                    'sql_type': actual_sql_type,
                    'tbname_or_trows_or_sourcetable': tbname_param,
                    'agg_or_select': agg_param
                })
            print(f"  {sql_type}: ç”Ÿæˆ {len(fixed_param_templates[sql_type])} ç§ç»„åˆ")
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯ç»„åˆæ¨¡æ¿
        elif sql_type in detailed_templates:            
            # è·å–å‘½ä»¤è¡Œä¼ å…¥çš„å‚æ•°ï¼Œå¦‚æœæ²¡æœ‰æŒ‡å®šåˆ™ä½¿ç”¨æ‰€æœ‰ç»„åˆ
            base_args = getattr(self, 'base_args', {})
            specified_tbname_param = base_args.get('tbname_or_trows_or_sourcetable')
            specified_agg_param = base_args.get('agg_or_select')
            
            # ç¡®å®šè¦ä½¿ç”¨çš„å‚æ•°ç»„åˆ
            if specified_tbname_param and specified_agg_param:
                # å¦‚æœæŒ‡å®šäº†å…·ä½“å‚æ•°ï¼Œåªç”ŸæˆæŒ‡å®šçš„ç»„åˆ
                tbname_params = [specified_tbname_param]
                agg_params = [specified_agg_param]
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šå‚æ•°ç»„åˆ - {specified_tbname_param} + {specified_agg_param}")
            elif specified_tbname_param:
                # å¦‚æœåªæŒ‡å®šäº† tbname å‚æ•°ï¼Œä½¿ç”¨æŒ‡å®šçš„ tbname + æ‰€æœ‰ agg å‚æ•°
                tbname_params = [specified_tbname_param]
                agg_params = ['agg', 'select']
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®š tbname å‚æ•° - {specified_tbname_param} + æ‰€æœ‰æŸ¥è¯¢ç±»å‹")
            elif specified_agg_param:
                # å¦‚æœåªæŒ‡å®šäº† agg å‚æ•°ï¼Œä½¿ç”¨æ‰€æœ‰ tbname + æŒ‡å®šçš„ agg å‚æ•°
                tbname_params = ['tbname', 'trows', 'sourcetable']
                agg_params = [specified_agg_param]
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šæŸ¥è¯¢ç±»å‹ - æ‰€æœ‰fromç±»å‹ + {specified_agg_param}")
            else:
                # å¦‚æœéƒ½æ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰ç»„åˆ
                tbname_params = ['tbname', 'trows', 'sourcetable']
                agg_params = ['agg', 'select']
                print(f"  {sql_type}: ä½¿ç”¨æ‰€æœ‰å‚æ•°ç»„åˆ")
                
            for actual_sql_type in detailed_templates[sql_type]:
                for tbname_param in tbname_params:
                    for agg_param in agg_params:
                        combinations.append({
                            'sql_type': actual_sql_type,
                            'tbname_or_trows_or_sourcetable': tbname_param,
                            'agg_or_select': agg_param
                        })
            
            total_combinations = len(detailed_templates[sql_type]) * len(tbname_params) * len(agg_params)
            print(f"  {sql_type}: ç”Ÿæˆ {total_combinations} ç§ç»„åˆ ({len(detailed_templates[sql_type])}ä¸ªæ¨¡æ¿ Ã— {len(tbname_params)}ä¸ªfromç±»å‹ Ã— {len(agg_params)}ä¸ªæŸ¥è¯¢ç±»å‹)")
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯all_detailedç‰¹æ®Šæ¨¡æ¿
        elif sql_type == 'all_detailed':
            all_sql_types = []
            for template_list in detailed_templates.values():
                all_sql_types.extend(template_list)
                            
            # è·å–å‘½ä»¤è¡Œä¼ å…¥çš„å‚æ•°
            base_args = getattr(self, 'base_args', {})
            specified_tbname_param = base_args.get('tbname_or_trows_or_sourcetable')
            specified_agg_param = base_args.get('agg_or_select')
            
            # ç¡®å®šè¦ä½¿ç”¨çš„å‚æ•°ç»„åˆ
            if specified_tbname_param and specified_agg_param:
                tbname_params = [specified_tbname_param]
                agg_params = [specified_agg_param]
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šå‚æ•°ç»„åˆ - {specified_tbname_param} + {specified_agg_param}")
            elif specified_tbname_param:
                tbname_params = [specified_tbname_param]
                agg_params = ['agg', 'select']
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®š tbname å‚æ•° - {specified_tbname_param} + æ‰€æœ‰æŸ¥è¯¢ç±»å‹")
            elif specified_agg_param:
                tbname_params = ['tbname', 'trows', 'sourcetable']
                agg_params = [specified_agg_param]
                print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šæŸ¥è¯¢ç±»å‹ - æ‰€æœ‰fromç±»å‹ + {specified_agg_param}")
            else:
                tbname_params = ['tbname', 'trows', 'sourcetable']
                agg_params = ['agg', 'select']
                print(f"  {sql_type}: ä½¿ç”¨æ‰€æœ‰å‚æ•°ç»„åˆ")
            
            
            for actual_sql_type in all_sql_types:
                for tbname_param in tbname_params:
                    for agg_param in agg_params:
                        combinations.append({
                            'sql_type': actual_sql_type,
                            'tbname_or_trows_or_sourcetable': tbname_param,
                            'agg_or_select': agg_param
                        })
            
            total_combinations = len(all_sql_types) * len(tbname_params) * len(agg_params)
            print(f"  {sql_type}: ç”Ÿæˆ {total_combinations} ç§ç»„åˆ ({len(all_sql_types)}ä¸ªæ¨¡æ¿ Ã— {len(tbname_params)}ä¸ªfromç±»å‹ Ã— {len(agg_params)}ä¸ªæŸ¥è¯¢ç±»å‹)")
            
        # æ£€æŸ¥æ˜¯å¦æ˜¯å•ä¸ªæ¨¡æ¿
        else:
            # è·å–å‘½ä»¤è¡Œä¼ å…¥çš„å‚æ•°
            base_args = getattr(self, 'base_args', {})
            specified_tbname_param = base_args.get('tbname_or_trows_or_sourcetable')
            specified_agg_param = base_args.get('agg_or_select')
            
            
            # æ£€æŸ¥æ‰¹é‡æµ‹è¯•æ¨¡å¼è®¾ç½®
            if hasattr(self, 'single_template_mode') and self.single_template_mode == 'all-combinations':
                # ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆï¼Œä½†å¦‚æœæŒ‡å®šäº†å‚æ•°åˆ™ä½¿ç”¨æŒ‡å®šçš„å‚æ•°
                if specified_tbname_param and specified_agg_param:
                    # å¦‚æœæŒ‡å®šäº†å…·ä½“å‚æ•°ï¼Œåªç”ŸæˆæŒ‡å®šçš„ç»„åˆ
                    tbname_params = [specified_tbname_param]
                    agg_params = [specified_agg_param]
                    print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šå‚æ•°ç»„åˆ - {specified_tbname_param} + {specified_agg_param}")
                elif specified_tbname_param:
                    # å¦‚æœåªæŒ‡å®šäº† tbname å‚æ•°ï¼Œä½¿ç”¨æŒ‡å®šçš„ tbname + æ‰€æœ‰ agg å‚æ•°
                    tbname_params = [specified_tbname_param]
                    agg_params = ['agg', 'select']
                    print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®š tbname å‚æ•° - {specified_tbname_param} + æ‰€æœ‰æŸ¥è¯¢ç±»å‹")
                elif specified_agg_param:
                    # å¦‚æœåªæŒ‡å®šäº† agg å‚æ•°ï¼Œä½¿ç”¨æ‰€æœ‰ tbname + æŒ‡å®šçš„ agg å‚æ•°
                    tbname_params = ['tbname', 'trows', 'sourcetable']
                    agg_params = [specified_agg_param]
                    print(f"  {sql_type}: ä½¿ç”¨æŒ‡å®šæŸ¥è¯¢ç±»å‹ - æ‰€æœ‰fromç±»å‹ + {specified_agg_param}")
                else:
                    # å¦‚æœéƒ½æ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨æ‰€æœ‰ç»„åˆ
                    tbname_params = ['tbname', 'trows', 'sourcetable']
                    agg_params = ['agg', 'select']
                    print(f"  {sql_type}: ä½¿ç”¨æ‰€æœ‰å‚æ•°ç»„åˆ")
                
                # åœ¨ all-combinations æ¨¡å¼ä¸‹ï¼Œå¿½ç•¥å‘½ä»¤è¡ŒæŒ‡å®šçš„å‚æ•°ï¼Œå¼ºåˆ¶ç”Ÿæˆæ‰€æœ‰ç»„åˆ
                tbname_params = ['tbname', 'trows', 'sourcetable']
                agg_params = ['agg', 'select']
                print(f"  {sql_type}: å¼ºåˆ¶ä½¿ç”¨æ‰€æœ‰å‚æ•°ç»„åˆ (all-combinationsæ¨¡å¼)")
    
                for tbname_param in tbname_params:
                    for agg_param in agg_params:
                        combinations.append({
                            'sql_type': sql_type,
                            'tbname_or_trows_or_sourcetable': tbname_param,
                            'agg_or_select': agg_param
                        })
                print(f"  {sql_type}: ç”Ÿæˆ {len(tbname_params) * len(agg_params)} ç§ç»„åˆ ({len(tbname_params)}ä¸ªfromç±»å‹ Ã— {len(agg_params)}ä¸ªæŸ¥è¯¢ç±»å‹)")
            else:
                # åªç”Ÿæˆé»˜è®¤ç»„åˆï¼Œä½†ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„å‚æ•°ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰
                tbname_param = specified_tbname_param if specified_tbname_param else 'sourcetable'
                agg_param = specified_agg_param if specified_agg_param else 'agg'
                
                combinations.append({
                    'sql_type': sql_type,
                    'tbname_or_trows_or_sourcetable': tbname_param,
                    'agg_or_select': agg_param
                })
                
                if specified_tbname_param or specified_agg_param:
                    print(f"  {sql_type}: ç”Ÿæˆ 1 ç§ç»„åˆ (ä½¿ç”¨æŒ‡å®šå‚æ•°: {tbname_param} + {agg_param})")
                else:
                    print(f"  {sql_type}: ç”Ÿæˆ 1 ç§ç»„åˆ (é»˜è®¤å‚æ•°: {tbname_param} + {agg_param})")
                    print(f"    æç¤º: ä½¿ç”¨ --batch-single-template-mode all-combinations å¯æµ‹è¯•æ‰€æœ‰6ç§ç»„åˆ")
            
        return combinations
    
    def filter_combinations(self, combinations):
        """è¿‡æ»¤æµ‹è¯•ç»„åˆ
        
        ç”±äºéœ€è¦å…ˆç”ŸæˆSQLæ‰èƒ½è·å¾—æµåç§°ï¼Œè¿™é‡ŒåªåšåŸºæœ¬çš„æœ‰æ•ˆæ€§æ£€æŸ¥
        å®é™…çš„å¤±è´¥è¿‡æ»¤å°†åœ¨execute_single_testä¸­è¿›è¡Œ
        
        Args:
            combinations: åŸå§‹ç»„åˆåˆ—è¡¨
            
        Returns:
            list: è¿‡æ»¤åçš„æœ‰æ•ˆç»„åˆåˆ—è¡¨
        """
        valid_combinations = []
        for combo in combinations:
            if self.is_valid_combination(combo):
                valid_combinations.append(combo)
        
        # æ‰“å°è¿‡æ»¤ç»Ÿè®¡
        total_original = len(combinations)
        total_filtered = len(valid_combinations)
        
        print(f"\n=== æµ‹è¯•ç»„åˆåŸºæœ¬è¿‡æ»¤ç»Ÿè®¡ ===")
        print(f"åŸå§‹ç»„åˆæ•°: {total_original}")
        print(f"æœ‰æ•ˆç»„åˆæ•°: {total_filtered}")
        
        if self.filter_mode != 'all':
            print(f"è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
            print(f"æ³¨æ„: å·²çŸ¥å¤±è´¥æµçš„è¿‡æ»¤å°†åœ¨å®é™…åˆ›å»ºæµæ—¶è¿›è¡Œ")
        
        return valid_combinations
    
    def is_valid_combination(self, combo):
        """æ£€æŸ¥ç»„åˆæ˜¯å¦æœ‰æ•ˆ
        
        Args:
            combo: å‚æ•°ç»„åˆå­—å…¸
            
        Returns:
            bool: æ˜¯å¦ä¸ºæœ‰æ•ˆç»„åˆ
        """
        sql_type = combo['sql_type']
        tbname_param = combo['tbname_or_trows_or_sourcetable']
        
        # Period ç±»å‹çš„ç‰¹æ®Šå¤„ç†
        if sql_type.startswith('period_'):
            pass
            
        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ æ›´å¤šè¿‡æ»¤è§„åˆ™
        # ä¾‹å¦‚ï¼šæŸäº›ç»„åˆå¯èƒ½ä¸æ”¯æŒæˆ–æ²¡æœ‰æ„ä¹‰
        
        return True
    
    def create_batch_result_dir(self):
        """åˆ›å»ºæ‰¹é‡æµ‹è¯•ç»“æœç›®å½•"""
        timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        result_dir = f"/tmp/stream_batch_test_{timestamp}"
        os.makedirs(result_dir, exist_ok=True)
        
        # åˆ›å»ºå­ç›®å½•
        for subdir in ['logs', 'performance', 'reports', 'configs']:
            os.makedirs(os.path.join(result_dir, subdir), exist_ok=True)
            
        return result_dir
    
    def generate_test_config(self, combination, test_index, result_dir):
        """ä¸ºå•ä¸ªæµ‹è¯•ç”Ÿæˆé…ç½®
        
        Args:
            combination: å‚æ•°ç»„åˆ
            test_index: æµ‹è¯•ç¼–å·
            result_dir: ç»“æœç›®å½•
            
        Returns:
            dict: å®Œæ•´çš„æµ‹è¯•é…ç½®
        """
        # åˆå¹¶å›ºå®šå‚æ•°å’Œå˜åŒ–å‚æ•°
        config = self.fixed_params.copy()
        config.update(combination)
        
        # å¼ºåˆ¶ç¡®ä¿æµå»¶è¿Ÿæ£€æŸ¥åœ¨æ‰¹é‡æµ‹è¯•ä¸­å¯ç”¨
        config['check_stream_delay'] = True
    
        # æ·»åŠ å»¶è¿Ÿæ¸…ç†åˆ†æé…ç½®
        config['delay_trends_analysis'] = self.delay_trends_analysis  
        
        if 'monitor_warm_up_time' not in config and self.base_args.get('monitor_warm_up_time') is not None:
            config['monitor_warm_up_time'] = self.base_args.get('monitor_warm_up_time')
    
        # è®¾ç½®è¾“å‡ºæ–‡ä»¶è·¯å¾„
        test_name = f"test_{test_index:03d}_{combination['sql_type']}_{combination['agg_or_select']}_{combination['tbname_or_trows_or_sourcetable']}"
        config['test_name'] = test_name
        config['perf_file'] = os.path.join(result_dir, 'performance', f'{test_name}_perf.log')
        config['delay_log_file'] = os.path.join(result_dir, 'logs', f'{test_name}_delay.log')
        config['test_log_file'] = os.path.join(result_dir, 'logs', f'{test_name}_test.log')
        config['perf_node'] = self.perf_node
        
        # è°ƒè¯•è¾“å‡ºï¼šéªŒè¯å»¶è¿Ÿæ£€æŸ¥é…ç½®
        print(f"è°ƒè¯•: ä¸ºæµ‹è¯• {test_name} è®¾ç½®æ€§èƒ½æ–‡ä»¶: {config['perf_file']}")
        print(f"è°ƒè¯•: ä¸ºæµ‹è¯• {test_name} è®¾ç½®å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶: {config['delay_log_file']}")
        print(f"  check_stream_delay: {config.get('check_stream_delay', 'NOT_SET')}")
        print(f"  delay_check_interval: {config.get('delay_check_interval', 'NOT_SET')}")
        print(f"  max_delay_threshold: {config.get('max_delay_threshold', 'NOT_SET')}")
        print(f"  stream_num: {config.get('stream_num', 'NOT_SET')}") 
        print(f"  monitor_warm_up_time: {config.get('monitor_warm_up_time', 'NOT_SET')}") 
        print(f"  delay_trends_analysis  : {config.get('delay_trends_analysis', 'NOT_SET')}")
        
        if not config['check_stream_delay']:
            # å¼ºåˆ¶å¯ç”¨
            config['check_stream_delay'] = True
            print(f"  âœ“ å·²å¼ºåˆ¶å¯ç”¨æµå»¶è¿Ÿæ£€æŸ¥")
        
        return config
    
    def execute_single_test(self, config):
        """æ‰§è¡Œå•ä¸ªæµ‹è¯•
        
        Args:
            config: æµ‹è¯•é…ç½®å­—å…¸
            
        Returns:
            dict: æµ‹è¯•ç»“æœ
        """
        test_name = config['test_name']
        start_time = time.time()
        
        print(f"\n{'='*80}")
        print(f"å¼€å§‹æµ‹è¯•: {test_name}")
        print(f"æµ‹è¯•ç¼–å·: {self.current_test_index}/{self.total_tests}")
        print(f"SQLç±»å‹: {config['sql_type']}")
        print(f"æŸ¥è¯¢ç±»å‹: {config['agg_or_select']}")
        print(f"FROMç±»å‹: {config['tbname_or_trows_or_sourcetable']}")
        print(f"è¿è¡Œæ—¶é—´: {config.get('time', 5)}åˆ†é’Ÿ")
        print(f"æµæ•°é‡: {config.get('stream_num', 1)}") 
        print(f"é¢„çƒ­æ—¶é—´: {config.get('monitor_warm_up_time', 'AUTO')}ç§’")
        print(f"{'='*80}")
        
        result = {
            'test_name': test_name,
            'config': config,
            'start_time': datetime.datetime.now().isoformat(),
            'status': 'RUNNING',
            'duration': 0,
            'error': None
        }
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦è·³è¿‡ï¼ˆåœ¨å®é™…åˆ›å»ºæµä¹‹å‰ï¼‰
        if self.filter_mode != 'all':
            try:
                # ç”ŸæˆSQLæ¨¡æ¿
                sql_templates = StreamSQLTemplates.get_sql(
                    config['sql_type'],
                    stream_num=config.get('stream_num', 1),
                    agg_or_select=config['agg_or_select'],
                    tbname_or_trows_or_sourcetable=config['tbname_or_trows_or_sourcetable']
                )
                
                # æå–æµåç§°
                stream_names = self.extract_stream_names_from_sql(sql_templates)
                
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥è·³è¿‡
                should_skip, skip_reason = self.should_skip_test_by_stream_names(stream_names)
                
                if should_skip:
                    # æ ¹æ®è·³è¿‡åŸå› ç¡®å®šè·³è¿‡ç±»å‹
                    if "å·²çŸ¥å¤±è´¥æµ" in skip_reason:
                        skip_status = "SKIP_FAILURE"
                        print(f"â­ï¸  è·³è¿‡æµ‹è¯• - å·²çŸ¥å¤±è´¥: {skip_reason}")
                    elif "å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰æµ" in skip_reason:
                        skip_status = "SKIP_POOR_PERFORMANCE"
                        print(f"â­ï¸  è·³è¿‡æµ‹è¯• - æ²¡æœ‰å®é™…æ„ä¹‰: {skip_reason}")
                    else:
                        skip_status = "SKIPPED"
                        print(f"â­ï¸  è·³è¿‡æµ‹è¯• - å…¶ä»–åŸå› : {skip_reason}")
                    
                    # è®°å½•è·³è¿‡ç»“æœ
                    end_time = time.time()
                    duration = end_time - start_time
                    
                    result.update({
                        'status': skip_status,
                        'end_time': datetime.datetime.now().isoformat(),
                        'duration': duration,
                        'skip_reason': skip_reason,
                        'stream_names': list(stream_names)
                    })
                    
                    return result
                else:
                    print(f"âœ… æµ‹è¯•é€šè¿‡è¿‡æ»¤æ£€æŸ¥ï¼Œå°†è¦åˆ›å»ºçš„æµ: {', '.join(stream_names)}")
                    
            except Exception as e:
                print(f"âš ï¸  è¿‡æ»¤æ£€æŸ¥æ—¶å‡ºé”™: {str(e)}ï¼Œç»§ç»­æ‰§è¡Œæµ‹è¯•")
        
        # ç»§ç»­æ‰§è¡ŒåŸæœ‰çš„æµ‹è¯•é€»è¾‘
        log_file = None
        original_stdout = sys.stdout
        
        try:
            # å¼ºåˆ¶æ¸…ç†ç¯å¢ƒ
            print("æ¸…ç†æµ‹è¯•ç¯å¢ƒ...")
            self.cleanup_environment()
            
            # ç­‰å¾…ç¯å¢ƒæ¸…ç†å®Œæˆ
            time.sleep(3)
        
            # é¢å¤–çš„çº¿ç¨‹æ¸…ç†æ£€æŸ¥
            #print("æ£€æŸ¥å¹¶æ¸…ç†å¯èƒ½çš„æ®‹ç•™çº¿ç¨‹...")
            import threading
            active_threads = threading.active_count()
            print(f"å½“å‰æ´»è·ƒçº¿ç¨‹æ•°: {active_threads}")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            import gc
            gc.collect()
            time.sleep(2)
        
            # éªŒè¯ç¯å¢ƒæ¸…ç†æ˜¯å¦æˆåŠŸ
            result_check = subprocess.run('ps -ef | grep taosd | grep -v grep', 
                                        shell=True, capture_output=True, text=True)
            if result_check.stdout:
                print("âš ï¸  å‘ç°æ®‹ç•™taosdè¿›ç¨‹ï¼Œå¼ºåˆ¶æ¸…ç†...")
                subprocess.run('pkill -9 taosd', shell=True)
                time.sleep(3)
                
            # âœ… ç¡®ä¿è™šæ‹Ÿè¡¨å‚æ•°æ­£ç¡®ä¼ é€’
            use_virtual_table = config.get('use_virtual_table', self.base_args.get('use_virtual_table', False))
            print(f"è°ƒè¯•: æ‰¹é‡æµ‹è¯•ä¸­çš„ use_virtual_table = {use_virtual_table}")
    
            
            # åˆ›å»ºStreamStarterå®ä¾‹
            starter = StreamStarter(
                runtime=config.get('time', 5),
                perf_file=config['perf_file'],
                table_count=config['table_count'],
                histroy_rows=config['histroy_rows'],
                real_time_batch_rows=config['real_time_batch_rows'],
                real_time_batch_sleep=config['real_time_batch_sleep'],
                disorder_ratio=config['disorder_ratio'],
                vgroups=config['vgroups'],
                sql_type=config['sql_type'],
                stream_num=config.get('stream_num', 1),
                stream_perf_test_dir=config.get('stream_perf_test_dir', '/home/stream_perf_test_dir'),
                monitor_interval=config['monitor_interval'],
                deployment_mode=config['deployment_mode'],
                debug_flag=config['debug_flag'],
                num_of_log_lines=config['num_of_log_lines'],
                agg_or_select=config['agg_or_select'],
                tbname_or_trows_or_sourcetable=config['tbname_or_trows_or_sourcetable'],
                check_stream_delay=config['check_stream_delay'],
                max_delay_threshold=config['max_delay_threshold'],
                delay_check_interval=config['delay_check_interval'],
                delay_log_file=config['delay_log_file'],
                monitor_warm_up_time=config.get('monitor_warm_up_time'),
                delay_trends_analysis  =config.get('delay_trends_analysis', False),
                use_virtual_table=use_virtual_table 
            )
            
            # æ‰“å¼€æ—¥å¿—æ–‡ä»¶å¹¶è®¾ç½®è¾“å‡ºé‡å®šå‘
            
            try:
                log_file = open(config['test_log_file'], 'w')
                print(f"æˆåŠŸæ‰“å¼€æ—¥å¿—æ–‡ä»¶: {config['test_log_file']}")
            except Exception as e:
                print(f"æ— æ³•æ‰“å¼€æ—¥å¿—æ–‡ä»¶: {str(e)}")
                log_file = None
            
            # åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶
            class TeeOutput:
                def __init__(self, *files):
                    self.files = []
                    for f in files:
                        if f is not None and hasattr(f, 'write') and not getattr(f, 'closed', False):
                            self.files.append(f)
                            
                def write(self, text):
                    for f in self.files:
                        try:
                            if not getattr(f, 'closed', False):
                                f.write(text)
                                f.flush()
                        except (ValueError, OSError, AttributeError) as e:
                            pass
                        
                def flush(self):
                    for f in self.files:
                        try:
                            if not getattr(f, 'closed', False):
                                f.flush()
                        except (ValueError, OSError, AttributeError):
                            pass
            
            if log_file:
                sys.stdout = TeeOutput(original_stdout, log_file)
            else:
                print("è­¦å‘Š: æ—¥å¿—æ–‡ä»¶æ‰“å¼€å¤±è´¥ï¼Œä»…è¾“å‡ºåˆ°æ§åˆ¶å°")
            
            # æ‰§è¡Œæµ‹è¯•
            print(f"å¼€å§‹æ‰§è¡Œæµè®¡ç®—æµ‹è¯•: {test_name}")
            print(f"å»¶è¿Ÿç›‘æ§çŠ¶æ€: {'å¯ç”¨' if config['check_stream_delay'] else 'ç¦ç”¨'}")
            print(f"æ€§èƒ½ç›‘æ§æ–‡ä»¶: {config['perf_file']}")
            print(f"æµæ•°é‡: {config.get('stream_num', 1)}") 
            
            # âœ… éªŒè¯é¢„çƒ­æ—¶é—´æ˜¯å¦æ­£ç¡®ä¼ é€’
            if hasattr(starter, 'monitor_warm_up_time'):
                print(f"é¢„çƒ­æ—¶é—´é…ç½®: {starter.monitor_warm_up_time}ç§’")
            else:
                print(f"è­¦å‘Š: é¢„çƒ­æ—¶é—´å‚æ•°æœªè®¾ç½®")
            
            
            # æ ¸å¿ƒæµ‹è¯•é€»è¾‘ - ä½¿ç”¨å†…éƒ¨å¼‚å¸¸å¤„ç†
            test_error = None
            try:
                starter.do_test_stream_with_realtime_data()
            except Exception as inner_e:
                # æ•è·å…·ä½“çš„æµåˆ›å»ºæˆ–æ‰§è¡Œé”™è¯¯
                error_message = str(inner_e)
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯æµåˆ›å»ºç›¸å…³çš„é”™è¯¯
                if any(keyword in error_message.lower() for keyword in ['create stream', 'cursor.execute', '%%tbname']):
                    test_error = extract_stream_creation_error(error_message)
                else:
                    test_error = extract_tdengine_error(error_message)
                
            # æ­£å¸¸å®Œæˆæˆ–æœ‰é”™è¯¯ï¼Œéƒ½å…ˆå®‰å…¨åœ°å…³é—­æ–‡ä»¶å’Œæ¢å¤è¾“å‡º
            sys.stdout = original_stdout
            if log_file:
                log_file.close()
                log_file = None
                
            # å¦‚æœæœ‰é”™è¯¯ï¼Œç°åœ¨æŠ›å‡º
            if test_error:
                raise Exception(test_error)
                
            end_time = time.time()
            duration = end_time - start_time
            
            result.update({
                'status': 'SUCCESS',
                'end_time': datetime.datetime.now().isoformat(),
                'duration': duration
            })
            
            print(f"æµ‹è¯• {test_name} å®Œæˆï¼Œè€—æ—¶: {duration:.2f}ç§’")
            
        except Exception as e:
            end_time = time.time()
            duration = end_time - start_time
            
            # ä½¿ç”¨å¼‚å¸¸æ¶ˆæ¯ä½œä¸ºé”™è¯¯ä¿¡æ¯
            error_message = str(e)
            
            # ç¡®ä¿é”™è¯¯ä¿¡æ¯ä¸ä¸ºç©º
            if not error_message or error_message.strip() == "":
                error_message = "æœªçŸ¥é”™è¯¯: æµ‹è¯•æ‰§è¡Œå¤±è´¥ä½†æ— å…·ä½“é”™è¯¯ä¿¡æ¯"
            
            result.update({
                'status': 'FAILED',
                'end_time': datetime.datetime.now().isoformat(),
                'duration': duration,
                'error': error_message
            })
            
            print(f"æµ‹è¯• {test_name} å¤±è´¥: {error_message}")
            
            self.failed_tests.append(result)
            
        finally:
            # å®‰å…¨åœ°æ¢å¤æ ‡å‡†è¾“å‡ºå’Œå…³é—­æ–‡ä»¶
            if sys.stdout != original_stdout:
                sys.stdout = original_stdout
            
            if log_file and not log_file.closed:
                try:
                    log_file.close()
                except:
                    pass
            
            # å¼ºåˆ¶æ¸…ç†ç¯å¢ƒï¼Œä¸ºä¸‹ä¸€ä¸ªæµ‹è¯•åšå‡†å¤‡
            print("æµ‹è¯•åå…¨é¢æ¸…ç†ç¯å¢ƒ...")
           
            # ä¸ºä¸‹ä¸€ä¸ªæµ‹è¯•ç•™å‡ºç¼“å†²æ—¶é—´
            if self.current_test_index < self.total_tests:
                
                try:
                    # 1. å¼ºåˆ¶åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹
                    print("  â†’ åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹")
                    subprocess.run('pkill -9 taosd', shell=True)
                    time.sleep(2)
                    
                    # 2. æ¸…ç†å¯èƒ½çš„ç›‘æ§çº¿ç¨‹å’Œæ–‡ä»¶å¥æŸ„
                    print("  â†’ æ¸…ç†ç³»ç»Ÿèµ„æº")
                    import gc
                    gc.collect()
                    
                    # 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    print("  â†’ æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
                    subprocess.run('rm -f /tmp/stream_from*.json', shell=True)
                    subprocess.run('rm -f /tmp/taosBenchmark_result.log', shell=True)
                    
                    # 4. æ£€æŸ¥æ´»è·ƒçº¿ç¨‹æ•°
                    import threading
                    active_threads = threading.active_count()
                    print(f"  â†’ å½“å‰æ´»è·ƒçº¿ç¨‹æ•°: {active_threads}")
                    
                    # 5. éªŒè¯æ¸…ç†ç»“æœ
                    check_result = subprocess.run('ps -ef | grep taosd | grep -v grep', 
                                                shell=True, capture_output=True, text=True)
                    if check_result.stdout:
                        print(f"  âš ï¸  è­¦å‘Š: ä»æœ‰taosdè¿›ç¨‹è¿è¡Œï¼Œå¯èƒ½å½±å“ä¸‹ä¸ªæµ‹è¯•")
                    else:
                        print(f"  âœ… ç¯å¢ƒæ¸…ç†å®Œæˆ")
                        
                except Exception as cleanup_e:
                    print(f"  âš ï¸  æ¸…ç†è¿‡ç¨‹å‡ºé”™: {str(cleanup_e)}")
                    
                print("  â†’ ç­‰å¾…3ç§’åå¼€å§‹ä¸‹ä¸€ä¸ªæµ‹è¯•...")
                time.sleep(3)
                
            else:
                print("âœ… è¿™æ˜¯æœ€åä¸€ä¸ªæµ‹è¯•ï¼Œä¿ç•™ç¯å¢ƒä¾›åˆ†æä½¿ç”¨")
                print("ğŸ’¡ å¦‚éœ€åœæ­¢æ‰€æœ‰è¿›ç¨‹ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: pkill taosd")
            
        return result
            
            
    def cleanup_environment(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            print("æ‰§è¡Œå¢å¼ºç¯å¢ƒæ¸…ç†...")
            
            # 1. å¼ºåˆ¶åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹
            print("  â†’ å¼ºåˆ¶åœæ­¢taosdè¿›ç¨‹")
            subprocess.run('pkill -9 taosd', shell=True)
            time.sleep(2)
            # å¼ºåˆ¶åœæ­¢æ‰€æœ‰æ´»è·ƒçš„ç›‘æ§çº¿ç¨‹
            stopped_threads = []
            for thread in threading.enumerate():
                if thread.name in ["MonitorSystemLoad", "TaosdMonitor", "StreamDelayMonitor", "DelayedStreamCreation", "ContinuousDataWriter"]:
                    try:
                        print(f"    å‘ç°æ´»è·ƒç›‘æ§çº¿ç¨‹: {thread.name}")
                        if hasattr(thread, '_target') and hasattr(thread._target, '__self__'):
                            monitor_obj = thread._target.__self__
                            if hasattr(monitor_obj, 'stop'):
                                print(f"    è°ƒç”¨ {thread.name} çš„stop()æ–¹æ³•")
                                monitor_obj.stop()
                            elif hasattr(monitor_obj, '_stop_event'):
                                print(f"    è®¾ç½® {thread.name} çš„_stop_event")
                                monitor_obj._stop_event.set()
                            elif hasattr(monitor_obj, '_should_stop'):
                                print(f"    è®¾ç½® {thread.name} çš„_should_stopæ ‡å¿—")
                                monitor_obj._should_stop = True
                        
                        # é€šç”¨çš„åœæ­¢æ ‡å¿—è®¾ç½®
                        if hasattr(thread, '_should_stop'):
                            thread._should_stop = True
                            print(f"    å·²è®¾ç½®çº¿ç¨‹ {thread.name} çš„åœæ­¢æ ‡å¿—")
                        
                        stopped_threads.append(thread.name)
                    except Exception as e:
                        print(f"    è®¾ç½®çº¿ç¨‹åœæ­¢æ ‡å¿—å¤±è´¥: {str(e)}")
            
            # ç­‰å¾…ç›‘æ§çº¿ç¨‹è‡ªç„¶ç»“æŸ
            if stopped_threads:
                print(f"  â†’ ç­‰å¾… {len(stopped_threads)} ä¸ªç›‘æ§çº¿ç¨‹ç»“æŸ...")
                start_wait = time.time()
                max_wait = 5  # æœ€å¤šç­‰å¾…5ç§’
                
                while time.time() - start_wait < max_wait:
                    active_monitor_threads = []
                    for thread in threading.enumerate():
                        if thread.name in ["MonitorSystemLoad", "TaosdMonitor", "StreamDelayMonitor", "DelayedStreamCreation", "ContinuousDataWriter"]:
                            active_monitor_threads.append(thread.name)
                    
                    if not active_monitor_threads:
                        print(f"  âœ… æ‰€æœ‰ç›‘æ§çº¿ç¨‹å·²åœæ­¢")
                        break
                        
                    print(f"    ç­‰å¾…ä¸­ï¼Œå‰©ä½™æ´»è·ƒçº¿ç¨‹: {', '.join(active_monitor_threads)}")
                    time.sleep(1)
                else:
                    print(f"  âš ï¸  è¶…æ—¶ï¼šä»æœ‰ç›‘æ§çº¿ç¨‹æœªç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­æ¸…ç†")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶ï¼Œæ¸…ç†å¯èƒ½çš„èµ„æº
            import gc
            gc.collect()
                   
            # å¤šæ¬¡å°è¯•åœæ­¢è¿›ç¨‹
            max_attempts = 5
            for attempt in range(max_attempts):
                # é¦–å…ˆå°è¯•æ­£å¸¸åœæ­¢
                subprocess.run('pkill -15 -f "^taosd.*-c.*conf"', shell=True)
                time.sleep(1)
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¿›ç¨‹
                result = subprocess.run('pgrep -f "^taosd.*-c.*conf"', shell=True, capture_output=True)
                if result.returncode != 0:  # æ²¡æœ‰æ‰¾åˆ°è¿›ç¨‹
                    print("  âœ… æ‰€æœ‰taosdè¿›ç¨‹å·²åœæ­¢")
                    break
                
                # å¼ºåˆ¶åœæ­¢
                subprocess.run('pkill -9 -f "^taosd.*-c.*conf"', shell=True)
                time.sleep(1)
                
                # å†æ¬¡æ£€æŸ¥
                result = subprocess.run('pgrep -f "^taosd.*-c.*conf"', shell=True, capture_output=True)
                if result.returncode != 0:
                    print("  âœ… æ‰€æœ‰taosdè¿›ç¨‹å·²åœæ­¢")
                    break
                else:
                    print(f"  âš ï¸  ç¬¬{attempt+1}æ¬¡å°è¯•: ä»æœ‰taosdè¿›ç¨‹è¿è¡Œï¼Œç»§ç»­æ¸…ç†...")
        
            # âœ… 2. æ¸…ç†å¯èƒ½çš„ç›‘æ§çº¿ç¨‹å’Œèµ„æº
            print("  â†’ å¼ºåˆ¶æ¸…ç†ç›‘æ§èµ„æº")
            
            # å¼ºåˆ¶åƒåœ¾å›æ”¶
            gc.collect()
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©æ‰€æœ‰çº¿ç¨‹ç»“æŸ
            time.sleep(2)
            
            # âœ… 3. æ¸…ç†ä¸´æ—¶æ–‡ä»¶å’Œsocketæ–‡ä»¶
            print("  â†’ æ¸…ç†ä¸´æ—¶æ–‡ä»¶")
            temp_patterns = [
                '/tmp/stream_from*.json',
                '/tmp/taosBenchmark_result.log',
                '/tmp/testlog/*',
            ]
            
            # å•ç‹¬å¤„ç†å¯èƒ½æœ‰é—®é¢˜çš„æ–‡ä»¶æ¨¡å¼
            socket_patterns = [
                '/tmp/*.sock*',
                '/tmp/taos*.sock'
            ]
            
            for pattern in temp_patterns:
                try:
                    subprocess.run(f'rm -f {pattern}', shell=True)
                except:
                    pass
                    
            # å°å¿ƒå¤„ç†socketæ–‡ä»¶ï¼Œé¿å…åˆ é™¤é‡è¦æ–‡ä»¶
            for pattern in socket_patterns:
                try:
                    # ä½¿ç”¨findå‘½ä»¤æ›´å®‰å…¨åœ°åˆ é™¤
                    subprocess.run(f'find /tmp -name "{pattern.split("/")[-1]}" -type f -delete 2>/dev/null', shell=True)
                except:
                    pass
            
            # 4. æœ€ç»ˆéªŒè¯
            print("  â†’ éªŒè¯æ¸…ç†ç»“æœ")
            result = subprocess.run('ps -ef | grep "taosd.*-c.*conf" | grep -v grep', 
                                    shell=True, capture_output=True, text=True)
            if result.stdout:
                print(f"  âš ï¸  è­¦å‘Š: å‘ç°æ®‹ç•™è¿›ç¨‹:")
                for line in result.stdout.strip().split('\n'):
                    print(f"       {line}")
                # æœ€åä¸€æ¬¡å¼ºåˆ¶æ¸…ç†
                subprocess.run('pkill -9 -f "^taosd.*-c.*conf"', shell=True)
                time.sleep(1)
            else:
                print(f"  âœ… ç¯å¢ƒæ¸…ç†éªŒè¯é€šè¿‡")
            
            # 5. æ£€æŸ¥å’ŒæŠ¥å‘Šæ´»è·ƒçº¿ç¨‹çŠ¶æ€
            print("  â†’ æ£€æŸ¥æ´»è·ƒçº¿ç¨‹çŠ¶æ€")
            active_monitor_threads = []
            for thread in threading.enumerate():
                if thread.name in ["MonitorSystemLoad", "TaosdMonitor", "StreamDelayMonitor", "DelayedStreamCreation", "ContinuousDataWriter"]:
                    active_monitor_threads.append(thread.name)
            
            if active_monitor_threads:
                print(f"  âš ï¸  è­¦å‘Š: ä»æœ‰æ´»è·ƒçš„ç›‘æ§çº¿ç¨‹: {', '.join(active_monitor_threads)}")
                print(f"    è¿™äº›çº¿ç¨‹åœ¨ä¸‹æ¬¡æµ‹è¯•æ—¶ä¼šè‡ªåŠ¨åœæ­¢")
            else:
                print(f"  âœ… æ‰€æœ‰ç›‘æ§çº¿ç¨‹å·²æ¸…ç†")
                
            total_active_threads = threading.active_count()
            print(f"  â†’ å½“å‰æ€»æ´»è·ƒçº¿ç¨‹æ•°: {total_active_threads}")
            
            print("å¢å¼ºç¯å¢ƒæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            print(f"å¢å¼ºç¯å¢ƒæ¸…ç†æ—¶å‡ºé”™: {str(e)}")
    
    def save_test_config(self, config, result_dir):
        """ä¿å­˜æµ‹è¯•é…ç½®åˆ°æ–‡ä»¶"""
        config_file = os.path.join(result_dir, 'configs', f"{config['test_name']}_config.json")
        
        # åˆ›å»ºå¯åºåˆ—åŒ–çš„é…ç½®å‰¯æœ¬
        serializable_config = {}
        for key, value in config.items():
            if isinstance(value, (str, int, float, bool, list, dict, type(None))):
                serializable_config[key] = value
            else:
                serializable_config[key] = str(value)
        
        with open(config_file, 'w') as f:
            json.dump(serializable_config, f, indent=2)
    
    def generate_progress_report(self, result_dir):
        """ç”Ÿæˆè¿›åº¦æŠ¥å‘Š"""
        if not self.test_results:
            return
            
        report_file = os.path.join(result_dir, 'reports', 'progress_report.txt')
        
        with open(report_file, 'w') as f:
            f.write(f"æ‰¹é‡æµè®¡ç®—æµ‹è¯•è¿›åº¦æŠ¥å‘Š\n")
            f.write(f"{'='*60}\n")
            f.write(f"å¼€å§‹æ—¶é—´: {self.start_time}\n")
            f.write(f"å½“å‰æ—¶é—´: {datetime.datetime.now().isoformat()}\n")
            f.write(f"æ€»æµ‹è¯•æ•°: {self.total_tests}\n")
            f.write(f"å·²å®Œæˆ: {len(self.test_results)}\n")
            f.write(f"æˆåŠŸ: {len([r for r in self.test_results if r['status'] == 'SUCCESS'])}\n")
            f.write(f"å¤±è´¥: {len([r for r in self.test_results if r['status'] == 'FAILED'])}\n")
            f.write(f"è¿›åº¦: {(len(self.test_results)/self.total_tests)*100:.1f}%\n")
            f.write(f"\næœ€è¿‘å®Œæˆçš„æµ‹è¯•:\n")
            
            for result in self.test_results[-5:]:  # æ˜¾ç¤ºæœ€è¿‘5ä¸ª
                status_icon = "âœ“" if result['status'] == 'SUCCESS' else "âœ—"
                f.write(f"  {status_icon} {result['test_name']} - {result.get('duration', 0):.1f}s\n")
                
    
    def simple_delay_trends_analysis(self, delay_log_file):
        """è¶…ç®€åŒ–çš„å»¶è¿Ÿè¶‹åŠ¿åˆ†æ - åªæ˜¾ç¤ºæ—¶é—´åºåˆ—"""
        try:
            if not os.path.exists(delay_log_file):
                return "å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"
                
            with open(delay_log_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•æå–æ¯æ¬¡æ£€æŸ¥çš„ç»“æœ
            trend_lines = []
            check_pattern = r'ç¬¬\s+(\d+)\s+æ¬¡æ£€æŸ¥.*?æ£€æŸ¥æ—¶é—´:\s*([^\n]+)'
            
            # æ‰¾åˆ°æ‰€æœ‰æ£€æŸ¥è®°å½•
            check_matches = re.findall(check_pattern, content, re.DOTALL)
            #print(f"è°ƒè¯•: å»¶è¿Ÿè¶‹åŠ¿åˆ†æ - æ‰¾åˆ° {len(check_matches)} ä¸ªæ£€æŸ¥è®°å½•")
                    
            for check_index, check_match in enumerate(check_matches):
                try:
                    check_num, check_time = check_match
                    
                    # ä¿®å¤è§£åŒ…é—®é¢˜ï¼šæ£€æŸ¥ check_match çš„ç»“æ„
                    if isinstance(check_match, tuple) and len(check_match) >= 1:
                        check_num = check_match[0]
                        #print(f"è°ƒè¯•: æ£€æŸ¥å·: {check_num}")
                    elif isinstance(check_match, str):
                        check_num = check_match
                        #print(f"è°ƒè¯•: æ£€æŸ¥å·(å­—ç¬¦ä¸²): {check_num}")
                    else:
                        #print(f"è°ƒè¯•: æœªçŸ¥çš„æ£€æŸ¥è®°å½•æ ¼å¼: {type(check_match)}, {check_match}")
                        continue
                    
                    # åœ¨è¿™æ¬¡æ£€æŸ¥çš„å†…å®¹ä¸­æŸ¥æ‰¾å»¶è¿Ÿä¿¡æ¯
                    section_start = content.find(f'ç¬¬ {check_num} æ¬¡æ£€æŸ¥')
                    next_check_num = int(check_num) + 1
                    next_check = content.find(f'ç¬¬ {int(check_num)+1} æ¬¡æ£€æŸ¥')
                    if next_check == -1:
                        section = content[section_start:]
                    else:
                        section = content[section_start:next_check]
                    
                    
                    # æå–å»¶è¿Ÿæ—¶é—´æ•°æ®
                    delay_info = self._extract_delay_times_from_section(section)
                    
                    if delay_info and delay_info != "æ— å»¶è¿Ÿæ•°æ®":
                        trend_lines.append(f"{delay_info}")
                    else:
                        trend_lines.append(f"æ— æ•°æ®")
                        
                    # print(f"è°ƒè¯•: æ£€æŸ¥ {check_num} çš„å»¶è¿Ÿä¿¡æ¯: {delay_info}")
                        
                except Exception as e:
                    print(f"è°ƒè¯•: å¤„ç†æ£€æŸ¥è®°å½• {check_index + 1} æ—¶å‡ºé”™: {str(e)}")
                    print(f"è°ƒè¯•: é—®é¢˜è®°å½•å†…å®¹: {check_match}")
                    trend_lines.append(f"æ£€æŸ¥{check_index+1}: è§£æå¤±è´¥")
                    continue
            
            # ç¡®ä¿è‡³å°‘æœ‰1è¡Œå†…å®¹ï¼Œä¸å¤Ÿçš„è¯è¡¥å……ç©ºè¡Œ
            while len(trend_lines) < 1:
                trend_lines.append("ã€€")  # æ·»åŠ ç©ºè¡Œå ä½
        
            # è¿”å›å®Œæ•´çš„è¶‹åŠ¿æ•°æ®
            result = " | ".join(trend_lines) if trend_lines else "æ— è¶‹åŠ¿æ•°æ® | ã€€ | ã€€"
            
            # è°ƒè¯•è¾“å‡º
            # print(f"è°ƒè¯•: å»¶è¿Ÿè¶‹åŠ¿åˆ†æç»“æœé•¿åº¦: {len(result)}")
            print(f"è°ƒè¯•: è¶‹åŠ¿è¡Œæ•°: {len(trend_lines)}")
            print(f"è°ƒè¯•: æœ€ç»ˆç»“æœå‰200å­—ç¬¦: {result[:200]}")
            
            return result
            
        except Exception as e:
            error_msg = f"åˆ†æå¤±è´¥: {str(e)}"
            print(f"è°ƒè¯•: å»¶è¿Ÿè¶‹åŠ¿åˆ†æå¼‚å¸¸: {error_msg}")
            print(f"è°ƒè¯•: å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return error_msg

    def _extract_delay_times_from_section(self, section):
        """ä»æ£€æŸ¥æ®µè½ä¸­æå–å»¶è¿Ÿæ—¶é—´ä¿¡æ¯
        
        Args:
            section: å•æ¬¡æ£€æŸ¥çš„æ—¥å¿—å†…å®¹
            
        Returns:
            str: æ ¼å¼åŒ–çš„å»¶è¿Ÿæ—¶é—´ä¿¡æ¯
        """
        try:
            # æå–æ‰€æœ‰æµçš„å»¶è¿Ÿæ—¶é—´
            delay_values = []
            
            # åŒ¹é…æ¨¡å¼ï¼šæµåç§°å’Œå»¶è¿Ÿæ—¶é—´
            # å»¶è¿Ÿ: 1500ms (1.50ç§’)
            delay_pattern = r'æµåç§°:\s*([^\n]+).*?å»¶è¿Ÿ:\s*([^\n\(]+)'
            
            # ä¹ŸåŒ¹é…ç›®æ ‡è¡¨æ— æ•°æ®æˆ–ä¸å­˜åœ¨çš„æƒ…å†µ
            no_data_pattern = r'æµåç§°:\s*([^\n]+).*?è­¦å‘Š:\s*ç›®æ ‡è¡¨æ— æ•°æ®'
            error_pattern = r'æµåç§°:\s*([^\n]+).*?é”™è¯¯:'
            
            # æå–æ­£å¸¸å»¶è¿Ÿæ—¶é—´
            delay_matches = re.findall(delay_pattern, section, re.DOTALL)
            # print(f"è°ƒè¯•: æ‰¾åˆ° {len(delay_matches)} ä¸ªå»¶è¿Ÿè®°å½•")
            # print(f"è°ƒè¯•: å»¶è¿ŸåŒ¹é…ç»“æœ: {delay_matches}")
            
            for match_index, delay_match in enumerate(delay_matches):
                try:
                    if isinstance(delay_match, tuple) and len(delay_match) >= 2:
                        stream_name = delay_match[0].strip()
                        delay_str = delay_match[1].strip()
                        #print(f"è°ƒè¯•: å»¶è¿Ÿè®°å½• {match_index + 1}: æµ={stream_name}, å»¶è¿Ÿ={delay_str}")
                    else:
                        print(f"è°ƒè¯•: å»¶è¿Ÿè®°å½• {match_index + 1} æ ¼å¼å¼‚å¸¸: {delay_match}")
                        continue
                    
                    delay_ms = self._parse_delay_string(delay_str)
                
                    #print(f"è°ƒè¯•: è§£æåçš„å»¶è¿Ÿæ¯«ç§’æ•°: {delay_ms}")
                    if delay_ms is not None:
                        formatted_delay = self._format_delay_time_simple(delay_ms)
                        delay_values.append(formatted_delay)
                    else:
                        print(f"è°ƒè¯•: æ— æ³•è§£æå»¶è¿Ÿå­—ç¬¦ä¸²: {delay_str}")
                        delay_values.append("è§£æå¤±è´¥")
                    
                except Exception as e:
                    print(f"è°ƒè¯•: å¤„ç†å»¶è¿Ÿè®°å½• {match_index + 1} æ—¶å‡ºé”™: {str(e)}")
                    continue
            
            # æå–æ— æ•°æ®æƒ…å†µ
            no_data_matches = re.findall(no_data_pattern, section, re.DOTALL)
            #print(f"è°ƒè¯•: æ‰¾åˆ° {len(no_data_matches)} ä¸ªæ— æ•°æ®è®°å½•")
            for no_data_match in no_data_matches:
                try:
                    if isinstance(no_data_match, tuple):
                        delay_values.append("æ— æ•°æ®")
                    elif isinstance(no_data_match, str):
                        delay_values.append("æ— æ•°æ®")
                    else:
                        print(f"è°ƒè¯•: æ— æ•°æ®è®°å½•æ ¼å¼å¼‚å¸¸: {type(no_data_match)}, {no_data_match}")
                        delay_values.append("æ— æ•°æ®")
                except Exception as e:
                    print(f"è°ƒè¯•: å¤„ç†æ— æ•°æ®è®°å½•æ—¶å‡ºé”™: {str(e)}")
                    delay_values.append("æ— æ•°æ®")
            
            # æå–é”™è¯¯æƒ…å†µ
            error_matches = re.findall(error_pattern, section, re.DOTALL)
            #print(f"è°ƒè¯•: æ‰¾åˆ° {len(error_matches)} ä¸ªé”™è¯¯è®°å½•")
            for error_match in error_matches:
                try:
                    if isinstance(error_match, tuple):
                        delay_values.append("è¡¨ä¸å­˜åœ¨")
                    elif isinstance(error_match, str):
                        delay_values.append("è¡¨ä¸å­˜åœ¨")
                    else:
                        print(f"è°ƒè¯•: é”™è¯¯è®°å½•æ ¼å¼å¼‚å¸¸: {type(error_match)}, {error_match}")
                        delay_values.append("è¡¨ä¸å­˜åœ¨")
                except Exception as e:
                    print(f"è°ƒè¯•: å¤„ç†é”™è¯¯è®°å½•æ—¶å‡ºé”™: {str(e)}")
                    delay_values.append("è¡¨ä¸å­˜åœ¨")
            
            #print(f"è°ƒè¯•: æ€»å…±æ”¶é›†åˆ° {len(delay_values)} ä¸ªå»¶è¿Ÿå€¼: {delay_values}")
            
            if delay_values:
                result = " | ".join(delay_values)
                #print(f"è°ƒè¯•: ç”Ÿæˆç»“æœ: {result}")
                return result
            else:
                print(f"è°ƒè¯•: æ— å»¶è¿Ÿæ•°æ®")
                return "æ— å»¶è¿Ÿæ•°æ®"
                
        except Exception as e:
            error_msg = f"è§£æé”™è¯¯: {str(e)}"
            print(f"è°ƒè¯•: æå–å»¶è¿Ÿæ—¶é—´æ—¶å‡ºé”™: {error_msg}")
            print(f"è°ƒè¯•: å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return error_msg

    def _parse_delay_string(self, delay_str):
        """è§£æå»¶è¿Ÿå­—ç¬¦ä¸²ï¼Œæå–æ¯«ç§’æ•°
        
        Args:
            delay_str: å»¶è¿Ÿå­—ç¬¦ä¸²ï¼Œå¦‚ "1500ms" æˆ– "1.50ç§’" æˆ– "1m25.9s"
            
        Returns:
            int: å»¶è¿Ÿæ¯«ç§’æ•°ï¼Œè§£æå¤±è´¥è¿”å›None
        """
        try:
            delay_str = delay_str.strip()
            # print(f"è°ƒè¯•: _parse_delay_string è¾“å…¥: '{delay_str}'")
            
            # âœ… ä¿®å¤ï¼šæ›´ç²¾ç¡®çš„æ¯«ç§’æ ¼å¼åŒ¹é… - ä¼˜å…ˆçº§æœ€é«˜
            ms_match = re.search(r'(\d+(?:\.\d+)?)ms\b', delay_str)
            if ms_match:
                ms_value = int(float(ms_match.group(1)))
                print(f"è°ƒè¯•: åŒ¹é…åˆ°æ¯«ç§’æ ¼å¼: {ms_match.group(1)}ms -> {ms_value}ms")
                return ms_value
            
            # âœ… ä¿®å¤ï¼šæ›´ç²¾ç¡®çš„ç§’æ ¼å¼åŒ¹é…ï¼ˆè‹±æ–‡sï¼‰
            s_match = re.search(r'(\d+(?:\.\d+)?)s\b', delay_str)
            if s_match:
                s_value = float(s_match.group(1))
                ms_value = int(s_value * 1000)
                # print(f"è°ƒè¯•: åŒ¹é…åˆ°ç§’æ ¼å¼: {s_match.group(1)}s -> {ms_value}ms")
                return ms_value
            
            # âœ… ä¿®å¤ï¼šä¸­æ–‡ç§’æ ¼å¼åŒ¹é…
            cn_s_match = re.search(r'(\d+(?:\.\d+)?)ç§’\b', delay_str)
            if cn_s_match:
                s_value = float(cn_s_match.group(1))
                ms_value = int(s_value * 1000)
                print(f"è°ƒè¯•: åŒ¹é…åˆ°ä¸­æ–‡ç§’æ ¼å¼: {cn_s_match.group(1)}ç§’ -> {ms_value}ms")
                return ms_value
            
            # å¤åˆæ—¶é—´æ ¼å¼: 1m25.9s, 2h30m15s ç­‰ - æ”¾åœ¨åé¢å¤„ç†
            complex_time_match = re.search(r'(?:(\d+(?:\.\d+)?)h)?(?:(\d+(?:\.\d+)?)m)?(?:(\d+(?:\.\d+)?)s)?', delay_str)
            if complex_time_match and any(complex_time_match.groups()):
                hours = float(complex_time_match.group(1)) if complex_time_match.group(1) else 0
                minutes = float(complex_time_match.group(2)) if complex_time_match.group(2) else 0  
                seconds = float(complex_time_match.group(3)) if complex_time_match.group(3) else 0
                
                # âœ… åªæœ‰åœ¨çœŸæ­£åŒ…å«å¤åˆæ ¼å¼æ—¶æ‰å¤„ç†
                if hours > 0 or minutes > 0:
                    total_ms = int((hours * 3600 + minutes * 60 + seconds) * 1000)
                    print(f"è°ƒè¯•: åŒ¹é…åˆ°å¤åˆæ—¶é—´æ ¼å¼: {hours}h {minutes}m {seconds}s -> {total_ms}ms")
                    return total_ms
            
            # åŒ¹é…åˆ†é’Ÿæ ¼å¼: 1.5m, 25m (ç‹¬ç«‹çš„åˆ†é’Ÿï¼Œä¸æ˜¯å¤åˆæ ¼å¼çš„ä¸€éƒ¨åˆ†)
            m_match = re.search(r'(\d+(?:\.\d+)?)m\b(?!s)', delay_str)  # é¿å…åŒ¹é…msä¸­çš„m
            if m_match:
                m_value = float(m_match.group(1))
                ms_value = int(m_value * 60 * 1000)
                print(f"è°ƒè¯•: åŒ¹é…åˆ°åˆ†é’Ÿæ ¼å¼: {m_match.group(1)}m -> {ms_value}ms")
                return ms_value
            
            # åŒ¹é…å°æ—¶æ ¼å¼: 1.5h, 2h (ç‹¬ç«‹çš„å°æ—¶)
            h_match = re.search(r'(\d+(?:\.\d+)?)h\b', delay_str)
            if h_match:
                h_value = float(h_match.group(1))
                ms_value = int(h_value * 3600 * 1000)
                print(f"è°ƒè¯•: åŒ¹é…åˆ°å°æ—¶æ ¼å¼: {h_match.group(1)}h -> {ms_value}ms")
                return ms_value
            
            # åŒ¹é…çº¯æ•°å­—ï¼ˆå‡è®¾æ˜¯æ¯«ç§’ï¼‰- æœ€åå¤„ç†
            num_match = re.search(r'^(\d+(?:\.\d+)?)$', delay_str)
            if num_match:
                num_value = int(float(num_match.group(1)))
                print(f"è°ƒè¯•: åŒ¹é…åˆ°çº¯æ•°å­—: {num_match.group(1)} -> å‡è®¾ä¸º{num_value}ms")
                return num_value
            
            print(f"è°ƒè¯•: æ— æ³•è§£æå»¶è¿Ÿå­—ç¬¦ä¸²: '{delay_str}'")
            return None
            
        except Exception as e:
            print(f"è°ƒè¯•: è§£æå»¶è¿Ÿå­—ç¬¦ä¸²æ—¶å‡ºé”™: {str(e)}")
            return None

    def _format_delay_time_simple(self, delay_ms):
        """æ ¼å¼åŒ–å»¶è¿Ÿæ—¶é—´ä¸ºç®€æ´æ˜¾ç¤º
        
        Args:
            delay_ms: å»¶è¿Ÿæ¯«ç§’æ•°
            
        Returns:
            str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸²
        """
        if delay_ms is None:
            return "N/A"
        
        if delay_ms < 1000:  # å°äº1ç§’ï¼Œæ˜¾ç¤ºæ¯«ç§’
            return f"{delay_ms}ms"
        elif delay_ms < 60000:  # å°äº1åˆ†é’Ÿï¼Œæ˜¾ç¤ºç§’
            seconds = delay_ms / 1000.0
            return f"{seconds:.1f}s"
        elif delay_ms < 3600000:  # å°äº1å°æ—¶ï¼Œæ˜¾ç¤ºåˆ†é’Ÿ
            minutes = delay_ms / 60000.0
            return f"{minutes:.1f}m"
        else:  # 1å°æ—¶ä»¥ä¸Šï¼Œæ˜¾ç¤ºå°æ—¶
            hours = delay_ms / 3600000.0
            return f"{hours:.1f}h"
                
    
    def generate_final_report_bak(self, result_dir):
        """ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        report_file = os.path.join(result_dir, 'reports', 'final_report.html')
        
        success_count = len([r for r in self.test_results if r['status'] == 'SUCCESS'])
        failed_count = len([r for r in self.test_results if r['status'] == 'FAILED'])
        total_duration = sum(r.get('duration', 0) for r in self.test_results)
        
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>æµè®¡ç®—æ‰¹é‡æµ‹è¯•æŠ¥å‘Š</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; }}
        .header {{ background-color: #f0f0f0; padding: 20px; border-radius: 5px; }}
        .summary {{ display: flex; justify-content: space-around; margin: 20px 0; }}
        .metric {{ text-align: center; padding: 10px; background-color: #e9e9e9; border-radius: 5px; }}
        .success {{ color: green; }}
        .failed {{ color: red; }}
        table {{ width: 100%; border-collapse: collapse; margin-top: 20px; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .status-success {{ background-color: #d4edda; }}
        .status-failed {{ background-color: #f8d7da; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>TDengine æµè®¡ç®—æ‰¹é‡æµ‹è¯•æŠ¥å‘Š</h1>
        <p>ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p>æµ‹è¯•å¼€å§‹: {self.start_time}</p>
        <p>æµ‹è¯•ç»“æŸ: {datetime.datetime.now().isoformat()}</p>
    </div>
    
    <div class="summary">
        <div class="metric">
            <h3>æ€»æµ‹è¯•æ•°</h3>
            <h2>{self.total_tests}</h2>
        </div>
        <div class="metric success">
            <h3>æˆåŠŸ</h3>
            <h2>{success_count}</h2>
        </div>
        <div class="metric failed">
            <h3>å¤±è´¥</h3>
            <h2>{failed_count}</h2>
        </div>
        <div class="metric">
            <h3>æˆåŠŸç‡</h3>
            <h2>{(success_count/self.total_tests*100):.1f}%</h2>
        </div>
        <div class="metric">
            <h3>æ€»è€—æ—¶</h3>
            <h2>{total_duration/3600:.1f}å°æ—¶</h2>
        </div>
    </div>
    
    <h2>è¯¦ç»†æµ‹è¯•ç»“æœ</h2>
    <table>
        <tr>
            <th>æµ‹è¯•åç§°</th>
            <th>SQLç±»å‹</th>
            <th>æŸ¥è¯¢ç±»å‹</th>
            <th>FROMç±»å‹</th>
            <th>çŠ¶æ€</th>
            <th>è€—æ—¶(ç§’)</th>
            <th>é”™è¯¯ä¿¡æ¯</th>
        </tr>
"""
        
        for result in self.test_results:
            config = result['config']
            status_class = 'status-success' if result['status'] == 'SUCCESS' else 'status-failed'
            error_msg = result.get('error', '')[:100] if result.get('error') else ''
            
            html_content += f"""
        <tr class="{status_class}">
            <td>{result['test_name']}</td>
            <td>{config['sql_type']}</td>
            <td>{config['agg_or_select']}</td>
            <td>{config['tbname_or_trows_or_sourcetable']}</td>
            <td>{result['status']}</td>
            <td>{result.get('duration', 0):.1f}</td>
            <td>{error_msg}</td>
        </tr>
"""
        
        html_content += """
    </table>
</body>
</html>
"""
        
        with open(report_file, 'w') as f:
            f.write(html_content)
        
        print(f"æœ€ç»ˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


    def generate_final_report(self, result_dir):
        """ç”Ÿæˆæœ€ç»ˆæµ‹è¯•æŠ¥å‘Š"""
        report_file = os.path.join(result_dir, 'reports', 'final_report.html')
        perf_node = getattr(self, 'perf_node', 'dnode1')
        # perf_file_node = perf_file.replace('.log', f'-{perf_node}.log')
        
        success_count = len([r for r in self.test_results if r['status'] == 'SUCCESS'])
        failed_count = len([r for r in self.test_results if r['status'] == 'FAILED'])
        skipped_count = len([r for r in self.test_results if r['status'] == 'SKIPPED'])
        skip_failure_count = len([r for r in self.test_results if r['status'] == 'SKIP_FAILURE'])
        skip_poor_performance_count = len([r for r in self.test_results if r['status'] == 'SKIP_POOR_PERFORMANCE'])
        
        # æ€»çš„è·³è¿‡æ•°é‡
        total_skipped = skipped_count + skip_failure_count + skip_poor_performance_count
        
        print(f"è°ƒè¯•ç»Ÿè®¡: æˆåŠŸ={success_count}, å¤±è´¥={failed_count}, è·³è¿‡å¤±è´¥={skip_failure_count}, è·³è¿‡æ€§èƒ½={skip_poor_performance_count}, å…¶ä»–è·³è¿‡={skipped_count}")
        
        total_duration = sum(r.get('duration', 0) for r in self.test_results)
        current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æµ‹è¯•ç»“æœ
        if not self.test_results:
            print("è­¦å‘Š: æ²¡æœ‰æµ‹è¯•ç»“æœå¯ä»¥ç”ŸæˆæŠ¥å‘Š")
            # ç”Ÿæˆä¸€ä¸ªç®€å•çš„ç©ºæŠ¥å‘Š
            report_file = os.path.join(result_dir, 'reports', 'final_report.html')
            try:
                os.makedirs(os.path.dirname(report_file), exist_ok=True)
                with open(report_file, 'w', encoding='utf-8') as f:
                    f.write(f"""
<!DOCTYPE html>
<html>
<head>
    <title>æµè®¡ç®—æ‰¹é‡æµ‹è¯•æŠ¥å‘Š - æ— æµ‹è¯•ç»“æœ</title>
    <meta charset="UTF-8">
</head>
<body>
    <h1>æµè®¡ç®—æ‰¹é‡æµ‹è¯•æŠ¥å‘Š</h1>
    <p>ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    <p><strong>è­¦å‘Š:</strong> æ²¡æœ‰æµ‹è¯•ç»“æœå¯ä»¥æ˜¾ç¤ºã€‚</p>
    <p>å¯èƒ½çš„åŸå› :</p>
    <ul>
        <li>è¿‡æ»¤è®¾ç½®å¯¼è‡´æ‰€æœ‰æµ‹è¯•éƒ½è¢«è·³è¿‡</li>
        <li>æµ‹è¯•é…ç½®é”™è¯¯</li>
        <li>æµ‹è¯•æå‰ç»ˆæ­¢</li>
    </ul>
    <p>è¯·æ£€æŸ¥è¿‡æ»¤æ¨¡å¼å’ŒSQLç±»å‹è®¾ç½®ã€‚</p>
</body>
</html>
""")
                print(f"ç©ºæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")
            except Exception as e:
                print(f"ç”Ÿæˆç©ºæŠ¥å‘Šå¤±è´¥: {str(e)}")
            return
        
        report_file = os.path.join(result_dir, 'reports', 'final_report.html')
        
        # é˜²æ­¢é™¤é›¶é”™è¯¯
        total_tests = len(self.test_results)
        if total_tests == 0:
            success_rate = 0
            avg_duration = 0
            efficiency = 0
        else:
            success_rate = (success_count / total_tests) * 100
            # avg_duration = total_duration / total_tests / 60
            # efficiency = total_tests / (total_duration / 3600) if total_duration > 0 else 0
            # å¹³å‡æ—¶é•¿åªè®¡ç®—æˆåŠŸçš„æµ‹è¯•
            if success_count > 0:
                avg_duration = sum(r.get('duration', 0) for r in self.test_results if r['status'] == 'SUCCESS') / success_count / 60
            else:
                avg_duration = 0
            
            # æ•ˆç‡è®¡ç®—ä¹ŸåŸºäºæˆåŠŸçš„æµ‹è¯•
            if success_count > 0 and total_duration > 0:
                efficiency = success_count / (total_duration / 3600)  # æˆåŠŸæµ‹è¯•æ•°/å°æ—¶
            else:
                efficiency = 0
        
        # è·å–ç³»ç»Ÿä¿¡æ¯
        def get_system_info():
            """è·å–ç³»ç»ŸCPUæ ¸æ•°å’Œæ€»å†…å­˜"""
            try:
                # è·å–CPUæ ¸æ•°
                cpu_count = None
                try:
                    result = subprocess.run('lscpu | grep "^CPU(s):"', shell=True, 
                                        capture_output=True, text=True)
                    if result.returncode == 0:
                        cpu_line = result.stdout.strip()
                        # è§£æ "CPU(s):                             16" æ ¼å¼
                        cpu_count = cpu_line.split(':')[1].strip()
                        print(f"è°ƒè¯•: è·å–åˆ°CPUæ ¸æ•°: {cpu_count}")
                except Exception as e:
                    print(f"è°ƒè¯•: è·å–CPUæ ¸æ•°å¤±è´¥: {str(e)}")
                
                # è·å–æ€»å†…å­˜
                total_memory_gb = None
                try:
                    result = subprocess.run('free -m | grep "^Mem:"', shell=True, 
                                        capture_output=True, text=True)
                    if result.returncode == 0:
                        mem_line = result.stdout.strip()
                        # è§£æ "Mem:           15944        1234        5678        ..." æ ¼å¼
                        total_memory_mb = int(mem_line.split()[1])
                        total_memory_gb = f"{total_memory_mb/1024:.1f}GB"
                        print(f"è°ƒè¯•: è·å–åˆ°æ€»å†…å­˜: {total_memory_gb}")
                except Exception as e:
                    print(f"è°ƒè¯•: è·å–æ€»å†…å­˜å¤±è´¥: {str(e)}")
                    
                return cpu_count, total_memory_gb
            except Exception as e:
                print(f"è°ƒè¯•: è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {str(e)}")
                return None, None
        
        system_cpu_count, system_total_memory = get_system_info()
        
        html_content = f"""
<!DOCTYPE html>
<html>
<head>
    <title>æµè®¡ç®—æ‰¹é‡æµ‹è¯•è¯¦ç»†æŠ¥å‘Š</title>
    <meta charset="UTF-8">
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 20px; }}
        .summary {{ display: flex; justify-content: space-around; margin: 20px 0; flex-wrap: wrap; }}
        .metric {{ text-align: center; padding: 20px; background-color: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); min-width: 150px; margin: 5px; }}
        .metric h3 {{ margin: 0 0 10px 0; color: #666; font-size: 14px; }}
        .metric h2 {{ margin: 0; font-size: 24px; }}
        .success {{ color: #28a745; }}
        .failed {{ color: #dc3545; }}
        .warning {{ color: #ffc107; }}
        .info {{ color: #17a2b8; }}
        
        /* è¡¨æ ¼æ ·å¼ */
        .table-container {{ background: white; border-radius: 10px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin: 20px 0; }}
        table {{ width: 100%; border-collapse: collapse; }}
        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 8px; text-align: left; font-weight: 600; font-size: 12px; }}
        td {{ border: none; padding: 12px 8px; text-align: left; border-bottom: 1px solid #eee; font-size: 11px; }}
        tr:hover {{ background-color: #f8f9fa; }}
        .status-success {{ background-color: #d4edda !important; }}
        .status-failed {{ background-color: #f8d7da !important; }}
        .status-skipped {{ background-color: #f8f9fa !important; }}
        
        /* çŠ¶æ€æ ‡ç­¾ */
        .status-badge {{ padding: 4px 8px; border-radius: 15px; font-size: 10px; font-weight: bold; text-transform: uppercase; }}
        .badge-success {{ background-color: #28a745; color: white; }}
        .badge-failed {{ background-color: #dc3545; color: white; }}
        .badge-skipped {{ background-color: #6c757d; color: white; }} 
        .badge-warning {{ background-color: #ffc107; color: #212529; }} 
        
        /* æ€§èƒ½æŒ‡æ ‡æ ·å¼ */
        .perf-good {{ color: #28a745; font-weight: bold; }}
        .perf-warning {{ color: #ffc107; font-weight: bold; }}
        .perf-danger {{ color: #dc3545; font-weight: bold; }}
        
        /* SQLå±•ç¤ºæ ·å¼ */
        .sql-preview {{ 
            font-family: 'Courier New', monospace; 
            font-size: 10px; 
            background-color: #f8f9fa; 
            padding: 5px; 
            border-radius: 3px; 
            max-width: 300px; 
            overflow: hidden; 
            text-overflow: ellipsis; 
            white-space: nowrap;
            cursor: pointer;
            border: 1px solid #dee2e6;
        }}
        .sql-preview:hover {{ background-color: #e9ecef; }}
        
        /* å»¶è¿Ÿè¶‹åŠ¿é¢„è§ˆæ ·å¼ */
        .delay-trends-preview {{ 
            font-family: 'Courier New', monospace; 
            font-size: 10px; 
            background-color: #f8f9fa; 
            padding: 5px; 
            border-radius: 3px; 
            max-width: 300px; 
            overflow: hidden; 
            text-overflow: ellipsis; 
            white-space: nowrap;
            cursor: pointer;
            border: 1px solid #dee2e6;
        }}
        .delay-trends-preview:hover {{ background-color: #e9ecef; }}
        
        /* å»¶è¿Ÿè¶‹åŠ¿å·¥å…·æç¤º */
        .trends-tooltip {{ position: relative; display: inline-block; }}
        .trends-tooltip .trendstooltiptext {{ 
            visibility: hidden; 
            width: 800px;
            min-height: 150px;
            max-height: 600px;  
            background-color: #333; 
            color: #fff; 
            text-align: left; 
            border-radius: 6px; 
            padding: 20px; 
            position: absolute; 
            z-index: 9999;
            top: 120%;        
            left: 50%; 
            margin-left: -400px;
            margin-top: 5px;
            opacity: 0; 
            transition: opacity 0.3s; 
            font-family: 'Courier New', monospace; 
            font-size: 12px; 
            white-space: pre-wrap; 
            overflow-y: auto;
            overflow-x: hidden;
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
            
            /* å…è®¸æ–‡æœ¬é€‰æ‹©å’Œå¤åˆ¶ */
            pointer-events: auto;
            user-select: text;
            -webkit-user-select: text;
            -moz-user-select: text;
            -ms-user-select: text;
            
            /* å¤šåˆ—æ˜¾ç¤ºæ”¯æŒ */
            line-height: 1.6;
            word-break: break-word;
            word-wrap: break-word;
        }}
        .trends-tooltip:hover .trendstooltiptext {{ visibility: visible; opacity: 1; }}
        
        /* å»¶è¿ŸæŒ‡æ ‡æ ·å¼ */
        .delay-excellent {{ color: #28a745; font-weight: bold; }}
        .delay-good {{ color: #20c997; font-weight: bold; }}
        .delay-normal {{ color: #ffc107; font-weight: bold; }}
        .delay-warning {{ color: #fd7e14; font-weight: bold; }}
        .delay-danger {{ color: #dc3545; font-weight: bold; }}
        .delay-critical {{ color: #6f42c1; font-weight: bold; }}
        .delay-no-data {{ color: #ff6b35; font-weight: bold; background-color: #fff3e0; padding: 2px 4px; border-radius: 3px; }}
        .delay-table-missing {{  color: #ffffff; font-weight: bold; background-color: #d32f2f; padding: 2px 4px; border-radius: 3px; }}
        
        /* å·¥å…·æç¤º */
        .tooltip {{ position: relative; display: inline-block; }}
        .tooltip .tooltiptext {{ 
            visibility: hidden; 
            width: 600px;
            min-height: 120px;
            max-height: 400px;
            background-color: #333; 
            color: #fff; 
            text-align: left; 
            border-radius: 6px; 
            padding: 15px; 
            position: absolute; 
            z-index: 9999;
            top: 120%;        
            left: 50%; 
            margin-left: -300px;
            margin-top: 5px;  
            opacity: 0; 
            transition: opacity 0.3s; 
            font-family: 'Courier New', monospace; 
            font-size: 11px; 
            white-space: pre-wrap; 
            overflow-y: auto;
            overflow-x: hidden;
            box-shadow: 0 4px 8px rgba(0,0,0,0.3);
            /* ç§»é™¤pointer-eventsé™åˆ¶ï¼Œå…è®¸æ–‡æœ¬é€‰æ‹©å’Œå¤åˆ¶ */
            pointer-events: auto;
            user-select: text;
            -webkit-user-select: text;
            -moz-user-select: text;
            -ms-user-select: text;
        }}
        .tooltip:hover .tooltiptext {{ visibility: visible; opacity: 1; }} 
        
        /* è‡ªå®šä¹‰æ»šåŠ¨æ¡æ ·å¼ */
        .tooltiptext::-webkit-scrollbar,
        .trendstooltiptext::-webkit-scrollbar {{
            width: 8px;
        }}
        .tooltiptext::-webkit-scrollbar-track,
        .trendstooltiptext::-webkit-scrollbar-track {{
            background: #555;
            border-radius: 4px;
        }}
        .tooltiptext::-webkit-scrollbar-thumb,
        .trendstooltiptext::-webkit-scrollbar-thumb {{
            background: #888;
            border-radius: 4px;
        }}
        .tooltiptext::-webkit-scrollbar-thumb:hover,
        .trendstooltiptext::-webkit-scrollbar-thumb:hover {{
            background: #aaa;
        }}
        
        
        /* æ™ºèƒ½å®šä½ç±» - å‘ä¸Šå¼¹å‡º */
        .tooltip .tooltiptext.upward,
        .trends-tooltip .trendstooltiptext.upward {{
            top: auto;
            bottom: 120%;
            margin-top: 0;
            margin-bottom: 5px;
        }}
        
        /* æ™ºèƒ½å®šä½ç±» - å‘å·¦åç§» */
        .tooltip .tooltiptext.leftward {{
            left: auto;
            right: 0;
            margin-left: 0;
            margin-right: -50px;
        }}
        .trends-tooltip .trendstooltiptext.leftward {{
            left: auto;
            right: 0;
            margin-left: 0;
            margin-right: -50px;
        }}
        
        /* æ™ºèƒ½å®šä½ç±» - å‘å³åç§» */
        .tooltip .tooltiptext.rightward {{
            left: 0;
            margin-left: -50px;
            margin-right: 0;
        }}
        .trends-tooltip .trendstooltiptext.rightward {{
            left: 0;
            margin-left: -50px;
            margin-right: 0;
        }}
        
        /* è‡ªå®šä¹‰æ»šåŠ¨æ¡æ ·å¼ */
        .tooltiptext::-webkit-scrollbar,
        .trendstooltiptext::-webkit-scrollbar {{
            width: 8px;
        }}
        .tooltiptext::-webkit-scrollbar-track,
        .trendstooltiptext::-webkit-scrollbar-track {{
            background: #555;
            border-radius: 4px;
        }}
        .tooltiptext::-webkit-scrollbar-thumb,
        .trendstooltiptext::-webkit-scrollbar-thumb {{
            background: #888;
            border-radius: 4px;
        }}
        .tooltiptext::-webkit-scrollbar-thumb:hover,
        .trendstooltiptext::-webkit-scrollbar-thumb:hover {{
            background: #aaa;
        }}
        
        /* ç­›é€‰å’Œæœç´¢ */
        .controls {{ margin: 20px 0; padding: 15px; background: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .filter-group {{ display: inline-block; margin-right: 20px; }}
        .filter-group label {{ font-weight: bold; margin-right: 5px; }}
        .filter-group select, .filter-group input {{ padding: 5px; border: 1px solid #ddd; border-radius: 4px; }}
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 1200px) {{
            th, td {{ font-size: 10px; padding: 8px 4px; }}
            .sql-preview {{ max-width: 200px; }}
            
            /* å°å±å¹•ä¸‹çš„å·¥å…·æç¤ºè°ƒæ•´ */
            .tooltip .tooltiptext {{
                width: 90vw;
                left: 50%;
                margin-left: -45vw;
            }}
            .trends-tooltip .trendstooltiptext {{
                width: 95vw;
                left: 50%;
                margin-left: -47.5vw;
            }}
        }}
    </style>
    <script>
        function filterTable() {{
            const statusFilter = document.getElementById('statusFilter').value;
            const sqlTypeFilter = document.getElementById('sqlTypeFilter').value;
            const fromTypeFilter = document.getElementById('fromTypeFilter').value;
            const searchTerm = document.getElementById('searchInput').value.toLowerCase();
            
            const table = document.getElementById('resultsTable');
            const rows = table.getElementsByTagName('tr');
            
            for (let i = 1; i < rows.length; i++) {{
                const row = rows[i];
                const status = row.cells[4].textContent;
                const sqlType = row.cells[1].textContent;
                const fromType = row.cells[3].textContent;
                const testName = row.cells[0].textContent.toLowerCase();
                
                let showRow = true;
                
                if (statusFilter && !status.includes(statusFilter)) showRow = false;
                if (sqlTypeFilter && sqlType !== sqlTypeFilter) showRow = false;
                
                // ä¿®æ”¹FROMç±»å‹è¿‡æ»¤é€»è¾‘ï¼Œæ”¯æŒåå‘ç­›é€‰
                if (fromTypeFilter) {{
                    if (fromTypeFilter.startsWith('!')) {{
                        // åå‘ç­›é€‰ï¼šæ’é™¤æŒ‡å®šç±»å‹
                        const excludeType = fromTypeFilter.substring(1);
                        if (fromType === excludeType) showRow = false;
                    }} else {{
                        // æ­£å‘ç­›é€‰ï¼šåªæ˜¾ç¤ºæŒ‡å®šç±»å‹
                        if (fromType !== fromTypeFilter) showRow = false;
                    }}
                }}
        
                if (searchTerm && !testName.includes(searchTerm)) showRow = false;
                
                row.style.display = showRow ? '' : 'none';
            }}
        }}
        
        function sortTable(columnIndex) {{
            const table = document.getElementById('resultsTable');
            const rows = Array.from(table.rows).slice(1);
            ////const isNumeric = columnIndex === 5 || columnIndex === 7 || columnIndex === 8|| columnIndex === 9 || columnIndex === 10 || columnIndex === 11 || columnIndex === 12; // è€—æ—¶ã€CPUå³°å€¼ã€å†…å­˜å³°å€¼ã€CPUå¹³å‡ã€å†…å­˜å¹³å‡ã€çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—ã€å†™å…¥é€Ÿåº¦
            //// âœ… æ›´æ–°åˆ—ç´¢å¼•æ³¨é‡Šï¼š
            //// åˆ—ç´¢å¼•: 0=æµ‹è¯•åç§°, 1=SQLç±»å‹, 2=æŸ¥è¯¢ç±»å‹, 3=FROMç±»å‹, 4=çŠ¶æ€, 5=è€—æ—¶
            //// 6=SQLé¢„è§ˆ, 7=CPUå³°å€¼, 8=å†…å­˜å³°å€¼, 9=CPUå¹³å‡, 10=å†…å­˜å¹³å‡, 11=çª—å£ç”Ÿæˆæ¯”ä¾‹
            //// 12=å†™å…¥é€Ÿåº¦, 13=å»¶è¿Ÿè¶‹åŠ¿, 14=é”™è¯¯ä¿¡æ¯
            //const isNumeric = columnIndex === 5 || columnIndex === 7 || columnIndex === 8|| columnIndex === 9 || columnIndex === 10 || columnIndex === 11 || columnIndex === 12; // è€—æ—¶ã€CPUå³°å€¼ã€å†…å­˜å³°å€¼ã€CPUå¹³å‡ã€å†…å­˜å¹³å‡ã€çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—ã€å†™å…¥é€Ÿåº¦
            
            
            //rows.sort((a, b) => {{
            //    const aVal = a.cells[columnIndex].textContent;
            //    const bVal = b.cells[columnIndex].textContent;
                
            //    if (isNumeric) {{
            //        // ç‰¹æ®Šå¤„ç†çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—ï¼ˆç¬¬11åˆ—ï¼‰
            //        if (columnIndex === 11) {{
            //            // æå–ç™¾åˆ†æ¯”æ•°å€¼
            //            const aPercent = parseFloat(aVal.replace('%', '').trim()) || 0;
            //            const bPercent = parseFloat(bVal.replace('%', '').trim()) || 0;
            //            return aPercent - bPercent;
            //        }} else {{
            //            // å…¶ä»–æ•°å€¼åˆ—çš„å¤„ç†
            //            return parseFloat(aVal) - parseFloat(bVal);
            //        }}
            //    }} else {{
            //        return aVal.localeCompare(bVal);
            //    }}
            //}});
            
            //rows.forEach(row => table.appendChild(row));
        //}}
        
            // è·å–è¡¨å¤´å…ƒç´ ï¼Œç”¨äºæ˜¾ç¤ºæ’åºçŠ¶æ€
            const headers = table.querySelectorAll('th');
            const currentHeader = headers[columnIndex];
            
            // è·å–å½“å‰æ’åºçŠ¶æ€ï¼ˆé€šè¿‡data-sortå±æ€§å­˜å‚¨ï¼‰
            let currentSort = currentHeader.getAttribute('data-sort') || 'none';
            let nextSort;
            
            // å¾ªç¯ï¼šnone -> asc -> desc -> none
            switch(currentSort) {{
                case 'none':
                    nextSort = 'asc';
                    break;
                case 'asc':
                    nextSort = 'desc';
                    break;
                case 'desc':
                    nextSort = 'none';
                    break;
                default:
                    nextSort = 'asc';
            }}
            
            // æ¸…é™¤æ‰€æœ‰è¡¨å¤´çš„æ’åºçŠ¶æ€æ˜¾ç¤º
            headers.forEach(header => {{
                header.removeAttribute('data-sort');
                // ç§»é™¤æ’åºæŒ‡ç¤ºç¬¦
                header.innerHTML = header.innerHTML.replace(/ â†‘| â†“/g, '');
            }});
            
            if (nextSort === 'none') {{
                // æ¢å¤åŸå§‹é¡ºåºï¼ˆæŒ‰æµ‹è¯•ç¼–å·ï¼‰
                rows.sort((a, b) => {{
                    const aTestName = a.cells[0].textContent;
                    const bTestName = b.cells[0].textContent;
                    
                    // æå–æµ‹è¯•ç¼–å·ï¼ˆtest_001_xxx æ ¼å¼ï¼‰
                    const aNum = parseInt(aTestName.match(/test_(\d+)_/)?.[1] || '0');
                    const bNum = parseInt(bTestName.match(/test_(\d+)_/)?.[1] || '0');
                    
                    return aNum - bNum;
                }});
                
                currentHeader.innerHTML += ' â—‹'; // åŸåºæ ‡è®°
            }} else {{
                // è®¾ç½®æ–°çš„æ’åºçŠ¶æ€
                currentHeader.setAttribute('data-sort', nextSort);
                
                // âœ… æ›´æ–°åˆ—ç´¢å¼•æ³¨é‡Šå’Œæ•°å€¼åˆ—åˆ¤æ–­ï¼š
                // åˆ—ç´¢å¼•: 0=æµ‹è¯•åç§°, 1=SQLç±»å‹, 2=æŸ¥è¯¢ç±»å‹, 3=FROMç±»å‹, 4=çŠ¶æ€, 5=è€—æ—¶
                // 6=SQLé¢„è§ˆ, 7=CPUå³°å€¼, 8=å†…å­˜å³°å€¼, 9=CPUå¹³å‡, 10=å†…å­˜å¹³å‡, 11=çª—å£ç”Ÿæˆæ¯”ä¾‹
                // 12=å†™å…¥é€Ÿåº¦, 13=å»¶è¿Ÿè¶‹åŠ¿, 14=é”™è¯¯ä¿¡æ¯
                const isNumeric = columnIndex === 5 || columnIndex === 7 || columnIndex === 8 || 
                                columnIndex === 9 || columnIndex === 10 || columnIndex === 11 || 
                                columnIndex === 12; // æ·»åŠ å†™å…¥é€Ÿåº¦åˆ—(ç¬¬12åˆ—)çš„æ•°å€¼æ’åºæ”¯æŒ
                
                rows.sort((a, b) => {{
                    const aVal = a.cells[columnIndex].textContent;
                    const bVal = b.cells[columnIndex].textContent;
                    
                    let comparison = 0;
                    
                    if (isNumeric) {{
                        // ç‰¹æ®Šå¤„ç†çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—ï¼ˆç¬¬11åˆ—ï¼‰
                        if (columnIndex === 11) {{
                            // æå–ç™¾åˆ†æ¯”æ•°å€¼
                            const aPercent = parseFloat(aVal.replace('%', '').trim()) || 0;
                            const bPercent = parseFloat(bVal.replace('%', '').trim()) || 0;
                            comparison = aPercent - bPercent;
                        }} 
                        // âœ… ç‰¹æ®Šå¤„ç†å†™å…¥é€Ÿåº¦åˆ—ï¼ˆç¬¬12åˆ—ï¼‰
                        else if (columnIndex === 12) {{
                            // æå–æ•°å€¼ï¼Œå¤„ç† "1,234 æ¡/ç§’" æ ¼å¼
                            const extractSpeed = (str) => {{
                                if (!str || str === 'N/A' || str === 'è·å–å¤±è´¥' || str === 'æ–‡ä»¶ä¸å­˜åœ¨') return 0;
                                const match = str.match(/([\d,]+(?:\.\d+)?)/);
                                return match ? parseFloat(match[1].replace(/,/g, '')) : 0;
                            }};
                            
                            const aSpeed = extractSpeed(aVal);
                            const bSpeed = extractSpeed(bVal);
                            comparison = aSpeed - bSpeed;
                        }} 
                        else {{
                            // å…¶ä»–æ•°å€¼åˆ—çš„å¤„ç†
                            const aNum = parseFloat(aVal.replace(/[^\d.-]/g, '')) || 0;
                            const bNum = parseFloat(bVal.replace(/[^\d.-]/g, '')) || 0;
                            comparison = aNum - bNum;
                        }}
                    }} else {{
                        comparison = aVal.localeCompare(bVal);
                    }}
                    
                    return nextSort === 'asc' ? comparison : -comparison;
                }});
                
                // æ·»åŠ æ’åºæŒ‡ç¤ºç¬¦
                currentHeader.innerHTML += nextSort === 'asc' ? ' â†‘' : ' â†“';
            }}
            
            // é‡æ–°æ’å…¥æ’åºåçš„è¡Œ
            rows.forEach(row => table.appendChild(row));
        }}

            
        // æ™ºèƒ½å·¥å…·æç¤ºå®šä½ç³»ç»Ÿ
        document.addEventListener('DOMContentLoaded', function() {{
            // è®¾ç½®é»˜è®¤ç­›é€‰ä¸ºæˆåŠŸ
            const statusFilter = document.getElementById('statusFilter');
            if (statusFilter) {{
                statusFilter.value = "SUCCESS";
                filterTable();
            }}
            
             // âœ… é»˜è®¤æŒ‰çª—å£ç”Ÿæˆæ¯”ä¾‹(ç¬¬11åˆ—)é™åºæ’åº
            setTimeout(() => {{
                const table = document.getElementById('resultsTable');
                if (table && table.rows.length > 1) {{
                    console.log('æ‰§è¡Œé»˜è®¤æ’åºï¼šæŒ‰çª—å£ç”Ÿæˆæ¯”ä¾‹é™åº');
                    
                    // ç›´æ¥è®¾ç½®ä¸ºé™åºçŠ¶æ€å¹¶æ’åº
                    const headers = table.querySelectorAll('th');
                    const targetHeader = headers[11]; // çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—
                    
                    if (targetHeader) {{
                        // æ¸…é™¤æ‰€æœ‰è¡¨å¤´çš„æ’åºçŠ¶æ€
                        headers.forEach(header => {{
                            header.removeAttribute('data-sort');
                            header.innerHTML = header.innerHTML.replace(/ â†‘| â†“| â—‹/g, '');
                        }});
                        
                        // è®¾ç½®çª—å£ç”Ÿæˆæ¯”ä¾‹åˆ—ä¸ºé™åº
                        targetHeader.setAttribute('data-sort', 'desc');
                        targetHeader.innerHTML += ' â†“';
                        
                        // æ‰§è¡Œæ’åº
                        const rows = Array.from(table.rows).slice(1);
                        rows.sort((a, b) => {{
                            const aVal = a.cells[11].textContent;
                            const bVal = b.cells[11].textContent;
                            
                            // æå–ç™¾åˆ†æ¯”æ•°å€¼
                            const aPercent = parseFloat(aVal.replace('%', '').trim()) || 0;
                            const bPercent = parseFloat(bVal.replace('%', '').trim()) || 0;
                            
                            return bPercent - aPercent; // é™åº
                        }});
                        
                        // é‡æ–°æ’å…¥æ’åºåçš„è¡Œ
                        rows.forEach(row => table.appendChild(row));
                        
                        console.log('é»˜è®¤æ’åºå®Œæˆ');
                    }}
                }}
            }}, 100); // å»¶è¿Ÿ100msç¡®ä¿è¡¨æ ¼å®Œå…¨æ¸²æŸ“
            
            console.log('é¡µé¢åŠ è½½å®Œæˆï¼Œåˆå§‹åŒ–æ™ºèƒ½å·¥å…·æç¤ºç³»ç»Ÿ...');
            
            // æ™ºèƒ½å®šä½å‡½æ•°
            function adjustTooltipPosition(tooltip, tooltipText, isWide = false) {{
                const rect = tooltip.getBoundingClientRect();
                const viewportHeight = window.innerHeight;
                const viewportWidth = window.innerWidth;
                
                // å·¥å…·æç¤ºå°ºå¯¸ (æ ¹æ®æ˜¯å¦ä¸ºå®½ç‰ˆæœ¬è°ƒæ•´)
                const tooltipHeight = isWide ? 600 : 400;
                const tooltipWidth = isWide ? 800 : 600;
                
                console.log(`è°ƒè¯•: å…ƒç´ ä½ç½® {{x: ${{rect.left}}, y: ${{rect.top}}, bottom: ${{rect.bottom}}}} è§†çª— {{w: ${{viewportWidth}}, h: ${{viewportHeight}}}}`);
                
                // é‡ç½®æ‰€æœ‰å®šä½ç±»
                tooltipText.classList.remove('upward', 'leftward', 'rightward');
                
                // å‚ç›´æ–¹å‘æ™ºèƒ½è°ƒæ•´
                if (rect.bottom + tooltipHeight > viewportHeight && rect.top > tooltipHeight) {{
                    // ä¸Šæ–¹ç©ºé—´è¶³å¤Ÿï¼Œå‘ä¸Šå¼¹å‡º
                    tooltipText.classList.add('upward');
                    console.log('æ·»åŠ  upward ç±» - å‘ä¸Šå¼¹å‡º');
                }}
                
                // æ°´å¹³æ–¹å‘æ™ºèƒ½è°ƒæ•´
                const centerNeeded = tooltipWidth / 2;
                if (rect.left + centerNeeded > viewportWidth) {{
                    // å³ä¾§ç©ºé—´ä¸è¶³ï¼Œå‘å·¦åç§»
                    tooltipText.classList.add('leftward');
                    console.log('æ·»åŠ  leftward ç±» - å‘å·¦åç§»');
                }} else if (rect.left - centerNeeded < 0) {{
                    // å·¦ä¾§ç©ºé—´ä¸è¶³ï¼Œå‘å³åç§»
                    tooltipText.classList.add('rightward');
                    console.log('æ·»åŠ  rightward ç±» - å‘å³åç§»');
                }}
            }}
            
            // ä¸ºæ‰€æœ‰SQLå·¥å…·æç¤ºæ·»åŠ æ™ºèƒ½å®šä½
            const sqlTooltips = document.querySelectorAll('.tooltip');
            console.log('æ‰¾åˆ°', sqlTooltips.length, 'ä¸ªSQLå·¥å…·æç¤º');
            
            sqlTooltips.forEach((tooltip, index) => {{
                const tooltipText = tooltip.querySelector('.tooltiptext');
                if (!tooltipText) return;
                
                tooltip.addEventListener('mouseenter', function() {{
                    adjustTooltipPosition(tooltip, tooltipText, false);
                }});
            }});
            
            // ä¸ºæ‰€æœ‰å»¶è¿Ÿè¶‹åŠ¿å·¥å…·æç¤ºæ·»åŠ æ™ºèƒ½å®šä½
            const trendsTooltips = document.querySelectorAll('.trends-tooltip');
            console.log('æ‰¾åˆ°', trendsTooltips.length, 'ä¸ªå»¶è¿Ÿè¶‹åŠ¿å·¥å…·æç¤º');
            
            trendsTooltips.forEach((tooltip, index) => {{
                const tooltipText = tooltip.querySelector('.trendstooltiptext');
                if (!tooltipText) return;
                
                tooltip.addEventListener('mouseenter', function() {{
                    console.log('é¼ æ ‡è¿›å…¥å»¶è¿Ÿè¶‹åŠ¿å·¥å…·æç¤º', index);
                    
                    // è·å–åŸå§‹çš„å»¶è¿Ÿè¶‹åŠ¿æ•°æ®
                    const originalData = tooltipText.textContent || tooltipText.innerText;
                    console.log('åŸå§‹å»¶è¿Ÿè¶‹åŠ¿æ•°æ®é•¿åº¦:', originalData.length);
                    console.log('åŸå§‹å»¶è¿Ÿè¶‹åŠ¿æ•°æ®é¢„è§ˆ:', originalData.substring(0, 100) + '...');
                    
                    // æ ¼å¼åŒ–æ•°æ®
                    const formattedData = formatDelayTrendsData(originalData);
                    console.log('æ ¼å¼åŒ–åæ•°æ®é•¿åº¦:', formattedData.length);
                    
                    // æ›´æ–°å·¥å…·æç¤ºå†…å®¹
                    tooltipText.textContent = formattedData;
                    
                    // è°ƒæ•´ä½ç½®
                    adjustTooltipPosition(tooltip, tooltipText, true);
                }});
                
                // æ·»åŠ å¤åˆ¶åŠŸèƒ½
                tooltip.addEventListener('click', function(e) {{
                    e.preventDefault();
                    e.stopPropagation();
                    
                    const textToCopy = tooltipText.textContent || tooltipText.innerText;
                    
                    // å°è¯•ä½¿ç”¨ç°ä»£APIå¤åˆ¶
                    if (navigator.clipboard && navigator.clipboard.writeText) {{
                        navigator.clipboard.writeText(textToCopy).then(function() {{
                            console.log('å»¶è¿Ÿè¶‹åŠ¿æ•°æ®å·²å¤åˆ¶åˆ°å‰ªè´´æ¿');
                            // å¯ä»¥æ·»åŠ ä¸€ä¸ªä¸´æ—¶æç¤º
                            const originalTitle = tooltip.title;
                            tooltip.title = 'å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼';
                            setTimeout(() => {{
                                tooltip.title = originalTitle;
                            }}, 2000);
                        }}).catch(function(err) {{
                            console.error('å¤åˆ¶å¤±è´¥:', err);
                            fallbackCopyTextToClipboard(textToCopy);
                        }});
                    }} else {{
                        // é™çº§æ–¹æ¡ˆ
                        fallbackCopyTextToClipboard(textToCopy);
                    }}
                }});
            }});
            
            // é™çº§å¤åˆ¶æ–¹æ¡ˆ
            function fallbackCopyTextToClipboard(text) {{
                const textArea = document.createElement("textarea");
                textArea.value = text;
                textArea.style.position = "fixed";
                textArea.style.top = "-1000px";
                textArea.style.left = "-1000px";
                document.body.appendChild(textArea);
                textArea.focus();
                textArea.select();
                
                try {{
                    const successful = document.execCommand('copy');
                    if (successful) {{
                        console.log('å»¶è¿Ÿè¶‹åŠ¿æ•°æ®å·²å¤åˆ¶åˆ°å‰ªè´´æ¿ï¼ˆé™çº§æ–¹æ¡ˆï¼‰');
                    }} else {{
                        console.error('å¤åˆ¶å‘½ä»¤æ‰§è¡Œå¤±è´¥');
                    }}
                }} catch (err) {{
                    console.error('é™çº§å¤åˆ¶æ–¹æ¡ˆä¹Ÿå¤±è´¥äº†:', err);
                }} finally {{
                    document.body.removeChild(textArea);
                }}
            }}
            
            console.log('æ™ºèƒ½å·¥å…·æç¤ºç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ');
        }});
        
        // æ ¼å¼åŒ–å»¶è¿Ÿè¶‹åŠ¿æ•°æ®ä¸ºå¤šåˆ—æ˜¾ç¤º
        function formatDelayTrendsData(trendsData) {{
            if (!trendsData || trendsData === 'N/A' || trendsData === 'æ— è¶‹åŠ¿æ•°æ®') {{
                return trendsData + '\\n\\nã€€\\nã€€\\nã€€';
            }}
            
            try {{
                // å¤„ç†HTMLå®ä½“å’Œæ¸…ç†æ•°æ®
                let cleanData = trendsData;
                
                // å¦‚æœæ•°æ®åŒ…å«HTMLè½¬ä¹‰å­—ç¬¦ï¼Œå…ˆè§£ç 
                if (cleanData.includes('&quot;') || cleanData.includes('&#39;') || cleanData.includes('&lt;') || cleanData.includes('&gt;')) {{
                    cleanData = cleanData
                        .replace(/&quot;/g, '"')
                        .replace(/&#39;/g, "'")
                        .replace(/&lt;/g, '<')
                        .replace(/&gt;/g, '>')
                        .replace(/\\\\n/g, '\\n')
                        .replace(/\\\\r/g, '\\r');
                }}
                
                console.log('æ¸…ç†å‰æ•°æ®:', trendsData.substring(0, 100) + '...');
                console.log('æ¸…ç†åæ•°æ®:', cleanData.substring(0, 100) + '...');
                
                // æŒ‰æ¢è¡Œç¬¦æˆ–<br>åˆ†å‰²æˆè¡Œ
                let lines = [];
                if (cleanData.includes('<br>')) {{
                    lines = cleanData.split('<br>');
                }} else if (cleanData.includes('\\n')) {{
                    lines = cleanData.split('\\n');
                }} else {{
                    // å¦‚æœæ²¡æœ‰æ˜æ˜¾çš„åˆ†éš”ç¬¦ï¼Œå°è¯•æŒ‰ | åˆ†å‰²å¹¶é‡æ–°ç»„ç»‡
                    const items = cleanData.split('|').map(item => item.trim()).filter(item => item);
                    if (items.length > 8) {{
                        // å¦‚æœé¡¹ç›®å¾ˆå¤šï¼ŒæŒ‰æ¯è¡Œ8ä¸ªé‡æ–°ç»„ç»‡
                        const itemsPerLine = 8;
                        for (let i = 0; i < items.length; i += itemsPerLine) {{
                            const lineItems = items.slice(i, i + itemsPerLine);
                            lines.push(lineItems.join(' | '));
                        }}
                    }} else {{
                        // å¦‚æœé¡¹ç›®ä¸å¤šï¼Œä¿æŒåŸæ ·
                        lines = [cleanData];
                    }}
                }}
                
                // è¿‡æ»¤ç©ºè¡Œå¹¶å¤„ç†æ¯è¡Œ
                lines = lines
                    .map(line => line.trim())
                    .filter(line => line && line !== '' && line !== 'ã€€')
                    .map((line, index) => {{
                        // å¦‚æœè¡Œå¾ˆé•¿ï¼ˆè¶…è¿‡80ä¸ªå­—ç¬¦ï¼‰ï¼Œå°è¯•åœ¨åˆé€‚çš„ä½ç½®æ–­è¡Œ
                        if (line.length > 80) {{
                            // åœ¨ | ç¬¦å·å¤„æ–­è¡Œ
                            const parts = line.split(' | ');
                            if (parts.length > 6) {{
                                const result = [];
                                for (let i = 0; i < parts.length; i += 6) {{
                                    const chunk = parts.slice(i, i + 6).join(' | ');
                                    result.push(chunk);
                                }}
                                return result.join('\\n  ');
                            }}
                        }}
                        return line;
                    }});
                
                // ç¡®ä¿è‡³å°‘æœ‰2è¡Œå†…å®¹ï¼Œä¸å¤Ÿçš„è¯è¡¥å……
                while (lines.length < 2) {{
                    lines.push('ã€€'); // æ·»åŠ å ä½è¡Œ
                }}
                
                console.log('æ ¼å¼åŒ–åè¡Œæ•°:', lines.length);
                console.log('å‰2è¡Œç¤ºä¾‹:', lines.slice(0, 2));
                
                // æ·»åŠ è¡Œå·æ ‡è¯†ï¼Œä½¿å†…å®¹æ›´æ¸…æ™°
                const formattedLines = lines.map((line, index) => {{
                    if (line === 'ã€€') {{
                        return line; // å ä½è¡Œä¿æŒåŸæ ·
                    }}
    
                    // æ£€æŸ¥æ˜¯å¦å·²ç»åŒ…å«"æ£€æŸ¥XX:"æ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™ä¸å†æ·»åŠ 
                    if (line.match(/^ç¬¬\d+è¡Œ:/)) {{
                        return line; // å·²ç»æ ¼å¼åŒ–è¿‡ï¼Œç›´æ¥è¿”å›
                    }}
            
                    // æ£€æŸ¥æ˜¯å¦åŒ…å«æ—§çš„"æ£€æŸ¥XX:"æ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™æ›¿æ¢
                    if (line.match(/^æ£€æŸ¥\d+:/)) {{
                        // æå–æ£€æŸ¥å·å¹¶æ›¿æ¢ä¸ºè¡Œå·
                        const checkMatch = line.match(/^æ£€æŸ¥(\d+):(.*)/);
                        if (checkMatch) {{
                            const lineNum = String(index + 1).padStart(2, '0');
                            return `ç¬¬${{lineNum}}è¡Œ:${{checkMatch[2]}}`;
                        }}
                    }}
                    
                    if (line.includes('|') && line.split('|').length > 3) {{
                        // å¦‚æœæ˜¯æ•°æ®è¡Œï¼Œæ·»åŠ æ£€æŸ¥åºå·
                        const lineNum = String(index + 1).padStart(2, '0');
                        return `ç¬¬${{lineNum}}è¡Œ: ${{line}}`;
                    }} else {{
                        // å¦‚æœæ˜¯æ™®é€šè¡Œï¼Œä¿æŒåŸæ ·
                        return line;
                    }}
                }});
                
                const result = formattedLines.join('\\n');
                console.log('æœ€ç»ˆæ ¼å¼åŒ–ç»“æœé•¿åº¦:', result.length);
                console.log('æœ€ç»ˆæ ¼å¼åŒ–ç»“æœé¢„è§ˆ:', result.substring(0, 200) + '...');
                
                return result;
                
            }} catch (e) {{
                console.error('æ ¼å¼åŒ–å»¶è¿Ÿè¶‹åŠ¿æ•°æ®å¤±è´¥:', e);
                console.error('åŸå§‹æ•°æ®:', trendsData);
                return 'æ ¼å¼åŒ–å¤±è´¥: ' + e.message + '\\n\\nåŸå§‹æ•°æ®:\\n' + trendsData;
            }}
        }}
    </script>
</head>
<body>
    <div class="header">
        <h1>ğŸš€ TDengine æµè®¡ç®—æ‰¹é‡æµ‹è¯•è¯¦ç»†æŠ¥å‘Š</h1>
        <p>ğŸ“… ç”Ÿæˆæ—¶é—´: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        <p>â° æµ‹è¯•å‘¨æœŸ: {self.start_time} â†’ {datetime.datetime.now().isoformat()}</p>
        <p>ğŸ—ï¸ æµ‹è¯•é…ç½®: {self.fixed_params.get('deployment_mode', 'single')}æ¨¡å¼ | 
           {self.fixed_params.get('table_count', 1000)}å¼ å­è¡¨ | 
           {self.fixed_params.get('real_time_batch_rows', 200)}æ¡/è½® | 
           æ¯è½®å†™å…¥é—´éš”{self.fixed_params.get('real_time_batch_sleep', 0)}ç§’</p>
        <p>ğŸ’» æµ‹è¯•ç¯å¢ƒ: CPUæ ¸æ•°{system_cpu_count or 'æœªçŸ¥'} | æ€»å†…å­˜{system_total_memory or 'æœªçŸ¥'}</p>
    </div>
    
    <div class="summary">
        <div class="metric">
            <h3>ğŸ“Š æ€»æµ‹è¯•æ•°</h3>
            <h2>{self.total_tests}</h2>
        </div>
        <div class="metric success">
            <h3>âœ… æˆåŠŸ</h3>
            <h2>{success_count}</h2>
            <small>{(success_count/self.total_tests*100):.1f}%</small>
        </div>
        <div class="metric failed">
            <h3>âŒ åˆ›å»ºæµè¯­å¥å¤±è´¥ï¼Œéæµè®¡ç®—å¤±è´¥</h3>
            <h2>{failed_count}</h2>
            <small>{(failed_count/self.total_tests*100):.1f}%</small>
        </div>
        <div class="metric skipped">
            <h3>â­ï¸ è·³è¿‡(å·²çŸ¥å¤±è´¥)</h3>
            <h2>{skip_failure_count}</h2>
            <small>{(skip_failure_count/self.total_tests*100):.1f}%</small>
        </div>
        <div class="metric warning">
            <h3>âš ï¸ è·³è¿‡(æ²¡æœ‰å®é™…æ„ä¹‰)</h3>
            <h2>{skip_poor_performance_count}</h2>
            <small>{(skip_poor_performance_count/self.total_tests*100):.1f}%</small>
        </div>
        <div class="metric info">
            <h3>â±ï¸ æ€»è€—æ—¶</h3>
            <h2>{total_duration/3600:.1f}h</h2>
            <small>å¹³å‡{avg_duration:.1f}åˆ†é’Ÿ/æˆåŠŸæµ‹è¯•</small>
        </div>
        <div class="metric info">
            <h3>ğŸ’ª æ•ˆç‡</h3>
            <h2>{efficiency:.1f}</h2>
            <small>æˆåŠŸæµ‹è¯•/å°æ—¶</small>
        </div>
    </div>
    
    <div class="controls">
        <div class="filter-group">
            <label for="statusFilter">çŠ¶æ€ç­›é€‰:</label>
            <select id="statusFilter" onchange="filterTable()">
                <option value="">å…¨éƒ¨</option>
                <option value="SUCCESS" selected>æˆåŠŸ</option>
                <option value="FAILED">å¤±è´¥</option>
                <option value="SKIP_FAILURE">è·³è¿‡(å·²çŸ¥å¤±è´¥)</option>
                <option value="SKIP_POOR_PERFORMANCE">è·³è¿‡(æ²¡æœ‰å®é™…æ„ä¹‰)</option>
                <option value="SKIPPED">è·³è¿‡(å…¶ä»–)</option>
            </select>
        </div>
        <div class="filter-group">
            <label for="sqlTypeFilter">SQLç±»å‹ç­›é€‰:</label>
            <select id="sqlTypeFilter" onchange="filterTable()">
                <option value="">å…¨éƒ¨</option>
"""
        
        # è·å–æ‰€æœ‰SQLç±»å‹ç”¨äºç­›é€‰
        sql_types = set()
        for result in self.test_results:
            sql_types.add(result['config']['sql_type'])
        
        for sql_type in sorted(sql_types):
            html_content += f'                <option value="{sql_type}">{sql_type}</option>\n'
        
        html_content += f"""
            </select>
        </div>
        
        <div class="filter-group">
            <label for="fromTypeFilter">ç­›é€‰ç±»å‹:</label>
            <select id="fromTypeFilter" onchange="filterTable()">
                <option value="">å…¨éƒ¨</option>
                <option value="tbname">tbname</option>
                <option value="trows">trows</option>
                <option value="sourcetable">sourcetable</option>
                <option value="!tbname">æ’é™¤ tbname (æ˜¾ç¤ºtrows+sourcetable)</option>
                <option value="!trows">æ’é™¤ trows (æ˜¾ç¤ºtbname+sourcetable)</option>
                <option value="!sourcetable">æ’é™¤ sourcetable (æ˜¾ç¤ºtbname+trows)</option>
            </select>
        </div>        
        <div class="filter-group">
            <label for="searchInput">æœç´¢æµ‹è¯•åç§°:</label>
            <input type="text" id="searchInput" placeholder="è¾“å…¥å…³é”®è¯..." onkeyup="filterTable()">
        </div>
    </div>
    
    <div class="table-container">
        <h2 style="margin: 0; padding: 20px; border-bottom: 1px solid #eee;">ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ</h2>
        <table id="resultsTable">
            <tr>
                <th onclick="sortTable(0)" style="cursor: pointer;">ğŸ“ æµ‹è¯•åç§°</th>
                <th onclick="sortTable(1)" style="cursor: pointer;">ğŸ”§ SQLç±»å‹</th>
                <th onclick="sortTable(2)" style="cursor: pointer;">ğŸ“Š æŸ¥è¯¢ç±»å‹</th>
                <th onclick="sortTable(3)" style="cursor: pointer;">ğŸ“‚ FROMç±»å‹</th>
                <th onclick="sortTable(4)" style="cursor: pointer;">ğŸ¯ çŠ¶æ€</th>
                <th onclick="sortTable(5)" style="cursor: pointer;">â±ï¸ è€—æ—¶(ç§’)</th>
                <th>ğŸ” SQLé¢„è§ˆ</th>
                <th onclick="sortTable(7)" style="cursor: pointer;">ğŸ’» {perf_node} CPUå³°å€¼èŒƒå›´(%)</th>
                <th onclick="sortTable(8)" style="cursor: pointer;">ğŸ§  {perf_node} å†…å­˜å³°å€¼èŒƒå›´(MB)</th>
                <th onclick="sortTable(9)" style="cursor: pointer;">ğŸ“Š {perf_node} CPUå¹³å‡å€¼(%)</th>
                <th onclick="sortTable(10)" style="cursor: pointer;">ğŸ“ˆ {perf_node} å†…å­˜å¹³å‡å€¼(MB)</th>
                <th onclick="sortTable(11)" style="cursor: pointer;">ğŸ“Š æµçª—å£ç”Ÿæˆæ¯”ä¾‹(%)</th>
                <th onclick="sortTable(12)" style="cursor: pointer;">âš¡ æ¯ç§’å†™å…¥é€Ÿåº¦(æ¡/ç§’)</th>
                <!-- âœ… æ³¨é‡Šæ‰åŸå§‹å»¶è¿Ÿç»Ÿè®¡åˆ—
                <th>ğŸ“ˆ åŸå§‹å»¶è¿Ÿç»Ÿè®¡</th>
                -->
                <th>ğŸ“Š åŸå§‹å»¶è¿Ÿè¶‹åŠ¿</th>
                <th>âŒ é”™è¯¯ä¿¡æ¯</th>
            </tr>
"""
        
        for result_index, result in enumerate(self.test_results):
            config = result['config']
            perf_file = config.get('perf_file', '')
            # perf_node = getattr(self, 'perf_node', 'dnode1')
            perf_file_node = perf_file.replace('.log', f'-{perf_node}.log')
            
            if result['status'] == 'SUCCESS':
                status_class = 'status-success'
                status_badge = 'badge-success'
            elif result['status'] == 'FAILED':
                status_class = 'status-failed'
                status_badge = 'badge-failed'
            elif result['status'] == 'SKIP_FAILURE':
                status_class = 'status-skipped'
                status_badge = 'badge-skipped'
            elif result['status'] == 'SKIP_POOR_PERFORMANCE':
                status_class = 'status-warning'
                status_badge = 'badge-warning'
            elif result['status'] == 'SKIPPED':
                status_class = 'status-skipped'
                status_badge = 'badge-skipped'
            else:
                status_class = ''
                status_badge = ''
                            
            # å¤„ç†è·³è¿‡åŸå› æ˜¾ç¤º
            if result['status'] in ['SKIPPED', 'SKIP_FAILURE', 'SKIP_POOR_PERFORMANCE']:
                skip_reason = result.get('skip_reason', 'æœªçŸ¥åŸå› ')
                if result['status'] == 'SKIP_FAILURE':
                    error_msg = f"è·³è¿‡åŸå› : {skip_reason}"
                elif result['status'] == 'SKIP_POOR_PERFORMANCE':
                    error_msg = f"å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰ï¼Œå¾…åæœŸå†ä¼˜åŒ–: {skip_reason}"
                else:
                    error_msg = f"è·³è¿‡åŸå› : {skip_reason}"
            
            print(f"è°ƒè¯•: å¤„ç†ç¬¬ {result_index + 1}/{len(self.test_results)} ä¸ªæµ‹è¯•ç»“æœ: {result['test_name']}")
            
            # è·å–SQLé¢„è§ˆ
            sql_preview = "N/A"
            sql_full = "æ— SQLä¿¡æ¯"
            try:
                # ä»StreamSQLTemplatesè·å–SQL
                sql_obj = StreamSQLTemplates.get_sql(
                    config['sql_type'],
                    agg_or_select=config.get('agg_or_select', 'agg'),
                    tbname_or_trows_or_sourcetable=config.get('tbname_or_trows_or_sourcetable', 'sourcetable')
                )
                
                if isinstance(sql_obj, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå–ç¬¬ä¸€ä¸ªSQLä½œä¸ºé¢„è§ˆ
                    first_key = list(sql_obj.keys())[0]
                    sql_full = sql_obj[first_key]
                    sql_preview = f"æ‰¹é‡({len(sql_obj)}ä¸ª) - {first_key}"
                else:
                    sql_full = str(sql_obj)
                    # æ ¼å¼åŒ–SQLç”¨äºæ˜¾ç¤º
                    formatted_sql = format_sql_for_display(sql_full)
                    
                    # æå–æµåç§°ä½œä¸ºé¢„è§ˆ
                    import re
                    match = re.search(r'create\s+stream\s+([^\s|]+)', formatted_sql, re.IGNORECASE)
                    if match:
                        stream_name = match.group(1)
                        # åˆ›å»ºç®€æ´çš„é¢„è§ˆï¼Œæ˜¾ç¤ºæµåç§°å’Œä¸»è¦å­å¥
                        preview_parts = []
                        preview_parts.append(f"CREATE STREAM {stream_name}")
                        
                        # æå–çª—å£ç±»å‹
                        if 'interval(' in formatted_sql.lower():
                            interval_match = re.search(r'interval\([^)]+\)', formatted_sql, re.IGNORECASE)
                            if interval_match:
                                preview_parts.append(interval_match.group(0).upper())
                        elif 'sliding(' in formatted_sql.lower():
                            sliding_match = re.search(r'sliding\([^)]+\)', formatted_sql, re.IGNORECASE)
                            if sliding_match:
                                preview_parts.append(sliding_match.group(0).upper())
                        elif 'session(' in formatted_sql.lower():
                            session_match = re.search(r'session\([^)]+\)', formatted_sql, re.IGNORECASE)
                            if session_match:
                                preview_parts.append(session_match.group(0).upper())
                        elif 'period(' in formatted_sql.lower():
                            period_match = re.search(r'period\([^)]+\)', formatted_sql, re.IGNORECASE)
                            if period_match:
                                preview_parts.append(period_match.group(0).upper())
                        elif 'count_window(' in formatted_sql.lower():
                            count_match = re.search(r'count_window\([^)]+\)', formatted_sql, re.IGNORECASE)
                            if count_match:
                                preview_parts.append(count_match.group(0).upper())
                        
                        sql_preview = " ".join(preview_parts)
                    else:
                        # å¦‚æœæ— æ³•æå–æµåç§°ï¼Œæ˜¾ç¤ºå‰50ä¸ªå­—ç¬¦
                        sql_preview = formatted_sql[:50] + "..." if len(formatted_sql) > 50 else formatted_sql
                    
                    # ä½¿ç”¨æ ¼å¼åŒ–åçš„SQLä½œä¸ºå®Œæ•´SQL
                    sql_full = formatted_sql
                        
                        
            except Exception as e:
                sql_preview = f"è·å–å¤±è´¥: {str(e)[:30]}"
                sql_full = f"SQLè·å–é”™è¯¯: {str(e)}"
            
            # æ¸…ç†SQLä¸­çš„ç‰¹æ®Šå­—ç¬¦
            sql_full_escaped = sql_full.replace('"', '&quot;').replace("'", '&#39;').replace('\n', '\\n').replace('\r', '\\r')
            
            # è¯»å–æ€§èƒ½æ•°æ®
            cpu_peak, memory_peak = "N/A", "N/A"
            cpu_range_info = ""
            memory_range_info = ""
            cpu_peak_value = None
            memory_peak_value = None
            cpu_avg_value = None
            memory_avg_value = None
            memory_avg_percentage = None
            cpu_avg_info = ""
            memory_avg_info = ""
            
            
            # åªæœ‰æµ‹è¯•æˆåŠŸæ—¶æ‰å°è¯•è¯»å–æ€§èƒ½æ•°æ®
            if result['status'] == 'SUCCESS':
                try:
                    perf_file = config.get('perf_file', '')
                    perf_node = getattr(self, 'perf_node', 'dnode1')
                    perf_file_node = perf_file.replace('.log', f'-{perf_node}.log')
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå°è¯•è¯»å–æ€§èƒ½æ–‡ä»¶: {perf_file_node}")
                    
                    # æ£€æŸ¥å„ç§å¯èƒ½çš„æ€§èƒ½æ–‡ä»¶è·¯å¾„
                    possible_files = []
                    if perf_file_node:
                        # åŸå§‹æ–‡ä»¶è·¯å¾„
                        possible_files.append(perf_file_node)
                        # å»æ‰æ‰©å±•ååŠ -all.log
                        base_name = os.path.splitext(perf_file_node)[0]
                        possible_files.append(f"{base_name}-all.log")
                        # ç›´æ¥åŠ -all.log
                        possible_files.append(f"{perf_file_node}-all.log")
                    
                    # æ·»åŠ ä¸€äº›å¸¸è§çš„æ€§èƒ½æ–‡ä»¶è·¯å¾„
                    possible_files.extend([
                        '/tmp/perf-taosd-all.log',
                        '/tmp/perf-stream-test-all.log', 
                        '/tmp/perf-all.log'
                    ])
                    
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ£€æŸ¥æ–‡ä»¶è·¯å¾„: {possible_files}")
                    
                    # å°è¯•è¯»å–ç¬¬ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶
                    perf_content = None
                    used_file = None
                    for file_path in possible_files:
                        if os.path.exists(file_path):
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ‰¾åˆ°æ€§èƒ½æ–‡ä»¶: {file_path}")
                            try:
                                with open(file_path, 'r') as f:
                                    perf_content = f.read()
                                    used_file = file_path
                                    break
                            except Exception as e:
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè¯»å–æ–‡ä»¶ {file_path} å¤±è´¥: {str(e)}")
                                continue
                    
                    if perf_content:
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼ŒæˆåŠŸè¯»å–æ€§èƒ½æ–‡ä»¶ {used_file}, å†…å®¹é•¿åº¦: {len(perf_content)}")
                        
                        # è§£ææ€§èƒ½æ•°æ®
                        cpu_values = []
                        memory_values = []
                        memory_percentages = []
                        
                        lines = perf_content.split('\n')
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ–‡ä»¶æ€»è¡Œæ•°: {len(lines)}")
                        
                        valid_lines_count = 0
                        warm_up_lines_count = 0  
                        formal_monitoring_started = False 
                        warm_up_end_detected = False 
                    
                        for line_num, line in enumerate(lines):
                            line = line.strip()
                            if not line:
                                continue
                            
                            # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„çƒ­æœŸç»“æŸæ ‡è®°
                            if '=== é¢„çƒ­æœŸç»“æŸï¼Œæ­£å¼ç›‘æ§å¼€å§‹ ===' in line or 'æ­£å¼ç›‘æ§å¼€å§‹' in line:
                                formal_monitoring_started = True
                                warm_up_end_detected = True
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œåœ¨ç¬¬{line_num+1}è¡Œå‘ç°æ­£å¼ç›‘æ§å¼€å§‹æ ‡è®°")
                                continue
                                
                            # æŸ¥æ‰¾åŒ…å«CPUå’ŒMemoryçš„è¡Œ
                            # æ ¼å¼: 2025-09-01 17:34:18 [dnode1] CPU: 271.4%, Memory: 787.64MB (1.23%), Read: 0.00MB (7492031), Write: 665.98MB (13546146)
                            if 'CPU:' in line and 'Memory:' in line and '%' in line and 'MB' in line and f'[{perf_node}]' in line:
                                
                                # æ£€æŸ¥æ˜¯å¦æ˜¯é¢„çƒ­æœŸæ•°æ®
                                is_warm_up_data = '[é¢„çƒ­æœŸæ•°æ®]' in line
                                
                                if is_warm_up_data:
                                    warm_up_lines_count += 1
                                    # è·³è¿‡é¢„çƒ­æœŸæ•°æ®ï¼Œä¸ç»Ÿè®¡
                                    continue
                                
                                # æ–°å¢é€»è¾‘ï¼šå¦‚æœè®¾ç½®äº†é¢„çƒ­æ—¶é—´ä½†æ²¡æœ‰æ£€æµ‹åˆ°é¢„çƒ­æœŸç»“æŸæ ‡è®°
                                # åˆ™æ ¹æ®æ—¶é—´æˆ³åˆ¤æ–­æˆ–è€…æ”¾å®½ç»Ÿè®¡æ¡ä»¶
                                if config.get('monitor_warm_up_time', 0) > 0:
                                    if not warm_up_end_detected and not formal_monitoring_started:
                                        # æ ¹æ®è¡Œæ•°åˆ¤æ–­ï¼šå‰é¢çš„è¡Œå¯èƒ½æ˜¯é¢„çƒ­æœŸæ•°æ®
                                        warm_up_cycles = config.get('monitor_warm_up_time', 0) // config.get('monitor_interval', 5)
                                        # å¯èƒ½æ˜¯æ ‡è®°æ ¼å¼é—®é¢˜ï¼Œå°è¯•æ›´å®½æ¾çš„åŒ¹é…
                                        if warm_up_lines_count > 0:
                                            # å·²ç»å¼€å§‹æœ‰é¢„çƒ­æœŸæ•°æ®ï¼Œç»§ç»­ç­‰å¾…ç»“æŸæ ‡è®°
                                            continue
                                        elif line_num < 10:
                                            # å‰10è¡Œå¯èƒ½è¿˜åœ¨é¢„çƒ­æœŸ
                                            continue
                                        else:
                                            # è¶…è¿‡10è¡Œåï¼Œå¦‚æœæ²¡æœ‰é¢„çƒ­æœŸæ ‡è®°ï¼Œå¯èƒ½æ˜¯æ­£å¼æ•°æ®
                                            formal_monitoring_started = True
                                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ‰¾åˆ°æ˜ç¡®çš„é¢„çƒ­æœŸç»“æŸæ ‡è®°ï¼Œä»ç¬¬{line_num+1}è¡Œå¼€å§‹ç»Ÿè®¡")
                                
                                # ç»Ÿè®¡æ­£å¼ç›‘æ§æœŸçš„æ•°æ®
                                valid_lines_count += 1
                                
                                try:
                                    import re
                                    
                                    # æå–CPUä½¿ç”¨ç‡
                                    cpu_match = re.search(r'CPU:\s*([\d.]+)%', line)
                                    if cpu_match:
                                        cpu_value = float(cpu_match.group(1))
                                        cpu_values.append(cpu_value)
                                        #print(f"è°ƒè¯•: æå–CPUå€¼: {cpu_value}")
                                    
                                    # æå–å†…å­˜ä½¿ç”¨é‡(MB)
                                    memory_match = re.search(r'Memory:\s*([\d.]+)MB\s*\(([\d.]+)%\)', line)
                                    if memory_match:
                                        memory_value = float(memory_match.group(1))
                                        memory_percentage = float(memory_match.group(2))
                                        memory_values.append(memory_value)
                                        memory_percentages.append(memory_percentage)
                                        #print(f"è°ƒè¯•: æå–å†…å­˜å€¼: {memory_value}")
                                        
                                except Exception as e:
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè§£æç¬¬{line_num+1}è¡Œå‡ºé”™: {str(e)}")
                                    continue
                        
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œé¢„çƒ­æœŸæ•°æ®è¡Œæ•°: {warm_up_lines_count}")
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸæ•°æ®è¡Œæ•°: {valid_lines_count}")
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œé¢„çƒ­æœŸç»“æŸæ£€æµ‹: {warm_up_end_detected}")
                        print(f"è°ƒè¯•: æ”¶é›†åˆ°CPUå³°å€¼: {max(cpu_values) if cpu_values else 'N/A'}")
                        print(f"è°ƒè¯•: æ”¶é›†åˆ°å†…å­˜å³°å€¼: {max(memory_values) if memory_values else 'N/A'}")
                        
                        if cpu_values:
                            cpu_peak_value = max(cpu_values)
                            cpu_min_value = min(cpu_values)
                            cpu_avg_value = sum(cpu_values) / len(cpu_values) 
                            
                            # æ„å»ºCPUèŒƒå›´ä¿¡æ¯ï¼ŒåŒ…å«ç³»ç»Ÿæ ¸æ•°
                            cpu_core_info = f"(CPU(s):{system_cpu_count})" if system_cpu_count else ""
                            cpu_range_info = f"{cpu_min_value:.1f}% -> {cpu_peak_value:.1f}%{cpu_core_info}"
                            cpu_peak = f"{cpu_peak_value:.1f}"
                            cpu_avg_info = f"avg:{cpu_avg_value:.1f}%"
                            
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸCPUå³°å€¼: {cpu_peak}%, å¹³å‡å€¼: {cpu_avg_value:.1f}%")
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸCPUèŒƒå›´: {cpu_range_info}")
                            
                        else:
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ”¶é›†åˆ°CPUæ•°æ®")
                            cpu_range_info = "æ— æ­£å¼ç›‘æ§æœŸæ•°æ®"
                            cpu_avg_info = ""
                        
                        if memory_values and memory_percentages:
                            memory_peak_value = max(memory_values)
                            memory_min_value = min(memory_values)
                            memory_avg_value = sum(memory_values) / len(memory_values)  # æ–°å¢ï¼šè®¡ç®—å¹³å‡å€¼
                            memory_avg_percentage = sum(memory_percentages) / len(memory_percentages)  # æ–°å¢ï¼šå¹³å‡ç™¾åˆ†æ¯”
                            
                            memory_peak_percentage = memory_percentages[memory_values.index(memory_peak_value)]
                            memory_min_percentage = memory_percentages[memory_values.index(memory_min_value)]
                            
                            memory_peak = f"{memory_peak_value:.0f}"
                            
                            # æ„å»ºå†…å­˜èŒƒå›´ä¿¡æ¯ï¼ŒåŒ…å«æ€»å†…å­˜å’Œç™¾åˆ†æ¯”
                            memory_total_info = f"({system_total_memory})" if system_total_memory else ""
                            memory_range_info = f"{memory_min_value:.0f}MB({memory_min_percentage:.1f}%) -> {memory_peak_value:.0f}MB({memory_peak_percentage:.1f}%){memory_total_info}"
                            # æ–°å¢ï¼šå†…å­˜å¹³å‡å€¼ä¿¡æ¯
                            memory_avg_info = f"avg:{memory_avg_value:.0f}MB({memory_avg_percentage:.1f}%){memory_total_info}"
                        
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸå†…å­˜å³°å€¼: {memory_peak}MB, å¹³å‡å€¼: {memory_avg_value:.0f}MB({memory_avg_percentage:.1f}%)")
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸå†…å­˜èŒƒå›´: {memory_range_info}")
                            
                        else:
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ”¶é›†åˆ°å†…å­˜æ•°æ®")
                            memory_range_info = "æ— æ­£å¼ç›‘æ§æœŸæ•°æ®"
                            memory_avg_value = None
                            memory_avg_percentage = None
                            memory_avg_info = ""
                            
                        # æ•°æ®è´¨é‡æ£€æŸ¥
                        if valid_lines_count == 0:
                            print(f"è­¦å‘Š: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ‰¾åˆ°æ­£å¼ç›‘æ§æœŸæ•°æ®")
                            for line_num, line in enumerate(lines):
                                line = line.strip()
                                if not line:
                                    continue
                                    
                                if 'CPU:' in line and 'Memory:' in line and '%' in line and 'MB' in line:
                                    valid_lines_count += 1
                                    
                                    try:
                                        import re
                                        
                                        cpu_match = re.search(r'CPU:\s*([\d.]+)%', line)
                                        if cpu_match:
                                            cpu_value = float(cpu_match.group(1))
                                            cpu_values.append(cpu_value)
                                        
                                        memory_match = re.search(r'Memory:\s*([\d.]+)MB\s*\(([\d.]+)%\)', line)
                                        if memory_match:
                                            memory_value = float(memory_match.group(1))
                                            memory_percentage = float(memory_match.group(2))
                                            memory_values.append(memory_value)
                                            memory_percentages.append(memory_percentage)
                                            
                                    except Exception as e:
                                        continue
                            
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå…œåº•å¤„ç†åæ”¶é›†åˆ°æ•°æ®è¡Œæ•°: {valid_lines_count}")
                        elif valid_lines_count < 5:
                            print(f"è­¦å‘Š: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ­£å¼ç›‘æ§æœŸæ•°æ®ç‚¹è¿‡å°‘({valid_lines_count}ä¸ª)ï¼Œå¯èƒ½å½±å“ç»Ÿè®¡å‡†ç¡®æ€§")
                            
                    else:
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ‰¾åˆ°ä»»ä½•å¯ç”¨çš„æ€§èƒ½æ–‡ä»¶")
                        cpu_range_info = "æ€§èƒ½æ–‡ä»¶ä¸å­˜åœ¨"
                        memory_range_info = "æ€§èƒ½æ–‡ä»¶ä¸å­˜åœ¨"
                        cpu_avg_value = None
                        memory_avg_value = None
                        memory_avg_percentage = None
                        cpu_avg_info = ""
                        memory_avg_info = ""
                        
                except Exception as e:
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè¯»å–æ€§èƒ½æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    cpu_range_info = f"è¯»å–å¤±è´¥: {str(e)}"
                    memory_range_info = f"è¯»å–å¤±è´¥: {str(e)}"
                    cpu_avg_value = None
                    memory_avg_value = None
                    memory_avg_percentage = None
                    cpu_avg_info = ""
                    memory_avg_info = ""
            else:
                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè·³è¿‡æ€§èƒ½æ•°æ®è¯»å–")
                cpu_range_info = "N/A"
                memory_range_info = "N/A"
                cpu_avg_value = None
                memory_avg_value = None
                memory_avg_percentage = None
                cpu_avg_info = ""
                memory_avg_info = ""
            
            
            # CPUå’Œå†…å­˜çš„é¢œè‰²æ ·å¼
            cpu_class = ""
            if cpu_peak != "N/A" and cpu_peak_value is not None:
                try:
                    # è®¡ç®—å®é™…çš„CPUä½¿ç”¨ç‡ç™¾åˆ†æ¯”
                    if system_cpu_count:
                        try:
                            total_cpu_cores = int(system_cpu_count)
                            # è®¡ç®—å®é™…CPUä½¿ç”¨ç‡ï¼šå½“å‰ä½¿ç”¨ç‡ / æ€»æ ¸æ•° 
                            actual_cpu_usage_percent = cpu_peak_value / total_cpu_cores
                            print(f"è°ƒè¯•: CPUå³°å€¼é¢œè‰²è®¡ç®— - å³°å€¼: {cpu_peak_value}%, æ€»æ ¸æ•°: {total_cpu_cores}, å®é™…ä½¿ç”¨ç‡: {actual_cpu_usage_percent:.1f}%")
                            
                            # åŸºäºå®é™…ä½¿ç”¨ç‡åˆ¤æ–­é¢œè‰²
                            if actual_cpu_usage_percent < 30:      # å®é™…ä½¿ç”¨ç‡ä½äº30%
                                cpu_class = "perf-good"
                                print(f"è°ƒè¯•: CPUå³°å€¼é¢œè‰²åˆ¤æ–­ -> ç»¿è‰² (å®é™…ä½¿ç”¨ç‡ {actual_cpu_usage_percent:.1f}% < 30%)")
                            elif actual_cpu_usage_percent < 70:   # å®é™…ä½¿ç”¨ç‡30%-70%
                                cpu_class = "perf-warning"
                                print(f"è°ƒè¯•: CPUå³°å€¼é¢œè‰²åˆ¤æ–­ -> é»„è‰² (å®é™…ä½¿ç”¨ç‡ {actual_cpu_usage_percent:.1f}% åœ¨30%-70%)")
                            else:                                  # å®é™…ä½¿ç”¨ç‡è¶…è¿‡70%
                                cpu_class = "perf-danger"
                                print(f"è°ƒè¯•: CPUå³°å€¼é¢œè‰²åˆ¤æ–­ -> çº¢è‰² (å®é™…ä½¿ç”¨ç‡ {actual_cpu_usage_percent:.1f}% > 70%)")
                                
                        except (ValueError, TypeError) as e:
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè§£æCPUæ ¸æ•°å¤±è´¥: {e}")
                            if cpu_peak_value < 500:
                                cpu_class = "perf-good"
                            elif cpu_peak_value < 1000:
                                cpu_class = "perf-warning"
                            else:
                                cpu_class = "perf-danger"
                    else:
                        print(f"è°ƒè¯•: æœªè·å–åˆ°CPUæ ¸æ•°ï¼Œä½¿ç”¨åŸå§‹å€¼åˆ¤æ–­")
                        # æ²¡æœ‰è·å–åˆ°CPUæ ¸æ•°ï¼Œä½¿ç”¨æ›´å®½æ¾çš„åˆ¤æ–­æ ‡å‡†
                        # å‡è®¾æ˜¯å¤šæ ¸ç³»ç»Ÿï¼Œé€‚å½“æ”¾å®½æ ‡å‡†
                        if cpu_peak_value < 500:      # å‡è®¾è‡³å°‘16æ ¸ï¼Œ500%ä»¥ä¸‹ä¸ºè‰¯å¥½
                            cpu_class = "perf-good"
                        elif cpu_peak_value < 1000:   # 500%-1000%ä¸ºè­¦å‘Š
                            cpu_class = "perf-warning"
                        else:                  # è¶…è¿‡1000%ä¸ºå±é™©
                            cpu_class = "perf-danger"
                            
                except Exception as e:
                    print(f"è°ƒè¯•:ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼ŒCPUé¢œè‰²åˆ¤æ–­å‡ºé”™: {e}")
                    cpu_class = ""
            else:
                print(f"è°ƒè¯•: CPUæ•°æ®æ— æ•ˆï¼Œè·³è¿‡é¢œè‰²åˆ¤æ–­ - cpu_peak: {cpu_peak}, cpu_peak_value: {cpu_peak_value}")
            
            
            # ========== CPUå¹³å‡å€¼çš„é¢œè‰²æ ·å¼ï¼ˆæ–°å¢ç‹¬ç«‹åˆ¤æ–­ï¼‰ ==========
            cpu_avg_class = ""
            if cpu_avg_value is not None:  # ä½¿ç”¨å¹³å‡å€¼è¿›è¡Œç‹¬ç«‹çš„é¢œè‰²åˆ¤æ–­
                try:
                    if system_cpu_count:
                        try:
                            total_cpu_cores = int(system_cpu_count)
                            # ä½¿ç”¨å¹³å‡å€¼è®¡ç®—å®é™…CPUä½¿ç”¨ç‡
                            actual_cpu_avg_usage_percent = cpu_avg_value / total_cpu_cores
                            print(f"è°ƒè¯•: CPUå¹³å‡å€¼é¢œè‰²è®¡ç®— - å¹³å‡å€¼: {cpu_avg_value:.1f}%, æ€»æ ¸æ•°: {total_cpu_cores}, å®é™…å¹³å‡ä½¿ç”¨ç‡: {actual_cpu_avg_usage_percent:.1f}%")
                            
                            # åŸºäºå¹³å‡ä½¿ç”¨ç‡åˆ¤æ–­é¢œè‰²
                            if actual_cpu_avg_usage_percent < 30:
                                cpu_avg_class = "perf-good"
                                print(f"è°ƒè¯•: CPUå¹³å‡å€¼é¢œè‰²åˆ¤æ–­ -> ç»¿è‰² (å¹³å‡ä½¿ç”¨ç‡ {actual_cpu_avg_usage_percent:.1f}% < 30%)")
                            elif actual_cpu_avg_usage_percent < 70:
                                cpu_avg_class = "perf-warning"
                                print(f"è°ƒè¯•: CPUå¹³å‡å€¼é¢œè‰²åˆ¤æ–­ -> é»„è‰² (å¹³å‡ä½¿ç”¨ç‡ {actual_cpu_avg_usage_percent:.1f}% åœ¨30%-70%)")
                            else:
                                cpu_avg_class = "perf-danger"
                                print(f"è°ƒè¯•: CPUå¹³å‡å€¼é¢œè‰²åˆ¤æ–­ -> çº¢è‰² (å¹³å‡ä½¿ç”¨ç‡ {actual_cpu_avg_usage_percent:.1f}% > 70%)")
                                
                        except (ValueError, TypeError) as e:
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè§£æCPUæ ¸æ•°å¤±è´¥: {e}")
                            # ä½¿ç”¨å¹³å‡å€¼çš„å¤‡ç”¨åˆ¤æ–­
                            if cpu_avg_value < 500:
                                cpu_avg_class = "perf-good"
                            elif cpu_avg_value < 1000:
                                cpu_avg_class = "perf-warning"
                            else:
                                cpu_avg_class = "perf-danger"
                    else:
                        print(f"è°ƒè¯•: æœªè·å–åˆ°CPUæ ¸æ•°ï¼Œä½¿ç”¨å¹³å‡å€¼åˆ¤æ–­")
                        if cpu_avg_value < 500:
                            cpu_avg_class = "perf-good"
                        elif cpu_avg_value < 1000:
                            cpu_avg_class = "perf-warning"
                        else:
                            cpu_avg_class = "perf-danger"
                            
                except Exception as e:
                    print(f"è°ƒè¯•:ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼ŒCPUå¹³å‡å€¼é¢œè‰²åˆ¤æ–­å‡ºé”™: {e}")
                    cpu_avg_class = ""
            else:
                print(f"è°ƒè¯•: CPUå¹³å‡å€¼æ•°æ®æ— æ•ˆï¼Œè·³è¿‡é¢œè‰²åˆ¤æ–­ - cpu_avg_value: {cpu_avg_value}")
            
            
            memory_class = ""
            if memory_range_info and "MB" in memory_range_info:
                try:
                    import re
                    # æå–å†…å­˜å³°å€¼å’Œç™¾åˆ†æ¯”ï¼ŒåŒ¹é… "96MB(0.1%) -> 787MB(1.2%)(62.5GB)" ä¸­çš„ 787MB(1.2%) éƒ¨åˆ†
                    match = re.search(r'(\d+)MB\(([\d.]+)%\)', memory_range_info.split('->')[-1])
                    if match:
                        memory_peak_mb = float(match.group(1))
                        memory_peak_percentage = float(match.group(2))
                        
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜åˆ¤æ–­ - å³°å€¼: {memory_peak_mb}MB, å ç”¨ç‡: {memory_peak_percentage}%")
                        
                        # åŸºäºå†…å­˜ä½¿ç”¨ç‡çš„åˆ¤æ–­
                        if memory_peak_percentage < 25.0:         # ä½¿ç”¨ç‡ < 25%
                            memory_class = "perf-good"
                            judgment_reason = f"å†…å­˜ä½¿ç”¨è‰¯å¥½ (ä½¿ç”¨ç‡{memory_peak_percentage:.1f}%, ç»å¯¹å€¼{memory_peak_mb:.0f}MB)"
                        elif memory_peak_percentage < 50.0:      # ä½¿ç”¨ç‡ 25%-50%
                            memory_class = "perf-warning" 
                            judgment_reason = f"å†…å­˜ä½¿ç”¨ä¸€èˆ¬ (ä½¿ç”¨ç‡{memory_peak_percentage:.1f}%, ç»å¯¹å€¼{memory_peak_mb:.0f}MB)"
                        else:                                     # ä½¿ç”¨ç‡ > 50%
                            memory_class = "perf-danger"
                            judgment_reason = f"å†…å­˜ä½¿ç”¨è¿‡é«˜ (ä½¿ç”¨ç‡{memory_peak_percentage:.1f}%, ç»å¯¹å€¼{memory_peak_mb:.0f}MB)"
                                                    
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜é¢œè‰²åˆ¤æ–­ -> {memory_class} ({judgment_reason})")
                        
                        # ç‰¹æ®Šæƒ…å†µå¤„ç†
                        # å¦‚æœç³»ç»Ÿå†…å­˜å¾ˆå¤§(>32GB)ä½†ä½¿ç”¨ç‡å¾ˆä½ï¼Œå³ä½¿ç»å¯¹å€¼å¤§ä¹Ÿè®¤ä¸ºæ˜¯å¥½çš„
                        if system_total_memory:
                            try:
                                total_memory_gb = float(system_total_memory.replace('GB', ''))
                                if total_memory_gb > 32 and memory_peak_percentage < 10.0:
                                    memory_class = "perf-good"
                                    print(f"è°ƒè¯•: å¤§å†…å­˜ç³»ç»Ÿç‰¹æ®Šå¤„ç† -> ç»¿è‰² (ç³»ç»Ÿ{total_memory_gb}GB, ä½¿ç”¨ç‡ä»…{memory_peak_percentage:.1f}%)")
                            except Exception as e:
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•è§£æç³»ç»Ÿæ€»å†…å­˜å¤±è´¥: {str(e)}")
                        
                        # æç«¯æƒ…å†µè­¦å‘Š
                        if memory_peak_mb > 49152:  # > 48GB
                            print(f"è°ƒè¯•: âš ï¸  å†…å­˜ä½¿ç”¨é‡è¿‡å¤§è­¦å‘Š: {memory_peak_mb:.0f}MBï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼")
                            
                    else:
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•æ— æ³•ä»å†…å­˜èŒƒå›´ä¿¡æ¯ä¸­è§£æå³°å€¼å’Œç™¾åˆ†æ¯”")
                        print(f"è°ƒè¯•: å†…å­˜èŒƒå›´ä¿¡æ¯å†…å®¹: {memory_range_info}")
                        
                except Exception as e:
                    print(f"è°ƒè¯•:ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜é¢œè‰²åˆ¤æ–­å‡ºé”™: {str(e)}")
                    import traceback
                    print(f"è°ƒè¯•: å¼‚å¸¸è¯¦æƒ…: {traceback.format_exc()}")
                    memory_class = ""
                    
            else:
                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜æ•°æ®æ— æ•ˆï¼Œè·³è¿‡é¢œè‰²åˆ¤æ–­ - memory_range_info: {memory_range_info}")
            
            
            # ========== å†…å­˜å¹³å‡å€¼çš„é¢œè‰²æ ·å¼ï¼ˆæ–°å¢ç‹¬ç«‹åˆ¤æ–­ï¼‰ ==========
            memory_avg_class = ""
            if memory_avg_value is not None and memory_avg_percentage is not None:  
                try:
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜å¹³å‡å€¼åˆ¤æ–­ - å¹³å‡å€¼: {memory_avg_value:.0f}MB, å¹³å‡å ç”¨ç‡: {memory_avg_percentage:.1f}%")
                    
                    # åŸºäºå†…å­˜å¹³å‡ä½¿ç”¨ç‡çš„åˆ¤æ–­
                    if memory_avg_percentage < 25.0:
                        memory_avg_class = "perf-good"
                        judgment_reason = f"å†…å­˜ä½¿ç”¨è‰¯å¥½ (å¹³å‡ä½¿ç”¨ç‡{memory_avg_percentage:.1f}%, å¹³å‡å€¼{memory_avg_value:.0f}MB)"
                    elif memory_avg_percentage < 50.0:
                        memory_avg_class = "perf-warning" 
                        judgment_reason = f"å†…å­˜ä½¿ç”¨ä¸€èˆ¬ (å¹³å‡ä½¿ç”¨ç‡{memory_avg_percentage:.1f}%, å¹³å‡å€¼{memory_avg_value:.0f}MB)"
                    else:
                        memory_avg_class = "perf-danger"
                        judgment_reason = f"å†…å­˜ä½¿ç”¨è¿‡é«˜ (å¹³å‡ä½¿ç”¨ç‡{memory_avg_percentage:.1f}%, å¹³å‡å€¼{memory_avg_value:.0f}MB)"
                                                
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜å¹³å‡å€¼é¢œè‰²åˆ¤æ–­ -> {memory_avg_class} ({judgment_reason})")
                    
                    # ç‰¹æ®Šæƒ…å†µå¤„ç†
                    if system_total_memory:
                        try:
                            total_memory_gb = float(system_total_memory.replace('GB', ''))
                            if total_memory_gb > 32 and memory_avg_percentage < 10.0:
                                memory_avg_class = "perf-good"
                                print(f"è°ƒè¯•: å¤§å†…å­˜ç³»ç»Ÿç‰¹æ®Šå¤„ç† -> ç»¿è‰² (ç³»ç»Ÿ{total_memory_gb}GB, å¹³å‡ä½¿ç”¨ç‡ä»…{memory_avg_percentage:.1f}%)")
                        except Exception as e:
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•è§£æç³»ç»Ÿæ€»å†…å­˜å¤±è´¥: {str(e)}")
                    
                    # æç«¯æƒ…å†µè­¦å‘Š
                    if memory_avg_value > 49152:  # > 48GB
                        print(f"è°ƒè¯•: âš ï¸  å†…å­˜å¹³å‡ä½¿ç”¨é‡è¿‡å¤§è­¦å‘Š: {memory_avg_value:.0f}MBï¼Œå»ºè®®æ£€æŸ¥æ˜¯å¦æœ‰å†…å­˜æ³„æ¼")
                        
                except Exception as e:
                    print(f"è°ƒè¯•:ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜å¹³å‡å€¼é¢œè‰²åˆ¤æ–­å‡ºé”™: {str(e)}")
                    memory_avg_class = ""
                    
            else:
                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•å†…å­˜å¹³å‡å€¼æ•°æ®æ— æ•ˆï¼Œè·³è¿‡é¢œè‰²åˆ¤æ–­ - memory_avg_value: {memory_avg_value}, memory_avg_percentage: {memory_avg_percentage}")
            
            
            # è¯»å–å†™å…¥é€Ÿåº¦ - ä¿®æ”¹ä¸ºä»test.logæ–‡ä»¶è¯»å–
            write_speed_display = "N/A"
            write_speed_class = ""
            
            # åªæœ‰æµ‹è¯•æˆåŠŸæ—¶æ‰å°è¯•è¯»å–å†™å…¥é€Ÿåº¦
            if result['status'] == 'SUCCESS':
                try:
                    # ä¿®æ”¹ï¼šä»test.logæ–‡ä»¶è¯»å–å†™å…¥é€Ÿåº¦ï¼Œè€Œä¸æ˜¯delay.logæ–‡ä»¶
                    test_log_file = config.get('test_log_file', '')
                    if test_log_file and os.path.exists(test_log_file):
                        print(f"è°ƒè¯•: ä»test.logæ–‡ä»¶è¯»å–å†™å…¥é€Ÿåº¦: {test_log_file}")
                        
                        with open(test_log_file, 'r') as f:
                            test_log_content = f.read()
                        
                        # æŸ¥æ‰¾å†™å…¥é€Ÿåº¦è®°å½•
                        speed_pattern = r'å†™å…¥é€Ÿåº¦:\s*([\d,.]+)\s*æ¡/ç§’'
                        speed_matches = re.findall(speed_pattern, test_log_content)
                        
                        if speed_matches:
                            # ç§»é™¤é€—å·åˆ†éš”ç¬¦å¹¶è½¬æ¢ä¸ºæ•°å­—
                            speed_str = speed_matches[-1].replace(',', '')
                            write_speed = float(speed_str)
                            write_speed_display = f"{write_speed:,.0f}"
                            print(f"è°ƒè¯•: æµ‹è¯• {result['test_name']} ä»test.logè¯»å–åˆ°å†™å…¥é€Ÿåº¦: {write_speed:,.0f} æ¡/ç§’")
                        else:
                            print(f"è°ƒè¯•: æµ‹è¯• {result['test_name']} åœ¨test.logä¸­æœªæ‰¾åˆ°å†™å…¥é€Ÿåº¦ä¿¡æ¯")
                            write_speed_display = "æœªæ‰¾åˆ°"
                    else:
                        print(f"è°ƒè¯•: æµ‹è¯• {result['test_name']} test.logæ–‡ä»¶ä¸å­˜åœ¨: {test_log_file}")
                        write_speed_display = "æ–‡ä»¶ä¸å­˜åœ¨"
                        
                except Exception as e:
                    print(f"è°ƒè¯•: æµ‹è¯• {result['test_name']} è¯»å–å†™å…¥é€Ÿåº¦å¤±è´¥: {str(e)}")
                    write_speed_display = "è¯»å–å¤±è´¥"
            else:
                write_speed_display = "N/A"
                
            # è¯»å–å»¶è¿Ÿç»Ÿè®¡
            delay_stats = "N/A"
            delay_stats_html = "N/A"
            # cleanup_delay_stats_html = "N/A"
            # delay_class = ""
            delay_trends_html = "N/A"
            delay_trends_preview = "N/A"
            window_completion_ratio_display = "N/A" 
            window_details_display = ""
            window_interval_display = "N/A"
            
            
            if result['status'] == 'SUCCESS':
                try:
                    delay_file = config.get('delay_log_file', '')
                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå°è¯•è¯»å–å»¶è¿Ÿæ–‡ä»¶: {delay_file}")
                    
                    # éªŒè¯è¿™æ˜¯å¦æ˜¯å½“å‰æµ‹è¯•çš„æ–‡ä»¶ï¼ˆé€šè¿‡æµ‹è¯•åç§°åŒ¹é…ï¼‰
                    test_name = result.get('test_name', '')
                    if delay_file and test_name:
                        # æ£€æŸ¥å»¶è¿Ÿæ–‡ä»¶è·¯å¾„æ˜¯å¦åŒ…å«å½“å‰æµ‹è¯•åç§°
                        if test_name.replace('test_', '').replace('_', '') not in delay_file.replace('_', '').replace('-', ''):
                            print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿæ–‡ä»¶è·¯å¾„ä¸æµ‹è¯•åç§°ä¸åŒ¹é…")
                            print(f"  æµ‹è¯•åç§°: {test_name}")
                            print(f"  å»¶è¿Ÿæ–‡ä»¶: {delay_file}")
                            # å°è¯•æ ¹æ®æµ‹è¯•åç§°é‡æ–°æ„å»ºæ­£ç¡®çš„å»¶è¿Ÿæ–‡ä»¶è·¯å¾„
                            result_dir_from_perf = os.path.dirname(os.path.dirname(config.get('perf_file', '')))
                            if result_dir_from_perf:
                                corrected_delay_file = os.path.join(result_dir_from_perf, 'logs', f'{test_name}_delay.log')
                                if os.path.exists(corrected_delay_file):
                                    delay_file = corrected_delay_file
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œä½¿ç”¨ä¿®æ­£çš„å»¶è¿Ÿæ–‡ä»¶: {delay_file}")
                    
                    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                    if not delay_file:
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿæ–‡ä»¶è·¯å¾„ä¸ºç©º")
                        delay_stats = "é…ç½®é”™è¯¯ï¼šå»¶è¿Ÿæ–‡ä»¶è·¯å¾„ä¸ºç©º"
                        delay_stats_html = "é…ç½®é”™è¯¯ï¼šå»¶è¿Ÿæ–‡ä»¶è·¯å¾„ä¸ºç©º"
                    elif not os.path.exists(delay_file):
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿæ–‡ä»¶ä¸å­˜åœ¨: {delay_file}")
                        delay_stats = "å»¶è¿Ÿæ–‡ä»¶ä¸å­˜åœ¨"
                        delay_stats_html = "å»¶è¿Ÿæ–‡ä»¶ä¸å­˜åœ¨"
                        
                        # å°è¯•æŸ¥æ‰¾å¯èƒ½çš„å»¶è¿Ÿæ–‡ä»¶
                        possible_delay_files = []
                        delay_dir = os.path.dirname(delay_file)
                        if os.path.exists(delay_dir):
                            try:
                                files = os.listdir(delay_dir)
                                # æŸ¥æ‰¾åŒ…å«å½“å‰æµ‹è¯•åç§°çš„å»¶è¿Ÿæ–‡ä»¶
                                test_specific_files = [f for f in files if 'delay' in f and test_name in f]
                                if test_specific_files:
                                    possible_delay_files.extend([os.path.join(delay_dir, f) for f in test_specific_files])
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ‰¾åˆ°å¯èƒ½çš„å»¶è¿Ÿæ–‡ä»¶: {test_specific_files}")
                            except Exception as e:
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè¯»å–ç›®å½•å¤±è´¥: {str(e)}")
                        
                        # å°è¯•ä½¿ç”¨æ‰¾åˆ°çš„å»¶è¿Ÿæ–‡ä»¶
                        for possible_file in possible_delay_files:
                            if os.path.exists(possible_file):
                                delay_file = possible_file
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œä½¿ç”¨æ‰¾åˆ°çš„å»¶è¿Ÿæ–‡ä»¶: {possible_file}")
                                break
                    
                    # è¯»å–å»¶è¿Ÿæ–‡ä»¶
                    if delay_file and os.path.exists(delay_file):
                        print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå¼€å§‹è¯»å–å»¶è¿Ÿæ–‡ä»¶: {delay_file}")
                        
                        with open(delay_file, 'r') as f:
                            content = f.read()
                            
                            if len(content) > 0:
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿæ–‡ä»¶å†…å®¹å‰200å­—ç¬¦: {content[:200]}")
                                                           
                            # âœ… æ–°å¢ï¼šæå–çª—å£ç”Ÿæˆæ¯”ä¾‹
                            window_info_pattern = r'ç†è®ºçª—å£æ•°:\s*(\d+).*?å®é™…ç”Ÿæˆè®°å½•æ•°:\s*(\d+).*?çª—å£ç”Ÿæˆæ¯”ä¾‹:\s*\d+/\d+\s*=\s*([\d.]+)%'
                            window_matches = re.findall(window_info_pattern, content, re.DOTALL)
                            
                            if window_matches:
                                # å–æœ€åä¸€æ¬¡çš„è®°å½•
                                last_match = window_matches[-1]
                                expected_windows = int(last_match[0])
                                actual_windows = int(last_match[1])
                                completion_percentage = float(last_match[2])
                                
                                window_completion_ratio_display = f"{completion_percentage:.1f}%"
                                window_details_display = f"å®é™…: {actual_windows} / ç†è®º: {expected_windows}"
                                
                                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè§£æåˆ°çª—å£ä¿¡æ¯: {expected_windows}/{actual_windows} = {completion_percentage:.1f}%")
                            else:
                                # å°è¯•ä»å»¶è¿Ÿæ—¥å¿—ä¸­æå–ç®€å•çš„æ¯”ä¾‹ä¿¡æ¯
                                ratio_pattern = r'çª—å£ç”Ÿæˆæ¯”ä¾‹:\s*([\d.]+)%'
                                ratio_matches = re.findall(ratio_pattern, content)
                                window_detail_pattern = r'ç†è®ºçª—å£æ•°:\s*(\d+).*?å®é™…ç”Ÿæˆè®°å½•æ•°:\s*(\d+)'
                                detail_matches = re.findall(window_detail_pattern, content, re.DOTALL)
                                
                                if ratio_matches and detail_matches:
                                    # å–æœ€åä¸€æ¬¡çš„è®°å½•
                                    last_ratio = float(ratio_matches[-1])
                                    last_detail = detail_matches[-1]
                                    expected_windows = int(last_detail[0])
                                    actual_windows = int(last_detail[1])
                                    
                                    window_completion_ratio_display = f"{last_ratio:.1f}%"
                                    window_details_display = f"å®é™…: {actual_windows} / ç†è®º: {expected_windows}"
                                    
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œä»æ£€æŸ¥ç»“æœè§£æåˆ°çª—å£ä¿¡æ¯: {expected_windows}/{actual_windows} = {last_ratio:.1f}%")
                                elif ratio_matches:
                                    # åªæœ‰æ¯”ä¾‹ï¼Œæ²¡æœ‰è¯¦æƒ…
                                    last_ratio = float(ratio_matches[-1])
                                    window_completion_ratio_display = f"{last_ratio:.1f}%"
                                    window_details_display = "è¯¦æƒ…å¯ç”¨"
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œä»…è§£æåˆ°æ¯”ä¾‹: {last_ratio:.1f}%")
                                else:
                                    window_completion_ratio_display = "æ— æ•°æ®"
                                    window_details_display = ""
                                    print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœªæ‰¾åˆ°çª—å£æ¯”ä¾‹ä¿¡æ¯")
                                    
                            # æ–°å¢ï¼šæå–çª—å£é—´éš”ä¿¡æ¯
                            window_interval_match = re.search(r'çª—å£é—´éš”æ£€æµ‹ç»“æœ:\s*(\d+)ms\s*\(([\d.]+)ç§’\)', content)
                            if window_interval_match:
                                interval_ms = int(window_interval_match.group(1))
                                interval_sec = float(window_interval_match.group(2))
                                window_interval_display = f"{interval_ms}ms ({interval_sec:.1f}s)"
                            else:
                                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å…·ä½“çš„é—´éš”ä¿¡æ¯ï¼Œå°è¯•ä»åŠ¨æ€é˜ˆå€¼ä¿¡æ¯ä¸­æå–
                                dynamic_threshold_match = re.search(r'åŠ¨æ€å»¶è¿Ÿé˜ˆå€¼:\s*([^\n]+)', content)
                                if dynamic_threshold_match:
                                    threshold_info = dynamic_threshold_match.group(1).strip()
                                    # ç»Ÿä¸€æ ¼å¼åŒ–é˜ˆå€¼ä¿¡æ¯ä¸º "XXXms (X.Xs)" æ ¼å¼
                                    formatted_threshold = self.format_window_interval_for_display(threshold_info)

                                    window_interval_display = f"é˜ˆå€¼: {threshold_info}"
                                else:
                                    window_interval_display = "N/A"
                                    
                            # # ç»Ÿè®¡å»¶è¿Ÿåˆ†å¸ƒ
                            # delay_counts = {
                            #     'ä¼˜ç§€': content.count('å»¶è¿Ÿç­‰çº§: ä¼˜ç§€'),
                            #     'è‰¯å¥½': content.count('å»¶è¿Ÿç­‰çº§: è‰¯å¥½'), 
                            #     'æ­£å¸¸': content.count('å»¶è¿Ÿç­‰çº§: æ­£å¸¸'),
                            #     'è½»å¾®å»¶è¿Ÿ': content.count('å»¶è¿Ÿç­‰çº§: è½»å¾®å»¶è¿Ÿ'),
                            #     'æ˜æ˜¾å»¶è¿Ÿ': content.count('å»¶è¿Ÿç­‰çº§: æ˜æ˜¾å»¶è¿Ÿ'),
                            #     'ä¸¥é‡å»¶è¿Ÿ': content.count('å»¶è¿Ÿç­‰çº§: ä¸¥é‡å»¶è¿Ÿ'),
                            #     'ç›®æ ‡è¡¨æ— æ•°æ®': content.count('å»¶è¿Ÿç­‰çº§: ç›®æ ‡è¡¨æ— æ•°æ®'),
                            #     'ç›®æ ‡è¡¨ä¸å­˜åœ¨': content.count('å»¶è¿Ÿç­‰çº§: ç›®æ ‡è¡¨ä¸å­˜åœ¨')
                            # }
                            
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿåˆ†å¸ƒç»Ÿè®¡: {delay_counts}")
                            
                            # # å°è¯•ä»å†…å®¹ä¸­æå–æ£€æŸ¥æ¬¡æ•°ä¿¡æ¯
                            # check_count = 0
                            
                            # # æ–¹æ³•1: ç»Ÿè®¡åŒ…å«"ç¬¬ X æ¬¡æ£€æŸ¥"çš„è¡Œæ•°
                            # check_pattern = r'ç¬¬\s+(\d+)\s+æ¬¡æ£€æŸ¥'
                            # check_matches = re.findall(check_pattern, content)
                            # if check_matches:
                            #     # è·å–æœ€å¤§çš„æ£€æŸ¥æ¬¡æ•°
                            #     check_count = max(int(match) for match in check_matches)
                            #     print(f"è°ƒè¯•: ä»å†…å®¹ä¸­è§£æå‡ºæ£€æŸ¥æ¬¡æ•°: {check_count}")
                            
                            # # æ–¹æ³•2: å¦‚æœæ–¹æ³•1å¤±è´¥ï¼Œå°è¯•ç»Ÿè®¡"æµåç§°:"çš„å‡ºç°æ¬¡æ•°æ¥ä¼°ç®—
                            # if check_count == 0:
                            #     stream_mentions = content.count('æµåç§°:')
                            #     if stream_mentions > 0:
                            #         # å‡è®¾æ¯æ¬¡æ£€æŸ¥æ¶‰åŠçš„æµæ•°é‡ï¼Œå¯ä»¥ä»contentä¸­è¿›ä¸€æ­¥åˆ†æ
                            #         # ç®€å•ä¼°ç®—ï¼šå¦‚æœæœ‰æµåç§°æåŠï¼Œè‡³å°‘æœ‰1æ¬¡æ£€æŸ¥
                            #         check_count = max(1, stream_mentions // 10)  # ç²—ç•¥ä¼°ç®—
                            #         print(f"è°ƒè¯•: é€šè¿‡æµåç§°ä¼°ç®—æ£€æŸ¥æ¬¡æ•°: {check_count} (åŸºäº{stream_mentions}ä¸ªæµåç§°æåŠ)")
                            
                            # # æ–¹æ³•3: å¦‚æœä»ç„¶ä¸º0ï¼Œè®¾ç½®é»˜è®¤å€¼
                            # if check_count == 0:
                            #     check_count = 1  # è®¾ç½®æœ€å°å€¼
                            #     print(f"è°ƒè¯•: ä½¿ç”¨é»˜è®¤æ£€æŸ¥æ¬¡æ•°: {check_count}")
                            
                            # # è®¡ç®—æ¯æ¬¡æ£€æŸ¥çš„æµæ•°é‡
                            # total_delay_records = sum(delay_counts.values())
                            # if total_delay_records > 0 and check_count > 0:
                            #     stream_count_per_check = total_delay_records // check_count
                            # else:
                            #     stream_count_per_check = 0
                                
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ€»å»¶è¿Ÿè®°å½•æ•°: {total_delay_records}")
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œè®¡ç®—å‡ºçš„æ¯æ¬¡æ£€æŸ¥æµæ•°: {stream_count_per_check}")
                            
                            # # éªŒè¯è®¡ç®—æ˜¯å¦æ­£ç¡®
                            # expected_total = check_count * stream_count_per_check
                            # actual_total = sum(delay_counts.values())
                            
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ£€æŸ¥æ¬¡æ•°: {check_count}")
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ¯æ¬¡æ£€æŸ¥æµæ•°: {stream_count_per_check}")
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œé¢„æœŸæ€»è®¡æ•°: {expected_total}")
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå®é™…æ€»è®¡æ•°: {actual_total}")
                            
                            # # ä½¿ç”¨å®é™…æ€»æ•°ä½œä¸ºåŸºå‡†ï¼Œæ›´å¯é 
                            # total_checks = actual_total if actual_total > 0 else expected_total
                            
                            # print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæœ€ç»ˆä½¿ç”¨çš„æ€»æ£€æŸ¥æ¬¡æ•°: {total_checks}")
                            
                            # if total_checks > 0:
                            #     # å®šä¹‰å»¶è¿Ÿçº§åˆ«å¯¹åº”çš„CSSç±»
                            #     delay_level_classes = {
                            #         'ä¼˜ç§€': 'delay-excellent',
                            #         'è‰¯å¥½': 'delay-good',
                            #         'æ­£å¸¸': 'delay-normal',
                            #         'è½»å¾®å»¶è¿Ÿ': 'delay-warning',
                            #         'æ˜æ˜¾å»¶è¿Ÿ': 'delay-danger',
                            #         'ä¸¥é‡å»¶è¿Ÿ': 'delay-critical',
                            #         'ç›®æ ‡è¡¨æ— æ•°æ®': 'delay-no-data',
                            #         'ç›®æ ‡è¡¨ä¸å­˜åœ¨': 'delay-table-missing'
                            #     }
                            
                            #     # æ„å»ºçº¯æ–‡æœ¬ç‰ˆæœ¬ï¼ˆç”¨äºå¯¼å‡ºç­‰ï¼‰
                            #     delay_parts = []
                            #     # æ„å»ºHTMLç‰ˆæœ¬ï¼ˆæ¯ä¸ªçº§åˆ«æœ‰è‡ªå·±çš„é¢œè‰²ï¼‰
                            #     delay_parts_html = []
                                
                            #     for level, count in delay_counts.items():
                            #         if count > 0:
                            #             percentage = count / total_checks * 100
                            #             text_part = f"{level}:{count}({percentage:.0f}%)"
                            #             delay_parts.append(text_part)
                                        
                            #             # HTMLç‰ˆæœ¬ï¼šæ¯ä¸ªçº§åˆ«ç”¨å¯¹åº”çš„CSSç±»åŒ…è£…
                            #             css_class = delay_level_classes.get(level, 'delay-normal')
                            #             html_part = f'<span class="{css_class}">{level}:{count}({percentage:.0f}%)</span>'
                            #             delay_parts_html.append(html_part)
                                
                            #     # çº¯æ–‡æœ¬ç‰ˆæœ¬
                            #     delay_stats = " | ".join(delay_parts) if delay_parts else "æ— æœ‰æ•ˆå»¶è¿Ÿæ•°æ®"
                                
                            #     # HTMLç‰ˆæœ¬ï¼ˆå¤šé¢œè‰²æ˜¾ç¤ºï¼‰
                            #     delay_stats_html = " | ".join(delay_parts_html) if delay_parts_html else "æ— æœ‰æ•ˆå»¶è¿Ÿæ•°æ®"
                                
                            #     print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œç”Ÿæˆçš„å»¶è¿Ÿç»Ÿè®¡: {delay_stats}")
                            #     print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œç”Ÿæˆçš„HTMLå»¶è¿Ÿç»Ÿè®¡: {delay_stats_html}")
                                
                            #     # æ ¹æ®ä¸»è¦å»¶è¿Ÿçº§åˆ«è®¾ç½®é¢œè‰²
                            #     if delay_counts['ç›®æ ‡è¡¨ä¸å­˜åœ¨'] > 0:
                            #         delay_class = "delay-table-missing"
                            #     elif delay_counts['ç›®æ ‡è¡¨æ— æ•°æ®'] > 0:
                            #         delay_class = "delay-no-data"
                            #     elif delay_counts['ä¸¥é‡å»¶è¿Ÿ'] > 0:
                            #         delay_class = "delay-critical"
                            #     elif delay_counts['æ˜æ˜¾å»¶è¿Ÿ'] > 0:
                            #         delay_class = "delay-danger"
                            #     elif delay_counts['è½»å¾®å»¶è¿Ÿ'] > 0:
                            #         delay_class = "delay-warning"
                            #     elif delay_counts['æ­£å¸¸'] + delay_counts['è‰¯å¥½'] + delay_counts['ä¼˜ç§€'] > total_checks * 0.6:
                            #         delay_class = "delay-normal"
                            #     elif delay_counts['è‰¯å¥½'] + delay_counts['ä¼˜ç§€'] > total_checks * 0.7:
                            #         delay_class = "delay-good"
                            #     elif delay_counts['ä¼˜ç§€'] > total_checks * 0.8:
                            #         delay_class = "delay-excellent"
                            #     else:
                            #         delay_class = "delay-normal"
                                    
                            #     print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿé¢œè‰²ç±»: {delay_class}")
                            # else:
                            #     print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œæ€»æ£€æŸ¥æ¬¡æ•°ä¸º0ï¼Œå»¶è¿Ÿç›‘æ§å¯èƒ½æœªæ­£å¸¸å·¥ä½œ")
                            #     delay_stats = "å»¶è¿Ÿç›‘æ§æœªç”Ÿæˆæœ‰æ•ˆæ•°æ®"
                            #     delay_stats_html = "å»¶è¿Ÿç›‘æ§æœªç”Ÿæˆæœ‰æ•ˆæ•°æ®"
                                
                        # # æ–°å¢ï¼šæ¸…ç†åå»¶è¿Ÿç»Ÿè®¡
                        # if hasattr(self, 'delay_trends_analysis') and self.delay_trends_analysis  :
                        #     cleanup_analysis = self.analyze_delay_cleanup_statistics(
                        #         delay_file, 
                        #         self.fixed_params.get('max_delay_threshold', 30000)
                        #     )
                            
                        #     if cleanup_analysis:
                        #         original_html, cleanup_html = self.format_delay_stats_comparison(
                        #             cleanup_analysis['original_stats'],
                        #             cleanup_analysis['cleanup_stats']
                        #         )
                                
                        #         delay_stats_html = original_html
                        #         cleanup_delay_stats_html = cleanup_html
                                
                        #         # æ·»åŠ æ¸…ç†ç»Ÿè®¡ä¿¡æ¯åˆ°è°ƒè¯•è¾“å‡º
                        #         print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•ï¼Œå»¶è¿Ÿæ¸…ç†åˆ†æå®Œæˆ")
                        #         print(f"  åŸå§‹æ£€æŸ¥æ¬¡æ•°: {cleanup_analysis['original_stats']['total_checks']}")
                        #         print(f"  æ¸…ç†åæ£€æŸ¥æ¬¡æ•°: {cleanup_analysis['cleanup_stats']['included_checks']}")
                        #         print(f"  ç§»é™¤çš„å‰æœŸæ£€æŸ¥: {cleanup_analysis['cleanup_removed_checks']}")
                        #     else:
                        #         cleanup_delay_stats_html = "æ¸…ç†åˆ†æå¤±è´¥"
                        # else:
                        #     cleanup_delay_stats_html = "æœªå¯ç”¨æ¸…ç†åˆ†æ"    
                        
                        full_trends_content = self.simple_delay_trends_analysis(delay_file)
                        if full_trends_content and full_trends_content != "å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨":
                            # åˆ†å‰²è¶‹åŠ¿è¡Œ
                            trend_lines = full_trends_content.split(' | ')
                            
                            # é»˜è®¤æ˜¾ç¤ºæœ€è¿‘5ä¸ªæ£€æŸ¥ç»“æœ
                            recent_count = 5
                            if len(trend_lines) <= recent_count:
                                # å¦‚æœæ€»æ•°ä¸è¶…è¿‡5ä¸ªï¼Œç›´æ¥æ˜¾ç¤ºå…¨éƒ¨
                                delay_trends_preview = full_trends_content
                                delay_trends_html = full_trends_content
                            else:
                                # æ˜¾ç¤ºæœ€è¿‘5ä¸ª + çœç•¥å·
                                recent_trends = trend_lines[-recent_count:]  # å–æœ€å5ä¸ª
                                delay_trends_preview = ' | '.join(recent_trends) + f" ...å…±{len(trend_lines)}æ¬¡æ£€æŸ¥"
                                delay_trends_html = full_trends_content  # å®Œæ•´å†…å®¹ç”¨äºå·¥å…·æç¤º
                                
                        else:
                            delay_trends_html = "æ— è¶‹åŠ¿æ•°æ®"
                            delay_trends_preview = "æ— è¶‹åŠ¿æ•°æ®"
                    else:
                        delay_trends_html = "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"
                        delay_trends_preview = "æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨"
                        window_completion_ratio_display = "N/A"
                        window_details_display = ""
                        write_speed_display = "N/A"
                        
                except Exception as e:
                    delay_trends_html = f"åˆ†æå¤±è´¥: {str(e)}"
                    delay_trends_preview = f"åˆ†æå¤±è´¥: {str(e)[:30]}..."
                    window_completion_ratio_display = "åˆ†æå¤±è´¥"
                    window_details_display = ""
                    write_speed_display = "è·å–å¤±è´¥"
                                
            else:
                print(f"è°ƒè¯•: ç¬¬ {result_index + 1} ä¸ªæµ‹è¯•çŠ¶æ€ä¸º {result['status']}ï¼Œè·³è¿‡å»¶è¿Ÿæ•°æ®è¯»å–")
                delay_stats = "N/A"
                delay_stats_html = "N/A"
                delay_trends_html = "N/A"
                delay_trends_preview = "N/A"
                window_completion_ratio_display = "N/A"
                window_details_display = ""
                write_speed_display = "N/A"
            
             # è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ªç»“æœçš„é”™è¯¯ä¿¡æ¯
            print(f"è°ƒè¯•HTMLæŠ¥å‘Š - æµ‹è¯• {result['test_name']}:")
            print(f"  çŠ¶æ€: {result['status']}")
            print(f"  é”™è¯¯å­—æ®µå­˜åœ¨: {'error' in result}")
            if 'error' in result:
                error_content = result.get('error', '')
                print(f"  é”™è¯¯å†…å®¹: {str(error_content)[:100]}..." if error_content else "  é”™è¯¯å†…å®¹: ç©º")
                
            # é”™è¯¯ä¿¡æ¯å¤„ç†
            error_msg = result.get('error', '')
            print(f"è°ƒè¯•: åŸå§‹error_msg = {repr(error_msg)}")
            
            if error_msg:
                # å¦‚æœé”™è¯¯ä¿¡æ¯å¤ªé•¿ï¼Œæˆªæ–­ä½†ä¿ç•™å…³é”®ä¿¡æ¯
                if len(error_msg) > 300:
                    error_msg = error_msg[:300] + "..."
                error_msg = error_msg.replace('<', '&lt;').replace('>', '&gt;')
                print(f"è°ƒè¯•: HTMLè½¬ä¹‰åerror_msg = {repr(error_msg[:300])}")
            else:
                error_msg = ""
                print(f"è°ƒè¯•: error_msgä¸ºç©º")
                
            # å¤„ç†è·³è¿‡åŸå› æ˜¾ç¤º
            if result['status'] == 'SKIPPED':
                skip_reason = result.get('skip_reason', 'æœªçŸ¥åŸå› ')
                error_msg = f"è·³è¿‡åŸå› : {skip_reason}"
 
            cpu_peak_display = f"{cpu_peak_value:.1f}" if cpu_peak_value is not None else "N/A"
            memory_peak_display = f"{memory_peak_value:.0f}" if memory_peak_value else "N/A"
            # ä¿®æ”¹å¹³å‡å€¼æ˜¾ç¤ºï¼ŒåŒ…å«å®Œæ•´çš„å•ä½å’Œç™¾åˆ†æ¯”ä¿¡æ¯
            if cpu_avg_value is not None:
                cpu_avg_display = f"{cpu_avg_value:.1f}%{cpu_core_info}"
            else:
                cpu_avg_display = "N/A"
                
            if memory_avg_value is not None and memory_avg_percentage is not None:
                memory_avg_display = f"{memory_avg_value:.0f}MB({memory_avg_percentage:.1f}%){memory_total_info}"
            else:
                memory_avg_display = "N/A"
                   
            
            delay_trends_escaped = delay_trends_html.replace('"', '&quot;').replace("'", '&#39;').replace('\n', '\\n').replace('\r', '\\r')
            
            html_content += f"""
            <tr class="{status_class}">
                <td><strong>{result['test_name']}</strong></td>
                <td>{config['sql_type']}</td>
                <td>{config['agg_or_select']}</td>
                <td>{config['tbname_or_trows_or_sourcetable']}</td>
                <td><span class="status-badge {status_badge}">{result['status']}</span></td>
                <td>{result.get('duration', 0):.1f}</td>
                <td>
                    <div class="tooltip">
                        <div class="sql-preview">{sql_preview}</div>
                        <span class="tooltiptext">{sql_full_escaped}</span>
                    </div>
                </td>
                <td class="{cpu_class}">
                    {cpu_range_info if cpu_range_info else 'N/A'}
                </td>
                <td class="{memory_class}">
                    {memory_range_info if memory_range_info else 'N/A'}
                </td>
                <td class="{cpu_avg_class}">
                    {cpu_avg_display}
                </td>
                <td class="{memory_avg_class}">
                    {memory_avg_display}
                </td>
                <td style="font-size: 10px; text-align: center;">
                    <div style="font-weight: bold; color: #2196F3;">{window_completion_ratio_display}</div>
                    <div style="font-size: 9px; color: #666; margin-top: 2px;">{window_details_display}</div>
                    <div style="font-size: 8px; color: #888; margin-top: 1px;">çª—å£é—´éš”: {window_interval_display}</div>
                </td>
                <td class="{write_speed_class}" style="text-align: center; font-weight: bold;">
                    {write_speed_display}
                </td>
                <!-- âœ… æ³¨é‡Šæ‰åŸå§‹å»¶è¿Ÿç»Ÿè®¡åˆ—
                <td style="font-size: 10px;">{delay_stats_html}</td>
                -->
                <td>
                    <div class="trends-tooltip">
                        <div class="delay-trends-preview">{delay_trends_preview}</div>
                        <span class="trendstooltiptext">{delay_trends_escaped}</span>
                    </div>
                </td>
                <td style="color: #dc3545; font-size: 10px;">{error_msg}</td>
            </tr>
"""
        
        print(f"è°ƒè¯•: HTMLè¡Œç”Ÿæˆå®Œæˆï¼Œé”™è¯¯åˆ—å†…å®¹: {error_msg[:300]}...")
        
        
        html_content += f"""
        </table>
    </div>
    
    <div style="margin-top: 30px; padding: 20px; background: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1);">
        <h3>ğŸ“Š ä½¿ç”¨è¯´æ˜</h3>
        <ul>
            <li><strong>çŠ¶æ€è¯´æ˜</strong>: 
                <span class="badge-success">æˆåŠŸ</span> - æµåˆ›å»ºæˆåŠŸå¹¶æ­£å¸¸è¿è¡Œ
                <span class="badge-failed">å¤±è´¥</span> - æµåˆ›å»ºå¤±è´¥ï¼Œé€šå¸¸ä¸ºSQLè¯­æ³•æˆ–åŠŸèƒ½é™åˆ¶
                <span class="badge-skipped">è·³è¿‡(å·²çŸ¥å¤±è´¥)</span> - å·²çŸ¥å¤±è´¥åœºæ™¯ï¼Œè¢«è¿‡æ»¤å™¨è·³è¿‡æµ‹è¯•
                <span class="badge-warning">è·³è¿‡(æ²¡æœ‰å®é™…æ„ä¹‰)</span> - å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„åœºæ™¯
                <span class="badge-skipped">è·³è¿‡(å…¶ä»–)</span> - å…¶ä»–åŸå› è·³è¿‡çš„æµ‹è¯•åœºæ™¯
            </li>
            <li><strong>SQLé¢„è§ˆ</strong>: é¼ æ ‡æ‚¬åœæŸ¥çœ‹å®Œæ•´SQLè¯­å¥</li>
            <li><strong>æ€§èƒ½æŒ‡æ ‡</strong>: 
                CPU/å†…å­˜ - <span class="perf-good">ç»¿è‰²(ä¼˜ç§€)</span> 
                <span class="perf-warning">é»„è‰²(ä¸€èˆ¬)</span> 
                <span class="perf-danger">çº¢è‰²(è¾ƒé«˜)</span>
                <br>æ˜¾ç¤ºæ ¼å¼: èµ„æºæ¶ˆè€—èŒƒå›´(æœ€å°->æœ€å¤§) + ç³»ç»Ÿä¿¡æ¯
                <br><strong>CPUé¢œè‰²åˆ¤æ–­</strong>: åŸºäºå®é™…CPUä½¿ç”¨ç‡ (æ˜¾ç¤ºå€¼Ã·æ€»æ ¸æ•°) 
                <br>ã€€ã€€ç»¿è‰²: å®é™…ä½¿ç”¨ç‡ < 30% | é»„è‰²: 30%-70% | çº¢è‰²: > 70%
                <br><strong>å†…å­˜é¢œè‰²åˆ¤æ–­</strong>: ç»¼åˆè€ƒè™‘ä½¿ç”¨ç‡å’Œç»å¯¹å€¼
                <br>ã€€ã€€ç»¿è‰²: ä½¿ç”¨ç‡<25% | é»„è‰²: ä½¿ç”¨ç‡25%-50% | çº¢è‰²: ä½¿ç”¨ç‡>50%
                <br>ã€€ã€€ç‰¹æ®Š: å¤§å†…å­˜ç³»ç»Ÿ(>32GB)ä¸”ä½¿ç”¨ç‡<10%æ—¶ä¼˜å…ˆåˆ¤ä¸ºä¼˜ç§€
            </li>
            <li><strong>æ€§èƒ½èŒƒå›´è¯´æ˜</strong>:
                <br>CPUå³°å€¼èŒƒå›´: æ˜¾ç¤ºæµ‹è¯•æœŸé—´çš„CPUä½¿ç”¨ç‡èŒƒå›´(æœ€å°->æœ€å¤§)ï¼Œæ‹¬å·å†…ä¸ºç³»ç»ŸCPUæ ¸æ•°
                <br>å†…å­˜å³°å€¼èŒƒå›´: æ˜¾ç¤ºå†…å­˜ä½¿ç”¨é‡èŒƒå›´(æœ€å°->æœ€å¤§)å’Œå ç³»ç»Ÿæ€»å†…å­˜ç™¾åˆ†æ¯”ï¼Œæ‹¬å·å†…ä¸ºç³»ç»Ÿæ€»å†…å­˜
                <br>CPUå¹³å‡å€¼: æ˜¾ç¤ºæµ‹è¯•æœŸé—´çš„CPUå¹³å‡å€¼
                <br>å†…å­˜å¹³å‡å€¼: æ˜¾ç¤ºå†…å­˜ä½¿ç”¨å¹³å‡å€¼
            </li>
            <li><strong>ğŸ“Š æµçª—å£ç”Ÿæˆæ¯”ä¾‹è¯´æ˜</strong>:
                <br><strong>ä½œç”¨</strong>: è¯„ä¼°æµè®¡ç®—çš„çª—å£ç”Ÿæˆæ•ˆç‡å’Œå®Œæ•´æ€§
                <br><strong>è®¡ç®—å…¬å¼</strong>: å®é™…ç”Ÿæˆçª—å£æ•° Ã· ç†è®ºåº”ç”Ÿæˆçª—å£æ•° Ã— 100%
                <br><strong>ç†è®ºçª—å£æ•°</strong>: æ ¹æ®æ•°æ®æ—¶é—´è·¨åº¦(æºè¡¨last(ts) - ç›®æ ‡è¡¨first(ts))å’Œè§¦å‘æ–¹å¼ï¼Œè½¬æˆç›¸åº”çš„æŸ¥è¯¢è¯­å¥ç”Ÿæˆé¢„æœŸçª—å£æ•°é‡
                <br><strong>å®é™…çª—å£æ•°</strong>: ç›®æ ‡è¡¨ä¸­å®é™…ç”Ÿæˆçš„è®°å½•æ¡æ•°
                <br><strong>æ˜¾ç¤ºæ ¼å¼</strong>: 
                <br>ã€€ã€€ç¬¬ä¸€è¡Œ: ç™¾åˆ†æ¯”(å¦‚ 95.2%) - çª—å£ç”Ÿæˆæ¯”ä¾‹
                <br>ã€€ã€€ç¬¬äºŒè¡Œ: å®é™…æ•°/ç†è®ºæ•°(å¦‚ å®é™…: 95 / ç†è®º: 100) - çª—å£é—´éš”
                <br><strong>æ¯”ä¾‹è§£è¯»</strong>:
                <br>ã€€ã€€â€¢ 95%-100%: ä¼˜ç§€ï¼Œæ‰€æœ‰çª—å£éƒ½å·²ç”Ÿæˆæˆ–è€…æœ€åä¸€ä¸ªçª—å£ç•¥å¾®å»¶è¿Ÿ
                <br>ã€€ã€€â€¢ 80%-95%: è‰¯å¥½ï¼Œå­˜åœ¨ä¸€å®šå»¶è¿Ÿ
                <br>ã€€ã€€â€¢ 60%-80%: ä¸€èˆ¬ï¼Œæœ‰æ˜æ˜¾å»¶è¿Ÿæˆ–ä¸¢å¤±
                <br>ã€€ã€€â€¢ < 60%: éœ€è¦å…³æ³¨ï¼Œå¯èƒ½å­˜åœ¨æ€§èƒ½ç“¶é¢ˆ
            </li>            
            <li><strong>æ¯ç§’å†™å…¥é€Ÿåº¦è¯´æ˜</strong>:
                <br><strong>è®¡ç®—æ–¹å¼</strong>: æ€»è®°å½•æ•° Ã· æ—¶é—´è·¨åº¦(ç§’)ï¼Œä½¿ç”¨å…¨è¡¨æ•°æ® select first(ts), last(ts), count(*) from æµè®¡ç®—æ•°æ®æºè¡¨
                <br><strong>ç”¨é€”</strong>: è¯„ä¼°æ•°æ®å†™å…¥æ€§èƒ½ï¼Œä¸æµè®¡ç®—å»¶è¿Ÿé…åˆåˆ†æç³»ç»Ÿè´Ÿè½½
            </li>
            <!-- âœ… æ³¨é‡Šæ‰å»¶è¿Ÿç»Ÿè®¡è¯´æ˜
            <li><strong>å»¶è¿Ÿç­‰çº§</strong> (åŸºäºæœ€å¤§å»¶è¿Ÿé˜ˆå€¼{self.fixed_params.get('max_delay_threshold', 30000)}msè¿›è¡Œåˆ†çº§):                  
                <br>â€¢ å»¶è¿Ÿæ—¶é—´ = æºæ•°æ®è¡¨çš„Lastï¼ˆTsï¼‰- æµç”Ÿæˆæ•°æ®è¡¨çš„Lastï¼ˆTsï¼‰
                <br>â€¢ å»¶è¿Ÿå€æ•° = å»¶è¿Ÿæ—¶é—´ / æœ€å¤§å»¶è¿Ÿé˜ˆå€¼ 
                <br><span class="delay-excellent">ğŸŸ¢ ä¼˜ç§€ (< 0.1å€é—´éš”)</span>: å»¶è¿Ÿ < {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 0.1)}ï¼Œæµè®¡ç®—éå¸¸åŠæ—¶
                <br><span class="delay-good">ğŸŸ¢ è‰¯å¥½ (0.1-0.5å€é—´éš”)</span>: å»¶è¿Ÿ {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 0.1)}-{format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 0.5)}ï¼Œæµè®¡ç®—åŠæ—¶
                <br><span class="delay-normal">ğŸŸ¡ æ­£å¸¸ (0.5-1å€é—´éš”)</span>: å»¶è¿Ÿ {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 0.5)}-{format_delay_time(self.fixed_params.get('max_delay_threshold', 30000))}ï¼Œåœ¨æ£€æŸ¥é—´éš”å†…
                <br><span class="delay-warning">ğŸŸ¡ è½»å¾®å»¶è¿Ÿ (1-6å€é—´éš”)</span>: å»¶è¿Ÿ {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000))}-{format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 6)}ï¼Œç•¥æœ‰æ»å
                <br><span class="delay-danger">ğŸŸ  æ˜æ˜¾å»¶è¿Ÿ (6-30å€é—´éš”)</span>: å»¶è¿Ÿ {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 6)}-{format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 30)}ï¼Œéœ€è¦å…³æ³¨
                <br><span class="delay-critical">ğŸ”´ ä¸¥é‡å»¶è¿Ÿ (> 30å€é—´éš”)</span>: å»¶è¿Ÿ > {format_delay_time(self.fixed_params.get('max_delay_threshold', 30000) * 30)}ï¼Œéœ€è¦ä¼˜åŒ–
                <br><span class="delay-no-data">ğŸ“Š ç›®æ ‡è¡¨æ— æ•°æ®</span>: æµè®¡ç®—å°šæœªç”Ÿæˆç»“æœæˆ–è€…æµçŠ¶æ€å¼‚å¸¸
                <br><span class="delay-table-missing">ğŸ’¥ ç›®æ ‡è¡¨ä¸å­˜åœ¨</span>: æµåˆ›å»ºå¤±è´¥æˆ–è€…ç›®æ ‡è¡¨é…ç½®é—®é¢˜
            </li>
            -->
            <li><strong>å»¶è¿Ÿç»Ÿè®¡è¯´æ˜</strong>:
                <br><strong>åŸå§‹å»¶è¿Ÿç»Ÿè®¡</strong>: ç»Ÿè®¡æ‰€æœ‰å»¶è¿Ÿæ£€æŸ¥çš„åˆ†å¸ƒæƒ…å†µ
                <br><strong>åŸå§‹å»¶è¿Ÿè¶‹åŠ¿</strong>: æ˜¾ç¤ºå„æ¬¡å»¶è¿Ÿæ£€æŸ¥çš„æ—¶é—´åºåˆ—è¶‹åŠ¿
                <br>æ ¼å¼: "è¡Œæ•° ï¼šä¸»è¦çŠ¶æ€æˆ–è€…å»¶è¿Ÿæ—¶é—´ | ä¸»è¦çŠ¶æ€æˆ–è€…å»¶è¿Ÿæ—¶é—´ | ä¸»è¦çŠ¶æ€æˆ–è€…å»¶è¿Ÿæ—¶é—´"
                <br>ç”¨é€”: è§‚å¯Ÿå»¶è¿Ÿå˜åŒ–è¶‹åŠ¿ï¼Œè¯†åˆ«æ€§èƒ½æ³¢åŠ¨æ¨¡å¼
                <br>äº¤äº’: é¼ æ ‡æ‚¬åœæŸ¥çœ‹å®Œæ•´è¶‹åŠ¿åºåˆ—
            </li>
            <li><strong>äº¤äº’åŠŸèƒ½</strong>: ç‚¹å‡»è¡¨å¤´æ’åºï¼Œä½¿ç”¨ç­›é€‰å™¨å¿«é€ŸæŸ¥æ‰¾</li>
        </ul>
    </div>
    
    <div style="margin-top: 20px; text-align: center; color: #666; font-size: 12px;">
        <p>ğŸ“ è¯¦ç»†æ—¥å¿—æ–‡ä»¶ä½ç½®: {result_dir}</p>
        <p>ğŸƒâ€â™‚ï¸ TDengine æµè®¡ç®—æ€§èƒ½æµ‹è¯•å·¥å…· | ç”Ÿæˆæ—¶é—´: {current_time}</p>
    </div>
</body>
</html>
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"è¯¦ç»†HTMLæŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


    def format_window_interval_for_display(self, interval_text):
        """æ ¼å¼åŒ–çª—å£é—´éš”ä¸ºç»Ÿä¸€çš„æ˜¾ç¤ºæ ¼å¼ "XXXms (X.Xs)"
        
        Args:
            interval_text: åŸå§‹é—´éš”æ–‡æœ¬ï¼Œå¦‚ "50000ms", "50s", "50ç§’", "1m25s" ç­‰
            
        Returns:
            str: ç»Ÿä¸€æ ¼å¼çš„é—´éš”æ˜¾ç¤º
        """
        try:
            if not interval_text or interval_text.strip() == "":
                return "50000ms (50.0s)"  # é»˜è®¤å€¼
            
            interval_text = interval_text.strip()
            
            # å¦‚æœå·²ç»æ˜¯ç›®æ ‡æ ¼å¼ï¼Œç›´æ¥è¿”å›
            if re.match(r'^\d+ms\s*\([0-9.]+s\)$', interval_text):
                return interval_text
            
            # æå–æ¯«ç§’æ•°
            ms_value = None
            
            # å°è¯•å„ç§æ ¼å¼çš„è§£æ
            patterns = [
                (r'(\d+)ms', lambda x: int(x)),                    # 50000ms
                (r'(\d+(?:\.\d+)?)s(?!.*ms)', lambda x: int(float(x) * 1000)),  # 50s, 50.5s (æ’é™¤50000msä¸­çš„s)
                (r'(\d+(?:\.\d+)?)ç§’', lambda x: int(float(x) * 1000)),         # 50ç§’, 50.5ç§’
                (r'(\d+(?:\.\d+)?)m(?:\s*(\d+(?:\.\d+)?)s)?', lambda x, y=0: int(float(x) * 60000 + float(y or 0) * 1000)),  # 1m, 1m30s
                (r'(\d+)$', lambda x: int(x)),                     # çº¯æ•°å­—ï¼Œå‡è®¾ä¸ºæ¯«ç§’
            ]
            
            for pattern, converter in patterns:
                match = re.search(pattern, interval_text)
                if match:
                    try:
                        if converter.__code__.co_argcount == 1:
                            ms_value = converter(match.group(1))
                        else:
                            # å¤„ç†åˆ†é’Ÿ+ç§’çš„æƒ…å†µ
                            minutes = match.group(1)
                            seconds = match.group(2) if len(match.groups()) > 1 else None
                            ms_value = converter(minutes, seconds)
                        break
                    except (ValueError, TypeError):
                        continue
            
            if ms_value is not None:
                # ç»Ÿä¸€æ ¼å¼åŒ–ä¸º "XXXms (X.Xs)" æ ¼å¼
                seconds = ms_value / 1000.0
                if seconds >= 1:
                    return f"{ms_value}ms ({seconds:.1f}s)"
                else:
                    return f"{ms_value}ms ({seconds:.2f}s)"
            else:
                # æ— æ³•è§£æï¼Œè¿”å›é»˜è®¤å€¼
                print(f"è°ƒè¯•: æ— æ³•è§£æé—´éš”æ–‡æœ¬: {interval_text}")
                return "50000ms (50.0s)"
                
        except Exception as e:
            print(f"æ ¼å¼åŒ–çª—å£é—´éš”æ˜¾ç¤ºæ—¶å‡ºé”™: {str(e)}")
            return "50000ms (50.0s)"
        
    def run_batch_tests(self, test_time_minutes=5, max_parallel=1, start_from=0, test_limit=None):
        """è¿è¡Œæ‰¹é‡æµ‹è¯•
        
        Args:
            test_time_minutes: æ¯ä¸ªæµ‹è¯•çš„è¿è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰
            max_parallel: æœ€å¤§å¹¶è¡Œæµ‹è¯•æ•°ï¼ˆå½“å‰åªæ”¯æŒ1ï¼‰
            start_from: ä»ç¬¬å‡ ä¸ªæµ‹è¯•å¼€å§‹
            test_limit: é™åˆ¶æµ‹è¯•æ•°é‡
        """
        print("å¼€å§‹æ‰¹é‡æµè®¡ç®—æµ‹è¯•...")
        
        # è·å–æ‰€æœ‰æµ‹è¯•ç»„åˆ
        combinations = self.get_test_combinations()
        combinations = self.filter_combinations(combinations)
        
        # æ£€æŸ¥è¿‡æ»¤åæ˜¯å¦è¿˜æœ‰æµ‹è¯•
        if not combinations:
            print(f"\nâŒ é”™è¯¯: è¿‡æ»¤åæ²¡æœ‰æœ‰æ•ˆçš„æµ‹è¯•ç»„åˆ!")
            print(f"å½“å‰è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
            print(f"æŒ‡å®šçš„SQLç±»å‹: {self.specified_sql_types}")
            print(f"\nğŸ’¡ å»ºè®®:")
            print(f"  1. æ£€æŸ¥ --batch-filter-mode å‚æ•°è®¾ç½®")
            print(f"  2. æ£€æŸ¥ --batch-sql-types å‚æ•°æ˜¯å¦æ­£ç¡®")
            print(f"  3. å°è¯•ä½¿ç”¨ --batch-filter-mode all è¿è¡Œæ‰€æœ‰æµ‹è¯•")
            print(f"  4. ä½¿ç”¨ --batch-filter-mode skip-known-failures è¿è¡ŒæˆåŠŸçš„æµ‹è¯•")
            
            # ä»ç„¶åˆ›å»ºç»“æœç›®å½•å’Œç”ŸæˆæŠ¥å‘Š
            result_dir = self.create_batch_result_dir()
            print(f"ç»“æœç›®å½•å·²åˆ›å»º: {result_dir}")
            self.start_time = datetime.datetime.now().isoformat()
            self.total_tests = 0
            self.generate_final_report(result_dir)
            return
        
        
        # åº”ç”¨å¯åŠ¨ä½ç½®å’Œé™åˆ¶
        if test_limit:
            combinations = combinations[start_from:start_from + test_limit]
        else:
            combinations = combinations[start_from:]
        
        self.total_tests = len(combinations)
        self.start_time = datetime.datetime.now().isoformat()
        
        print(f"æ€»æµ‹è¯•ç»„åˆæ•°: {self.total_tests}")
        print(f"æ¯ä¸ªæµ‹è¯•è¿è¡Œæ—¶é—´: {test_time_minutes}åˆ†é’Ÿ")
        
        # é˜²æ­¢é™¤é›¶é”™è¯¯
        if self.total_tests > 0:
            print(f"é¢„è®¡æ€»è€—æ—¶: {(self.total_tests * test_time_minutes / 60):.1f}å°æ—¶")
        else:
            print(f"é¢„è®¡æ€»è€—æ—¶: 0å°æ—¶ (æ²¡æœ‰æµ‹è¯•è¦æ‰§è¡Œ)")
        
        print(f"\næ‰¹é‡æµ‹è¯•å›ºå®šé…ç½®:")
        print(f"  æµå»¶è¿Ÿæ£€æŸ¥: {'å¯ç”¨' if self.fixed_params.get('check_stream_delay', False) else 'ç¦ç”¨'}")
        if self.fixed_params.get('check_stream_delay', False):
            print(f"  å»¶è¿Ÿæ£€æŸ¥é—´éš”: {self.fixed_params.get('delay_check_interval', 10)}ç§’")
            print(f"  æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {self.fixed_params.get('max_delay_threshold', 30000)}ms")
        print(f"  å­è¡¨æ•°é‡: {self.fixed_params.get('table_count', 1000)}")
        print(f"  æ¯è½®å†™å…¥è®°å½•æ•°: {self.fixed_params.get('real_time_batch_rows', 200)}")
        print(f"  æ•°æ®å†™å…¥é—´éš”: {self.fixed_params.get('real_time_batch_sleep', 0)}ç§’")
        print(f"  éƒ¨ç½²æ¨¡å¼: {self.fixed_params.get('deployment_mode', 'single')}")
        
        if start_from > 0:
            print(f"ä»ç¬¬ {start_from + 1} ä¸ªæµ‹è¯•å¼€å§‹")
        if test_limit:
            print(f"é™åˆ¶æµ‹è¯•æ•°é‡: {test_limit}")
        
        # åˆ›å»ºç»“æœç›®å½•
        result_dir = self.create_batch_result_dir()
        print(f"æµ‹è¯•ç»“æœå°†ä¿å­˜åˆ°: {result_dir}")
        
        # âœ… åˆå§‹åŒ–å®æ—¶HTMLæŠ¥å‘Š
        self.realtime_report_file = os.path.join(result_dir, 'reports', 'realtime_report.html')
        self.initialize_realtime_report(result_dir)
        print(f"å®æ—¶HTMLæŠ¥å‘Š: {self.realtime_report_file}")
        print(f"ğŸ’¡ å¯ä»¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€è¯¥æ–‡ä»¶å®æ—¶æŸ¥çœ‹æµ‹è¯•è¿›åº¦")
        
        # å¦‚æœæ²¡æœ‰æµ‹è¯•è¦æ‰§è¡Œï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Šå¹¶è¿”å›
        if self.total_tests == 0:
            print(f"\nâš ï¸ æ²¡æœ‰æµ‹è¯•éœ€è¦æ‰§è¡Œï¼Œç›´æ¥ç”ŸæˆæŠ¥å‘Š")
            self.generate_final_report(result_dir)
            return
        
        # # ç¡®è®¤å¼€å§‹æµ‹è¯•
        # if self.total_tests > 10:
        #     response = input(f"\nå°†è¦æ‰§è¡Œ {self.total_tests} ä¸ªæµ‹è¯•ï¼Œé¢„è®¡è€—æ—¶ {(self.total_tests * test_time_minutes / 60):.1f} å°æ—¶ï¼Œæ˜¯å¦ç»§ç»­ï¼Ÿ(y/N): ")
        #     if response.lower() != 'y':
        #         print("æµ‹è¯•å·²å–æ¶ˆ")
        #         return
        
        # æ‰§è¡Œæµ‹è¯•
        for i, combination in enumerate(combinations, 1):
            self.current_test_index = start_from + i
            
            # ç”Ÿæˆæµ‹è¯•é…ç½®
            config = self.generate_test_config(combination, self.current_test_index, result_dir)
            config['time'] = test_time_minutes
            
            # ä¿å­˜æµ‹è¯•é…ç½®
            self.save_test_config(config, result_dir)
            
            # æ‰§è¡Œæµ‹è¯•
            result = self.execute_single_test(config)
            self.test_results.append(result)
            
            # âœ… æ¯ä¸ªæµ‹è¯•å®Œæˆåç«‹å³æ›´æ–°å®æ—¶HTMLæŠ¥å‘Š
            self.update_realtime_report()
            
            # ç”Ÿæˆè¿›åº¦æŠ¥å‘Š
            self.generate_progress_report(result_dir)
            
            # æ˜¾ç¤ºè¿›åº¦
            remaining_tests = self.total_tests - len(self.test_results)
            estimated_remaining_time = remaining_tests * test_time_minutes
            
            # ç»Ÿè®¡å„ç§çŠ¶æ€
            success_count = len([r for r in self.test_results if r['status'] == 'SUCCESS'])
            failed_count = len([r for r in self.test_results if r['status'] == 'FAILED'])
            skip_failure_count = len([r for r in self.test_results if r['status'] == 'SKIP_FAILURE'])
            skip_poor_performance_count = len([r for r in self.test_results if r['status'] == 'SKIP_POOR_PERFORMANCE'])
            skipped_count = len([r for r in self.test_results if r['status'] == 'SKIPPED'])
        
            
            print(f"\nè¿›åº¦æ€»ç»“:")
            print(f"  å·²å®Œæˆ: {len(self.test_results)}/{self.total_tests}")
            print(f"  æˆåŠŸ: {success_count}")
            print(f"  å¤±è´¥: {failed_count}")
            if skip_failure_count > 0:
                print(f"  è·³è¿‡(å·²çŸ¥å¤±è´¥): {skip_failure_count}")
            if skip_poor_performance_count > 0:
                print(f"  è·³è¿‡(æ²¡æœ‰å®é™…æ„ä¹‰): {skip_poor_performance_count}")
            if skipped_count > 0:
                print(f"  è·³è¿‡(å…¶ä»–): {skipped_count}")
            print(f"  å‰©ä½™ä¼°è®¡æ—¶é—´: {estimated_remaining_time:.0f}åˆ†é’Ÿ ({estimated_remaining_time/60:.1f}å°æ—¶)")
            print(f"  ğŸ“Š å®æ—¶æŠ¥å‘Š: {self.realtime_report_file}")
            
            # åœ¨æµ‹è¯•ä¹‹é—´æ·»åŠ çŸ­æš‚ä¼‘æ¯
            if i < len(combinations):
                print("ç­‰å¾…2ç§’åå¼€å§‹ä¸‹ä¸€ä¸ªæµ‹è¯•...")
                time.sleep(2)
        
        # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
        final_report_file = os.path.join(result_dir, 'reports', 'final_report.html')
        self.generate_final_report(result_dir)
        
        # å¤åˆ¶æœ€ç»ˆæŠ¥å‘Šä¸ºå®æ—¶æŠ¥å‘Šï¼ˆç¡®ä¿ä¸€è‡´æ€§ï¼‰
        try:
            import shutil
            shutil.copy2(final_report_file, self.realtime_report_file)
            print(f"âœ… æœ€ç»ˆæŠ¥å‘Šå·²æ›´æ–°: {self.realtime_report_file}")
        except Exception as e:
            print(f"âš ï¸ å¤åˆ¶æœ€ç»ˆæŠ¥å‘Šå¤±è´¥: {str(e)}")
        
        print(f"\n{'='*80}")
        print("æ‰¹é‡æµ‹è¯•å®Œæˆ!")
        print(f"æ€»æµ‹è¯•æ•°: {self.total_tests}")
        
        if self.total_tests > 0:
            success_count = len([r for r in self.test_results if r['status'] == 'SUCCESS'])
            failed_count = len([r for r in self.test_results if r['status'] == 'FAILED'])
            skip_failure_count = len([r for r in self.test_results if r['status'] == 'SKIP_FAILURE'])
            skip_poor_performance_count = len([r for r in self.test_results if r['status'] == 'SKIP_POOR_PERFORMANCE'])
            skipped_count = len([r for r in self.test_results if r['status'] == 'SKIPPED'])
            
            print(f"æˆåŠŸ: {success_count}")
            print(f"å¤±è´¥: {failed_count}")
            if skip_failure_count > 0:
                print(f"è·³è¿‡(å·²çŸ¥å¤±è´¥): {skip_failure_count}")
            if skip_poor_performance_count > 0:
                print(f"è·³è¿‡(æ²¡æœ‰å®é™…æ„ä¹‰): {skip_poor_performance_count}")
            if skipped_count > 0:
                print(f"è·³è¿‡(å…¶ä»–): {skipped_count}")
            print(f"æˆåŠŸç‡: {(success_count/self.total_tests*100):.1f}%")
            
            if self.filter_mode == 'skip-known-case':
                total_skip_count = skip_failure_count + skip_poor_performance_count
                print(f"è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
                print(f"è¿‡æ»¤æ•ˆæœ: æˆåŠŸè·³è¿‡ {total_skip_count} ä¸ªæµ‹è¯• (å¤±è´¥: {skip_failure_count}, æ²¡æœ‰å®é™…æ„ä¹‰: {skip_poor_performance_count})")
            elif self.filter_mode != 'all':
                total_skip_count = skip_failure_count + skip_poor_performance_count + skipped_count
                print(f"è¿‡æ»¤æ¨¡å¼: {self.filter_mode}")
                if total_skip_count > 0:
                    print(f"è¿‡æ»¤æ•ˆæœ: æˆåŠŸè·³è¿‡ {total_skip_count} ä¸ªæµ‹è¯•")
        else:
            print(f"æ²¡æœ‰æ‰§è¡Œä»»ä½•æµ‹è¯•")
            
        print(f"ç»“æœç›®å½•: {result_dir}")
        print(f"{'='*80}")


    def initialize_realtime_report(self, result_dir):
        """åˆå§‹åŒ–å®æ—¶HTMLæŠ¥å‘Š"""
        try:
            # ç¡®ä¿reportsç›®å½•å­˜åœ¨
            reports_dir = os.path.join(result_dir, 'reports')
            os.makedirs(reports_dir, exist_ok=True)
            
            # è·å–ç³»ç»Ÿä¿¡æ¯
            def get_system_info():
                try:
                    # è·å–CPUæ ¸æ•°
                    cpu_count = None
                    try:
                        result = subprocess.run('lscpu | grep "^CPU(s):"', shell=True, 
                                            capture_output=True, text=True)
                        if result.returncode == 0:
                            cpu_line = result.stdout.strip()
                            cpu_count = cpu_line.split(':')[1].strip()
                    except Exception as e:
                        pass
                    
                    # è·å–æ€»å†…å­˜
                    total_memory_gb = None
                    try:
                        result = subprocess.run('free -m | grep "^Mem:"', shell=True, 
                                            capture_output=True, text=True)
                        if result.returncode == 0:
                            mem_line = result.stdout.strip()
                            total_memory_mb = int(mem_line.split()[1])
                            total_memory_gb = f"{total_memory_mb/1024:.1f}GB"
                    except Exception as e:
                        pass
                        
                    return cpu_count, total_memory_gb
                except Exception as e:
                    return None, None
            
            system_cpu_count, system_total_memory = get_system_info()
            current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # åˆ›å»ºåˆå§‹HTMLç»“æ„
            initial_html = f"""
<!DOCTYPE html>
<html>
<head>
    <title>æµè®¡ç®—æ‰¹é‡æµ‹è¯•å®æ—¶æŠ¥å‘Š</title>
    <meta charset="UTF-8">
    <meta http-equiv="refresh" content="30">
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; background-color: #f5f5f5; }}
        .header {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin-bottom: 20px; }}
        .summary {{ display: flex; justify-content: space-around; margin: 20px 0; flex-wrap: wrap; }}
        .metric {{ text-align: center; padding: 20px; background-color: white; border-radius: 10px; box-shadow: 0 2px 10px rgba(0,0,0,0.1); min-width: 150px; margin: 5px; }}
        .metric h3 {{ margin: 0 0 10px 0; color: #666; font-size: 14px; }}
        .metric h2 {{ margin: 0; font-size: 24px; }}
        .success {{ color: #28a745; }}
        .failed {{ color: #dc3545; }}
        .warning {{ color: #ffc107; }}
        .info {{ color: #17a2b8; }}
        .running {{ color: #007bff; }}
        
        .progress-container {{ background: white; border-radius: 10px; padding: 20px; margin: 20px 0; box-shadow: 0 2px 10px rgba(0,0,0,0.1); }}
        .progress-bar {{ width: 100%; height: 30px; background-color: #e9ecef; border-radius: 15px; overflow: hidden; margin: 10px 0; }}
        .progress-fill {{ height: 100%; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); transition: width 0.5s ease; }}
        .progress-text {{ text-align: center; color: white; font-weight: bold; line-height: 30px; }}
        
        .status-pending {{ background-color: #f8f9fa !important; }}
        .status-running {{ background-color: #cce5ff !important; }}
        .status-success {{ background-color: #d4edda !important; }}
        .status-failed {{ background-color: #f8d7da !important; }}
        .status-skipped {{ background-color: #f8f9fa !important; }}
        
        .status-badge {{ padding: 4px 8px; border-radius: 15px; font-size: 10px; font-weight: bold; text-transform: uppercase; }}
        .badge-pending {{ background-color: #6c757d; color: white; }}
        .badge-running {{ background-color: #007bff; color: white; }}
        .badge-success {{ background-color: #28a745; color: white; }}
        .badge-failed {{ background-color: #dc3545; color: white; }}
        .badge-skipped {{ background-color: #6c757d; color: white; }} 
        .badge-warning {{ background-color: #ffc107; color: #212529; }} 
        
        .table-container {{ background: white; border-radius: 10px; overflow: hidden; box-shadow: 0 2px 10px rgba(0,0,0,0.1); margin: 20px 0; }}
        table {{ width: 100%; border-collapse: collapse; }}
        th {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 15px 8px; text-align: left; font-weight: 600; font-size: 12px; }}
        td {{ border: none; padding: 12px 8px; text-align: left; border-bottom: 1px solid #eee; font-size: 11px; }}
        tr:hover {{ background-color: #f8f9fa; }}
        
        .refresh-info {{ position: fixed; top: 10px; right: 10px; background: rgba(0,0,0,0.8); color: white; padding: 10px; border-radius: 5px; font-size: 12px; }}
        .test-log {{ background: #f8f9fa; border-left: 4px solid #007bff; padding: 15px; margin: 10px 0; border-radius: 0 5px 5px 0; }}
        .test-log h4 {{ margin-top: 0; color: #007bff; }}
    </style>
    <script>
        var lastUpdateTime = new Date();
        
        function updateRefreshInfo() {{
            var now = new Date();
            var elapsed = Math.floor((now - lastUpdateTime) / 1000);
            var refreshElement = document.getElementById('refreshInfo');
            if (refreshElement) {{
                refreshElement.innerHTML = 'ğŸ”„ è‡ªåŠ¨åˆ·æ–°: ' + (30 - elapsed) + 'ç§’ååˆ·æ–°<br>ğŸ“… ' + now.toLocaleString();
            }}
        }}
        
        setInterval(updateRefreshInfo, 1000);
        
        window.onload = function() {{
            lastUpdateTime = new Date();
            updateRefreshInfo();
        }};
    </script>
</head>
<body>
    <div id="refreshInfo" class="refresh-info">ğŸ”„ è‡ªåŠ¨åˆ·æ–°: 30ç§’</div>
    
    <div class="header">
        <h1>ğŸš€ TDengine æµè®¡ç®—æ‰¹é‡æµ‹è¯•å®æ—¶æŠ¥å‘Š</h1>
        <p>ğŸ“… å¼€å§‹æ—¶é—´: {self.start_time}</p>
        <p>ğŸ”„ æœ€åæ›´æ–°: {current_time}</p>
        <p>ğŸ—ï¸ æµ‹è¯•é…ç½®: {self.fixed_params.get('deployment_mode', 'single')}æ¨¡å¼ | 
           {self.fixed_params.get('table_count', 1000)}å¼ å­è¡¨ | 
           {self.fixed_params.get('real_time_batch_rows', 200)}æ¡/è½® | 
           æ¯è½®å†™å…¥é—´éš”{self.fixed_params.get('real_time_batch_sleep', 0)}ç§’</p>
        <p>ğŸ’» æµ‹è¯•ç¯å¢ƒ: CPUæ ¸æ•°{system_cpu_count or 'æœªçŸ¥'} | æ€»å†…å­˜{system_total_memory or 'æœªçŸ¥'}</p>
    </div>
    
    <div class="progress-container">
        <h3>ğŸ“Š æµ‹è¯•è¿›åº¦</h3>
        <div class="progress-bar">
            <div class="progress-fill" style="width: 0%" id="progressFill">
                <div class="progress-text" id="progressText">å‡†å¤‡å¼€å§‹æµ‹è¯•...</div>
            </div>
        </div>
        <p id="progressDetails">æ€»è®¡: {self.total_tests} ä¸ªæµ‹è¯• | å·²å®Œæˆ: 0 | å‰©ä½™: {self.total_tests}</p>
    </div>
    
    <div class="summary">
        <div class="metric">
            <h3>ğŸ“Š æ€»æµ‹è¯•æ•°</h3>
            <h2 id="totalTests">{self.total_tests}</h2>
        </div>
        <div class="metric success">
            <h3>âœ… æˆåŠŸ</h3>
            <h2 id="successCount">0</h2>
            <small id="successPercent">0.0%</small>
        </div>
        <div class="metric failed">
            <h3>âŒ å¤±è´¥</h3>
            <h2 id="failedCount">0</h2>
            <small id="failedPercent">0.0%</small>
        </div>
        <div class="metric skipped">
            <h3>â­ï¸ è·³è¿‡</h3>
            <h2 id="skippedCount">0</h2>
            <small id="skippedPercent">0.0%</small>
        </div>
        <div class="metric running">
            <h3>ğŸ”„ å½“å‰çŠ¶æ€</h3>
            <h2 id="currentStatus">å‡†å¤‡ä¸­</h2>
            <small id="currentTest">-</small>
        </div>
    </div>
    
    <div class="test-log">
        <h4>ğŸ“ æœ€æ–°æµ‹è¯•æ—¥å¿—</h4>
        <div id="latestLog">ç­‰å¾…æµ‹è¯•å¼€å§‹...</div>
    </div>
    
    <div class="table-container">
        <h2 style="margin: 0; padding: 20px; border-bottom: 1px solid #eee;">ğŸ“‹ æµ‹è¯•ç»“æœåˆ—è¡¨</h2>
        <table id="resultsTable">
            <tr>
                <th>ğŸ“ æµ‹è¯•åç§°</th>
                <th>ğŸ”§ SQLç±»å‹</th>
                <th>ğŸ“Š æŸ¥è¯¢ç±»å‹</th>
                <th>ğŸ“‚ FROMç±»å‹</th>
                <th>ğŸ¯ çŠ¶æ€</th>
                <th>â±ï¸ è€—æ—¶(ç§’)</th>
                <th>âŒ é”™è¯¯ä¿¡æ¯</th>
            </tr>
            <tbody id="resultsBody">
                <!-- æµ‹è¯•ç»“æœå°†åœ¨è¿™é‡ŒåŠ¨æ€æ·»åŠ  -->
            </tbody>
        </table>
    </div>
    
    <div style="margin-top: 20px; text-align: center; color: #666; font-size: 12px;">
        <p>ğŸ“ è¯¦ç»†æ—¥å¿—æ–‡ä»¶ä½ç½®: {result_dir}</p>
        <p>ğŸƒâ€â™‚ï¸ TDengine æµè®¡ç®—æ€§èƒ½æµ‹è¯•å·¥å…· | å®æ—¶æ›´æ–°ä¸­...</p>
        <p>ğŸ’¡ æ­¤é¡µé¢æ¯30ç§’è‡ªåŠ¨åˆ·æ–°ï¼Œæ‚¨ä¹Ÿå¯ä»¥æ‰‹åŠ¨åˆ·æ–°é¡µé¢æŸ¥çœ‹æœ€æ–°çŠ¶æ€</p>
    </div>
</body>
</html>
"""
            
            # å†™å…¥åˆå§‹HTMLæ–‡ä»¶
            with open(self.realtime_report_file, 'w', encoding='utf-8') as f:
                f.write(initial_html)
                
            print(f"âœ… å®æ—¶HTMLæŠ¥å‘Šå·²åˆå§‹åŒ–: {self.realtime_report_file}")
            
        except Exception as e:
            print(f"âŒ åˆå§‹åŒ–å®æ—¶æŠ¥å‘Šå¤±è´¥: {str(e)}")
            self.realtime_report_file = None

    def update_realtime_report(self):
        """æ›´æ–°å®æ—¶HTMLæŠ¥å‘Š"""
        if not self.realtime_report_file:
            return
            
        try:
            # ç»Ÿè®¡å½“å‰çŠ¶æ€
            success_count = len([r for r in self.test_results if r['status'] == 'SUCCESS'])
            failed_count = len([r for r in self.test_results if r['status'] == 'FAILED'])
            skip_failure_count = len([r for r in self.test_results if r['status'] == 'SKIP_FAILURE'])
            skip_poor_performance_count = len([r for r in self.test_results if r['status'] == 'SKIP_POOR_PERFORMANCE'])
            skipped_count = len([r for r in self.test_results if r['status'] == 'SKIPPED'])
            
            total_skipped = skip_failure_count + skip_poor_performance_count + skipped_count
            completed_count = len(self.test_results)
            remaining_count = self.total_tests - completed_count
            
            # è®¡ç®—è¿›åº¦ç™¾åˆ†æ¯”
            if self.total_tests > 0:
                progress_percentage = (completed_count / self.total_tests) * 100
                success_rate = (success_count / self.total_tests) * 100
                failed_rate = (failed_count / self.total_tests) * 100
                skipped_rate = (total_skipped / self.total_tests) * 100
            else:
                progress_percentage = 100
                success_rate = failed_rate = skipped_rate = 0
                
            current_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            
            # è·å–å½“å‰æµ‹è¯•ä¿¡æ¯
            if self.current_test_index <= self.total_tests:
                current_status = f"æ­£åœ¨æ‰§è¡Œç¬¬ {self.current_test_index} ä¸ªæµ‹è¯•"
                if self.test_results:
                    last_result = self.test_results[-1]
                    current_test_info = f"{last_result['test_name']} - {last_result['status']}"
                else:
                    current_test_info = "å‡†å¤‡ä¸­..."
            else:
                current_status = "æµ‹è¯•å®Œæˆ"
                current_test_info = f"å…±å®Œæˆ {completed_count} ä¸ªæµ‹è¯•"
            
            # è¯»å–ç°æœ‰HTMLå†…å®¹
            with open(self.realtime_report_file, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # æ›´æ–°ç»Ÿè®¡æ•°æ®
            html_content = re.sub(r'ğŸ”„ æœ€åæ›´æ–°: [^<]+', f'ğŸ”„ æœ€åæ›´æ–°: {current_time}', html_content)
            html_content = re.sub(r'<h2 id="successCount">\d+</h2>', f'<h2 id="successCount">{success_count}</h2>', html_content)
            html_content = re.sub(r'<h2 id="failedCount">\d+</h2>', f'<h2 id="failedCount">{failed_count}</h2>', html_content)
            html_content = re.sub(r'<h2 id="skippedCount">\d+</h2>', f'<h2 id="skippedCount">{total_skipped}</h2>', html_content)
            html_content = re.sub(r'<h2 id="currentStatus">[^<]+</h2>', f'<h2 id="currentStatus">{current_status}</h2>', html_content)
            
            html_content = re.sub(r'<small id="successPercent">[^<]+</small>', f'<small id="successPercent">{success_rate:.1f}%</small>', html_content)
            html_content = re.sub(r'<small id="failedPercent">[^<]+</small>', f'<small id="failedPercent">{failed_rate:.1f}%</small>', html_content)
            html_content = re.sub(r'<small id="skippedPercent">[^<]+</small>', f'<small id="skippedPercent">{skipped_rate:.1f}%</small>', html_content)
            html_content = re.sub(r'<small id="currentTest">[^<]+</small>', f'<small id="currentTest">{current_test_info}</small>', html_content)
            
            # æ›´æ–°è¿›åº¦æ¡
            progress_text = f"{progress_percentage:.1f}% ({completed_count}/{self.total_tests})"
            html_content = re.sub(r'style="width: [\d.]+%"', f'style="width: {progress_percentage:.1f}%"', html_content)
            html_content = re.sub(r'<div class="progress-text" id="progressText">[^<]+</div>', 
                                f'<div class="progress-text" id="progressText">{progress_text}</div>', html_content)
            
            # æ›´æ–°è¿›åº¦è¯¦æƒ…
            progress_details = f"æ€»è®¡: {self.total_tests} ä¸ªæµ‹è¯• | å·²å®Œæˆ: {completed_count} | å‰©ä½™: {remaining_count}"
            html_content = re.sub(r'<p id="progressDetails">[^<]+</p>', f'<p id="progressDetails">{progress_details}</p>', html_content)
            
            # æ›´æ–°æœ€æ–°æµ‹è¯•æ—¥å¿—
            if self.test_results:
                last_result = self.test_results[-1]
                latest_log = f"""
                <strong>æµ‹è¯• {len(self.test_results)}/{self.total_tests}:</strong> {last_result['test_name']}<br>
                <strong>çŠ¶æ€:</strong> {last_result['status']} | 
                <strong>è€—æ—¶:</strong> {last_result.get('duration', 0):.1f}ç§’<br>
                <strong>æ—¶é—´:</strong> {last_result.get('end_time', current_time)}<br>
                """
                if last_result.get('error'):
                    error_msg = str(last_result['error'])[:100]
                    latest_log += f"<strong>é”™è¯¯:</strong> <span style='color: #dc3545;'>{error_msg}...</span><br>"
                    
                html_content = re.sub(r'<div id="latestLog">[^<]*(?:<[^>]*>[^<]*)*</div>', 
                                    f'<div id="latestLog">{latest_log}</div>', html_content, flags=re.DOTALL)
            
            # æ›´æ–°æµ‹è¯•ç»“æœè¡¨æ ¼
            tbody_content = ""
            for result in self.test_results:
                config = result['config']
                
                if result['status'] == 'SUCCESS':
                    status_class = 'status-success'
                    status_badge = 'badge-success'
                elif result['status'] == 'FAILED':
                    status_class = 'status-failed'
                    status_badge = 'badge-failed'
                elif result['status'] in ['SKIP_FAILURE', 'SKIP_POOR_PERFORMANCE', 'SKIPPED']:
                    status_class = 'status-skipped'
                    status_badge = 'badge-skipped'
                else:
                    status_class = ''
                    status_badge = ''
                
                error_msg = result.get('error', '')
                if error_msg:
                    if len(error_msg) > 150:
                        error_msg = error_msg[:150] + "..."
                    error_msg = error_msg.replace('<', '&lt;').replace('>', '&gt;')
                else:
                    error_msg = ""
                
                # å¤„ç†è·³è¿‡åŸå› æ˜¾ç¤º
                if result['status'] in ['SKIPPED', 'SKIP_FAILURE', 'SKIP_POOR_PERFORMANCE']:
                    skip_reason = result.get('skip_reason', 'æœªçŸ¥åŸå› ')
                    if result['status'] == 'SKIP_FAILURE':
                        error_msg = f"è·³è¿‡åŸå› : {skip_reason}"
                    elif result['status'] == 'SKIP_POOR_PERFORMANCE':
                        error_msg = f"å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰: {skip_reason}"
                    else:
                        error_msg = f"è·³è¿‡åŸå› : {skip_reason}"
                
                tbody_content += f"""
                <tr class="{status_class}">
                    <td><strong>{result['test_name']}</strong></td>
                    <td>{config['sql_type']}</td>
                    <td>{config['agg_or_select']}</td>
                    <td>{config['tbname_or_trows_or_sourcetable']}</td>
                    <td><span class="status-badge {status_badge}">{result['status']}</span></td>
                    <td>{result.get('duration', 0):.1f}</td>
                    <td style="color: #dc3545; font-size: 10px;">{error_msg}</td>
                </tr>
                """
            
            # æ›¿æ¢è¡¨æ ¼å†…å®¹
            tbody_pattern = r'<tbody id="resultsBody">.*?</tbody>'
            new_tbody = f'<tbody id="resultsBody">{tbody_content}</tbody>'
            html_content = re.sub(tbody_pattern, new_tbody, html_content, flags=re.DOTALL)
            
            # å†™å…¥æ›´æ–°åçš„HTML
            with open(self.realtime_report_file, 'w', encoding='utf-8') as f:
                f.write(html_content)
                
            print(f"âœ… å®æ—¶æŠ¥å‘Šå·²æ›´æ–°: è¿›åº¦ {progress_percentage:.1f}% ({completed_count}/{self.total_tests})")
            
        except Exception as e:
            print(f"âŒ æ›´æ–°å®æ—¶æŠ¥å‘Šå¤±è´¥: {str(e)}")
        
        
class StreamStarter:
    def __init__(self, runtime=None, perf_file=None, table_count=500, 
                histroy_rows=1, real_time_batch_rows=200, disorder_ratio=0, vgroups=10,
                stream_sql=None, sql_type='select_stream', stream_num=1, stream_perf_test_dir=None, monitor_interval=1,
                create_data=False, restore_data=False, deployment_mode='single',
                debug_flag=131, num_of_log_lines=500000, 
                agg_or_select='agg', tbname_or_trows_or_sourcetable='sourcetable', custom_columns=None,
                check_stream_delay=False, max_delay_threshold=30000, delay_check_interval=10,
                real_time_batch_sleep=0, delay_log_file=None, auto_combine=False, monitor_warm_up_time=None,
                delay_trends_analysis=False, keep_taosd_alive=True, use_tcmalloc=False, perf_node='dnode1',
                use_virtual_table=False) -> None:
        
        self.cleanup_environment_variables()
        
        self.stream_perf_test_dir = stream_perf_test_dir if stream_perf_test_dir else '/home/taos_stream_cluster'        
        self.table_count = table_count      
        self.histroy_rows = histroy_rows      
        self.real_time_batch_rows = real_time_batch_rows    
        self.real_time_batch_sleep = real_time_batch_sleep  
        self.disorder_ratio = disorder_ratio 
        self.vgroups = vgroups 
        self.monitor_interval = monitor_interval
        self.taosd_processes = [] 
        self.create_data = create_data
        self.restore_data = restore_data
        self.backup_dir = os.path.join(self.stream_perf_test_dir, 'data_bak')
        self.deployment_mode = deployment_mode
        self.debug_flag = debug_flag
        self.num_of_log_lines = num_of_log_lines
        self.auto_combine = auto_combine
        self.use_virtual_table = use_virtual_table
        print(f"è°ƒè¯•: StreamStarteråˆå§‹åŒ– - use_virtual_table = {self.use_virtual_table} (ç±»å‹: {type(self.use_virtual_table)})")
    
        if self.use_virtual_table:
            print(f"å¯ç”¨è™šæ‹Ÿè¡¨æ¨¡å¼")
            print(f"  - æºæ•°æ®è¶…çº§è¡¨: forvt_stb (å‰ç¼€: forvt_ctb0_)")  
            print(f"  - è™šæ‹Ÿè¶…çº§è¡¨: stb")
            print(f"  - è™šæ‹Ÿå­è¡¨: ctb0_0 åˆ° ctb0_{self.table_count-1}")
            print(f"  - æ˜ å°„å…³ç³»: è™šæ‹Ÿè¡¨ç›´æ¥æ˜ å°„ç‰©ç†è¡¨ï¼Œæ— éœ€é¢å¤–æ•°æ®ç”Ÿæˆ")
        else:
            print(f"ä½¿ç”¨æ™®é€šè¶…çº§è¡¨æ¨¡å¼")
            
        self.monitor_warm_up_time = monitor_warm_up_time
        self.delay_trends_analysis = delay_trends_analysis
        self.keep_taosd_alive = keep_taosd_alive 
        self.use_tcmalloc = use_tcmalloc
        
        self.sql_type = sql_type
        self.stream_num = stream_num
        self.agg_or_select = agg_or_select
        self.tbname_or_trows_or_sourcetable = tbname_or_trows_or_sourcetable
        self.custom_columns = custom_columns
        print(f"è°ƒè¯•ä¿¡æ¯: tbname_or_trows_or_sourcetable = {tbname_or_trows_or_sourcetable}")
        print(f"è°ƒè¯•ä¿¡æ¯: sql_type = {sql_type}")
        print(f"è°ƒè¯•ä¿¡æ¯: agg_or_select = {agg_or_select}")
        print(f"è°ƒè¯•ä¿¡æ¯:æ•°æ®å†™å…¥é—´éš”: {real_time_batch_sleep}ç§’")
        print(f"è°ƒè¯•ä¿¡æ¯: auto_combine = {auto_combine}")
        self.stream_sql = stream_sql if stream_sql else StreamSQLTemplates.get_sql(
            sql_type, 
            stream_num=stream_num, 
            auto_combine=auto_combine, 
            agg_or_select=agg_or_select,
            tbname_or_trows_or_sourcetable=tbname_or_trows_or_sourcetable,
            custom_columns=custom_columns
        )
        #print(f"ç”Ÿæˆçš„SQL:\n{self.stream_sql}")
        
        self.check_stream_delay = check_stream_delay
        self.max_delay_threshold = max_delay_threshold  # æ¯«ç§’
        self.delay_check_interval = delay_check_interval  # ç§’
        
        # å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶è·¯å¾„è®¾ç½®
        if delay_log_file:
            # å¦‚æœå¤–éƒ¨æŒ‡å®šäº†å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶è·¯å¾„ï¼Œä½¿ç”¨æŒ‡å®šçš„è·¯å¾„
            self.delay_log_file = delay_log_file
            print(f"è°ƒè¯•: ä½¿ç”¨å¤–éƒ¨æŒ‡å®šçš„å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶: {self.delay_log_file}")
        else:
            # å¦‚æœæ²¡æœ‰æŒ‡å®šï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
            self.delay_log_file = f"{os.path.splitext(perf_file)[0]}-stream-delay.log"
            print(f"è°ƒè¯•: ä½¿ç”¨é»˜è®¤å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶: {self.delay_log_file}")
        
        print(f"æµå»¶è¿Ÿæ£€æŸ¥: {'å¯ç”¨' if check_stream_delay else 'ç¦ç”¨'}")
        if check_stream_delay:
            print(f"æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {max_delay_threshold}ms")
            print(f"å»¶è¿Ÿæ£€æŸ¥é—´éš”: {delay_check_interval}ç§’")
            print(f"å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶: {self.delay_log_file}")
        
        # æ ¹æ®éƒ¨ç½²æ¨¡å¼è°ƒæ•´å®ä¾‹é…ç½®
        if self.deployment_mode == 'single':
            # å•èŠ‚ç‚¹æ¨¡å¼åªä½¿ç”¨ç¬¬ä¸€ä¸ªå®ä¾‹
            self.instances = [
                {
                    'name': 'dnode1',
                    'host': 'localhost',
                    'port': 6030,
                    'user': 'root',
                    'passwd': 'taosdata',
                    'data_dir': f'{self.stream_perf_test_dir}/dnode1/data',
                    'log_dir': f'{self.stream_perf_test_dir}/dnode1/log',
                }
            ]
            
            # å•èŠ‚ç‚¹æ¨¡å¼çš„æ•°æ®åº“é…ç½®
            self.db_config = {
                'stream_from': {
                    'name': 'stream_from',
                    'vgroups': self.vgroups
                },
                'stream_to': {
                    'name': 'stream_to', 
                    'vgroups': self.vgroups
                }
            }
        else:
            # å®šä¹‰3ä¸ªå®ä¾‹çš„é…ç½®
            self.instances = [
                {
                    'name': 'dnode1',
                    'host': 'localhost',
                    'port': 6030,
                    'user': 'root',
                    'passwd': 'taosdata',
                    'data_dir': f'{self.stream_perf_test_dir}/dnode1/data',
                    'log_dir': f'{self.stream_perf_test_dir}/dnode1/log',
                },
                {
                    'name': 'dnode2',
                    'host': 'localhost',
                    'port': 7030,
                    'user': 'root',
                    'passwd': 'taosdata',
                    'data_dir': f'{self.stream_perf_test_dir}/dnode2/data',
                    'log_dir': f'{self.stream_perf_test_dir}/dnode2/log',
                },
                {
                    'name': 'dnode3',
                    'host': 'localhost',
                    'port': 8030,
                    'user': 'root',
                    'passwd': 'taosdata',
                    'data_dir': f'{self.stream_perf_test_dir}/dnode3/data/',
                    'log_dir': f'{self.stream_perf_test_dir}/dnode3/log',
                }
            ]
            
            self.db_config = {
                'stream_from': {
                    'name': 'stream_from',
                    'vgroups': self.vgroups,
                    'dnodes': '1'  # é»˜è®¤åœ¨dnode1ä¸Š
                },
                'stream_to': {
                    'name': 'stream_to', 
                    'vgroups': self.vgroups,
                    'dnodes': '2'  # é»˜è®¤åœ¨dnode2ä¸Š
                }
            }
            
        self.sql = None
        self.host = self.instances[0]['host']
        self.user = self.instances[0]['user']
        self.passwd = self.instances[0]['passwd']
        self.conf = f"{self.stream_perf_test_dir}/dnode1/conf/taos.cfg"
        self.tz = 'Asia/Shanghai'
        # è®¾ç½®è¿è¡Œæ—¶é—´å’Œæ€§èƒ½æ–‡ä»¶è·¯å¾„
        self.runtime = runtime if runtime else 600  # é»˜è®¤è¿è¡Œ10åˆ†é’Ÿ
        self.perf_file = perf_file if perf_file else '/tmp/perf.log'
        

    def get_connection(self):
        """è·å–æ•°æ®åº“è¿æ¥
        
        Returns:
            tuple: (connection, cursor)
        """
        try:
            conn = taos.connect(
                host=self.host,
                user=self.user,
                password=self.passwd,
                config=self.conf,
                timezone=self.tz
            )
            cursor = conn.cursor()
            return conn, cursor
        except Exception as e:
            print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {str(e)}")
            raise
        
    def stop_taosd(self):
        """åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹"""
        try:
            # å…ˆå°è¯•æ­£å¸¸åœæ­¢
            subprocess.run('pkill taosd', shell=True)
            time.sleep(10)
            
            # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¿›ç¨‹å­˜åœ¨
            result = subprocess.run('ps -ef | grep "taosd -c" | grep -v grep', 
                                shell=True, capture_output=True, text=True)
            if result.stdout:
                print("å‘ç°é¡½å›ºè¿›ç¨‹ï¼Œå¼ºåˆ¶åœæ­¢...")
                for line in result.stdout.splitlines():
                    try:
                        pid = int(line.split()[1])
                        subprocess.run(f'kill -9 {pid}', shell=True)
                        print(f"å¼ºåˆ¶ç»ˆæ­¢è¿›ç¨‹ PID: {pid}")
                    except:
                        continue
                
            print("æ‰€æœ‰taosdè¿›ç¨‹å·²åœæ­¢")
            
        except Exception as e:
            print(f"åœæ­¢è¿›ç¨‹å‡ºé”™: {str(e)}")
            raise

    def check_taosd_status(self):
        """æ£€æŸ¥taosdè¿›ç¨‹çŠ¶æ€"""
        try:
            result = subprocess.run('ps -ef | grep "taosd -c" | grep -v grep', 
                                shell=True, capture_output=True, text=True)
            if result.stdout:
                print("\nå½“å‰è¿è¡Œçš„taosdè¿›ç¨‹:")
                for line in result.stdout.splitlines():
                    print(line)
                return True
            else:
                print("è­¦å‘Š: æœªå‘ç°è¿è¡Œä¸­çš„taosdè¿›ç¨‹")
                return False
                
        except Exception as e:
            print(f"æ£€æŸ¥è¿›ç¨‹çŠ¶æ€å‡ºé”™: {str(e)}")
            return False

        
    def create_database(self, db_name, vgroups=None, dnodes=None):
        """åˆ›å»ºæ•°æ®åº“
        
        Args:
            db_name: æ•°æ®åº“åç§°
            vgroups: vgroupsæ•°é‡,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å€¼
            dnodes: æŒ‡å®šæ•°æ®åº“æ‰€åœ¨çš„dnode,å¦‚æœä¸æŒ‡å®šåˆ™ä½¿ç”¨é…ç½®ä¸­çš„å€¼
        """
        try:
            # è·å–æ•°æ®åº“é…ç½®
            db_config = self.db_config.get(db_name, {})
            vgroups = vgroups or db_config.get('vgroups', self.vgroups)
            dnodes = dnodes or db_config.get('dnodes', '1')
            
            # åˆ›å»ºæ•°æ®åº“
            conn, cursor = self.get_connection()
            create_db_sql = f"create database {db_name} vgroups {vgroups}"
            if dnodes:
                create_db_sql += f" dnodes '{dnodes}'"
                
            print(f"\nåˆ›å»ºæ•°æ®åº“: {create_db_sql}")
            cursor.execute(create_db_sql)
            
            # å…³é—­è¿æ¥
            cursor.close()
            conn.close()
            
            print(f"æ•°æ®åº“ {db_name} åˆ›å»ºæˆåŠŸ")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºæ•°æ®åº“ {db_name} å¤±è´¥: {str(e)}")
            return False
    
    def create_virtual_tables(self):
        """åˆ›å»ºè™šæ‹Ÿè¶…çº§è¡¨å’Œè™šæ‹Ÿå­è¡¨"""
        if not self.use_virtual_table:
            print("æœªå¯ç”¨è™šæ‹Ÿè¡¨æ¨¡å¼ï¼Œè·³è¿‡è™šæ‹Ÿè¡¨åˆ›å»º")
            return True
            
        try:
            print(f"\n=== å¼€å§‹åˆ›å»ºè™šæ‹Ÿè¡¨ ===")
            conn, cursor = self.get_connection()
            
            # ä½¿ç”¨ stream_from æ•°æ®åº“
            cursor.execute("use stream_from")
            
            # 1. åˆ›å»ºè™šæ‹Ÿè¶…çº§è¡¨
            create_virtual_stb_sql = """
            create stable stb (
                ts timestamp,
                c0 INT,
                c1 BIGINT,
                c2 DOUBLE,
                c3 FLOAT
            ) TAGS (t0 INT, t1 VARCHAR(32)) VIRTUAL 1;
            """
            
            print("åˆ›å»ºè™šæ‹Ÿè¶…çº§è¡¨ stb...")
            cursor.execute(create_virtual_stb_sql)
            print("âœ“ è™šæ‹Ÿè¶…çº§è¡¨ stb åˆ›å»ºæˆåŠŸ")
            
            # 2. åˆ›å»ºè™šæ‹Ÿå­è¡¨
            print(f"å¼€å§‹åˆ›å»º {self.table_count} ä¸ªè™šæ‹Ÿå­è¡¨...")
            
            for i in range(self.table_count):
                # è®¡ç®— tag å€¼ï¼ˆ0-9 å¾ªç¯ï¼‰
                tag_value = i % 10
                
                vtable_name = f"ctb0_{i}"
                source_table_name = f"forvt_ctb0_{i}"
                
                create_vtable_sql = f"""
                create vtable {vtable_name}
                ({source_table_name}.c0, {source_table_name}.c1,
                {source_table_name}.c2, {source_table_name}.c3)
                using stb
                TAGS ({tag_value}, '{source_table_name}');
                """
                
                try:
                    cursor.execute(create_vtable_sql)
                    if (i + 1) % 100 == 0:  # æ¯100ä¸ªæ‰“å°ä¸€æ¬¡è¿›åº¦
                        print(f"  å·²åˆ›å»ºè™šæ‹Ÿå­è¡¨: {i + 1}/{self.table_count}")
                        print(f"  åˆ›å»ºè™šæ‹Ÿå­è¡¨: {vtable_name} æ˜ å°„æºè¡¨: {source_table_name} create_vtable_sql:{create_vtable_sql}")
                except Exception as e:
                    print(f"åˆ›å»ºè™šæ‹Ÿå­è¡¨ {vtable_name} å¤±è´¥: {str(e)}")
                    cursor.close()
                    conn.close()
                    return False
            
            print(f"âœ“ æˆåŠŸåˆ›å»º {self.table_count} ä¸ªè™šæ‹Ÿå­è¡¨")
            
            # éªŒè¯åˆ›å»ºç»“æœ
            cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_from' and stable_name='stb'")
            vtable_count = cursor.fetchall()[0][0]
            print(f"éªŒè¯ç»“æœ: å…±åˆ›å»º {vtable_count} ä¸ªè™šæ‹Ÿå­è¡¨")
            
            cursor.close()
            conn.close()
            
            print("=== è™šæ‹Ÿè¡¨åˆ›å»ºå®Œæˆ ===")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºè™šæ‹Ÿè¡¨å¤±è´¥: {str(e)}")
            return False
        
    def start_taosd_processes(self):
        """å¯åŠ¨æ‰€æœ‰ taosd è¿›ç¨‹ - æ”¯æŒå•èŠ‚ç‚¹å’Œé›†ç¾¤æ¨¡å¼"""
        try:
            mode_desc = "å•èŠ‚ç‚¹" if self.deployment_mode == 'single' else "é›†ç¾¤"
            print(f"\n=== å¼€å§‹å¯åŠ¨ {mode_desc} taosd è¿›ç¨‹ ===")
            
            # æ ¹æ®éƒ¨ç½²æ¨¡å¼ç¡®å®šè¦å¯åŠ¨çš„èŠ‚ç‚¹
            nodes_to_start = []
            if self.deployment_mode == 'single':
                nodes_to_start = ['dnode1']
            else:
                nodes_to_start = ['dnode1', 'dnode2', 'dnode3']
            
            for dnode in nodes_to_start:
                cfg_file = os.path.join(self.stream_perf_test_dir, dnode, 'conf', 'taos.cfg')
                cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                print(f"æ‰§è¡Œå¯åŠ¨å‘½ä»¤: {cmd}")
                
                # æ‰§è¡Œå¯åŠ¨å‘½ä»¤
                result = subprocess.run(cmd, shell=True)
                if result.returncode == 0:
                    print(f"å·²æ‰§è¡Œ {dnode} çš„å¯åŠ¨å‘½ä»¤")
                else:
                    print(f"è­¦å‘Š: {dnode} å¯åŠ¨å‘½ä»¤æ‰§è¡Œå¤±è´¥")
                    
                # éªŒè¯è¿›ç¨‹æ˜¯å¦å¯åŠ¨
                time.sleep(2)
                check_cmd = f"pgrep -f 'taosd -c {cfg_file}'"
                if subprocess.run(check_cmd, shell=True, stdout=subprocess.PIPE).stdout:
                    print(f"{dnode} è¿›ç¨‹å·²æˆåŠŸå¯åŠ¨")
                else:
                    print(f"è­¦å‘Š: {dnode} è¿›ç¨‹å¯èƒ½æœªæ­£å¸¸å¯åŠ¨")
            
            # ç­‰å¾…æœåŠ¡å®Œå…¨å¯åŠ¨
            wait_time = 3 if self.deployment_mode == 'single' else 10
            print(f"\nç­‰å¾…æœåŠ¡å¯åŠ¨ ({wait_time}ç§’)...")
            time.sleep(wait_time)             
            self.check_taosd_status()
            
            # é…ç½®é›†ç¾¤ï¼ˆå¦‚æœæ˜¯é›†ç¾¤æ¨¡å¼ï¼‰
            if self.deployment_mode == 'cluster':
                try:
                    # è¿æ¥åˆ°ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
                    conn = taos.connect(
                        host=self.host,
                        user=self.user,
                        password=self.passwd,
                        config=self.conf
                    )
                    cursor = conn.cursor()
                    
                    print("\n=== æ£€æŸ¥é›†ç¾¤é…ç½® ===")
                    
                    # æŸ¥è¯¢å¹¶æ˜¾ç¤ºèŠ‚ç‚¹çŠ¶æ€
                    try:
                        # æŸ¥è¯¢ dnodes ä¿¡æ¯
                        print("\nDNode ä¿¡æ¯:")
                        cursor.execute("show dnodes")
                        result = cursor.fetchall()
                        for row in result:
                            print(f"ID: {row[0]}, endpoint: {row[1]}, status: {row[4]}")
                        
                        # æŸ¥è¯¢ mnodes ä¿¡æ¯
                        print("\nMNode ä¿¡æ¯:")
                        cursor.execute("show mnodes")
                        result = cursor.fetchall()
                        if result:
                            for row in result:
                                print(f"ID: {row[0]}, endpoint: {row[1]}, role: {row[2]}, status: {row[3]}")
                        else:
                            print("å½“å‰ç³»ç»Ÿä¸­æ²¡æœ‰é¢å¤–çš„mnode")
                        
                        # æŸ¥è¯¢ snodes ä¿¡æ¯
                        print("\nSNode ä¿¡æ¯:")
                        cursor.execute("show snodes")
                        result = cursor.fetchall()
                        if result:
                            for row in result:
                                print(f"ID: {row[0]}, endpoint: {row[1]}, create_time: {row[2]}")
                        else:
                            print("å½“å‰ç³»ç»Ÿä¸­æ²¡æœ‰snode")
                            
                    except Exception as e:
                        print(f"æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {str(e)}")
                    
                    # å…³é—­è¿æ¥
                    cursor.close()
                    conn.close()
                    
                except Exception as e:
                    print(f"æ£€æŸ¥é›†ç¾¤é…ç½®å¤±è´¥: {str(e)}")
                    
            print(f"\n{mode_desc}æ¨¡å¼ taosd è¿›ç¨‹å¯åŠ¨å®Œæˆ")
            return True
            
        except Exception as e:
            print(f"å¯åŠ¨ taosd è¿›ç¨‹æ—¶å‡ºé”™: {str(e)}")
            return False
        return True
        
    def backup_cluster_data(self):
        """å¤‡ä»½é›†ç¾¤æ•°æ® - æ”¯æŒå•èŠ‚ç‚¹å’Œé›†ç¾¤æ¨¡å¼"""
        try:
            mode_desc = "å•èŠ‚ç‚¹" if self.deployment_mode == 'single' else "é›†ç¾¤"
            print(f"å¼€å§‹å¤‡ä»½{mode_desc}æ•°æ®...")
            
            # å…ˆåœæ­¢æ‰€æœ‰ taosd è¿›ç¨‹
            print("åœæ­¢æ‰€æœ‰ taosd è¿›ç¨‹...")
            subprocess.run('pkill -15 taosd', shell=True)
            time.sleep(5)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨åœæ­¢
            
            # æ£€æŸ¥è¿›ç¨‹æ˜¯å¦å®Œå…¨åœæ­¢
            if subprocess.run('pgrep -x taosd', shell=True, stdout=subprocess.PIPE).stdout:
                print("ç­‰å¾… taosd è¿›ç¨‹åœæ­¢...")
                time.sleep(5)
                # å†æ¬¡æ£€æŸ¥ï¼Œå¦‚æœè¿˜æœ‰è¿›ç¨‹åˆ™å¼ºåˆ¶ç»ˆæ­¢
                if subprocess.run('pgrep -x taosd', shell=True, stdout=subprocess.PIPE).stdout:
                    print("å¼ºåˆ¶ç»ˆæ­¢ taosd è¿›ç¨‹...")
                    subprocess.run('pkill -9 taosd', shell=True)
                    time.sleep(2)
                    
            # åˆ›å»ºå¤‡ä»½ç›®å½•
            if os.path.exists(self.backup_dir):
                print(f"æ¸…ç†å·²å­˜åœ¨çš„å¤‡ä»½ç›®å½•: {self.backup_dir}")
                shutil.rmtree(self.backup_dir)
            os.makedirs(self.backup_dir)
            print(f"åˆ›å»ºå¤‡ä»½ç›®å½•: {self.backup_dir}")
            
            # æ ¹æ®éƒ¨ç½²æ¨¡å¼ç¡®å®šéœ€è¦å¤‡ä»½çš„èŠ‚ç‚¹
            nodes_to_backup = []
            if self.deployment_mode == 'single':
                nodes_to_backup = ['dnode1']
                print("å•èŠ‚ç‚¹æ¨¡å¼: ä»…å¤‡ä»½ dnode1 æ•°æ®")
            else:
                nodes_to_backup = ['dnode1', 'dnode2', 'dnode3']
                print("é›†ç¾¤æ¨¡å¼: å¤‡ä»½ dnode1, dnode2, dnode3 æ•°æ®")
                
            # åªå¤‡ä»½dataç›®å½•ï¼Œä¸å¤‡ä»½logå’Œconf
            for dnode in nodes_to_backup:
                src_data_dir = os.path.join(self.stream_perf_test_dir, dnode, 'data')
                dst_data_dir = os.path.join(self.backup_dir, dnode, 'data')
                
                if os.path.exists(src_data_dir):
                    print(f"\nå¤‡ä»½ {dnode}/data ç›®å½•...")
                    try:
                        # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                        os.makedirs(os.path.dirname(dst_data_dir), exist_ok=True)
                        
                        # ä½¿ç”¨ rsync æ’é™¤ä¸´æ—¶æ–‡ä»¶å’Œsocketæ–‡ä»¶
                        cmd = f'rsync -av --exclude="*.sock*" --exclude="*.tmp" --exclude="*.lock" {src_data_dir}/ {dst_data_dir}/'
                        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                        
                        if result.returncode == 0:
                            print(f"å®Œæˆå¤‡ä»½: {dst_data_dir}")
                            
                            # æ˜¾ç¤ºå¤‡ä»½æ•°æ®çš„ç»Ÿè®¡ä¿¡æ¯
                            try:
                                # è·å–å¤‡ä»½ç›®å½•å¤§å°
                                du_result = subprocess.run(f'du -sh {dst_data_dir}', shell=True, 
                                                        capture_output=True, text=True)
                                if du_result.returncode == 0:
                                    size_info = du_result.stdout.strip().split()[0]
                                    print(f"  å¤‡ä»½å¤§å°: {size_info}")
                                    
                                # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
                                find_result = subprocess.run(f'find {dst_data_dir} -type f | wc -l', 
                                                            shell=True, capture_output=True, text=True)
                                if find_result.returncode == 0:
                                    file_count = find_result.stdout.strip()
                                    print(f"  æ–‡ä»¶æ•°é‡: {file_count}")
                            except Exception as e:
                                print(f"  ç»Ÿè®¡å¤‡ä»½ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}")
                        else:
                            # rsync å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ cp å‘½ä»¤
                            print(f"rsync å¤±è´¥ï¼Œä½¿ç”¨ cp å‘½ä»¤å¤‡ä»½...")
                            cmd = f'cp -r {src_data_dir} {dst_data_dir}'
                            subprocess.run(cmd, shell=True, check=True)
                            print(f"å®Œæˆå¤‡ä»½: {dst_data_dir}")
                            
                    except subprocess.CalledProcessError as e:
                        print(f"å¤‡ä»½ {dnode}/data å¤±è´¥: {str(e)}")
                        return False
                    except Exception as e:
                        print(f"å¤‡ä»½ {dnode}/data æ—¶å‡ºé”™: {str(e)}")
                        return False
                else:
                    print(f"è­¦å‘Š: {dnode}/data ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤‡ä»½")
            
            # åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶
            backup_info_file = os.path.join(self.backup_dir, 'backup_info.txt')
            try:
                with open(backup_info_file, 'w') as f:
                    f.write(f"TDengine æ•°æ®å¤‡ä»½ä¿¡æ¯\n")
                    f.write(f"=" * 50 + "\n")
                    f.write(f"å¤‡ä»½æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"éƒ¨ç½²æ¨¡å¼: {self.deployment_mode}\n")
                    f.write(f"å¤‡ä»½èŠ‚ç‚¹: {', '.join(nodes_to_backup)}\n")
                    f.write(f"å¤‡ä»½å†…å®¹: ä»…æ•°æ®ç›®å½• (data)\n")
                    f.write(f"å­è¡¨æ•°é‡: {self.table_count}\n")
                    f.write(f"æ¯è¡¨è®°å½•æ•°: {self.histroy_rows}\n")
                    f.write(f"æ•°æ®ä¹±åºç‡: {self.disorder_ratio}\n")
                    f.write(f"vgroupsæ•°: {self.vgroups}\n")
                    f.write(f"=" * 50 + "\n")
                    
                    # è®°å½•æ¯ä¸ªèŠ‚ç‚¹çš„å¤‡ä»½çŠ¶æ€
                    for dnode in nodes_to_backup:
                        dst_data_dir = os.path.join(self.backup_dir, dnode, 'data')
                        if os.path.exists(dst_data_dir):
                            f.write(f"{dnode}: å¤‡ä»½æˆåŠŸ\n")
                        else:
                            f.write(f"{dnode}: å¤‡ä»½å¤±è´¥\n")
                            
                print(f"å¤‡ä»½ä¿¡æ¯å·²ä¿å­˜åˆ°: {backup_info_file}")
            except Exception as e:
                print(f"åˆ›å»ºå¤‡ä»½ä¿¡æ¯æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            print(f"\n=== {mode_desc}æ•°æ®å¤‡ä»½å®Œæˆ! ===")
            print(f"å¤‡ä»½ç›®å½•: {self.backup_dir}")
            return True
    
        except Exception as e:
            print(f"å¤‡ä»½æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False
        finally:
            # é‡æ–°å¯åŠ¨ taosd è¿›ç¨‹
            if not self.start_taosd_processes():
                print("è­¦å‘Š: taosd è¿›ç¨‹å¯åŠ¨å¤±è´¥")
        
    def restore_cluster_data(self):
        """ä»å¤‡ä»½æ¢å¤é›†ç¾¤æ•°æ® - æ”¯æŒå•èŠ‚ç‚¹å’Œé›†ç¾¤æ¨¡å¼"""
        try:
            if not os.path.exists(self.backup_dir):
                raise Exception(f"é”™è¯¯: å¤‡ä»½ç›®å½•ä¸å­˜åœ¨: {self.backup_dir}")
                
            # è¯»å–å¤‡ä»½ä¿¡æ¯
            backup_info_file = os.path.join(self.backup_dir, 'backup_info.txt')
            backup_mode = None
            if os.path.exists(backup_info_file):
                try:
                    with open(backup_info_file, 'r') as f:
                        content = f.read()
                        # ä»å¤‡ä»½ä¿¡æ¯ä¸­æå–éƒ¨ç½²æ¨¡å¼
                        for line in content.split('\n'):
                            if line.startswith('éƒ¨ç½²æ¨¡å¼:'):
                                backup_mode = line.split(':')[1].strip()
                                break
                except Exception as e:
                    print(f"è¯»å–å¤‡ä»½ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            current_mode_desc = "å•èŠ‚ç‚¹" if self.deployment_mode == 'single' else "é›†ç¾¤"
            backup_mode_desc = "å•èŠ‚ç‚¹" if backup_mode == 'single' else "é›†ç¾¤" if backup_mode == 'cluster' else "æœªçŸ¥"
            
            print(f"å¼€å§‹æ¢å¤æ•°æ®...")
            print(f"å½“å‰æ¨¡å¼: {current_mode_desc}")
            if backup_mode:
                print(f"å¤‡ä»½æ¨¡å¼: {backup_mode_desc}")
                if backup_mode != self.deployment_mode:
                    print(f"è­¦å‘Š: å½“å‰æ¨¡å¼({self.deployment_mode})ä¸å¤‡ä»½æ¨¡å¼({backup_mode})ä¸åŒ¹é…!")
                    response = input("æ˜¯å¦ç»§ç»­æ¢å¤? (y/N): ")
                    if response.lower() != 'y':
                        print("æ¢å¤æ“ä½œå·²å–æ¶ˆ")
                        return False
            
            # åœæ­¢ç°æœ‰taosdè¿›ç¨‹
            subprocess.run('pkill -15 taosd', shell=True)
            time.sleep(5)
            # ç¡®ä¿è¿›ç¨‹å®Œå…¨åœæ­¢
            while subprocess.run('pgrep -x taosd', shell=True, stdout=subprocess.PIPE).stdout:
                print("ç­‰å¾… taosd è¿›ç¨‹åœæ­¢...")
                time.sleep(2)
                subprocess.run('pkill -9 taosd', shell=True)
                
            # æ ¹æ®å½“å‰éƒ¨ç½²æ¨¡å¼ç¡®å®šéœ€è¦æ¢å¤çš„èŠ‚ç‚¹
            nodes_to_restore = []
            if self.deployment_mode == 'single':
                nodes_to_restore = ['dnode1']
                print("å•èŠ‚ç‚¹æ¨¡å¼: ä»…æ¢å¤ dnode1 æ•°æ®")
            else:
                nodes_to_restore = ['dnode1', 'dnode2', 'dnode3']
                print("é›†ç¾¤æ¨¡å¼: æ¢å¤ dnode1, dnode2, dnode3 æ•°æ®")
                
            # æ¢å¤æ¯ä¸ªèŠ‚ç‚¹çš„æ•°æ®
            restored_count = 0
            for dnode in nodes_to_restore:
                backup_data_dir = os.path.join(self.backup_dir, dnode, 'data')
                cluster_data_dir = os.path.join(self.stream_perf_test_dir, dnode, 'data')
                
                if not os.path.exists(backup_data_dir):
                    print(f"è­¦å‘Š: å¤‡ä»½ç›®å½•ä¸­æœªæ‰¾åˆ° {dnode}/data")
                    # å¯¹äºé›†ç¾¤æ¨¡å¼ï¼Œå¦‚æœæŸäº›èŠ‚ç‚¹çš„å¤‡ä»½ä¸å­˜åœ¨ï¼Œè·³è¿‡ä½†ç»§ç»­
                    if self.deployment_mode == 'cluster':
                        continue
                    else:
                        # å¯¹äºå•èŠ‚ç‚¹æ¨¡å¼ï¼Œå¦‚æœdnode1çš„å¤‡ä»½ä¸å­˜åœ¨ï¼Œåˆ™å¤±è´¥
                        if dnode == 'dnode1':
                            raise Exception(f"å•èŠ‚ç‚¹æ¨¡å¼ä¸‹å¿…é¡»çš„ {dnode}/data å¤‡ä»½ä¸å­˜åœ¨")
                        continue
                        
                print(f"\nè¿˜åŸ {dnode}/data ...")
                
                # æ˜¾ç¤ºå¤‡ä»½ç›®å½•ä¿¡æ¯
                try:
                    du_result = subprocess.run(f'du -sh {backup_data_dir}', shell=True, 
                                            capture_output=True, text=True)
                    if du_result.returncode == 0:
                        backup_size = du_result.stdout.strip().split()[0]
                        print(f"å¤‡ä»½æ•°æ®å¤§å°: {backup_size}")
                except:
                    pass
                
                # æ¸…ç†ç°æœ‰æ•°æ®ç›®å½•
                if os.path.exists(cluster_data_dir):
                    print(f"æ¸…ç†ç°æœ‰æ•°æ®ç›®å½•: {cluster_data_dir}")
                    shutil.rmtree(cluster_data_dir)
                
                # ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
                os.makedirs(os.path.dirname(cluster_data_dir), exist_ok=True)
                
                # æ¢å¤æ•°æ®ç›®å½•
                try:
                    shutil.copytree(backup_data_dir, cluster_data_dir, symlinks=True)
                    print(f"å®Œæˆè¿˜åŸ: {cluster_data_dir}")
                    restored_count += 1
                    
                    # æ˜¾ç¤ºæ¢å¤åçš„ä¿¡æ¯
                    try:
                        du_result = subprocess.run(f'du -sh {cluster_data_dir}', shell=True, 
                                                capture_output=True, text=True)
                        if du_result.returncode == 0:
                            restored_size = du_result.stdout.strip().split()[0]
                            print(f"æ¢å¤æ•°æ®å¤§å°: {restored_size}")
                    except:
                        pass
                        
                except Exception as e:
                    print(f"è¿˜åŸ {dnode}/data æ—¶å‡ºé”™: {str(e)}")
                    return False
            
            if restored_count == 0:
                print("é”™è¯¯: æ²¡æœ‰æˆåŠŸæ¢å¤ä»»ä½•èŠ‚ç‚¹çš„æ•°æ®")
                return False
                
            print(f"\n=== æ•°æ®è¿˜åŸå®Œæˆ! ===")
            print(f"æˆåŠŸæ¢å¤ {restored_count} ä¸ªèŠ‚ç‚¹çš„æ•°æ®")
            
            # é‡å¯ taosd è¿›ç¨‹
            return self.start_taosd_processes()
            
        except Exception as e:
            print(f"\nè¿˜åŸæ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False
        
    def do_test_stream_with_restored_data(self):
        """æ¢å¤æ•°æ®åæµ‹è¯•æŒ‡å®šçš„æµè®¡ç®—SQL"""
        
        loader = None
        monitor_thread = None
        delay_monitor_thread = None
        conn = None
        cursor = None
    
        try:
            print("=== æ¢å¤æ•°æ®åæµ‹è¯•æµè®¡ç®— ===")
            
            # å…ˆæ¢å¤æ•°æ®
            print("1. æ¢å¤å†å²æ•°æ®...")
            if not self.restore_cluster_data():
                raise Exception("æ¢å¤é›†ç¾¤æ•°æ®å¤±è´¥")
            
            print("2. åˆ›å»ºç›®æ ‡æ•°æ®åº“...")
            # åˆ›å»ºstream_toæ•°æ®åº“
            if not self.create_database('stream_to'):
                raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
            
            # âœ… å¦‚æœå¯ç”¨äº†è™šæ‹Ÿè¡¨æ¨¡å¼ï¼Œéœ€è¦é‡æ–°åˆ›å»ºè™šæ‹Ÿè¡¨
            if self.use_virtual_table:
                print("3. é‡æ–°åˆ›å»ºè™šæ‹Ÿè¡¨æ˜ å°„...")
                if not self.create_virtual_tables():
                    raise Exception("è™šæ‹Ÿè¡¨åˆ›å»ºå¤±è´¥")
                print("âœ… è™šæ‹Ÿè¡¨é‡æ–°åˆ›å»ºå®Œæˆ")
            
            
            print("4. å¼€å§‹æµè®¡ç®—æµ‹è¯•...")
            print(f"SQLç±»å‹: {self.sql_type}")
            print(f"æµæ•°é‡: {self.stream_num}")
            print(f"è‡ªå®šä¹‰SQL: {'æ˜¯' if self.stream_sql else 'å¦'}")
            
            # è·å–æ•°æ®åº“è¿æ¥
            conn, cursor = self.get_connection()
            
            
            # è¿æ¥åˆ°æºæ•°æ®åº“
            print("è¿æ¥åˆ°æºæ•°æ®åº“ stream_from...")
            cursor.execute('use stream_from')
            
            # æ£€æŸ¥æºæ•°æ®çŠ¶æ€
            print("æ£€æŸ¥æºæ•°æ®çŠ¶æ€...")
            cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_from'")
            table_count = cursor.fetchall()[0][0]
            
            cursor.execute("select count(*) from stream_from.stb")
            record_count = cursor.fetchall()[0][0]
            
            print(f"æºæ•°æ®ç»Ÿè®¡: {table_count} å¼ è¡¨, {record_count:,} æ¡è®°å½•")
            
            # è·å– SQL æ¨¡æ¿å¹¶åˆ›å»ºæµ
            sql_templates = self.stream_sql 
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰¹é‡æ‰§è¡Œ
            if isinstance(sql_templates, dict):
                print("\n=== å¼€å§‹æ‰¹é‡åˆ›å»ºæµ ===")
                total_streams = len(sql_templates)
                success_count = 0
                failed_count = 0
                
                for index, (sql_name, sql_template) in enumerate(sql_templates.items(), 1):
                    try:
                        print(f"\n[{index}/{total_streams}] åˆ›å»ºæµ: {sql_name}")
                        
                        # æå–å®é™…çš„æµåç§°ï¼ˆä»SQLä¸­è§£æï¼‰
                        import re
                        # åŒ¹é… create stream åé¢çš„æµåç§°
                        match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                        actual_stream_name = match.group(1) if match else sql_name
                        
                        print(f"  SQLæµåç§°: {actual_stream_name}")
                        # æ˜¾ç¤ºå®Œæ•´çš„æµSQLè¯­å¥
                        print(f"  æµSQLè¯­å¥:")
                        # æ ¼å¼åŒ–SQLæ˜¾ç¤ºï¼Œå»æ‰å¤šä½™çš„ç©ºè¡Œå’Œç¼©è¿›
                        formatted_sql = '\n'.join([
                            '    ' + line.strip() 
                            for line in sql_template.strip().split('\n') 
                            if line.strip()
                        ])
                        print(formatted_sql)
                        
                        print(f"  æ‰§è¡Œåˆ›å»º...")
                        cursor.execute(sql_template)
                        success_count += 1
                        print(f"  âœ“ åˆ›å»ºæˆåŠŸ")
                        
                    except Exception as e:
                        failed_count += 1
                    
                        # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                        error_message = str(e)
                        tdengine_error = extract_stream_creation_error(error_message)
                        
                        print(f"æ‰§è¡Œé”™è¯¯: {tdengine_error}")
                
                # æ˜¾ç¤ºæ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦
                print(f"\n=== æ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦ ===")
                print(f"æ€»æµæ•°: {total_streams}")
                print(f"æˆåŠŸ: {success_count}")
                print(f"å¤±è´¥: {failed_count}")
                print(f"æˆåŠŸç‡: {(success_count/total_streams*100):.1f}%")
                
                if failed_count > 0:
                    print(f"âš ï¸  {failed_count} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                else:
                    print("æ‰€æœ‰æµåˆ›å»ºæˆåŠŸï¼")
                    
            else:
                # å•ä¸ªæµçš„åˆ›å»º
                print("\n=== å¼€å§‹åˆ›å»ºæµ ===")
                
                # æå–å®é™…çš„æµåç§°
                import re
                match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                actual_stream_name = match.group(1) if match else "æœªçŸ¥æµåç§°"
                
                print(f"æµåç§°: {actual_stream_name}")
                print("æ‰§è¡Œæµè®¡ç®—SQL:")
                print("-" * 60)
                print(sql_templates)
                print("-" * 60)
                
                try:
                    start_time = time.time()
                    cursor.execute(sql_templates)
                    create_time = time.time() - start_time
                    
                    print(f"âœ“ æµ {actual_stream_name} åˆ›å»ºå®Œæˆ! è€—æ—¶: {create_time:.2f}ç§’")
                    
                except Exception as e:
                    # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                    error_message = str(e)
                    tdengine_error = extract_stream_creation_error(error_message)
                    
                    print(f"æ‰§è¡Œé”™è¯¯: {tdengine_error}")
                    raise
            
            # å¯åŠ¨ç³»ç»Ÿç›‘æ§
            print("\nå¼€å§‹ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨æƒ…å†µ...")
        
            # è®¡ç®—é¢„çƒ­æ—¶é—´
            if hasattr(self, 'monitor_warm_up_time') and self.monitor_warm_up_time is not None:
                warm_up_time = self.monitor_warm_up_time
                print(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
            else:
                warm_up_time = 60 if self.runtime >= 2 else 0
                if warm_up_time > 0:
                    print(f"ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
                    
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file='/tmp/perf-stream-test.log',
                interval=self.monitor_interval,
                deployment_mode=self.deployment_mode,
                warm_up_time=warm_up_time
            )
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
            monitor_thread = threading.Thread(
                target=loader.get_proc_status,
                name="StreamTestMonitor"
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            
            # å¯åŠ¨æµå»¶è¿Ÿç›‘æ§
            delay_monitor_thread = self.start_stream_delay_monitor()
            
            # ç­‰å¾…æµè®¡ç®—å®Œæˆ
            print(f"ç­‰å¾…æµè®¡ç®—å®Œæˆ... (ç›‘æ§æ—¶é—´: {self.runtime}åˆ†é’Ÿ)")
            
            # å®šæœŸæ£€æŸ¥æµè®¡ç®—è¿›åº¦
            check_interval = 30  # æ¯30ç§’æ£€æŸ¥ä¸€æ¬¡
            total_checks = (self.runtime * 60) // check_interval
            
            for i in range(total_checks):
                time.sleep(check_interval)
                
                try:
                    # æ£€æŸ¥ç›®æ ‡è¡¨æ•°æ®é‡
                    cursor.execute("use stream_to")
                    
                    # æŸ¥è¯¢ç›®æ ‡è¡¨æ•°é‡å’Œè®°å½•æ•°
                    cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                    target_table_count = cursor.fetchall()[0][0]
                    
                    if target_table_count > 0:
                        # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å†™å…¥
                        cursor.execute("show tables")
                        tables = cursor.fetchall()
                        
                        total_target_records = 0
                        for table in tables:
                            table_name = table[0]
                            try:
                                cursor.execute(f"select count(*) from stream_to.{table_name}")
                                count = cursor.fetchall()[0][0]
                                total_target_records += count
                            except:
                                continue
                        
                        progress = (i + 1) / total_checks * 100
                        print(f"è¿›åº¦: {progress:.1f}% - ç›®æ ‡è¡¨: {target_table_count}, ç›®æ ‡è®°å½•: {total_target_records:,}")
                    else:
                        progress = (i + 1) / total_checks * 100
                        print(f"è¿›åº¦: {progress:.1f}% - ç­‰å¾…æµè®¡ç®—å¼€å§‹...")
                        
                    cursor.execute('use stream_from')  # åˆ‡æ¢å›æºæ•°æ®åº“
                    
                except Exception as e:
                    print(f"æ£€æŸ¥è¿›åº¦æ—¶å‡ºé”™: {str(e)}")
                    
                # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶
                if i >= total_checks - 1:
                    print(f"\nå·²è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶ ({self.runtime} åˆ†é’Ÿ)")
                    break
            
            print("\næµè®¡ç®—æµ‹è¯•å®Œæˆ!")
            
            # æ˜¾ç¤ºæœ€ç»ˆç»“æœç»Ÿè®¡
            print("\n=== æµè®¡ç®—ç»“æœç»Ÿè®¡ ===")
            try:
                cursor.execute("use stream_to")
                cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                final_table_count = cursor.fetchall()[0][0]
                
                cursor.execute("show tables")
                tables = cursor.fetchall()
                
                final_total_records = 0
                table_details = []
                for table in tables:
                    table_name = table[0]
                    try:
                        cursor.execute(f"select count(*) from stream_to.{table_name}")
                        count = cursor.fetchall()[0][0]
                        final_total_records += count
                        table_details.append(f"è¡¨ {table_name}: {count:,} æ¡è®°å½•")
                    except Exception as e:
                        table_details.append(f"è¡¨ {table_name}: æŸ¥è¯¢å¤±è´¥ - {str(e)}")
                
                print(f"æ€»è®¡: {final_table_count} å¼ ç›®æ ‡è¡¨, {final_total_records:,} æ¡ç»“æœè®°å½•")
                
                # æ˜¾ç¤ºå‰å‡ å¼ è¡¨çš„è¯¦æƒ…
                for detail in table_details[:5]:
                    print(f"  {detail}")
                if len(table_details) > 5:
                    print(f"  ... è¿˜æœ‰ {len(table_details) - 5} å¼ è¡¨")
                
                # è®¡ç®—å¤„ç†æ•ˆç‡
                if record_count > 0:
                    processing_ratio = final_total_records / record_count * 100
                    print(f"å¤„ç†æ•ˆç‡: {processing_ratio:.2f}% ({final_total_records:,}/{record_count:,})")
                
            except Exception as e:
                print(f"ç»Ÿè®¡ç»“æœæ—¶å‡ºé”™: {str(e)}")
                
            print("\n=== æµè®¡ç®—æµ‹è¯•å®Œæˆ ===")
            print("æ€§èƒ½ç›‘æ§æ•°æ®å·²ä¿å­˜åˆ°: /tmp/perf-stream-test-*.log")
            print("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç›‘æ§æ•°æ®:")
            print("cat /tmp/perf-stream-test-all.log")
            
        except Exception as e:
            print(f"æµè®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")
            raise
        finally:
            # å®‰å…¨åœ°å…³é—­æ•°æ®åº“è¿æ¥
            try:
                if cursor:
                    cursor.close()
                if conn:
                    conn.close()
            except Exception as e:
                print(f"å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {str(e)}")
            
            # å®‰å…¨åœ°åœæ­¢ç›‘æ§
            try:
                if loader:
                    print("ä¸»åŠ¨åœæ­¢ç³»ç»Ÿç›‘æ§...")
                    loader.stop()
            except Exception as e:
                print(f"åœæ­¢ç³»ç»Ÿç›‘æ§æ—¶å‡ºé”™: {str(e)}")
            
            # å®‰å…¨åœ°ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            try:
                if monitor_thread:
                    print("ç­‰å¾…ç›‘æ§æ•°æ®æ”¶é›†å®Œæˆ...")
                    monitor_thread.join(timeout=15)
                    
                    if monitor_thread.is_alive():
                        print("ç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
                    else:
                        print("ç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
            except Exception as e:
                print(f"ç­‰å¾…ç›‘æ§çº¿ç¨‹æ—¶å‡ºé”™: {str(e)}")
                
            # å®‰å…¨åœ°ç­‰å¾…å»¶è¿Ÿç›‘æ§çº¿ç¨‹ç»“æŸ
            try:
                if delay_monitor_thread:
                    print("ç­‰å¾…å»¶è¿Ÿç›‘æ§å®Œæˆ...")
                    delay_monitor_thread.join(timeout=10)
                    if delay_monitor_thread.is_alive():
                        print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
                    else:
                        print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
            except Exception as e:
                print(f"ç­‰å¾…å»¶è¿Ÿç›‘æ§çº¿ç¨‹æ—¶å‡ºé”™: {str(e)}")
            
            # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
            try:
                if self.check_stream_delay:
                    print(f"\næµå»¶è¿Ÿç›‘æ§æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.delay_log_file}")
                    self.print_final_delay_summary()
            except Exception as e:
                print(f"æ‰“å°æœ€ç»ˆæŠ¥å‘Šæ—¶å‡ºé”™: {str(e)}")

        
    def create_test_data(self):
        """åˆ›å»ºå¹¶å¤‡ä»½æµ‹è¯•æ•°æ®"""
        try:
            print("å¼€å§‹ç”Ÿæˆæµ‹è¯•æ•°æ®...")
            self.prepare_env()
            self.prepare_source_from_data()
            # è¿è¡Œæ•°æ®ç”Ÿæˆ
            proc = subprocess.Popen('taosBenchmark --f /tmp/stream_from.json',
                                    stdout=subprocess.PIPE, shell=True, text=True)
            
            # ç­‰å¾…æ•°æ®å†™å…¥å®Œæˆ
            conn = taos.connect(host=self.host, user=self.user, 
                                password=self.passwd, config=self.conf)
            cursor = conn.cursor()
            
            if not self.wait_for_data_ready(cursor,self.table_count, self.histroy_rows):
                print("æ•°æ®ç”Ÿæˆå¤±è´¥")
                return False
        
        
            # âœ… å¦‚æœå¯ç”¨è™šæ‹Ÿè¡¨æ¨¡å¼ï¼Œåˆ›å»ºè™šæ‹Ÿè¡¨
            if self.use_virtual_table:
                print("\n=== åˆ›å»ºè™šæ‹Ÿè¡¨æ˜ å°„ ===")
                if not self.create_virtual_tables():
                    print("è™šæ‹Ÿè¡¨åˆ›å»ºå¤±è´¥")
                    return False
                            
            # å¤‡ä»½æ•°æ®
            if self.backup_cluster_data():
                print("æµ‹è¯•æ•°æ®å·²ç”Ÿæˆå¹¶å¤‡ä»½")
                return True
                
            print("æµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ")
            return True
            
        except Exception as e:
            print(f"åˆ›å»ºæµ‹è¯•æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            return False
        
    
    def cleanup_environment_variables(self):
        """æ¸…ç†å¯èƒ½æœ‰é—®é¢˜çš„ç¯å¢ƒå˜é‡"""
        print("æ¸…ç†ç¯å¢ƒå˜é‡...")
        
        # æ¸…ç† LD_PRELOAD ä¸­çš„æ— æ•ˆè·¯å¾„
        current_ld_preload = os.environ.get('LD_PRELOAD', '')
        if current_ld_preload:
            print(f"  å½“å‰ LD_PRELOAD: {current_ld_preload}")
            
            # ç§»é™¤ä¸å­˜åœ¨çš„jemallocè·¯å¾„
            invalid_paths = ['/usr/local/taos/driver/libjemalloc.so']
            
            valid_paths = []
            for path in current_ld_preload.split(':'):
                path = path.strip()
                if path and path not in invalid_paths:
                    if os.path.exists(path):
                        valid_paths.append(path)
                    else:
                        print(f"    ç§»é™¤æ— æ•ˆè·¯å¾„: {path}")
            
            # æ›´æ–° LD_PRELOAD
            new_ld_preload = ':'.join(valid_paths)
            os.environ['LD_PRELOAD'] = new_ld_preload
            print(f"    æ›´æ–°å LD_PRELOAD: {new_ld_preload}")
        else:
            # å¦‚æœæ²¡æœ‰è®¾ç½®ï¼Œç¡®ä¿ä¸ºç©º
            os.environ['LD_PRELOAD'] = ''
            print("  LD_PRELOAD å·²è®¾ç½®ä¸ºç©º")
        
    def prepare_env(self):
        """
        æ¸…ç†ç¯å¢ƒå¹¶å¯åŠ¨TDengineæœåŠ¡
        æ”¯æŒå•èŠ‚ç‚¹(single)å’Œé›†ç¾¤(cluster)ä¸¤ç§æ¨¡å¼
        """
        try:
            print_title(f"\n=== å¼€å§‹å‡†å¤‡ç¯å¢ƒ (æ¨¡å¼: {self.deployment_mode}) ===")
            
            # å†æ¬¡ç¡®ä¿ç¯å¢ƒå˜é‡æ¸…ç†
            print("éªŒè¯ç¯å¢ƒå˜é‡æ¸…ç†çŠ¶æ€...")
            current_ld_preload = os.environ.get('LD_PRELOAD', '')
            if current_ld_preload:
                print(f"è­¦å‘Š: LD_PRELOAD ä»ç„¶è®¾ç½®ä¸º: {current_ld_preload}")
                # å¼ºåˆ¶æ¸…ç©º
                os.environ['LD_PRELOAD'] = ''
                print("å·²å¼ºåˆ¶æ¸…ç©º LD_PRELOAD")
            else:
                print("âœ“ LD_PRELOAD ç¯å¢ƒå˜é‡å·²æ¸…ç†")
                
            # åœæ­¢å·²å­˜åœ¨çš„taosdè¿›ç¨‹
            print_info("åœæ­¢ç°æœ‰taosdè¿›ç¨‹")
            self.stop_taosd()
            
            # æ£€æŸ¥å¹¶å¤„ç†é›†ç¾¤æ ¹ç›®å½•
            if os.path.exists(self.stream_perf_test_dir):
                print_info(f"æ¸…ç†å·²å­˜åœ¨çš„é›†ç¾¤ç›®å½•: {self.stream_perf_test_dir}")
                subprocess.run(f'rm -rf {self.stream_perf_test_dir}/*', shell=True)
            else:
                print_info(f"åˆ›å»ºæ–°çš„é›†ç¾¤ç›®å½•: {self.stream_perf_test_dir}")
                subprocess.run(f'mkdir -p {self.stream_perf_test_dir}', shell=True)
            
                
            for instance in self.instances:
                # åˆ›å»ºå¿…è¦çš„ç›®å½•
                for dir_type in ['data', 'log', 'conf']:
                    dir_path = f"{self.stream_perf_test_dir}/{instance['name']}/{dir_type}"
                    subprocess.run(f'mkdir -p {dir_path}', shell=True)
                
                # æ¸…ç†æ•°æ®ç›®å½•
                data_dir = f"{self.stream_perf_test_dir}/{instance['name']}/data"
                subprocess.run(f'rm -rf {data_dir}', shell=True)
                print(f"åˆ›å»ºç›®å½•: {dir_path}")
                
                # æ ¹æ®éƒ¨ç½²æ¨¡å¼ç”Ÿæˆä¸åŒçš„é…ç½®æ–‡ä»¶
                if self.deployment_mode == 'single':
                    # å•èŠ‚ç‚¹é…ç½®ç”Ÿæˆé…ç½®æ–‡ä»¶
                    cfg_content = f"""
firstEP         localhost:6030
fqdn            localhost
serverPort      {instance['port']}
supportVnodes   100
dataDir         {instance['data_dir']}
logDir          {instance['log_dir']}
asyncLog        1
tagFilterCache  true
WAL_RETENTION_PERIOD 3600
debugFlag       {self.debug_flag}
numOfLogLines   {self.num_of_log_lines}
"""
                else:
                    # é›†ç¾¤é…ç½®ç”Ÿæˆé…ç½®æ–‡ä»¶
                    cfg_content = f"""
firstEP         localhost:6030
secondEP        localhost:7030
fqdn            localhost
serverPort      {instance['port']}
supportVnodes   50
dataDir         {instance['data_dir']}
logDir          {instance['log_dir']}
asyncLog        1
tagFilterCache  true
WAL_RETENTION_PERIOD 3600
debugFlag       {self.debug_flag}
numOfLogLines   {self.num_of_log_lines}
"""
                cfg_file = f"{self.stream_perf_test_dir}/{instance['name']}/conf/taos.cfg"
                
                # ä½¿ç”¨ EOF æ–¹å¼å†™å…¥é…ç½®æ–‡ä»¶
                subprocess.run(f"""
cat << 'EOF' > {cfg_file}
{cfg_content}
EOF
""", shell=True)
            print_success("ç¯å¢ƒå‡†å¤‡å®Œæˆï¼Œé…ç½®æ–‡ä»¶å·²ç”Ÿæˆ")
            
            
            # å¯åŠ¨æ‰€æœ‰taosdå®ä¾‹
            self.taosd_processes = []  
            for instance in self.instances:
                cfg_file = f"{self.stream_perf_test_dir}/{instance['name']}/conf/taos.cfg"
                
                # # æ„å»ºå¯åŠ¨å‘½ä»¤ï¼Œä¼˜å…ˆå°è¯•ä½¿ç”¨ set_taos_malloc.sh è„šæœ¬
                # script_dir = os.path.dirname(os.path.abspath(__file__))
                # malloc_script = os.path.join(script_dir, 'set_taos_malloc.sh')

                # if os.path.exists(malloc_script) and os.access(malloc_script, os.X_OK):                   
                #     #cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                #     cmd = f'env LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so HEAPCHECK=strict HEAPPROFILE=/root/pw/taosd HEAP_PROFILE_ALLOCATION_INTERVAL=1024 HEAP_PROFILE_INUSE_INTERVAL=1024 && nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                #     #cmd = f'bash -c "{malloc_script} -m 4 && . /usr/local/taos/bin/set_taos_malloc_env.sh && nohup taosd -c {cfg_file} > /dev/null 2>&1 &"'
                #     #ok cmd = f'bash -c "{malloc_script} -m 4 && unset MALLOC_CONF && unset JEMALLOC_CONF  &&  . /usr/local/taos/bin/set_taos_malloc_env.sh && taosd -c {cfg_file} > /dev/null 2>&1 "'                    
                #     #faile cmd = f'bash -c "{malloc_script} -m 4 && cp /coredump/set_taos_malloc_env.sh /usr/local/taos/bin/set_taos_malloc_env.sh && unset MALLOC_CONF && unset JEMALLOC_CONF  &&  . /usr/local/taos/bin/set_taos_malloc_env.sh && taosd -c {cfg_file} > /dev/null 2>/tmp/dlog "'                    
                    
                #     # print(f"ä½¿ç”¨å†…å­˜é…ç½®è„šæœ¬å¯åŠ¨: {malloc_script} -m 4")
                # else:
                #     # å¦‚æœè„šæœ¬ä¸å­˜åœ¨æˆ–ä¸å¯æ‰§è¡Œï¼Œç›´æ¥å¯åŠ¨ taosd
                #     cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                #     if os.path.exists(malloc_script):
                #         print(f"è­¦å‘Š: å‘ç°è„šæœ¬ {malloc_script} ä½†ä¸å¯æ‰§è¡Œï¼Œè·³è¿‡å†…å­˜é…ç½®")
                #     else:
                #         print(f"æœªæ‰¾åˆ°å†…å­˜é…ç½®è„šæœ¬ {malloc_script}ï¼Œä½¿ç”¨é»˜è®¤å¯åŠ¨æ–¹å¼")
                
                # æ ¹æ®å‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨tcmalloc
                if self.use_tcmalloc:
                    tcmalloc_path = '/usr/lib/x86_64-linux-gnu/libtcmalloc.so'
                    if os.path.exists(tcmalloc_path):
                        print(f"ä½¿ç”¨ tcmalloc å¯åŠ¨ {instance['name']} (--use-tcmalloc å‚æ•°å¯ç”¨)")
                        
                        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
                        profile_dir = '/root/pw'
                        os.makedirs(profile_dir, exist_ok=True)
                        
                        # ä½¿ç”¨æ­£ç¡®çš„å‘½ä»¤æ ¼å¼
                        cmd = f"""bash -c '
                    export LD_PRELOAD={tcmalloc_path}
                    export HEAPPROFILE=/root/pw/taosd_{instance["name"]}
                    export HEAP_PROFILE_ALLOCATION_INTERVAL=8147483648
                    export HEAP_PROFILE_INUSE_INTERVAL=536870912
                    nohup taosd -c {cfg_file} > /dev/null 2>&1 &
                    '"""
                        
                    else:
                        print(f"è­¦å‘Š: tcmalloc åº“ä¸å­˜åœ¨äº {tcmalloc_path}ï¼Œä½¿ç”¨é»˜è®¤å¯åŠ¨ {instance['name']}")
                        cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                else:
                    # é»˜è®¤å¯åŠ¨æ–¹å¼ï¼ˆä¸ä½¿ç”¨tcmallocï¼‰
                    print(f"ä½¿ç”¨é»˜è®¤æ–¹å¼å¯åŠ¨ {instance['name']} (æœªå¯ç”¨ --use-tcmalloc å‚æ•°)")
                    cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'

                print(f"å¯åŠ¨å‘½ä»¤: {cmd}")
                                
                #cmd = f'nohup taosd -c {cfg_file} > /dev/null 2>&1 &'
                #cmd = f'bash -c "export LD_PRELOAD=/usr/lib/x86_64-linux-gnu/libtcmalloc.so && export HEAPCHECK=strict && export HEAPPROFILE=/root/pw/taosd && export HEAP_PROFILE_ALLOCATION_INTERVAL=1024 && export HEAP_PROFILE_INUSE_INTERVAL=1024 && nohup taosd -c {cfg_file} > /dev/null 2>&1 &"'                    
                
                try:
                    process = subprocess.Popen(cmd, shell=True)
                    self.taosd_processes.append({
                        'name': instance,
                        'pid': process.pid,
                        'cfg': cfg_file
                    })
                    print(f"å¯åŠ¨taosdè¿›ç¨‹: {instance}, PID: {process.pid}")
                except Exception as e:
                    print(f"å¯åŠ¨ {instance} å¤±è´¥: {str(e)}")
                    raise
            
            # ç­‰å¾…æœåŠ¡å®Œå…¨å¯åŠ¨
            wait_time = 3 if self.deployment_mode == 'single' else 10
            print(f"ç­‰å¾…æœåŠ¡å¯åŠ¨ ({wait_time}ç§’)...")
            time.sleep(wait_time)             
            self.check_taosd_status()
            
            # é…ç½®é›†ç¾¤
            try:
                # è¿æ¥åˆ°ç¬¬ä¸€ä¸ªèŠ‚ç‚¹
                conn = taos.connect(
                    host=self.host,
                    user=self.user,
                    password=self.passwd,
                    config=self.conf
                )
                cursor = conn.cursor()
                
                if self.deployment_mode == 'cluster':
                    # é›†ç¾¤æ¨¡å¼é…ç½®
                    print("\n=== å¼€å§‹é…ç½®é›†ç¾¤ ===")
                    cluster_cmds = [
                        'create dnode "localhost:7030"',
                        'create dnode "localhost:8030"',
                        'create mnode on dnode 2',
                        'create mnode on dnode 3',
                        'create snode on dnode 1'
                        # ,
                        
                        # 'create snode on dnode 2',
                        # 'create snode on dnode 1'
                    ]
                
                    for cmd in cluster_cmds:
                        try:
                            cursor.execute(cmd)
                            time.sleep(1)
                            print(f"æ‰§è¡ŒæˆåŠŸ: {cmd}")
                        except Exception as e:
                            print(f"æ‰§è¡Œå¤±è´¥: {cmd}")
                            print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
                
                    # æŸ¥è¯¢å¹¶æ˜¾ç¤ºé›†ç¾¤çŠ¶æ€
                    print("\né›†ç¾¤èŠ‚ç‚¹ä¿¡æ¯:")
                    print("-" * 50)
                    
                else:
                    # å•èŠ‚ç‚¹æ¨¡å¼é…ç½®
                    print("\n=== é…ç½®å•èŠ‚ç‚¹ç¯å¢ƒ ===")
                    try:
                        cursor.execute('create snode on dnode 1')
                        print("æ‰§è¡ŒæˆåŠŸ: create snode on dnode 1")
                        time.sleep(1)
                    except Exception as e:
                        print(f"åˆ›å»ºsnodeå¤±è´¥: {str(e)}")
                
                # æŸ¥è¯¢å¹¶æ˜¾ç¤ºèŠ‚ç‚¹çŠ¶æ€ï¼ˆå•èŠ‚ç‚¹å’Œé›†ç¾¤éƒ½æ˜¾ç¤ºï¼‰
                print(f"\n=== {self.deployment_mode.upper()}æ¨¡å¼èŠ‚ç‚¹ä¿¡æ¯ ===")
                print("-" * 60)
                
                try:
                    # æŸ¥è¯¢ dnodes ä¿¡æ¯
                    print("\nDNode ä¿¡æ¯:")
                    cursor.execute("show dnodes")
                    result = cursor.fetchall()
                    for row in result:
                        print(f"ID: {row[0]}, endpoint: {row[1]}, status: {row[4]}")
                    
                    # æŸ¥è¯¢ mnodes ä¿¡æ¯
                    print("\nMNode ä¿¡æ¯:")
                    cursor.execute("show mnodes")
                    result = cursor.fetchall()
                    if result:
                        for row in result:
                            print(f"ID: {row[0]}, endpoint: {row[1]}, role: {row[2]}, status: {row[3]}")
                    else:
                        print("å½“å‰ç³»ç»Ÿä¸­æ²¡æœ‰é¢å¤–çš„mnode")
                    
                    # æŸ¥è¯¢ snodes ä¿¡æ¯
                    print("\nSNode ä¿¡æ¯:")
                    cursor.execute("show snodes")
                    result = cursor.fetchall()
                    if result:
                        for row in result:
                            print(f"ID: {row[0]}, endpoint: {row[1]}, create_time: {row[2]}")
                    else:
                        print("å½“å‰ç³»ç»Ÿä¸­æ²¡æœ‰snode")
                        
                except Exception as e:
                    print(f"æŸ¥è¯¢èŠ‚ç‚¹ä¿¡æ¯å¤±è´¥: {str(e)}")
                
                print("-" * 50)
                
                # å…³é—­è¿æ¥
                cursor.close()
                conn.close()
                
                print(f"{self.deployment_mode.upper()}æ¨¡å¼é…ç½®å®Œæˆ")
                
            except Exception as e:
                print_error(f"èŠ‚ç‚¹é…ç½®å¤±è´¥: {str(e)}")
                raise
                
        except Exception as e:
            print_error(f"ç¯å¢ƒå‡†å¤‡å¤±è´¥: {str(e)}")
            raise
        
    def prepare_source_from_data(self) -> dict:
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿè¡¨æ¥è®¾ç½®ä¸åŒçš„åç§°
        print(f"è°ƒè¯•: prepare_source_from_data() - use_virtual_table = {getattr(self, 'use_virtual_table', 'UNDEFINED')} (ç±»å‹: {type(getattr(self, 'use_virtual_table', None))})")
        
        # æ£€æŸ¥å±æ€§æ˜¯å¦å­˜åœ¨
        if not hasattr(self, 'use_virtual_table'):
            print("âŒ é”™è¯¯: use_virtual_table å±æ€§æœªå®šä¹‰!")
            self.use_virtual_table = False
        
        if self.use_virtual_table:
            stb_name = "forvt_stb"
            childtable_prefix = "forvt_ctb0_"
            print("ä½¿ç”¨è™šæ‹Ÿè¡¨æ¨¡å¼: è¶…çº§è¡¨å=forvt_stb, å­è¡¨å‰ç¼€=forvt_ctb0_")
        else:
            stb_name = "stb"
            childtable_prefix = "ctb0_"
            print("ä½¿ç”¨æ™®é€šè¶…çº§è¡¨æ¨¡å¼: è¶…çº§è¡¨å=stb, å­è¡¨å‰ç¼€=ctb0_")
            
        json_data = {
            "filetype": "insert",
            "cfgdir": f"{self.stream_perf_test_dir}/dnode1/conf",
            "host": "localhost",
            "port": 6030,
            "rest_port": 6041,
            "user": "root",
            "password": "taosdata",
            "thread_count": 10,
            "create_table_thread_count": 5,
            "result_file": "/tmp/taosBenchmark_result.log",
            "confirm_parameter_prompt": "no",
            "insert_interval": 10,
            "num_of_records_per_req": 1000,
            "max_sql_len": 102400,
            "databases": [
                {
                    "dbinfo": {
                        "name": "stream_from",
                        "drop": "yes",
                        "replica": 1,
                        "duration": 10,
                        "precision": "ms",
                        "keep": 3650,
                        "minRows": 100,
                        "maxRows": 4096,
                        "comp": 2,
                        "dnodes": "1",
                        "vgroups": self.vgroups,
                        "stt_trigger": 1,
                        "WAL_RETENTION_PERIOD": 86400
                    },
                    "super_tables": [
                        {
                            "name": stb_name,
                            "child_table_exists": "yes",
                            "childtable_count": self.table_count,
                            "childtable_prefix": childtable_prefix,
                            "escape_character": "no",
                            "auto_create_table": "yes",
                            "batch_create_tbl_num": 1000,
                            "data_source": "rand",
                            "insert_mode": "taosc",
                            "interlace_rows": 1,
                            "tcp_transfer": "no",
                            "insert_rows": self.histroy_rows,
                            "partial_col_num": 0,
                            "childtable_limit": 0,
                            "childtable_offset": 0,
                            "rows_per_tbl": 0,
                            "max_sql_len": 1024000,
                            "disorder_ratio": self.disorder_ratio,
                            "disorder_range": 1000,
                            "keep_trying": -1,
                            "timestamp_step": 50,
                            "trying_interval": 10,
                            "start_timestamp": "2025-06-01 00:00:00",
                            "sample_format": "csv",
                            "sample_file": "./sample.csv",
                            "tags_file": "",
                            "columns": [
                                {
                                    "type": "INT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "BIGINT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "DOUBLE",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "FLOAT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                }
                            ],
                            "tags": [
                                {
                                    "type": "INT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "VARCHAR",
                                    "count": 1,
                                    "len": 32
                                }
                            ]
                        }
                    ]
                }
            ],
            "prepare_rand": 10000,
            "chinese": "no",
            "test_log": "/tmp/testlog/"
        }

        with open('/tmp/stream_from.json', 'w+') as f:
            json.dump(json_data, f, indent=4)
            

    def insert_source_from_data(self) -> dict:
        # æ ¹æ®æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿè¡¨æ¥è®¾ç½®ä¸åŒçš„åç§°
        if self.use_virtual_table:
            stb_name = "forvt_stb"
            childtable_prefix = "forvt_ctb0_"
        else:
            stb_name = "stb"
            childtable_prefix = "ctb0_"
            
        json_data = {
            "filetype": "insert",
            "cfgdir": f"{self.stream_perf_test_dir}/dnode1/conf",
            "host": "localhost",
            "port": 6030,
            "rest_port": 6041,
            "user": "root",
            "password": "taosdata",
            "thread_count": 10,
            "create_table_thread_count": 5,
            "result_file": "/tmp/taosBenchmark_result.log",
            "confirm_parameter_prompt": "no",
            "insert_interval": 1,
            "num_of_records_per_req": 1000,
            "max_sql_len": 102400,
            "databases": [
                {
                    "dbinfo": {
                        "name": "stream_from",
                        "drop": "no",
                        "replica": 1,
                        "duration": 10,
                        "precision": "ms",
                        "keep": 3650,
                        "minRows": 100,
                        "maxRows": 4096,
                        "comp": 2,
                        "dnodes": "1",
                        "vgroups": self.vgroups,
                        "stt_trigger": 1,
                        "WAL_RETENTION_PERIOD": 86400
                    },
                    "super_tables": [
                        {
                            "name": stb_name,
                            "child_table_exists": "yes",
                            "childtable_count": self.table_count,
                            "childtable_prefix": childtable_prefix,
                            "escape_character": "no",
                            "auto_create_table": "yes",
                            "batch_create_tbl_num": 1000,
                            "data_source": "rand",
                            "insert_mode": "taosc",
                            "interlace_rows": 1,
                            "tcp_transfer": "no",
                            "insert_rows": self.real_time_batch_rows,
                            "partial_col_num": 0,
                            "childtable_limit": 0,
                            "childtable_offset": 0,
                            "rows_per_tbl": 0,
                            "max_sql_len": 1024000,
                            "disorder_ratio": self.disorder_ratio,
                            "disorder_range": 1000,
                            "keep_trying": -1,
                            "timestamp_step": 50,
                            "trying_interval": 10,
                            "start_timestamp": "2025-06-01 00:00:00",
                            "sample_format": "csv",
                            "sample_file": "./sample.csv",
                            "tags_file": "",
                            "columns": [
                                {
                                    "type": "INT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "BIGINT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "DOUBLE",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "FLOAT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                }
                            ],
                            "tags": [
                                {
                                    "type": "INT",
                                    "count": 1,
                                    "max": 10, "min": 1
                                },
                                {
                                    "type": "VARCHAR",
                                    "count": 1,
                                    "len": 32
                                }
                            ]
                        }
                    ]
                }
            ],
            "prepare_rand": 10000,
            "chinese": "no",
            "test_log": "/tmp/testlog/"
        }

        with open('/tmp/stream_from_insertdata.json', 'w+') as f:
            json.dump(json_data, f, indent=4)
            
    def update_insert_config(self):
        """
        æ›´æ–°æ•°æ®æ’å…¥é…ç½®
        Args:
            real_time_batch_rows: ä¸‹ä¸€è½®è¦æ’å…¥çš„æ•°æ®è¡Œæ•°
        """
        try:
            print("\n=== æ›´æ–°æ•°æ®æ’å…¥é…ç½® ===")
            #print(f"å½“å‰SQLç±»å‹: {self.sql_type}")
            
            # è·å–æœ€æ–°æ—¶é—´æˆ³
            conn = taos.connect(
                host=self.host,
                user=self.user,
                password=self.passwd,
                config=self.conf
            )
            cursor = conn.cursor()
            
            try:
                # æ ¹æ® SQL ç±»å‹å†³å®šæ—¶é—´æˆ³æ›´æ–°æ–¹å¼
                # æ£€æŸ¥æ˜¯å¦ä¸º period ç±»å‹çš„æµè®¡ç®—
                is_period_type = (
                    self.sql_type.startswith('period_') or 
                    'period_' in self.sql_type or
                    self.sql_type == 's2_5' or 
                    self.sql_type == 's2_11' or
                    (isinstance(self.stream_sql, dict) and 
                    any('period_' in key for key in self.stream_sql.keys())) or
                    (isinstance(self.stream_sql, str) and 
                    'period(' in self.stream_sql.lower())
                )
                
                if is_period_type:
                    next_start_time = time.strftime("%Y-%m-%d %H:%M:%S")
                    print(f"æ£€æµ‹åˆ° PERIOD ç±»å‹æµè®¡ç®—ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºèµ·å§‹æ—¶é—´: {next_start_time}")
                    print(f"PERIOD ç±»å‹è¯´æ˜: ä½¿ç”¨ cast(_tprev_localtime/1000000 as timestamp) å’Œ cast(_tnext_localtime/1000000 as timestamp) ä½œä¸ºæ—¶é—´èŒƒå›´å˜é‡")
                
                else:
                    # æ ¹æ®æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿè¡¨æ¥è®¾ç½®ä¸åŒçš„è¡¨å
                    if self.use_virtual_table:
                        table_name = "stream_from.forvt_stb"
                    else:
                        table_name = "stream_from.stb"
                    
                    # æŸ¥è¯¢æœ€æ–°æ—¶é—´æˆ³
                    cursor.execute(f"select last(ts) from {table_name}")
                    last_ts = cursor.fetchall()[0][0]
                
                    if not last_ts:
                        raise Exception("æœªèƒ½è·å–åˆ°æœ€æ–°æ—¶é—´æˆ³")
                        
                    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶åŠ ä¸Š1ç§’
                    next_start_time = (last_ts + datetime.timedelta(seconds=1)).strftime("%Y-%m-%d %H:%M:%S")
                    print(f"å½“å‰æœ€æ–°æ—¶é—´æˆ³: {last_ts}")
                    print(f"æ›´æ–°èµ·å§‹æ—¶é—´ä¸º: {next_start_time}")
                    
                    # next_start_time = time.strftime("%Y-%m-%d %H:%M:%S")
                    # print(f"ç»Ÿä¸€ä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºèµ·å§‹æ—¶é—´: {next_start_time}")
                
                # è¯»å–ç°æœ‰é…ç½®
                config_file = '/tmp/stream_from_insertdata.json'
                with open(config_file, 'r') as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ—¶é—´æˆ³
                import re
                new_content = re.sub(
                    r'"start_timestamp":\s*"[^"]*"',
                    f'"start_timestamp": "{next_start_time}"',
                    content,
                    count=1  # åªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´æˆ³
                )
                
                # æ ¼å¼åŒ–å†™å…¥ä»¥ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®
                with open(config_file, 'w') as f:
                    f.write(new_content)
                
                print("é…ç½®æ—¶é—´æˆ³å·²æ›´æ–°")
                return True
                
            except Exception as e:
                print(f"æ›´æ–°é…ç½®æ—¶å‡ºé”™: {str(e)}")
                return False
            finally:
                cursor.close()
                conn.close()
                
        except Exception as e:
            print(f"æ‰§è¡Œæ›´æ–°é…ç½®æ—¶å‡ºé”™: {str(e)}")
            return False
        
    
    def update_insert_config_bak(self):
        """
        æ›´æ–°æ•°æ®æ’å…¥é…ç½®
        Args:
            real_time_batch_rows: ä¸‹ä¸€è½®è¦æ’å…¥çš„æ•°æ®è¡Œæ•°
        """
        try:
            print("\n=== æ›´æ–°æ•°æ®æ’å…¥é…ç½® ===")
            #print(f"å½“å‰SQLç±»å‹: {self.sql_type}")
            
            # è·å–æœ€æ–°æ—¶é—´æˆ³
            conn = taos.connect(
                host=self.host,
                user=self.user,
                password=self.passwd,
                config=self.conf
            )
            cursor = conn.cursor()
            
            try:
                # æ ¹æ® SQL ç±»å‹å†³å®šæ—¶é—´æˆ³æ›´æ–°æ–¹å¼
                # æ£€æŸ¥æ˜¯å¦ä¸º period ç±»å‹çš„æµè®¡ç®—
                is_period_type = (
                    self.sql_type.startswith('period_') or 
                    'period_' in self.sql_type or
                    self.sql_type == 's2_5' or 
                    self.sql_type == 's2_11' or
                    (isinstance(self.stream_sql, dict) and 
                    any('period_' in key for key in self.stream_sql.keys())) or
                    (isinstance(self.stream_sql, str) and 
                    'period(' in self.stream_sql.lower())
                )
                
                if is_period_type:
                    next_start_time = time.strftime("%Y-%m-%d %H:%M:%S")
                    print(f"æ£€æµ‹åˆ° PERIOD ç±»å‹æµè®¡ç®—ï¼Œä½¿ç”¨å½“å‰æ—¶é—´ä½œä¸ºèµ·å§‹æ—¶é—´: {next_start_time}")
                    print(f"PERIOD ç±»å‹è¯´æ˜: ä½¿ç”¨ cast(_tprev_localtime/1000000 as timestamp) å’Œ cast(_tnext_localtime/1000000 as timestamp) ä½œä¸ºæ—¶é—´èŒƒå›´å˜é‡")
                
                else:
                    # æ ¹æ®æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿè¡¨æ¥è®¾ç½®ä¸åŒçš„è¡¨å
                    if self.use_virtual_table:
                        table_name = "stream_from.forvt_stb"
                    else:
                        table_name = "stream_from.stb"
                    
                    # æŸ¥è¯¢æœ€æ–°æ—¶é—´æˆ³
                    cursor.execute(f"select last(ts) from {table_name}")
                    last_ts = cursor.fetchall()[0][0]
                
                    if not last_ts:
                        raise Exception("æœªèƒ½è·å–åˆ°æœ€æ–°æ—¶é—´æˆ³")
                        
                    # å°†æ—¶é—´æˆ³è½¬æ¢ä¸ºå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¹¶åŠ ä¸Š1ç§’
                    next_start_time = (last_ts + datetime.timedelta(seconds=1)).strftime("%Y-%m-%d %H:%M:%S")
                    print(f"å½“å‰æœ€æ–°æ—¶é—´æˆ³: {last_ts}")
                    print(f"æ›´æ–°èµ·å§‹æ—¶é—´ä¸º: {next_start_time}")
                
                # è¯»å–ç°æœ‰é…ç½®
                config_file = '/tmp/stream_from_insertdata.json'
                with open(config_file, 'r') as f:
                    content = f.read()
                
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ›¿æ¢æ—¶é—´æˆ³
                import re
                new_content = re.sub(
                    r'"start_timestamp":\s*"[^"]*"',
                    f'"start_timestamp": "{next_start_time}"',
                    content,
                    count=1  # åªæ›¿æ¢ç¬¬ä¸€æ¬¡å‡ºç°çš„æ—¶é—´æˆ³
                )
                
                # æ ¼å¼åŒ–å†™å…¥ä»¥ç¡®ä¿ JSON æ ¼å¼æ­£ç¡®
                with open(config_file, 'w') as f:
                    f.write(new_content)
                
                print("é…ç½®æ—¶é—´æˆ³å·²æ›´æ–°")
                return True
                
            except Exception as e:
                print(f"æ›´æ–°é…ç½®æ—¶å‡ºé”™: {str(e)}")
                return False
            finally:
                cursor.close()
                conn.close()
                
        except Exception as e:
            print(f"æ‰§è¡Œæ›´æ–°é…ç½®æ—¶å‡ºé”™: {str(e)}")
            return False

    def wait_for_data_ready(self, cursor, expected_tables, expected_records):
        """ç­‰å¾…æ•°æ®å†™å…¥å®Œæˆ   
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡
            expected_tables: é¢„æœŸçš„å­è¡¨æ•°é‡
            expected_records: æ¯ä¸ªå­è¡¨çš„è®°å½•æ•°
            
        Returns:
            bool: æ•°æ®æ˜¯å¦å‡†å¤‡å°±ç»ª
        """
        max_wait_time = 3600  # æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)
        check_interval = 2   # æ£€æŸ¥é—´éš”(ç§’)
        start_time = time.time()
        
        while True:
            try:
                # æ£€æŸ¥å­è¡¨æ•°é‡
                cursor.execute("select count(*) from information_schema.ins_tables "
                            "where db_name='stream_from'")
                table_count = cursor.fetchall()[0][0]
                
                if table_count < expected_tables:
                    print(f"\rç­‰å¾…å­è¡¨åˆ›å»ºå®Œæˆ... å½“å‰: {table_count}/{expected_tables}", end='')
                    if time.time() - start_time > max_wait_time:
                        print(f"\nç­‰å¾…è¶…æ—¶! å­è¡¨æ•°é‡ä¸è¶³: {table_count}/{expected_tables}")
                        return False
                    time.sleep(check_interval)
                    continue
                
                # ä½¿ç”¨è¶…çº§è¡¨æŸ¥è¯¢æ€»è®°å½•æ•°
                # âœ… æ ¹æ®è™šæ‹Ÿè¡¨æ¨¡å¼é€‰æ‹©æ­£ç¡®çš„è¶…çº§è¡¨å
                if self.use_virtual_table:
                    # è™šæ‹Ÿè¡¨æ¨¡å¼ï¼šä½¿ç”¨ç‰©ç†è¡¨ forvt_stb
                    cursor.execute("select count(*) from stream_from.forvt_stb")
                else:
                    # æ™®é€šæ¨¡å¼ï¼šä½¿ç”¨ stb
                    cursor.execute("select count(*) from stream_from.stb")
                
                total_records = cursor.fetchall()[0][0]
                expected_total = expected_tables * expected_records
                
                if total_records < expected_total:
                    print(f"\rç­‰å¾…æ•°æ®å†™å…¥å®Œæˆ... å½“å‰: {total_records}/{expected_total}", end='')
                    
                    # å¦‚æœæ¥è¿‘è¶…æ—¶ï¼Œæ£€æŸ¥æ¯ä¸ªå­è¡¨çš„è®°å½•æ•°
                    if time.time() - start_time > max_wait_time - 30:  # ç•™å‡º30ç§’ç”¨äºè¯¦ç»†æ£€æŸ¥
                        print("\nå³å°†è¶…æ—¶ï¼Œæ£€æŸ¥å„å­è¡¨æ•°æ®æƒ…å†µ:")
                        insufficient_tables = []
                        
                        # âœ… æ ¹æ®è™šæ‹Ÿè¡¨æ¨¡å¼é€‰æ‹©æ­£ç¡®çš„è¡¨åå‰ç¼€
                        if self.use_virtual_table:
                            table_prefix = "forvt_ctb0_"
                        else:
                            table_prefix = "ctb0_"
                        
                        for i in range(expected_tables):
                            cursor.execute(f"select count(*) from stream_from.{table_prefix}{i}")
                            count = cursor.fetchall()[0][0]
                            if count < expected_records:
                                insufficient_tables.append({
                                    'table': f'{table_prefix}{i}',
                                    'current': count,
                                    'expected': expected_records,
                                    'missing': expected_records - count
                                })
                        
                        if insufficient_tables:
                            print("\nä»¥ä¸‹å­è¡¨æ•°æ®ä¸è¶³:")
                            for table in insufficient_tables:
                                print(f"è¡¨ {table['table']}: "
                                    f"å½“å‰ {table['current']}/{table['expected']}, "
                                    f"ç¼ºå°‘ {table['missing']} æ¡è®°å½•")
                        return False
                    
                    time.sleep(check_interval)
                    continue
                
                print(f"\næ•°æ®å‡†å¤‡å°±ç»ª! å…± {table_count} å¼ å­è¡¨ï¼Œ{total_records} æ¡è®°å½•")
                return True
                
            except Exception as e:
                print(f"\næ£€æŸ¥æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                if time.time() - start_time > max_wait_time:
                    print("ç­‰å¾…è¶…æ—¶!")
                    return False
                time.sleep(check_interval)
                
    def _parse_target_table_from_sql(self, sql):
        """ä»æµSQLä¸­è§£æç›®æ ‡è¡¨å
        
        Args:
            sql: æµçš„SQLè¯­å¥
            
        Returns:
            str: ç›®æ ‡è¡¨åï¼Œå¦‚æœè§£æå¤±è´¥åˆ™è¿”å›None
            
        Example SQL:
            create stream qdb.s18  interval(58s) intervalsliding(11m, 4m)  
                    from qdb.v1   stream_options(watermark(43m)) 
                    into qdb.st18 
                    as select _twstart ts, c2 as c2_val, c1 as c1_val 
                    from stream_trigger;
            
            åº”è¯¥è¿”å›: qdb.st18
        """
        try:
            import re
            
            # æ¸…ç†SQLï¼šç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦å’Œæ¢è¡Œç¬¦
            cleaned_sql = ' '.join(sql.split())
            
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é… into å…³é”®å­—åé¢çš„è¡¨å
            # æ¨¡å¼è¯´æ˜:
            # \binto\s+ : åŒ¹é…å•è¯è¾¹ç•Œçš„intoï¼Œåè·Ÿä¸€ä¸ªæˆ–å¤šä¸ªç©ºç™½å­—ç¬¦
            # ([^\s]+)  : æ•è·ä¸€ä¸ªæˆ–å¤šä¸ªéç©ºç™½å­—ç¬¦ï¼ˆè¡¨åï¼‰
            # \s+as\s+  : åŒ¹é…ç©ºç™½å­—ç¬¦ + as + ç©ºç™½å­—ç¬¦
            pattern = r'\binto\s+([^\s]+)\s+as\s+'
            
            match = re.search(pattern, cleaned_sql, re.IGNORECASE)
            
            if match:
                target_table = match.group(1)
                # ç§»é™¤å¯èƒ½çš„åˆ†å·æˆ–å…¶ä»–æ ‡ç‚¹ç¬¦å·
                target_table = target_table.rstrip(';').rstrip(',')
                #print(f"ä»SQLä¸­è§£æå‡ºç›®æ ‡è¡¨: {target_table}")
                return target_table
            else:
                # å¦‚æœç¬¬ä¸€ä¸ªæ¨¡å¼æ²¡åŒ¹é…åˆ°ï¼Œå°è¯•æ›´å®½æ¾çš„æ¨¡å¼
                # æœ‰äº›SQLå¯èƒ½æ ¼å¼ä¸åŒï¼Œå°è¯•åªåŒ¹é…intoåé¢çš„ç¬¬ä¸€ä¸ªæ ‡è¯†ç¬¦
                pattern2 = r'\binto\s+([^\s\n]+)'
                match2 = re.search(pattern2, cleaned_sql, re.IGNORECASE)
                
                if match2:
                    target_table = match2.group(1)
                    target_table = target_table.rstrip(';').rstrip(',')
                    print(f"ä½¿ç”¨å¤‡ç”¨æ¨¡å¼è§£æå‡ºç›®æ ‡è¡¨: {target_table}")
                    return target_table
                else:
                    print(f"æ— æ³•ä»SQLä¸­è§£æç›®æ ‡è¡¨: {cleaned_sql[:200]}...")
                    return None
                    
        except Exception as e:
            print(f"è§£æSQLæ—¶å‡ºé”™: {str(e)}")
            return None
                
    def get_stream_target_tables(self):
        """è·å–æµè®¡ç®—çš„ç›®æ ‡è¡¨åˆ—è¡¨
        
        Returns:
            list: ç›®æ ‡è¡¨ååˆ—è¡¨
        """
        try:
            conn, cursor = self.get_connection()
            
            # æŸ¥è¯¢æ‰€æœ‰æµä¿¡æ¯
            cursor.execute("select stream_name, sql from information_schema.ins_streams")
            streams = cursor.fetchall()
            print(f"ä» information_schema.ins_streams æŸ¥è¯¢åˆ° {len(streams)} ä¸ªæµ")
        
            
            target_tables = []
            for stream in streams:
                stream_name = stream[0]
                sql = stream[1]
            
                # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼è§£æSQLä¸­çš„ç›®æ ‡è¡¨
                target_table = self._parse_target_table_from_sql(sql)
                
                if target_table:
                    target_tables.append({
                        'stream_name': stream_name,
                        'target_table': target_table,
                        'target_db': target_table.split('.')[0] if '.' in target_table else 'stream_to',
                        'target_table_name': target_table.split('.')[-1],
                        'sql': sql  # ä¿å­˜åŸå§‹SQLç”¨äºè°ƒè¯•
                    })
                    #print(f"  æµ: {stream_name} -> ç›®æ ‡è¡¨: {target_table}")
                else:
                    print(f"  è­¦å‘Š: æ— æ³•è§£ææµ {stream_name} çš„ç›®æ ‡è¡¨ï¼ŒSQL: {sql[:100]}...")
            
            cursor.close()
            conn.close()
            
            if len(target_tables) == 0:
                print("è­¦å‘Š: æœªæ‰¾åˆ°ä»»ä½•æµæˆ–æ— æ³•è§£æç›®æ ‡è¡¨")
            else:
                print(f"æˆåŠŸè§£æ {len(target_tables)} ä¸ªæµçš„ç›®æ ‡è¡¨")
                
            return target_tables
            
        except Exception as e:
            print(f"è·å–æµç›®æ ‡è¡¨å¤±è´¥: {str(e)}")
            return []
        
    def _calculate_event_window_count(self, cursor, stream_name, target_first_ts, source_last_ts, source_type='stb'):
        """è®¡ç®— EVENT_WINDOW çš„çœŸå®çª—å£æ•°é‡
        
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡
            stream_name: æµåç§°
            target_first_ts: ç›®æ ‡è¡¨é¦–æ¡è®°å½•æ—¶é—´
            source_last_ts: æºè¡¨æœ€æ–°è®°å½•æ—¶é—´
            source_type: æºè¡¨ç±»å‹ ('stb' æˆ– 'tb')
            
        Returns:
            int: çœŸå®çš„äº‹ä»¶çª—å£æ•°é‡ï¼Œè®¡ç®—å¤±è´¥è¿”å›None
        """
        try:
            print(f"    å¼€å§‹è®¡ç®— EVENT_WINDOW çœŸå®çª—å£æ•°...")
            print(f"    æ—¶é—´èŒƒå›´: {target_first_ts} -> {source_last_ts}")
            
            # æ ¹æ®æµåç§°å’Œæºè¡¨ç±»å‹ç¡®å®šæŸ¥è¯¢è¡¨
            if 'event_tb' in stream_name:
                # event_tb æ¨¡å¼ï¼šä½¿ç”¨å•ä¸ªå­è¡¨
                query_table = "stream_from.ctb0_0"
                use_single_table = True
                print(f"    æ£€æµ‹åˆ° event_tb æ¨¡å¼ï¼Œä½¿ç”¨å•ä¸ªå­è¡¨: {query_table}")
            else:
                # event_stb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨è¶…çº§è¡¨
                # query_table = "stream_from.stb"
                # print(f"    æ£€æµ‹åˆ° event_stb æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨è¶…çº§è¡¨: {query_table}")
                query_table = "stream_from.ctb0_0"
                use_single_table = False
                print(f"    æ£€æµ‹åˆ° event_stb æ¨¡å¼ï¼Œä½†æ€§èƒ½ä¸å¥½ï¼Œä¸ä½¿ç”¨è¶…çº§è¡¨ï¼Œæ¢æˆå­è¡¨: {query_table}")
            
            # æ„å»º EVENT_WINDOW æŸ¥è¯¢SQL
            event_window_sql = f"""
            select count(*) from {query_table} 
            where ts >= '{target_first_ts}' and ts <= '{source_last_ts}' 
            EVENT_WINDOW START WITH c0 > 5 END WITH c0 < 5
            """
            
            print(f"    æ‰§è¡Œ EVENT_WINDOW æŸ¥è¯¢: {event_window_sql}")
            cursor.execute(event_window_sql)
            result = cursor.fetchall()
            
            if result:
                single_table_event_count = len(result)
                
                if use_single_table:
                    # event_tb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å•è¡¨ç»“æœ
                    event_count = single_table_event_count
                    print(f"    EVENT_WINDOW æŸ¥è¯¢ç»“æœ (event_tb): {event_count} ä¸ªçŠ¶æ€çª—å£")
                else:
                    # event_stb æ¨¡å¼ï¼šå•è¡¨ç»“æœä¹˜ä»¥å­è¡¨æ•°é‡
                    event_count = single_table_event_count * self.table_count
                    print(f"    EVENT_WINDOW æŸ¥è¯¢ç»“æœ (event_stb): å•è¡¨{single_table_event_count} Ã— å­è¡¨æ•°{self.table_count} = {event_count} ä¸ªçŠ¶æ€çª—å£")
                    print(f"    è¯´æ˜: å› è¶…çº§è¡¨æŸ¥è¯¢æ€§èƒ½é—®é¢˜ï¼Œä½¿ç”¨å•ä¸ªå­è¡¨é‡‡æ ·ç„¶åä¹˜ä»¥å­è¡¨æ•°é‡æ¥ä¼°ç®—æ€»æ•°")
                
                return event_count
            else:
                print(f"    EVENT_WINDOW æŸ¥è¯¢æ— ç»“æœ")
                return 0
                
        except Exception as e:
            print(f"    è®¡ç®— EVENT_WINDOW çœŸå®çª—å£æ•°æ—¶å‡ºé”™: {str(e)}")
            print(f"    è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None
        
    def _is_event_window_stream(self, stream_name, sql_type):
        """æ£€æŸ¥æ˜¯å¦ä¸º EVENT_WINDOW ç±»å‹çš„æµ
        
        Args:
            stream_name: æµåç§°
            sql_type: SQLç±»å‹
            
        Returns:
            bool: æ˜¯å¦ä¸º EVENT_WINDOW æµ
        """
        return ('event_' in stream_name.lower() or 
                'event_' in sql_type.lower() or
                'event_window' in stream_name.lower() or
                'event_window' in sql_type.lower())

    def _calculate_state_window_count(self, cursor, stream_name, target_first_ts, source_last_ts, source_type='stb'):
        """è®¡ç®— STATE_WINDOW çš„çœŸå®çª—å£æ•°é‡
        
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡
            stream_name: æµåç§°
            target_first_ts: ç›®æ ‡è¡¨é¦–æ¡è®°å½•æ—¶é—´
            source_last_ts: æºè¡¨æœ€æ–°è®°å½•æ—¶é—´
            source_type: æºè¡¨ç±»å‹ ('stb' æˆ– 'tb')
            
        Returns:
            int: çœŸå®çš„çŠ¶æ€çª—å£æ•°é‡ï¼Œè®¡ç®—å¤±è´¥è¿”å›None
        """
        try:
            print(f"    å¼€å§‹è®¡ç®— STATE_WINDOW çœŸå®çª—å£æ•°...")
            print(f"    æ—¶é—´èŒƒå›´: {target_first_ts} -> {source_last_ts}")
            
            # æ ¹æ®æµåç§°å’Œæºè¡¨ç±»å‹ç¡®å®šæŸ¥è¯¢è¡¨
            if 'state_tb' in stream_name:
                # state_tb æ¨¡å¼ï¼šä½¿ç”¨å•ä¸ªå­è¡¨
                query_table = "stream_from.ctb0_0"
                use_single_table = True
                print(f"    æ£€æµ‹åˆ° state_tb æ¨¡å¼ï¼Œä½¿ç”¨å•ä¸ªå­è¡¨: {query_table}")
            else:
                # state_stb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨è¶…çº§è¡¨
                # query_table = "stream_from.stb"
                # print(f"    æ£€æµ‹åˆ° state_stb æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨è¶…çº§è¡¨: {query_table}")
                query_table = "stream_from.ctb0_0"
                use_single_table = False
                print(f"    æ£€æµ‹åˆ° state_stb æ¨¡å¼ï¼Œä½†æ€§èƒ½ä¸å¥½ï¼Œä¸ä½¿ç”¨è¶…çº§è¡¨ï¼Œæ¢æˆå­è¡¨: {query_table}")
            
            # æ„å»º STATE_WINDOW æŸ¥è¯¢SQL
            state_window_sql = f"""
            select count(*) from {query_table} 
            where ts >= '{target_first_ts}' and ts <= '{source_last_ts}' 
            STATE_WINDOW(c0)
            """
            
            print(f"    æ‰§è¡Œ STATE_WINDOW æŸ¥è¯¢: {state_window_sql}")
            cursor.execute(state_window_sql)
            result = cursor.fetchall()
            
            if result:
                single_table_state_count = len(result)
            
                if use_single_table:
                    # state_tb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨å•è¡¨ç»“æœ
                    state_count = single_table_state_count
                    print(f"    STATE_WINDOW æŸ¥è¯¢ç»“æœ (state_tb): {state_count} ä¸ªçŠ¶æ€çª—å£")
                else:
                    # state_stb æ¨¡å¼ï¼šå•è¡¨ç»“æœä¹˜ä»¥å­è¡¨æ•°é‡
                    state_count = single_table_state_count * self.table_count
                    print(f"    STATE_WINDOW æŸ¥è¯¢ç»“æœ (state_stb): å•è¡¨{single_table_state_count} Ã— å­è¡¨æ•°{self.table_count} = {state_count} ä¸ªçŠ¶æ€çª—å£")
                    print(f"    è¯´æ˜: å› è¶…çº§è¡¨æŸ¥è¯¢æ€§èƒ½é—®é¢˜ï¼Œä½¿ç”¨å•ä¸ªå­è¡¨é‡‡æ ·ç„¶åä¹˜ä»¥å­è¡¨æ•°é‡æ¥ä¼°ç®—æ€»æ•°")
                
                return state_count
            else:
                print(f"    STATE_WINDOW æŸ¥è¯¢æ— ç»“æœ")
                return 0
                
        except Exception as e:
            print(f"    è®¡ç®— STATE_WINDOW çœŸå®çª—å£æ•°æ—¶å‡ºé”™: {str(e)}")
            print(f"    è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    def _is_state_window_stream(self, stream_name, sql_type):
        """æ£€æŸ¥æ˜¯å¦ä¸º STATE_WINDOW ç±»å‹çš„æµ
        
        Args:
            stream_name: æµåç§°
            sql_type: SQLç±»å‹
            
        Returns:
            bool: æ˜¯å¦ä¸º STATE_WINDOW æµ
        """
        return ('state_' in stream_name.lower() or 
                'state_' in sql_type.lower() or
                'state_window' in stream_name.lower() or
                'state_window' in sql_type.lower())

    def check_stream_computation_delay(self):
        """æ£€æŸ¥æµè®¡ç®—å»¶è¿Ÿ
        
        Returns:
            dict: å»¶è¿Ÿæ£€æŸ¥ç»“æœ
        """
        try:
            conn, cursor = self.get_connection()
            
            window_interval_display = "N/A"
            window_interval_method = "æœªåˆå§‹åŒ–"
            window_completion_ratio = None
            window_completion_percentage = None
            expected_windows = None
            actual_windows = None
            write_speed_per_second = None
        
            
            # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨
            try:
                cursor.execute("show databases")
                databases = cursor.fetchall()
                db_names = [db[0] for db in databases]
                #print(f"å‘ç°æ•°æ®åº“: {db_names}")
                
                if 'stream_from' not in db_names:
                    print("é”™è¯¯: æºæ•°æ®åº“ stream_from ä¸å­˜åœ¨")
                    cursor.close()
                    conn.close()
                    return None
            except Exception as e:
                print(f"æŸ¥è¯¢æ•°æ®åº“åˆ—è¡¨å¤±è´¥: {str(e)}")
                cursor.close()
                conn.close()
                return None
        
            # è·å–æºè¡¨æœ€æ–°æ—¶é—´æˆ³
            try:
                # æ ¹æ®æ˜¯å¦ä½¿ç”¨è™šæ‹Ÿè¡¨æ¥è®¾ç½®ä¸åŒçš„è¡¨å
                if self.use_virtual_table:
                    table_name = "stream_from.forvt_stb"
                else:
                    table_name = "stream_from.stb"
                
                cursor.execute(f"select last(ts) from {table_name}")
                source_result = cursor.fetchall()
                #print(f"æºè¡¨æŸ¥è¯¢ç»“æœ: {source_result}")
            except Exception as e:
                print(f"æŸ¥è¯¢æºè¡¨å¤±è´¥: {str(e)}")
                cursor.close()
                conn.close()
                return None
            
            if not source_result or not source_result[0][0]:
                print("è­¦å‘Š: æ— æ³•è·å–æºè¡¨æœ€æ–°æ—¶é—´æˆ³")
                cursor.close()
                conn.close()
                return None
                
            source_last_ts = source_result[0][0]
            source_ts_ms = int(source_last_ts.timestamp() * 1000)
            print(f"æºè¡¨æœ€æ–°æ—¶é—´æˆ³: {source_last_ts} ({source_ts_ms}ms)")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æµå­˜åœ¨
            
            streams_status_info = {}
            print("æŸ¥è¯¢æµçš„è¯¦ç»†ä¿¡æ¯...")
            try:
                cursor.execute("select stream_name, status, sql, create_time from information_schema.ins_streams")
                streams_info = cursor.fetchall()
                print(f"å‘ç° {len(streams_info)} ä¸ªæµ:")
                
                for stream in streams_info:
                    stream_name = stream[0]
                    stream_status = stream[1]
                    stream_sql = stream[2]
                    create_time = stream[3] if len(stream) > 3 else "æœªçŸ¥"
                    
                    streams_status_info[stream_name] = {
                        'status': stream_status,
                        'sql': stream_sql,
                        'create_time': create_time
                    }
                    
                    print(f"  æµåç§°: {stream_name}")
                    print(f"    çŠ¶æ€: {stream_status}")
                    print(f"    åˆ›å»ºæ—¶é—´: {create_time}")
                    #print(f"    SQL: {stream_sql[:100]}...")  # åªæ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
                    
            except Exception as e:
                print(f"æŸ¥è¯¢æµè¯¦ç»†ä¿¡æ¯å¤±è´¥: {str(e)}")
            
            # è·å–æµç›®æ ‡è¡¨
            target_tables = self.get_stream_target_tables()
            if not target_tables:
                print("è­¦å‘Š: æœªæ‰¾åˆ°æµç›®æ ‡è¡¨")
                cursor.close()
                conn.close()
                return None
            
            
            # âœ… æ–°å¢ï¼šè®¡ç®—å†™å…¥é€Ÿåº¦
            try:
                print(f"å¼€å§‹è®¡ç®—å†™å…¥é€Ÿåº¦...")
                
                # æ ¹æ®SQLç±»å‹åˆ¤æ–­æ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                is_period_type = (
                    'period_' in getattr(self, 'sql_type', '') or 
                    'period' in getattr(self, 'sql_type', '').lower()
                )
                
                if is_period_type:
                    # period ç±»å‹ç‰¹æ®Šå¤„ç†ï¼šåªæŸ¥è¯¢æœ€è¿‘2å¤©çš„æ•°æ®
                    print(f"æ£€æµ‹åˆ° period ç±»å‹æµï¼Œä½¿ç”¨æœ€è¿‘2å¤©æ•°æ®è®¡ç®—å†™å…¥é€Ÿåº¦")
                    
                    # è®¡ç®—2å¤©å‰çš„æ—¶é—´æˆ³
                    import datetime
                    two_days_ago = datetime.datetime.now() - datetime.timedelta(days=2)
                    two_days_ago_ts = two_days_ago.strftime('%Y-%m-%d %H:%M:%S')
                    
                    speed_sql = f"select first(ts), last(ts), count(*) from {table_name} where ts > '{two_days_ago_ts}'"
                    print(f"æ‰§è¡Œ period ç‰¹æ®ŠæŸ¥è¯¢: {speed_sql}")
                else:
                    # æ™®é€šç±»å‹ï¼šæŸ¥è¯¢å…¨éƒ¨æ•°æ®
                    speed_sql = f"select first(ts), last(ts), count(*) from {table_name}"
                    print(f"æ‰§è¡Œæ™®é€šæŸ¥è¯¢: {speed_sql}")
                
                cursor.execute(speed_sql)
                speed_result = cursor.fetchall()
                
                if speed_result and speed_result[0][0] and speed_result[0][1] and speed_result[0][2]:
                    first_ts = speed_result[0][0]
                    last_ts = speed_result[0][1] 
                    total_count = speed_result[0][2]
                    
                    # è®¡ç®—æ—¶é—´è·¨åº¦ï¼ˆç§’ï¼‰
                    time_span_seconds = (last_ts - first_ts).total_seconds()
                    
                    if time_span_seconds > 0:
                        write_speed_per_second = total_count / time_span_seconds
                        print(f"å†™å…¥é€Ÿåº¦è®¡ç®—æˆåŠŸ:")
                        print(f"  æ—¶é—´èŒƒå›´: {first_ts} -> {last_ts}")
                        print(f"  æ—¶é—´è·¨åº¦: {time_span_seconds:.1f}ç§’")
                        print(f"  æ€»è®°å½•æ•°: {total_count:,}")
                        print(f"  å†™å…¥é€Ÿåº¦: {write_speed_per_second:.2f} æ¡/ç§’")
                        
                        if is_period_type:
                            print(f"  æ³¨æ„: period ç±»å‹ä½¿ç”¨æœ€è¿‘2å¤©æ•°æ®è®¡ç®—")
                    else:
                        print(f"æ—¶é—´è·¨åº¦ä¸º0ï¼Œæ— æ³•è®¡ç®—å†™å…¥é€Ÿåº¦")
                        write_speed_per_second = None
                else:
                    print(f"å†™å…¥é€Ÿåº¦æŸ¥è¯¢æ— æœ‰æ•ˆç»“æœ")
                    write_speed_per_second = None
                    
            except Exception as e:
                print(f"è®¡ç®—å†™å…¥é€Ÿåº¦å¤±è´¥: {str(e)}")
                write_speed_per_second = None
                
            
            delay_results = {
                'check_time': time.strftime('%Y-%m-%d %H:%M:%S'),
                'source_last_ts': source_last_ts,
                'source_ts_ms': source_ts_ms,
                'write_speed_per_second': write_speed_per_second, 
                'streams': [],
                'dynamic_threshold_info': {}  # æ–°å¢ï¼šå­˜å‚¨åŠ¨æ€é˜ˆå€¼ä¿¡æ¯
            }
            
            # æ£€æŸ¥æ¯ä¸ªæµçš„å»¶è¿Ÿ
            for table_info in target_tables:
                try:
                    target_table = table_info['target_table']
                    stream_name = table_info['stream_name']
                    
                    
                    window_interval_display = "N/A"
                    window_interval_method = "æœªåˆå§‹åŒ–"
                    window_completion_ratio = None
                    window_completion_percentage = None
                    expected_windows = None
                    actual_windows = None
                    
                    # âœ… æ–°å¢ï¼šè·å–æµçŠ¶æ€ä¿¡æ¯
                    stream_status_info = streams_status_info.get(stream_name, {})
                    stream_status = stream_status_info.get('status', 'æœªçŸ¥')
                    stream_create_time = stream_status_info.get('create_time', 'æœªçŸ¥')
                    
                    print(f"æ£€æŸ¥æµ {stream_name} (çŠ¶æ€: {stream_status}) çš„ç›®æ ‡è¡¨ {target_table}")
                    
                    # å…ˆæ£€æŸ¥ç›®æ ‡è¡¨æ˜¯å¦å­˜åœ¨
                    try:
                        cursor.execute(f"describe {target_table}")
                        #print(f"ç›®æ ‡è¡¨ {target_table} ç»“æ„æ­£å¸¸")
                    except Exception as e:
                        print(f"ç›®æ ‡è¡¨ {target_table} ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®")
                        
                        stream_result = {
                            'stream_name': stream_name,
                            'target_table': target_table,
                            'error': f"ç›®æ ‡è¡¨ä¸å­˜åœ¨: {str(e)}",
                            'status': 'ERROR',
                            'stream_status': stream_status,
                            'stream_create_time': stream_create_time,
                            'window_completion_ratio': None,
                            'window_completion_percentage': None,
                            'dynamic_threshold_ms': None,
                            'window_interval_display': window_interval_display,
                            'window_interval_method': window_interval_method,
                            'write_speed_per_second': write_speed_per_second 
                        }
                        delay_results['streams'].append(stream_result)
                        continue
                    
                    # âœ… æ–°å¢ï¼šåŠ¨æ€è®¡ç®—è¯¥æµçš„çª—å£é—´éš”ä½œä¸ºå»¶è¿Ÿåˆ¤æ–­åŸºå‡†
                    dynamic_threshold_ms = self.max_delay_threshold
                    
                    # å°è¯•åŠ¨æ€è®¡ç®—çª—å£é—´éš”
                    try:
                        window_interval_ms = self._get_dynamic_window_interval(cursor, target_table)
                        if window_interval_ms and window_interval_ms > 0:
                            dynamic_threshold_ms = window_interval_ms
                            window_interval_display = f"{window_interval_ms}ms"
                            window_interval_method = "é€šç”¨åŠ¨æ€è®¡ç®—"
                        else:
                            dynamic_threshold_ms = self.max_delay_threshold
                            window_interval_display = "50000ms"
                            window_interval_method = "é»˜è®¤å€¼"
                        print(f"  çª—å£é—´éš”è®¡ç®—: {window_interval_display} | æ–¹æ³•: {window_interval_method}")
                    except Exception as e:
                        print(f"è®¡ç®—åŠ¨æ€é˜ˆå€¼å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {str(e)}")
                        dynamic_threshold_ms = self.max_delay_threshold
                        window_interval_display = "50000ms"
                        window_interval_method = "è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼"
                    
                    # å­˜å‚¨åŠ¨æ€é˜ˆå€¼ä¿¡æ¯
                    delay_results['dynamic_threshold_info'][stream_name] = {
                        'threshold_ms': dynamic_threshold_ms,
                        'threshold_seconds': dynamic_threshold_ms / 1000.0,
                        'calculation_method': 'åŸºäºç›®æ ‡è¡¨æ—¶é—´é—´éš”åŠ¨æ€è®¡ç®—'
                    }
                    
                    print(f"  æµ {stream_name} åŠ¨æ€é˜ˆå€¼: {dynamic_threshold_ms}ms ({dynamic_threshold_ms/1000:.1f}ç§’)")
                                    
                    # æŸ¥è¯¢ç›®æ ‡è¡¨æœ€æ–°æ—¶é—´æˆ³
                    cursor.execute(f"select last(ts) from {target_table}")
                    target_result = cursor.fetchall()
                    #print(f"ç›®æ ‡è¡¨ {target_table} æŸ¥è¯¢ç»“æœ: {target_result}")
                    
                    # âœ… æ–°å¢ï¼šè®¡ç®—çª—å£ç”Ÿæˆæ¯”ä¾‹
                    window_completion_ratio = None
                    window_completion_percentage = None
                    expected_windows = None  
                    actual_windows = None 
                    
                    if target_result and target_result[0][0]:
                        target_last_ts = target_result[0][0]
                        target_ts_ms = int(target_last_ts.timestamp() * 1000)
                        
                        # è®¡ç®—å»¶è¿Ÿ(æ¯«ç§’)
                        delay_ms = source_ts_ms - target_ts_ms
                        
                        
                        # âœ… è®¡ç®—çª—å£ç”Ÿæˆæ¯”ä¾‹
                        try:
                            # æŸ¥è¯¢ç›®æ ‡è¡¨çš„æœ€æ—©æ—¶é—´æˆ³
                            print(f"æ‰§è¡ŒæŸ¥è¯¢: select first(ts), last(ts), count(*) from {target_table}")
                            cursor.execute(f"select first(ts), last(ts), count(*) from {target_table}")
                            target_stats_result = cursor.fetchall()
                            
                            if target_stats_result and target_stats_result[0][0]:
                                target_first_ts = target_stats_result[0][0]
                                target_last_ts_verify = target_stats_result[0][1]  
                                target_record_count = target_stats_result[0][2]
                                 
                                print(f"ç›®æ ‡è¡¨ç»Ÿè®¡:")
                                print(f"  é¦–æ¡è®°å½•æ—¶é—´: {target_first_ts}")
                                print(f"  æœ«æ¡è®°å½•æ—¶é—´: {target_last_ts_verify}")
                                print(f"  æ€»è®°å½•æ•°: {target_record_count}")
                                
                                # âœ… æ–°å¢ï¼šæ£€æŸ¥ç›®æ ‡æ•°æ®åº“çš„è¶…çº§è¡¨ç»“æ„
                                print(f"æ£€æŸ¥ç›®æ ‡æ•°æ®åº“çš„è¡¨ç»“æ„...")
                                cursor.execute("show stream_to.stables")
                                stables_result = cursor.fetchall()
                                stable_count = len(stables_result)
                                
                                print(f"ç›®æ ‡æ•°æ®åº“è¶…çº§è¡¨æ•°é‡: {stable_count}")
                                
                                # âœ… æ ¹æ®è¡¨ç»“æ„ç¡®å®šå®é™…çª—å£æ•°çš„è®¡ç®—æ–¹å¼
                                if stable_count > 0:
                                    print(f"æ£€æµ‹åˆ°åˆ†ç»„æµæ¨¡å¼ (partition by tbname)")
                                    expected_child_table_count = self.table_count 
                                    
                                    # æŸ¥è¯¢å­è¡¨æ•°é‡æ¥ç¡®å®šåˆ†ç»„æ•°
                                    cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                                    actual_child_table_result = cursor.fetchall() 
                                    actual_child_table_count = actual_child_table_result[0][0] if actual_child_table_result and len(actual_child_table_result) > 0 else 0
    
                                    print(f"é…ç½®å­è¡¨æ•°é‡: {expected_child_table_count} (--table-countå‚æ•°)")
                                    print(f"å®é™…å­è¡¨æ•°é‡: {actual_child_table_count} (æ•°æ®åº“ä¸­å®é™…ç”Ÿæˆ)")
                                    
                                    if expected_child_table_count > 0:
                                        # ä½¿ç”¨å‘ä¸Šå–æ•´çš„é€»è¾‘ï¼Œç¡®ä¿æœ‰æ•°æ®å°±è‡³å°‘ç®—1ä¸ªçª—å£
                                        import math
                                        actual_windows = math.ceil(target_record_count / expected_child_table_count)
                                        
                                        # ç¡®ä¿æœ€å°å€¼ä¸º1ï¼ˆå¦‚æœæœ‰ä»»ä½•æ•°æ®çš„è¯ï¼‰
                                        if target_record_count > 0 and actual_windows == 0:
                                            actual_windows = 1
                                            
                                        print(f"åˆ†ç»„æµè®¡ç®—: æ€»è®°å½•æ•°({target_record_count}) Ã· é…ç½®å­è¡¨æ•°({expected_child_table_count}) = {target_record_count / expected_child_table_count:.2f}")
                                        print(f"å‘ä¸Šå–æ•´ç»“æœ: {actual_windows} (æ¯ä¸ªå­è¡¨å¹³å‡ {target_record_count / expected_child_table_count:.2f} ä¸ªçª—å£)")
                                        
                                        # æä¾›æ›´è¯¦ç»†çš„è§£é‡Š
                                        if actual_windows == 1 and target_record_count < expected_child_table_count:
                                            print(f"è¯´æ˜: æµè®¡ç®—åˆšå¼€å§‹ï¼Œå¤§éƒ¨åˆ†å­è¡¨å°šæœªç”Ÿæˆæ•°æ®ï¼ŒæŒ‰1ä¸ªçª—å£è®¡ç®—ï¼ˆå‘ä¸Šå–æ•´ä¿è¯æœ‰æ•°æ®å°±ç®—çª—å£ï¼‰")
                                        elif actual_windows > 1:
                                            print(f"è¯´æ˜: æµè®¡ç®—è¿›å±•è‰¯å¥½ï¼Œå¹³å‡æ¯ä¸ªå­è¡¨å·²ç”Ÿæˆçº¦ {actual_windows} ä¸ªçª—å£ï¼ˆå‘ä¸Šå–æ•´ä¿è¯æœ‰æ•°æ®å°±ç®—çª—å£ï¼‰")
                                            
                                    else:
                                        print(f"è­¦å‘Š: é…ç½®çš„table_countä¸º0ï¼Œä½¿ç”¨å®é™…å­è¡¨æ•°é‡ä¼°ç®—")
                                        cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                                        fallback_table_result = cursor.fetchall()
                                        fallback_table_count = fallback_table_result[0][0] if fallback_table_result and len(fallback_table_result) > 0 else 1
                                        
                                        import math
                                        actual_windows = math.ceil(target_record_count / fallback_table_count)
                                        if target_record_count > 0 and actual_windows == 0:
                                            actual_windows = 1
                                            
                                        print(f"åå¤‡è®¡ç®—: æ€»è®°å½•æ•°({target_record_count}) Ã· å®é™…å­è¡¨æ•°({fallback_table_count}) = {actual_windows}")
                                else:
                                    # æ²¡æœ‰è¶…çº§è¡¨ï¼Œè¯´æ˜æ˜¯éåˆ†ç»„æµï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°
                                    actual_windows = target_record_count
                                    print(f"æ£€æµ‹åˆ°éåˆ†ç»„æµæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°: {actual_windows}")
                            
                            else:
                                print(f"ç›®æ ‡è¡¨ {target_table} ç»Ÿè®¡æŸ¥è¯¢å¤±è´¥ï¼Œè·³è¿‡çª—å£è®¡ç®—")
                                target_first_ts = None
                                target_record_count = 0
                            
                            # æŸ¥è¯¢æºè¡¨çš„ç»Ÿè®¡ä¿¡æ¯
                            print(f"æ‰§è¡ŒæŸ¥è¯¢: select first(ts), last(ts), count(*) from stream_from.stb")
                            cursor.execute("select first(ts), last(ts), count(*) from stream_from.stb")
                            source_stats_result = cursor.fetchall()   
                            
                            if source_stats_result and source_stats_result[0][0]:
                                source_first_ts = source_stats_result[0][0]
                                source_last_ts_verify = source_stats_result[0][1]
                                source_record_count = source_stats_result[0][2]
                                
                                print(f"æºè¡¨ç»Ÿè®¡:")
                                print(f"  é¦–æ¡è®°å½•æ—¶é—´: {source_first_ts}")
                                print(f"  æœ«æ¡è®°å½•æ—¶é—´: {source_last_ts_verify}")
                                print(f"  æ€»è®°å½•æ•°: {source_record_count}")
                            else:
                                print(f"æºè¡¨ç»Ÿè®¡æŸ¥è¯¢å¤±è´¥ï¼Œè·³è¿‡çª—å£è®¡ç®—")
                                source_first_ts = None
                                source_record_count = 0
                            
                            if (target_first_ts and source_first_ts and 
                                target_record_count > 0 and source_record_count > 0):
                                
                                # åŸºäºæ—¶é—´è·¨åº¦æ¯”ä¾‹
                                #source_duration_ms = int((source_last_ts_verify - source_first_ts).total_seconds() * 1000)
                                source_duration_ms = int((source_last_ts_verify - target_first_ts).total_seconds() * 1000)
                                target_duration_ms = int((target_last_ts_verify - target_first_ts).total_seconds() * 1000)
                                
                                print(f"æ—¶é—´è·¨åº¦å¯¹æ¯”:")
                                print(f"  æºè¡¨æ—¶é—´è·¨åº¦ã€æºè¡¨çš„last(Ts)-ç›®æ ‡è¡¨çš„first(Ts)ã€‘: {source_duration_ms}ms ({source_duration_ms/1000:.1f}ç§’)")
                                print(f"  ç›®æ ‡è¡¨æ—¶é—´è·¨åº¦ã€ç›®æ ‡è¡¨çš„last(Ts)-ç›®æ ‡è¡¨çš„first(Ts)ã€‘: {target_duration_ms}ms ({target_duration_ms/1000:.1f}ç§’)")
                                
                                if source_duration_ms > 0:
                                    duration_ratio = (target_duration_ms / source_duration_ms) * 100
                                    print(f"æ—¶é—´è·¨åº¦æ¯”ä¾‹: {target_duration_ms}/{source_duration_ms} = {duration_ratio:.2f}%")
                                else:
                                    duration_ratio = 0
                                    print(f"æºè¡¨æ—¶é—´è·¨åº¦ä¸º0ï¼Œæ— æ³•è®¡ç®—æ—¶é—´æ¯”ä¾‹")
                                
                                # âœ… åŸºäºçª—å£ç”Ÿæˆç†è®ºè®¡ç®—
                                # å‡è®¾15ç§’ä¸€ä¸ªçª—å£ï¼Œè®¡ç®—ç†è®ºåº”è¯¥ç”Ÿæˆå¤šå°‘ä¸ªçª—å£
                                # window_interval_ms = 15 * 1000  # 15ç§’çª—å£
                                window_interval_ms = self._get_dynamic_window_interval(cursor, target_table)
                                print(f"çª—å£é—´éš”æ£€æµ‹ç»“æœ: {window_interval_ms}ms ({window_interval_ms/1000:.1f}ç§’)")
                            
                                
                                if source_duration_ms > 0:
                                                                    
                                    # æ£€æŸ¥æ˜¯å¦ä¸ºæŒ‰ tag åˆ†ç»„çš„æµè®¡ç®—
                                    is_tag_partition = False
                                    tag_group_count = None
                                    
                                    # åˆ¤æ–­æ˜¯å¦ä¸ºæŒ‰ tag åˆ†ç»„ï¼ˆé€šè¿‡æµåç§°æˆ–SQLç±»å‹åˆ¤æ–­ï¼‰
                                    if ('partition_by_tag' in stream_name or 
                                        'partition_by_tag' in self.sql_type or
                                        (hasattr(self, 'tbname_or_trows_or_sourcetable') and 
                                        'tag' in getattr(self, 'tbname_or_trows_or_sourcetable', ''))):
                                        
                                        is_tag_partition = True
                                        print(f"  æ£€æµ‹åˆ°æŒ‰ tag åˆ†ç»„çš„æµè®¡ç®—ï¼Œè®¡ç®—å®é™…åˆ†ç»„æ•°...")
                                        
                                        # è·å–å®é™…çš„ tag åˆ†ç»„æ•°é‡
                                        try:
                                            cursor.execute("select distinct t0 from stream_from.stb")
                                            tag_results = cursor.fetchall()
                                            tag_group_count = len(tag_results) if tag_results else 1
                                            print(f"  å®é™… tag åˆ†ç»„æ•°: {tag_group_count} (é€šè¿‡ select distinct t0 from stream_from.stb è·å–)")
                                            
                                            # æ˜¾ç¤ºå‰å‡ ä¸ª tag å€¼ä½œä¸ºå‚è€ƒ
                                            if tag_results and len(tag_results) > 0:
                                                sample_tags = [str(row[0]) for row in tag_results[:5]]
                                                if len(tag_results) > 5:
                                                    sample_tags.append(f"...è¿˜æœ‰{len(tag_results)-5}ä¸ª")
                                                print(f"  tag å€¼ç¤ºä¾‹: {', '.join(sample_tags)}")
                                                
                                        except Exception as e:
                                            print(f"  è·å– tag åˆ†ç»„æ•°å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                                            tag_group_count = self.table_count  # å›é€€åˆ°é…ç½®çš„å­è¡¨æ•°
                                            is_tag_partition = False
                                    
                                    
                                    # æ ¹æ®åˆ†ç»„ç±»å‹è®¡ç®—ç†è®ºçª—å£æ•°
                                    if is_tag_partition and tag_group_count:
                                        # æŒ‰ tag åˆ†ç»„ï¼šä½¿ç”¨å®é™… tag åˆ†ç»„æ•°
                                        effective_group_count = tag_group_count
                                        expected_windows = max(1, int(source_duration_ms / window_interval_ms))
                                        print(f"  ç†è®ºçª—å£æ•°: {expected_windows} (åŸºäºæºè¡¨æ—¶é—´è·¨åº¦{source_duration_ms}ms)")
                                        print(f"  åˆ†ç»„æ–¹å¼: æŒ‰ tag åˆ†ç»„ï¼Œå®é™…åˆ†ç»„æ•° {effective_group_count}")
                                                                                
                                        # æŒ‰ tag åˆ†ç»„æ—¶ï¼Œå®é™…çª—å£æ•°åº”è¯¥åŸºäº tag åˆ†ç»„æ•°è®¡ç®—
                                        if stable_count > 0:
                                            print(f"æ£€æµ‹åˆ°åˆ†ç»„æµæ¨¡å¼ (partition by tag)")
                                            
                                            # ä½¿ç”¨å®é™… tag åˆ†ç»„æ•°æ¥è®¡ç®—æ¯ç»„å¹³å‡çª—å£æ•°
                                            actual_windows = math.ceil(target_record_count / tag_group_count)
                                            
                                            # ç¡®ä¿æœ€å°å€¼ä¸º1ï¼ˆå¦‚æœæœ‰ä»»ä½•æ•°æ®çš„è¯ï¼‰
                                            if target_record_count > 0 and actual_windows == 0:
                                                actual_windows = 1
                                                
                                            print(f"æŒ‰ tag åˆ†ç»„è®¡ç®—: æ€»è®°å½•æ•°({target_record_count}) Ã· å®é™…tagåˆ†ç»„æ•°({tag_group_count}) = {target_record_count / tag_group_count:.2f}")
                                            print(f"å‘ä¸Šå–æ•´ç»“æœ: {actual_windows} (æ¯ä¸ªtagåˆ†ç»„å¹³å‡ {target_record_count / tag_group_count:.2f} ä¸ªçª—å£)")
                                            
                                            # æä¾›æ›´è¯¦ç»†çš„è§£é‡Š
                                            if actual_windows == 1 and target_record_count < tag_group_count:
                                                print(f"è¯´æ˜: æµè®¡ç®—åˆšå¼€å§‹ï¼Œå¤§éƒ¨åˆ†tagåˆ†ç»„å°šæœªç”Ÿæˆæ•°æ®ï¼ŒæŒ‰1ä¸ªçª—å£è®¡ç®—")
                                            elif actual_windows > 1:
                                                print(f"è¯´æ˜: æµè®¡ç®—è¿›å±•è‰¯å¥½ï¼Œå¹³å‡æ¯ä¸ªtagåˆ†ç»„å·²ç”Ÿæˆçº¦ {actual_windows} ä¸ªçª—å£")
                                        else:
                                            # æ²¡æœ‰è¶…çº§è¡¨ï¼Œè¯´æ˜æ˜¯éåˆ†ç»„æµï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°
                                            actual_windows = target_record_count
                                            print(f"æ£€æµ‹åˆ°éåˆ†ç»„æµæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°: {actual_windows}")
            
                                    else:
                                        # æŒ‰å­è¡¨ååˆ†ç»„æˆ–æ— åˆ†ç»„ï¼šä½¿ç”¨é…ç½®çš„å­è¡¨æ•°
                                        effective_group_count = self.table_count
                                        expected_windows = max(1, int(source_duration_ms / window_interval_ms))
                                        print(f"  ç†è®ºçª—å£æ•°: {expected_windows} (åŸºäºæºè¡¨æ—¶é—´è·¨åº¦{source_duration_ms}ms)")
                                        print(f"  åˆ†ç»„æ–¹å¼: æŒ‰å­è¡¨ååˆ†ç»„æˆ–æ— åˆ†ç»„ï¼Œé…ç½®å­è¡¨æ•° {effective_group_count}")
                                        
                                        
                                        # âœ… ç‰¹æ®Šå¤„ç†ï¼šEVENT_WINDOW çª—å£çš„çœŸå®çª—å£æ•°è®¡ç®—
                                        if self._is_event_window_stream(stream_name, self.sql_type):
                                            print(f"  æ£€æµ‹åˆ° EVENT_WINDOW æµï¼Œä½¿ç”¨çœŸå®çª—å£è®¡ç®—æ–¹æ³•...")
                                            
                                            try:
                                                # è·å–ç›®æ ‡è¡¨çš„é¦–æ¡è®°å½•æ—¶é—´å’Œæºè¡¨çš„æœ€æ–°æ—¶é—´
                                                if target_first_ts and source_last_ts_verify:
                                                    # åŸºäºã€æºè¡¨çš„last(Ts)-ç›®æ ‡è¡¨çš„first(Ts)ã€‘Ã· ç†è®ºçª—å£æ•°
                                                    source_duration_ms = int((source_last_ts_verify - target_first_ts).total_seconds() * 1000)
                                                    
                                                    print(f"    EVENT_WINDOW åŠ¨æ€é—´éš”è®¡ç®—:")
                                                    print(f"      æ—¶é—´è·¨åº¦ã€æºè¡¨last(Ts) - ç›®æ ‡è¡¨first(Ts)ã€‘: {source_duration_ms}ms ({source_duration_ms/1000:.1f}ç§’)")
                                                    
                                                    # é€šè¿‡å®é™…çš„äº‹ä»¶çª—å£æŸ¥è¯¢è·å–çœŸå®çª—å£æ•°
                                                    event_window_count = self._calculate_event_window_count(
                                                        cursor, stream_name, target_first_ts, source_last_ts_verify
                                                    )
                                                    
                                                    if event_window_count is not None:
                                                        # è·å–å•è¡¨çª—å£æ•°
                                                        if 'event_tb' in stream_name:
                                                            # event_tb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨æŸ¥è¯¢ç»“æœ
                                                            single_table_event_count = event_window_count
                                                        else:
                                                            # event_stb æ¨¡å¼ï¼šæ€»æ•°é™¤ä»¥å­è¡¨æ•°å¾—åˆ°å•è¡¨æ•°
                                                            single_table_event_count = event_window_count // self.table_count
                                                        
                                                        # âœ… ä½¿ç”¨å•è¡¨çª—å£æ•°è®¡ç®—åŠ¨æ€é—´éš”
                                                        if single_table_event_count > 0:
                                                            dynamic_interval_ms = source_duration_ms / single_table_event_count
                                                        else:
                                                            dynamic_interval_ms = source_duration_ms  # å¦‚æœæ²¡æœ‰çª—å£ï¼Œé—´éš”ç­‰äºæ€»æ—¶é—´
                                                        
                                                        print(f"      å•è¡¨äº‹ä»¶çª—å£æ•°: {single_table_event_count}")
                                                        print(f"      åŠ¨æ€è®¡ç®—é—´éš”: {source_duration_ms}ms Ã· {single_table_event_count} = {dynamic_interval_ms:.2f}ms ({dynamic_interval_ms/1000:.1f}ç§’)")
                                                        
                                                        window_interval_display = f"{dynamic_interval_ms:.0f}ms"
                                                        window_interval_method = "EVENT_WINDOWåŠ¨æ€è®¡ç®—"
                                                        # âœ… åŒæ—¶æ›´æ–°åŠ¨æ€é˜ˆå€¼ä¸ºæ–°è®¡ç®—å‡ºçš„é—´éš”
                                                        dynamic_threshold_ms = int(dynamic_interval_ms)
                                                        print(f"âœ… EVENT_WINDOW è®¾ç½®å®Œæˆ: window_interval_display = {window_interval_display}")
                                                        
                                                        if 'event_stb_partition_by_tbname' in stream_name:
                                                            # event_stb_partition_by_tbname: æ¯ä¸ªå­è¡¨çš„ç†è®ºçª—å£æ•°
                                                            expected_windows_per_table = math.ceil(event_window_count / self.table_count)
                                                            expected_windows = expected_windows_per_table
                                                            print(f"EVENT_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tbname): æ€»äº‹ä»¶çª—å£æ•°({event_window_count}) Ã· å­è¡¨æ•°({self.table_count}) = {expected_windows} ä¸ª/å­è¡¨")
                                                        elif 'event_stb_partition_by_tag' in stream_name:
                                                            # event_stb_partition_by_tag: æ¯ä¸ªtagåˆ†ç»„çš„ç†è®ºçª—å£æ•°
                                                            if tag_group_count:
                                                                expected_windows_per_tag = math.ceil(event_window_count / tag_group_count)
                                                                expected_windows = expected_windows_per_tag
                                                                print(f"EVENT_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tag): æ€»äº‹ä»¶çª—å£æ•°({event_window_count}) Ã· tagåˆ†ç»„æ•°({tag_group_count}) = {expected_windows} ä¸ª/tagåˆ†ç»„")
                                                            else:
                                                                expected_windows = event_window_count
                                                                print(f"EVENT_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tagï¼Œtagåˆ†ç»„æ•°æœªçŸ¥): ç›´æ¥ä½¿ç”¨æ€»äº‹ä»¶çª—å£æ•° = {expected_windows}")
                                                        elif 'event_stb' in stream_name:
                                                            # event_stb: ä¸åˆ†ç»„ï¼Œç›´æ¥ä½¿ç”¨æ€»æ•°
                                                            expected_windows = event_window_count
                                                            print(f"EVENT_WINDOW ç†è®ºè®¡ç®— (stb ä¸åˆ†ç»„): ç›´æ¥ä½¿ç”¨æ€»äº‹ä»¶çª—å£æ•° = {expected_windows}")
                                                        else:
                                                            # event_tb: å•è¡¨æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨è®¡ç®—ç»“æœ
                                                            expected_windows = event_window_count
                                                            print(f"EVENT_WINDOW ç†è®ºè®¡ç®— (tb): ç›´æ¥ä½¿ç”¨äº‹ä»¶çª—å£æ•° = {expected_windows}")
                    
                                                        
                                                        print(f"EVENT_WINDOW ç‰¹æ®Šå¤„ç†å®Œæˆ:")
                                                        print(f"  ç†è®ºçª—å£æ•° (expected_windows): {expected_windows}")
                                                        print(f"  å®é™…ç”Ÿæˆè®°å½•æ•° (actual_windows): {actual_windows}")
                                                        print(f"  è¯´æ˜: EVENT_WINDOW åŸºäºæ•°æ®æ¡ä»¶è§¦å‘ï¼Œç†è®ºçª—å£æ•°é€šè¿‡äº‹ä»¶æ¡ä»¶SQLè®¡ç®—")
                                                    
                                                        
                                                    else:
                                                        print(f"  EVENT_WINDOW çœŸå®çª—å£è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                        window_interval_display = "è®¡ç®—å‡ºé”™"
                                                        window_interval_method = "é»˜è®¤é€»è¾‘"
                                                else:
                                                    print(f"  EVENT_WINDOW ç¼ºå°‘å¿…è¦æ—¶é—´ä¿¡æ¯ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                    window_interval_display = "è®¡ç®—å‡ºé”™"
                                                    window_interval_method = "é»˜è®¤é€»è¾‘"
                                                    
                                            except Exception as e:
                                                print(f"  EVENT_WINDOW çœŸå®çª—å£è®¡ç®—å‡ºé”™: {str(e)}ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                # window_interval_display = "è®¡ç®—å‡ºé”™"
                                                # window_interval_method = "é»˜è®¤é€»è¾‘"
                                                
                                        # âœ… æ–°å¢ï¼šç‰¹æ®Šå¤„ç† STATE_WINDOW çª—å£çš„çœŸå®çª—å£æ•°è®¡ç®—
                                        elif self._is_state_window_stream(stream_name, self.sql_type):
                                            print(f"  æ£€æµ‹åˆ° STATE_WINDOW æµï¼Œä½¿ç”¨çœŸå®çª—å£è®¡ç®—æ–¹æ³•...")
                                            
                                            try:
                                                # è·å–ç›®æ ‡è¡¨çš„é¦–æ¡è®°å½•æ—¶é—´å’Œæºè¡¨çš„æœ€æ–°æ—¶é—´
                                                if target_first_ts and source_last_ts_verify:
                                                    # åŸºäºã€æºè¡¨çš„last(Ts)-ç›®æ ‡è¡¨çš„first(Ts)ã€‘Ã· ç†è®ºçª—å£æ•°
                                                    source_duration_ms = int((source_last_ts_verify - target_first_ts).total_seconds() * 1000)
                                                    
                                                    print(f"    STATE_WINDOW åŠ¨æ€é—´éš”è®¡ç®—:")
                                                    print(f"      æ—¶é—´è·¨åº¦ã€æºè¡¨last(Ts) - ç›®æ ‡è¡¨first(Ts)ã€‘: {source_duration_ms}ms ({source_duration_ms/1000:.1f}ç§’)")
                                                    
                                                    # é€šè¿‡å®é™…çš„çŠ¶æ€çª—å£æŸ¥è¯¢è·å–çœŸå®çª—å£æ•°
                                                    state_window_count = self._calculate_state_window_count(
                                                        cursor, stream_name, target_first_ts, source_last_ts_verify
                                                    )
                                                    
                                                    if state_window_count is not None:
                                                        # è·å–å•è¡¨çª—å£æ•°
                                                        if 'state_tb' in stream_name:
                                                            # state_tb æ¨¡å¼ï¼šç›´æ¥ä½¿ç”¨æŸ¥è¯¢ç»“æœ
                                                            single_table_state_count = state_window_count
                                                        else:
                                                            # state_stb æ¨¡å¼ï¼šæ€»æ•°é™¤ä»¥å­è¡¨æ•°å¾—åˆ°å•è¡¨æ•°
                                                            single_table_state_count = state_window_count // self.table_count
                                                        
                                                        # âœ… ä½¿ç”¨å•è¡¨çª—å£æ•°è®¡ç®—åŠ¨æ€é—´éš”
                                                        if single_table_state_count > 0:
                                                            dynamic_interval_ms = source_duration_ms / single_table_state_count
                                                        else:
                                                            dynamic_interval_ms = source_duration_ms  # å¦‚æœæ²¡æœ‰çª—å£ï¼Œé—´éš”ç­‰äºæ€»æ—¶é—´
                                                        
                                                        print(f"      å•è¡¨çŠ¶æ€çª—å£æ•°: {single_table_state_count}")
                                                        print(f"      åŠ¨æ€è®¡ç®—é—´éš”: {source_duration_ms}ms Ã· {single_table_state_count} = {dynamic_interval_ms:.2f}ms ({dynamic_interval_ms/1000:.1f}ç§’)")
                                                        window_interval_display = f"{dynamic_interval_ms:.0f}ms"
                                                        window_interval_method = "STATE_WINDOWåŠ¨æ€è®¡ç®—"
                                                        # âœ… åŒæ—¶æ›´æ–°åŠ¨æ€é˜ˆå€¼ä¸ºæ–°è®¡ç®—å‡ºçš„é—´éš”
                                                        dynamic_threshold_ms = int(dynamic_interval_ms)
                                                        print(f"âœ… STATE_WINDOW è®¾ç½®å®Œæˆ: window_interval_display = {window_interval_display}")
                                                        
                                                        if 'state_stb_partition_by_tbname' in stream_name:
                                                            # state_stb_partition_by_tbname: æ¯ä¸ªå­è¡¨çš„ç†è®ºçª—å£æ•°
                                                            expected_windows_per_table = math.ceil(state_window_count / self.table_count)
                                                            expected_windows = expected_windows_per_table
                                                            print(f"STATE_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tbname): æ€»çŠ¶æ€çª—å£æ•°({state_window_count}) Ã· å­è¡¨æ•°({self.table_count}) = {expected_windows} ä¸ª/å­è¡¨")
                                                        elif 'state_stb_partition_by_tag' in stream_name:
                                                            # state_stb_partition_by_tag: æ¯ä¸ªtagåˆ†ç»„çš„ç†è®ºçª—å£æ•°
                                                            if tag_group_count:
                                                                expected_windows_per_tag = math.ceil(state_window_count / tag_group_count)
                                                                expected_windows = expected_windows_per_tag
                                                                print(f"STATE_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tag): æ€»çŠ¶æ€çª—å£æ•°({state_window_count}) Ã· tagåˆ†ç»„æ•°({tag_group_count}) = {expected_windows} ä¸ª/tagåˆ†ç»„")
                                                            else:
                                                                expected_windows = state_window_count
                                                                print(f"STATE_WINDOW ç†è®ºè®¡ç®— (stb + partition_by_tagï¼Œtagåˆ†ç»„æ•°æœªçŸ¥): ç›´æ¥ä½¿ç”¨æ€»çŠ¶æ€çª—å£æ•° = {expected_windows}")
                                                        elif 'state_stb' in stream_name:
                                                            # state_stb: ä¸åˆ†ç»„ï¼Œç›´æ¥ä½¿ç”¨æ€»æ•°
                                                            expected_windows = state_window_count
                                                            print(f"STATE_WINDOW ç†è®ºè®¡ç®— (stb ä¸åˆ†ç»„): ç›´æ¥ä½¿ç”¨æ€»çŠ¶æ€çª—å£æ•° = {expected_windows}")
                                                        else:
                                                            # state_tb: å•è¡¨æ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨è®¡ç®—ç»“æœ
                                                            expected_windows = state_window_count
                                                            print(f"STATE_WINDOW ç†è®ºè®¡ç®— (tb): ç›´æ¥ä½¿ç”¨çŠ¶æ€çª—å£æ•° = {expected_windows}")

                                                        
                                                        print(f"STATE_WINDOW ç‰¹æ®Šå¤„ç†å®Œæˆ:")
                                                        print(f"  ç†è®ºçª—å£æ•° (expected_windows): {expected_windows}")
                                                        print(f"  å®é™…ç”Ÿæˆè®°å½•æ•° (actual_windows): {actual_windows}")
                                                        print(f"  è¯´æ˜: STATE_WINDOW åŸºäºçŠ¶æ€å˜åŒ–è§¦å‘ï¼Œç†è®ºçª—å£æ•°é€šè¿‡çŠ¶æ€å˜åŒ–SQLè®¡ç®—")
                                                    
                                                        
                                                    else:
                                                        print(f"  STATE_WINDOW çœŸå®çª—å£è®¡ç®—å¤±è´¥ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                        window_interval_display = "è®¡ç®—å‡ºé”™"
                                                        window_interval_method = "é»˜è®¤é€»è¾‘"
                                                else:
                                                    print(f"  STATE_WINDOW ç¼ºå°‘å¿…è¦æ—¶é—´ä¿¡æ¯ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                    window_interval_display = "è®¡ç®—å‡ºé”™"
                                                    window_interval_method = "é»˜è®¤é€»è¾‘"
                                                    
                                            except Exception as e:
                                                print(f"  STATE_WINDOW çœŸå®çª—å£è®¡ç®—å‡ºé”™: {str(e)}ï¼Œå›é€€åˆ°é»˜è®¤é€»è¾‘")
                                                # window_interval_display = "è®¡ç®—å‡ºé”™"
                                                # window_interval_method = "é»˜è®¤é€»è¾‘"
                                                
                                        else:
                                            # éEVENT_WINDOWå’ŒSTATE_WINDOWæµï¼Œæ ‡è®°éœ€è¦ä½¿ç”¨é€šç”¨é€»è¾‘
                                            try:
                                                window_interval_ms = self._get_dynamic_window_interval(cursor, target_table)
                                                window_interval_display = f"{window_interval_ms}ms"
                                                window_interval_method = "é€šç”¨åŠ¨æ€è®¡ç®—"
                                            except Exception as e:
                                                window_interval_display = "50000ms"
                                                window_interval_method = "é»˜è®¤å€¼"
                                                
                                        # å¦‚æœä¸æ˜¯ EVENT_WINDOW æˆ–è€… EVENT_WINDOW è®¡ç®—å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸæœ‰é€»è¾‘
                                        if  (not self._is_event_window_stream(stream_name, self.sql_type) and 
                                            not self._is_state_window_stream(stream_name, self.sql_type)) or expected_windows is None:
                                            # æŒ‰å­è¡¨ååˆ†ç»„æ—¶ï¼Œç»§ç»­ä½¿ç”¨åŸæœ‰é€»è¾‘
                                            if stable_count > 0:
                                                print(f"æ£€æµ‹åˆ°åˆ†ç»„æµæ¨¡å¼ (partition by tbname)")
                                                expected_child_table_count = self.table_count 
                                                
                                                # æŸ¥è¯¢å­è¡¨æ•°é‡æ¥ç¡®å®šåˆ†ç»„æ•°
                                                cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                                                actual_child_table_result = cursor.fetchall() 
                                                actual_child_table_count = actual_child_table_result[0][0] if actual_child_table_result and len(actual_child_table_result) > 0 else 0

                                                print(f"é…ç½®å­è¡¨æ•°é‡: {expected_child_table_count} (--table-countå‚æ•°)")
                                                print(f"å®é™…å­è¡¨æ•°é‡: {actual_child_table_count} (æ•°æ®åº“ä¸­å®é™…ç”Ÿæˆ)")
                                                
                                                if expected_child_table_count > 0:
                                                    # ä½¿ç”¨å‘ä¸Šå–æ•´çš„é€»è¾‘ï¼Œç¡®ä¿æœ‰æ•°æ®å°±è‡³å°‘ç®—1ä¸ªçª—å£
                                                    actual_windows = math.ceil(target_record_count / expected_child_table_count)
                                                    
                                                    # ç¡®ä¿æœ€å°å€¼ä¸º1ï¼ˆå¦‚æœæœ‰ä»»ä½•æ•°æ®çš„è¯ï¼‰
                                                    if target_record_count > 0 and actual_windows == 0:
                                                        actual_windows = 1
                                                        
                                                    print(f"åˆ†ç»„æµè®¡ç®—: æ€»è®°å½•æ•°({target_record_count}) Ã· é…ç½®å­è¡¨æ•°({expected_child_table_count}) = {target_record_count / expected_child_table_count:.2f}")
                                                    print(f"å‘ä¸Šå–æ•´ç»“æœ: {actual_windows} (æ¯ä¸ªå­è¡¨å¹³å‡ {target_record_count / expected_child_table_count:.2f} ä¸ªçª—å£)")
                                                    
                                                    # æä¾›æ›´è¯¦ç»†çš„è§£é‡Š
                                                    if actual_windows == 1 and target_record_count < expected_child_table_count:
                                                        print(f"è¯´æ˜: æµè®¡ç®—åˆšå¼€å§‹ï¼Œå¤§éƒ¨åˆ†å­è¡¨å°šæœªç”Ÿæˆæ•°æ®ï¼ŒæŒ‰1ä¸ªçª—å£è®¡ç®—ï¼ˆå‘ä¸Šå–æ•´ä¿è¯æœ‰æ•°æ®å°±ç®—çª—å£ï¼‰")
                                                    elif actual_windows > 1:
                                                        print(f"è¯´æ˜: æµè®¡ç®—è¿›å±•è‰¯å¥½ï¼Œå¹³å‡æ¯ä¸ªå­è¡¨å·²ç”Ÿæˆçº¦ {actual_windows} ä¸ªçª—å£ï¼ˆå‘ä¸Šå–æ•´ä¿è¯æœ‰æ•°æ®å°±ç®—çª—å£ï¼‰")
                                                        
                                                else:
                                                    print(f"è­¦å‘Š: é…ç½®çš„table_countä¸º0ï¼Œä½¿ç”¨å®é™…å­è¡¨æ•°é‡ä¼°ç®—")
                                                    cursor.execute("select count(*) from information_schema.ins_tables where db_name='stream_to'")
                                                    fallback_table_result = cursor.fetchall()
                                                    fallback_table_count = fallback_table_result[0][0] if fallback_table_result and len(fallback_table_result) > 0 else 1
                                                    actual_windows = math.ceil(target_record_count / fallback_table_count)
                                                    if target_record_count > 0 and actual_windows == 0:
                                                        actual_windows = 1
                                                        
                                                    print(f"åå¤‡è®¡ç®—: æ€»è®°å½•æ•°({target_record_count}) Ã· å®é™…å­è¡¨æ•°({fallback_table_count}) = {actual_windows}")
                                            else:
                                                # æ²¡æœ‰è¶…çº§è¡¨ï¼Œè¯´æ˜æ˜¯éåˆ†ç»„æµï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°
                                                actual_windows = target_record_count
                                                print(f"æ£€æµ‹åˆ°éåˆ†ç»„æµæ¨¡å¼ï¼Œç›´æ¥ä½¿ç”¨æ€»è®°å½•æ•°: {actual_windows}")
        
                                    exact_windows = source_duration_ms / window_interval_ms
                                    print(f"  è¯¦ç»†è®¡ç®—: {source_duration_ms}ms Ã· {window_interval_ms}ms = {exact_windows:.2f} â†’ å–æ•´æ•°éƒ¨åˆ† = {expected_windows}")
                                    
                                    # å¦‚æœæœ‰æœªå®Œæ•´çš„æ—¶é—´æ®µï¼Œæç¤ºè¯´æ˜
                                    remaining_time = source_duration_ms % window_interval_ms
                                    if remaining_time > 0:
                                        print(f"  æœªå®Œæ•´é—´éš”: {remaining_time}ms ({remaining_time/1000:.1f}ç§’)ï¼Œä¸è®¡å…¥ç†è®ºçª—å£æ•°")
                                        
                                    # è¡¥å……è¯´æ˜ä¸åŒåˆ†ç»„æ–¹å¼å¯¹çª—å£è®¡ç®—çš„å½±å“
                                    if is_tag_partition:
                                        print(f"  è¯´æ˜: tag åˆ†ç»„æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ª tag å€¼å¯¹åº”ä¸€ä¸ªåˆ†ç»„ï¼Œæ€»çª—å£æ•° = {expected_windows} Ã— {effective_group_count} = {expected_windows * effective_group_count}")
                                    else:
                                        print(f"  è¯´æ˜: å­è¡¨åˆ†ç»„æ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªå­è¡¨å¯¹åº”ä¸€ä¸ªåˆ†ç»„ï¼Œæ€»çª—å£æ•° = {expected_windows} Ã— {effective_group_count} = {expected_windows * effective_group_count}")
        
                                else:
                                    # ç‰¹æ®Šæƒ…å†µï¼šæ—¶é—´è·¨åº¦ä¸º0ä½†æœ‰æ•°æ®ï¼Œä¸»è¦æ˜¯è®¡ç®—å¤ªæ…¢ï¼Œæ¯ä¸ªå­è¡¨çš„æ•°æ®éƒ½æ²¡æœ‰ç”Ÿæˆå®Œï¼Œè®¤ä¸ºè‡³å°‘æœ‰1ä¸ªçª—å£
                                    print(f"  âš ï¸  ç›®æ ‡è¡¨æ—¶é—´è·¨åº¦ä¸º0ï¼Œä½†æœ‰{target_record_count}æ¡è®°å½•ï¼Œè®¤ä¸ºè‡³å°‘æœ‰1ä¸ªçª—å£")
                                    expected_windows = 1    
                                    
                                if expected_windows > 0:
                                    window_completion_percentage = min(100.0, (actual_windows / expected_windows) * 100)
                                else:
                                    window_completion_percentage = 0.0
                                
                                window_completion_ratio = f"{actual_windows}/{expected_windows}"
                                
                                print(f"çª—å£ç”Ÿæˆè®¡ç®—:")
                                print(f"  ç†è®ºçª—å£æ•°: {expected_windows} (åŸºäº{target_duration_ms}msæ—¶é—´è·¨åº¦)")
                                if stable_count > 0:
                                    print(f"  å®é™…å¹³å‡æ¯è¡¨è®°å½•æ•°: {actual_windows}")
                                    print(f"  çª—å£ç”Ÿæˆæ¯”ä¾‹: {actual_windows}/{expected_windows} = {window_completion_percentage:.1f}%")
                                else:
                                    print(f"  å®é™…ç”Ÿæˆè®°å½•æ•°: {actual_windows}")
                                    print(f"  çª—å£ç”Ÿæˆæ¯”ä¾‹: {actual_windows}/{expected_windows} = {window_completion_percentage:.1f}%")
                                
                            else:
                                print(f"âš ï¸  ç¼ºå°‘å¿…è¦æ•°æ®ï¼Œæ— æ³•è®¡ç®—çª—å£ç”Ÿæˆæ¯”ä¾‹")
                                print(f"    target_first_ts: {target_first_ts}")
                                print(f"    source_first_ts: {source_first_ts}")
                                print(f"    target_record_count: {target_record_count}")
                                print(f"    source_record_count: {source_record_count}")
                                expected_windows = None
                                actual_windows = None
                                window_completion_percentage = None
                            
                            print(f"=== çª—å£ç”Ÿæˆæ¯”ä¾‹è®¡ç®—å®Œæˆ ===\n")
                            
                            print(f"è°ƒè¯•: æœ€ç»ˆçª—å£ç”Ÿæˆæ¯”ä¾‹ = {window_completion_percentage}")
                            print(f"è°ƒè¯•: expected_windows = {expected_windows}")
                            print(f"è°ƒè¯•: actual_windows = {actual_windows}")
                            
                        except Exception as e:
                            print(f"è®¡ç®—æµ {stream_name} çª—å£ç”Ÿæˆæ¯”ä¾‹æ—¶å‡ºé”™: {str(e)}")
                            print(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
                            window_completion_percentage = None
                                    
                            
                        stream_result = {
                            'stream_name': stream_name,
                            'target_table': target_table,
                            'target_last_ts': target_last_ts,
                            'delay_ms': delay_ms,
                            'delay_seconds': delay_ms / 1000.0,
                            'is_lagging': delay_ms > dynamic_threshold_ms,
                            'status': 'LAGGING' if delay_ms > self.max_delay_threshold else 'OK',
                            'stream_status': stream_status,
                            'stream_create_time': stream_create_time,
                            'window_completion_ratio': window_completion_ratio,
                            'window_completion_percentage': window_completion_percentage,
                            'expected_windows': expected_windows, 
                            'actual_windows': actual_windows,
                            'dynamic_threshold_ms': dynamic_threshold_ms,
                            'window_interval_display': window_interval_display, 
                            'window_interval_method': window_interval_method,
                            'write_speed_per_second': write_speed_per_second   
                        }
                        
                        print(f"æµ {stream_name} å»¶è¿Ÿ: {delay_ms}ms ({delay_ms/1000.0:.2f}ç§’)")
                        
                    else:
                        # ç›®æ ‡è¡¨æ— æ•°æ®
                        stream_result = {
                            'stream_name': stream_name,
                            'target_table': target_table,
                            'target_last_ts': None,
                            'delay_ms': None,
                            'delay_seconds': None,
                            'is_lagging': True,
                            'status': 'NO_DATA',
                            'stream_status': stream_status,
                            'stream_create_time': stream_create_time,
                            'window_completion_ratio': None,
                            'window_completion_percentage': None,
                            'expected_windows': None,  
                            'actual_windows': None,
                            'dynamic_threshold_ms': dynamic_threshold_ms,
                            'window_interval_display': window_interval_display,  
                            'window_interval_method': window_interval_method,
                            'write_speed_per_second': write_speed_per_second
                        }
                        
                        print(f"æµ {stream_name} (çŠ¶æ€: {stream_status}) ç›®æ ‡è¡¨æ— æ•°æ®")
                    
                    delay_results['streams'].append(stream_result)
                    
                except Exception as e:
                    error_msg = f"æ£€æŸ¥æµ {stream_name} å»¶è¿Ÿæ—¶å‡ºé”™: {str(e)}"
                    print(error_msg)
                    # âœ… ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿè®°å½•æµçŠ¶æ€
                    stream_status_info = streams_status_info.get(stream_name, {})
                    stream_status = stream_status_info.get('status', 'æœªçŸ¥')
                    stream_create_time = stream_status_info.get('create_time', 'æœªçŸ¥')
                
                    stream_result = {
                        'stream_name': stream_name,
                        'target_table': target_table,
                        'error': str(e),
                        'status': 'ERROR',
                        'stream_status': stream_status,
                        'stream_create_time': stream_create_time,
                        'window_completion_ratio': None,
                        'window_completion_percentage': None,
                        'expected_windows': None,  
                        'actual_windows': None,
                        'dynamic_threshold_ms': None,
                        'window_interval_display': "N/A",
                        'window_interval_method': "å¼‚å¸¸æƒ…å†µ",
                        'write_speed_per_second': write_speed_per_second  
                    }
                    delay_results['streams'].append(stream_result)
            
            cursor.close()
            conn.close()
            
            return delay_results
            
        except Exception as e:
            print(f"æ£€æŸ¥æµè®¡ç®—å»¶è¿Ÿæ—¶å‡ºé”™: {str(e)}")
            return None

    def _get_dynamic_window_interval(self, cursor, target_table):
        """åŠ¨æ€è·å–çª—å£é—´éš”
        
        Args:
            cursor: æ•°æ®åº“æ¸¸æ ‡
            target_table: ç›®æ ‡è¡¨å
            
        Returns:
            int: çª—å£é—´éš”(æ¯«ç§’)ï¼Œå¦‚æœæ— æ³•è·å–åˆ™è¿”å›é»˜è®¤å€¼50000ms
        """
        try:
            # âœ… æ–°å¢ï¼šå¯¹äº EVENT_WINDOW å’Œ STATE_WINDOW ç±»å‹ï¼Œè·³è¿‡é€šç”¨è®¡ç®—
            # æ£€æŸ¥å½“å‰æµç±»å‹ï¼Œå¦‚æœæ˜¯ EVENT_WINDOW æˆ– STATE_WINDOWï¼Œç›´æ¥è¿”å›é»˜è®¤å€¼
            if hasattr(self, 'sql_type') and self.sql_type:
                if ('event_' in self.sql_type.lower() or 
                    'state_' in self.sql_type.lower() or
                    'event_window' in self.sql_type.lower() or
                    'state_window' in self.sql_type.lower()):
                    print(f"æ£€æµ‹åˆ° EVENT_WINDOW æˆ– STATE_WINDOW ç±»å‹æµï¼Œè·³è¿‡é€šç”¨çª—å£é—´éš”è®¡ç®—")
                    return 50000  # è¿”å›é»˜è®¤å€¼ï¼Œå®é™…é—´éš”å°†ç”±ä¸“é—¨çš„è®¡ç®—é€»è¾‘å¤„ç†
            
            # âœ… å¯¹äºæµåç§°ä¹Ÿè¿›è¡Œæ£€æŸ¥ï¼ˆä½œä¸ºå¤‡ç”¨åˆ¤æ–­ï¼‰
            if target_table:
                table_name = target_table.split('.')[-1] if '.' in target_table else target_table
                if ('event_' in table_name.lower() or 
                    'state_' in table_name.lower()):
                    print(f"ä»ç›®æ ‡è¡¨åæ£€æµ‹åˆ° EVENT_WINDOW æˆ– STATE_WINDOW ç±»å‹ï¼Œè·³è¿‡é€šç”¨çª—å£é—´éš”è®¡ç®—")
                    return 50000  # è¿”å›é»˜è®¤å€¼
            
            print(f"å°è¯•åŠ¨æ€è·å–çª—å£é—´éš”: {target_table}")
            
            # é¦–å…ˆæ£€æŸ¥è¡¨æ˜¯å¦å­˜åœ¨
            try:
                cursor.execute(f"describe {target_table}")
            except Exception as e:
                print(f"  ç›®æ ‡è¡¨ä¸å­˜åœ¨æˆ–æ— æ³•è®¿é—®: {str(e)}")
                return 50000  # è¿”å›é»˜è®¤50ç§’
            
            # é¦–å…ˆæ£€æŸ¥æ˜¯å¦ä¸ºåˆ†ç»„æµï¼ˆæœ‰è¶…çº§è¡¨ç»“æ„ï¼‰
            cursor.execute("show stream_to.stables")
            stables_result = cursor.fetchall()
            
            if len(stables_result) > 0:
                # åˆ†ç»„æµï¼šä»ç¬¬ä¸€ä¸ªå­è¡¨è·å–æ—¶é—´é—´éš”
                cursor.execute("select table_name from information_schema.ins_tables where db_name='stream_to' limit 1")
                child_table_result = cursor.fetchall()
                
                if child_table_result:
                    child_table = child_table_result[0][0]
                    sample_table = f"stream_to.`{child_table}`" 
                    print(f"  æ£€æµ‹åˆ°åˆ†ç»„æµï¼Œä½¿ç”¨å­è¡¨æ ·æœ¬: {sample_table}")
                else:
                    print(f"  åˆ†ç»„æµä½†æœªæ‰¾åˆ°å­è¡¨ï¼Œä½¿ç”¨é»˜è®¤é—´éš”")
                    return 50000  # é»˜è®¤50ç§’
            else:
                # éåˆ†ç»„æµï¼šç›´æ¥ä½¿ç”¨ç›®æ ‡è¡¨
                # âœ… æ£€æŸ¥ç›®æ ‡è¡¨åæ˜¯å¦éœ€è¦ç‰¹æ®Šå¤„ç†
                if '.' in target_table:
                    db_name, table_name = target_table.split('.', 1)
                    sample_table = f"{db_name}.`{table_name}`"  # åªå¯¹è¡¨åéƒ¨åˆ†åŠ åå¼•å·
                else:
                    sample_table = f"`{target_table}`"  # æ•´ä¸ªè¡¨ååŠ åå¼•å·
                print(f"  æ£€æµ‹åˆ°éåˆ†ç»„æµï¼Œä½¿ç”¨ç›®æ ‡è¡¨: {sample_table}")
            
            # æŸ¥è¯¢å‰å‡ æ¡è®°å½•çš„æ—¶é—´æˆ³
            cursor.execute(f"select ts from {sample_table} order by ts limit 10")
            ts_result = cursor.fetchall()
            
            if not ts_result or len(ts_result) < 2:
                print(f"  æ•°æ®ä¸è¶³ï¼ˆåªæœ‰{len(ts_result) if ts_result else 0}æ¡è®°å½•ï¼‰ï¼Œä½¿ç”¨é»˜è®¤é—´éš”")
                return 50000  # é»˜è®¤50ç§’
            
            # è®¡ç®—ç›¸é‚»è®°å½•çš„æ—¶é—´é—´éš”
            intervals = []
            for i in range(1, min(len(ts_result), 9)):  # æœ€å¤šè®¡ç®—9ä¸ªé—´éš”
                prev_ts = ts_result[i-1][0]
                curr_ts = ts_result[i][0]
                
                if prev_ts and curr_ts:
                    interval_ms = int((curr_ts - prev_ts).total_seconds() * 1000)
                    intervals.append(interval_ms)
                    print(f"    ç¬¬{i}ä¸ªé—´éš”: {prev_ts} -> {curr_ts} = {interval_ms}ms")
            
            if not intervals:
                print(f"  æ— æ³•è®¡ç®—æ—¶é—´é—´éš”ï¼Œä½¿ç”¨é»˜è®¤é—´éš”")
                return 50000  # é»˜è®¤50ç§’
            
            # ç®€åŒ–é€»è¾‘ï¼šåªè¦æœ‰é—´éš”æ•°æ®ï¼Œå°±ä½¿ç”¨å¹³å‡å€¼
            if intervals:
                avg_interval = sum(intervals) / len(intervals)
                window_interval = int(avg_interval)
                
                print(f"  åŠ¨æ€é—´éš”è®¡ç®—å®Œæˆ: {window_interval}ms ({window_interval/1000:.1f}ç§’)")
                print(f"  åŸºäº {len(intervals)} ä¸ªæ ·æœ¬çš„å¹³å‡å€¼")
                
                # æ–°å¢ï¼šè®°å½•åˆ°å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶ä¸­ï¼ˆå¦‚æœå»¶è¿Ÿç›‘æ§å·²å¯ç”¨ï¼‰
                if hasattr(self, 'delay_log_file') and hasattr(self, 'check_stream_delay') and self.check_stream_delay:
                    try:
                        with open(self.delay_log_file, 'a') as f:
                            f.write(f"çª—å£é—´éš”æ£€æµ‹ç»“æœ: {window_interval}ms ({window_interval/1000:.1f}ç§’)\n")
                    except:
                        pass  # é™é»˜å¤„ç†æ—¥å¿—å†™å…¥é”™è¯¯
                
                return window_interval
                
        except Exception as e:
            print(f"  åŠ¨æ€è·å–çª—å£é—´éš”å¤±è´¥: {str(e)}ï¼Œä½¿ç”¨é»˜è®¤é—´éš”")
            return 50000  # é»˜è®¤50ç§’


    def log_stream_delay_results(self, delay_results):
        """è®°å½•æµå»¶è¿Ÿæ£€æŸ¥ç»“æœåˆ°æ—¥å¿—æ–‡ä»¶"""
        if not delay_results:
            return
            
        try:           
            # åŸºäº max_delay_threshold è®¡ç®—åŠ¨æ€é˜ˆå€¼
            base_threshold_ms = self.max_delay_threshold
            
            # å®šä¹‰å€æ•°é˜ˆå€¼
            excellent_threshold = base_threshold_ms * 0.1    # 0.1å€æ£€æŸ¥é—´éš” - ä¼˜ç§€
            good_threshold = base_threshold_ms * 0.5         # 0.5å€æ£€æŸ¥é—´éš” - è‰¯å¥½  
            normal_threshold = base_threshold_ms * 1.0       # 1å€æ£€æŸ¥é—´éš” - æ­£å¸¸
            mild_delay_threshold = base_threshold_ms * 6.0   # 6å€æ£€æŸ¥é—´éš” - è½»å¾®å»¶è¿Ÿ
            obvious_delay_threshold = base_threshold_ms * 30.0  # 30å€æ£€æŸ¥é—´éš” - æ˜æ˜¾å»¶è¿Ÿ
            
            with open(self.delay_log_file, 'a') as f:
                # å†™å…¥æ£€æŸ¥æ—¶é—´å’Œæºè¡¨ä¿¡æ¯
                f.write(f"\n{'='*80}\n")
                f.write(f"æ£€æŸ¥æ—¶é—´: {delay_results['check_time']}\n")
                f.write(f"æºè¡¨æœ€æ–°æ—¶é—´: {delay_results['source_last_ts']}\n")
                f.write(f"æºè¡¨æ—¶é—´æˆ³(ms): {delay_results['source_ts_ms']}\n")
                f.write(f"å»¶è¿Ÿé˜ˆå€¼æ¨¡å¼: åŠ¨æ€è®¡ç®— (åŸºäºå„æµçš„çª—å£é—´éš”)\n")
                f.write(f"æ£€æŸ¥é¢‘ç‡: {self.delay_check_interval}ç§’\n")
                f.write(f"-" * 80 + "\n")
                
                # âœ… æ–°å¢ï¼šæ˜¾ç¤ºåŠ¨æ€é˜ˆå€¼ä¿¡æ¯æ±‡æ€»
                dynamic_threshold_info = delay_results.get('dynamic_threshold_info', {})
                if dynamic_threshold_info:
                    f.write(f"\nåŠ¨æ€é˜ˆå€¼ä¿¡æ¯æ±‡æ€»:\n")
                    for stream_name, threshold_info in dynamic_threshold_info.items():
                        threshold_ms = threshold_info['threshold_ms']
                        f.write(f"  {stream_name}: {format_delay_time(threshold_ms)}\n")
                
                f.write(f"-" * 80 + "\n")
                
                # å†™å…¥æ¯ä¸ªæµçš„å»¶è¿Ÿä¿¡æ¯
                for stream in delay_results['streams']:
                    f.write(f"æµåç§°: {stream['stream_name']}\n")
                    f.write(f"ç›®æ ‡è¡¨: {stream['target_table']}\n")
                    f.write(f"çŠ¶æ€: {stream['status']}\n")
                    f.write(f"æµçŠ¶æ€: {stream.get('stream_status', 'æœªçŸ¥')}\n")
                    f.write(f"æµåˆ›å»ºæ—¶é—´: {stream.get('stream_create_time', 'æœªçŸ¥')}\n")  
                    
                    # âœ… æ–°å¢ï¼šå†™å…¥è¯¥æµçš„åŠ¨æ€é˜ˆå€¼
                    dynamic_threshold_ms = stream.get('dynamic_threshold_ms', self.max_delay_threshold)
                    if dynamic_threshold_ms:
                        f.write(f"åŠ¨æ€å»¶è¿Ÿé˜ˆå€¼: {format_delay_time(dynamic_threshold_ms)}\n")
                    else:
                        f.write(f"åŠ¨æ€å»¶è¿Ÿé˜ˆå€¼: æ— æ³•è®¡ç®—\n")
                    
                    # âœ… æ–°å¢ï¼šå†™å…¥çª—å£ç”Ÿæˆæ¯”ä¾‹ä¿¡æ¯
                    window_completion_percentage = stream.get('window_completion_percentage')
                    expected_windows = stream.get('expected_windows')
                    actual_windows = stream.get('actual_windows')

                    if window_completion_percentage is not None:
                        f.write(f"çª—å£ç”Ÿæˆæ¯”ä¾‹: {window_completion_percentage:.2f}%\n")
                        # âœ… æ·»åŠ è¯¦ç»†çš„çª—å£æ•°æ®è®°å½•
                        if expected_windows is not None and actual_windows is not None:
                            f.write(f"ç†è®ºçª—å£æ•°: {expected_windows}\n")
                            f.write(f"å®é™…ç”Ÿæˆè®°å½•æ•°: {actual_windows}\n")
                            f.write(f"çª—å£ç”Ÿæˆæ¯”ä¾‹: {actual_windows}/{expected_windows} = {window_completion_percentage:.1f}%\n")
                        else:
                            f.write(f"çª—å£è¯¦ç»†æ•°æ®: è®¡ç®—è¿‡ç¨‹ä¸­æœªèƒ½è·å–\n")
                    else:
                        f.write(f"çª—å£ç”Ÿæˆæ¯”ä¾‹: N/A\n")              
                    
                    if stream['status'] == 'OK' or stream['status'] == 'LAGGING':
                        f.write(f"ç›®æ ‡è¡¨æœ€æ–°æ—¶é—´: {stream['target_last_ts']}\n")
                        delay_ms = stream['delay_ms']
                        f.write(f"å»¶è¿Ÿ: {format_delay_time(delay_ms)}\n")
                        
                        # âœ… ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è®¡ç®—å»¶è¿Ÿå€æ•°å’Œç­‰çº§
                        if dynamic_threshold_ms and dynamic_threshold_ms > 0:
                            delay_multiplier = delay_ms / dynamic_threshold_ms
                            
                            # åŸºäºåŠ¨æ€é˜ˆå€¼çš„å»¶è¿Ÿç­‰çº§åˆ¤æ–­
                            excellent_threshold = dynamic_threshold_ms * 0.1
                            good_threshold = dynamic_threshold_ms * 0.5
                            normal_threshold = dynamic_threshold_ms * 1.0
                            mild_delay_threshold = dynamic_threshold_ms * 6.0
                            obvious_delay_threshold = dynamic_threshold_ms * 30.0
                            
                            if delay_ms < excellent_threshold:
                                delay_level = "ä¼˜ç§€"
                                delay_desc = f"(< 0.1å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                            elif delay_ms < good_threshold:
                                delay_level = "è‰¯å¥½"
                                delay_desc = f"(0.1-0.5å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                            elif delay_ms < normal_threshold:
                                delay_level = "æ­£å¸¸"
                                delay_desc = f"(0.5-1å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                            elif delay_ms < mild_delay_threshold:
                                delay_level = "è½»å¾®å»¶è¿Ÿ"
                                delay_desc = f"(1-6å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                            elif delay_ms < obvious_delay_threshold:
                                delay_level = "æ˜æ˜¾å»¶è¿Ÿ"
                                delay_desc = f"(6-30å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                            else:
                                delay_level = "ä¸¥é‡å»¶è¿Ÿ"
                                delay_desc = f"(> 30å€çª—å£é—´éš”, {delay_multiplier:.2f}å€)"
                        else:
                            # å¦‚æœæ— æ³•è·å–åŠ¨æ€é˜ˆå€¼ï¼Œä½¿ç”¨å›ºå®šé˜ˆå€¼ä½œä¸ºåå¤‡
                            delay_multiplier = delay_ms / self.max_delay_threshold
                            delay_level = "æ— æ³•åˆ¤æ–­"
                            delay_desc = f"(åŠ¨æ€é˜ˆå€¼è®¡ç®—å¤±è´¥, åŸºäºå›ºå®šé˜ˆå€¼{delay_multiplier:.2f}å€)"
                        
                        # å†™å…¥å»¶è¿Ÿç­‰çº§
                        f.write(f"å»¶è¿Ÿç­‰çº§: {delay_level}\n")
                        f.write(f"å»¶è¿Ÿå€æ•°: {delay_desc}\n")
                        
                        # åŠ¨æ€å»¶è¿Ÿåˆ¤æ–­
                        if dynamic_threshold_ms and delay_ms > dynamic_threshold_ms:
                            f.write(f"è­¦å‘Š: å»¶è¿Ÿè¶…è¿‡åŠ¨æ€é˜ˆå€¼ {format_delay_time(dynamic_threshold_ms)}!\n")
                            
                    elif stream['status'] == 'NO_DATA':
                        f.write(f"è­¦å‘Š: ç›®æ ‡è¡¨æ— æ•°æ®\n")
                        f.write(f"å»¶è¿Ÿç­‰çº§: ç›®æ ‡è¡¨æ— æ•°æ®\n")
                        f.write(f"å»¶è¿Ÿå€æ•°: (æ— æ•°æ®çŠ¶æ€)\n")
                        
                        stream_status = stream.get('stream_status', 'æœªçŸ¥')
                        if stream_status.lower() != 'running':
                            f.write(f"å¯èƒ½åŸå› : æµçŠ¶æ€ä¸º '{stream_status}'ï¼Œéè¿è¡ŒçŠ¶æ€\n")
                        else:
                            f.write(f"å¯èƒ½åŸå› : æµæ­£åœ¨è¿è¡Œä½†å°šæœªç”Ÿæˆæ•°æ®ï¼Œå¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´\n")
                        
                    elif stream['status'] == 'ERROR':
                        f.write(f"é”™è¯¯: {stream.get('error', 'æœªçŸ¥é”™è¯¯')}\n")
                        f.write(f"å»¶è¿Ÿç­‰çº§: ç›®æ ‡è¡¨ä¸å­˜åœ¨\n")
                        f.write(f"å»¶è¿Ÿå€æ•°: (é”™è¯¯çŠ¶æ€)\n")
                    
                        stream_status = stream.get('stream_status', 'æœªçŸ¥')
                        if stream_status.lower() != 'running':
                            f.write(f"å¯èƒ½åŸå› : æµçŠ¶æ€ä¸º '{stream_status}'ï¼Œæµå¯èƒ½åˆ›å»ºå¤±è´¥\n")
                        else:
                            f.write(f"å¯èƒ½åŸå› : æµè¿è¡Œæ­£å¸¸ä½†ç›®æ ‡è¡¨é…ç½®é—®é¢˜\n")
                        
                    f.write(f"-" * 40 + "\n")
                    
        except Exception as e:
            print(f"å†™å…¥å»¶è¿Ÿæ—¥å¿—å¤±è´¥: {str(e)}")

    def print_stream_delay_summary(self, delay_results):
        """æ‰“å°æµå»¶è¿Ÿæ£€æŸ¥æ‘˜è¦"""
        if not delay_results:
            return
        
        c = Colors.get_colors()
        
        # åŸºäº delay_check_interval è®¡ç®—åŠ¨æ€é˜ˆå€¼
        base_threshold_ms = self.max_delay_threshold
        
        # å®šä¹‰å€æ•°é˜ˆå€¼
        excellent_threshold = base_threshold_ms * 0.1    # 0.1å€æ£€æŸ¥é—´éš” - ä¼˜ç§€
        good_threshold = base_threshold_ms * 0.5         # 0.5å€æ£€æŸ¥é—´éš” - è‰¯å¥½  
        normal_threshold = base_threshold_ms * 1.0       # 1å€æ£€æŸ¥é—´éš” - æ­£å¸¸
        mild_delay_threshold = base_threshold_ms * 6.0   # 6å€æ£€æŸ¥é—´éš” - è½»å¾®å»¶è¿Ÿ
        obvious_delay_threshold = base_threshold_ms * 30.0  # 30å€æ£€æŸ¥é—´éš” - æ˜æ˜¾å»¶è¿Ÿ
            
        print(f"\n=== æµè®¡ç®—å»¶è¿Ÿæ£€æŸ¥ ({delay_results['check_time']}) ===")
        print(f"æºè¡¨æœ€æ–°æ—¶é—´: {delay_results['source_last_ts']}")
        print(f"é…ç½®ä¿¡æ¯: å­è¡¨æ•°é‡({self.table_count}) | æ¯è½®æ’å…¥è®°å½•æ•°({self.real_time_batch_rows}) | vgroups({self.vgroups}) | æ•°æ®ä¹±åº({self.disorder_ratio})")
        
        # âœ… æ˜¾ç¤ºåŠ¨æ€é˜ˆå€¼ä¿¡æ¯
        dynamic_threshold_info = delay_results.get('dynamic_threshold_info', {})
        if dynamic_threshold_info:
            print(f"å»¶è¿Ÿåˆ¤æ–­åŸºå‡†: åŠ¨æ€è®¡ç®— (åŸºäºå„æµçª—å£é—´éš”) | æ£€æŸ¥é¢‘ç‡ {self.delay_check_interval}s | éƒ¨ç½²æ¨¡å¼({self.deployment_mode}) | SQLç±»å‹({self.sql_type})")
            print(f"åŠ¨æ€é˜ˆå€¼è¯¦æƒ…:")
            for stream_name, threshold_info in dynamic_threshold_info.items():
                threshold_ms = threshold_info['threshold_ms']
                print(f"  {stream_name}: {format_delay_time(threshold_ms)}")
        else:
            print(f"å»¶è¿Ÿåˆ¤æ–­åŸºå‡†: å›ºå®šé˜ˆå€¼ {format_delay_time(self.max_delay_threshold)} (åŠ¨æ€è®¡ç®—å¤±è´¥) | æ£€æŸ¥é¢‘ç‡ {self.delay_check_interval}s")
            
        ok_count = 0
        lagging_count = 0
        no_data_count = 0
        error_count = 0
        stream_status_stats = {}
        
        # æŒ‰å»¶è¿Ÿçº§åˆ«åˆ†ç±»ç»Ÿè®¡
        excellent_count = 0
        good_count = 0
        normal_count = 0
        mild_delay_count = 0
        obvious_delay_count = 0
        severe_delay_count = 0
    
        for stream in delay_results['streams']:
            status = stream['status']
            stream_name = stream['stream_name']
            
            stream_status = stream.get('stream_status', 'æœªçŸ¥')
            stream_status_stats[stream_status] = stream_status_stats.get(stream_status, 0) + 1
            # âœ… è·å–è¯¥æµçš„åŠ¨æ€é˜ˆå€¼
            dynamic_threshold_ms = stream.get('dynamic_threshold_ms', self.max_delay_threshold)
            
            
            if status == 'OK':
                ok_count += 1
                target_time = stream['target_last_ts']
                delay_ms = stream['delay_ms']
                # âœ… ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è®¡ç®—å»¶è¿Ÿçº§åˆ«
                if dynamic_threshold_ms and dynamic_threshold_ms > 0:
                    excellent_threshold = dynamic_threshold_ms * 0.1
                    good_threshold = dynamic_threshold_ms * 0.5
                    normal_threshold = dynamic_threshold_ms * 1.0
                    
                    if delay_ms < excellent_threshold:
                        excellent_count += 1
                        status_icon = "ğŸŸ¢" if Colors.supports_color() else "âœ“"
                        delay_desc = f"ä¼˜ç§€(<{format_delay_time(excellent_threshold)})"
                        color = c.GREEN
                    elif delay_ms < good_threshold:
                        good_count += 1
                        status_icon = "ğŸŸ¢" if Colors.supports_color() else "âœ“"
                        delay_desc = f"è‰¯å¥½(<{format_delay_time(good_threshold)})"
                        color = c.GREEN
                    else:  # delay_ms < normal_threshold
                        normal_count += 1
                        status_icon = "ğŸŸ¡" if Colors.supports_color() else "âœ“"
                        delay_desc = f"æ­£å¸¸(<{format_delay_time(normal_threshold)})"
                        color = c.YELLOW
                else:
                    # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨å›ºå®šé˜ˆå€¼
                    normal_count += 1
                    status_icon = "ğŸŸ¡" if Colors.supports_color() else "âœ“"
                    delay_desc = f"æ­£å¸¸(åŠ¨æ€é˜ˆå€¼å¤±è´¥)"
                    color = c.YELLOW
                    
                print(f"{color}{status_icon} {stream_name}(æµçŠ¶æ€: {stream_status}): å»¶è¿Ÿ {format_delay_time(delay_ms)} - {delay_desc}{c.END}")
                print(f"  {c.BLUE}ç›®æ ‡è¡¨æœ€æ–°æ—¶é—´: {target_time} | åŠ¨æ€é˜ˆå€¼: {format_delay_time(dynamic_threshold_ms)}{c.END}")
            
            
            elif status == 'LAGGING':
                lagging_count += 1
                target_time = stream['target_last_ts']
                delay_ms = stream['delay_ms']
            
                # âœ… ä½¿ç”¨åŠ¨æ€é˜ˆå€¼è®¡ç®—å»¶è¿Ÿçº§åˆ«
                if dynamic_threshold_ms and dynamic_threshold_ms > 0:
                    mild_delay_threshold = dynamic_threshold_ms * 6.0
                    obvious_delay_threshold = dynamic_threshold_ms * 30.0
                    
                    if delay_ms < mild_delay_threshold:
                        mild_delay_count += 1
                        status_icon = "ğŸŸ¡" if Colors.supports_color() else "âš "
                        color = c.YELLOW
                        delay_desc = f"è½»å¾®å»¶è¿Ÿ(<{format_delay_time(mild_delay_threshold)})"
                    elif delay_ms < obvious_delay_threshold:
                        obvious_delay_count += 1
                        status_icon = "ğŸŸ " if Colors.supports_color() else "âš "
                        color = c.YELLOW
                        delay_desc = f"æ˜æ˜¾å»¶è¿Ÿ(<{format_delay_time(obvious_delay_threshold)})"
                    else:
                        severe_delay_count += 1
                        status_icon = "ğŸ”´" if Colors.supports_color() else "âš "
                        color = c.RED
                        delay_desc = f"ä¸¥é‡å»¶è¿Ÿ(>{format_delay_time(obvious_delay_threshold)})"
                else:
                    severe_delay_count += 1
                    status_icon = "ğŸ”´" if Colors.supports_color() else "âš "
                    color = c.RED
                    delay_desc = f"å»¶è¿Ÿ(åŠ¨æ€é˜ˆå€¼å¤±è´¥)"
                    
                print(f"{color}{c.BOLD}{status_icon} {stream_name}(æµçŠ¶æ€: {stream_status}): å»¶è¿Ÿ {format_delay_time(delay_ms)} - {delay_desc}!{c.END}")
                print(f"  {c.BLUE}ç›®æ ‡è¡¨æœ€æ–°æ—¶é—´: {target_time} | åŠ¨æ€é˜ˆå€¼: {format_delay_time(dynamic_threshold_ms)}{c.END}")
                
                
            elif status == 'NO_DATA':
                no_data_count += 1
                #ä¸å†å°†æ— æ•°æ®å½’ç±»ä¸ºä¸¥é‡å»¶è¿Ÿï¼Œå•ç‹¬ç»Ÿè®¡ severe_delay_count += 1
                status_icon = "âŒ" if Colors.supports_color() else "âœ—"
                print(f"{c.RED}{status_icon} {stream_name}(æµçŠ¶æ€: {stream_status}): ç›®æ ‡è¡¨æœªç”Ÿæˆæ•°æ®{c.END}")
                
                if stream_status.lower() != 'running':
                    print(f"  {c.YELLOW}å¯èƒ½åŸå› : æµçŠ¶æ€ä¸º '{stream_status}'ï¼Œæµå¯èƒ½æœªæ­£å¸¸å¯åŠ¨{c.END}")
                else:
                    print(f"  {c.BLUE}å¯èƒ½åŸå› : æµæ­£åœ¨è¿è¡Œä½†å°šæœªç”Ÿæˆæ•°æ®ï¼Œå»ºè®®ç»§ç»­è§‚å¯Ÿ{c.END}")
                
            elif status == 'ERROR':
                error_count += 1
                #ä¸å†å°†é”™è¯¯å½’ç±»ä¸ºä¸¥é‡å»¶è¿Ÿï¼Œå•ç‹¬ç»Ÿè®¡severe_delay_count += 1
                status_icon = "ğŸ’¥" if Colors.supports_color() else "âœ—"
                print(f"{c.RED}{c.BOLD}{status_icon} {stream_name}(æµçŠ¶æ€: {stream_status}): ç›®æ ‡è¡¨ä¸å­˜åœ¨æˆ–æ£€æŸ¥å‡ºé”™{c.END}")
                error_msg = stream.get('error', 'æœªçŸ¥é”™è¯¯')
                print(f"  {c.RED}é”™è¯¯ä¿¡æ¯: {error_msg}{c.END}")
                
                if stream_status.lower() != 'running':
                    print(f"  {c.YELLOW}è¯Šæ–­: æµçŠ¶æ€ä¸º '{stream_status}'ï¼Œæµåˆ›å»ºå¯èƒ½å¤±è´¥{c.END}")
                else:
                    print(f"  {c.BLUE}è¯Šæ–­: æµè¿è¡Œæ­£å¸¸ä½†ç›®æ ‡è¡¨é…ç½®é—®é¢˜{c.END}")
 
    
        # è®¡ç®—æ€»æ•°å’Œç™¾åˆ†æ¯”
        total_streams = len(delay_results['streams'])
        
        def get_percentage(count, total):
            return f"{(count/total*100):.1f}%" if total > 0 else "0.0%"
           
        # æ‘˜è¦ä¿¡æ¯å¸¦é¢œè‰²å’Œå›¾æ ‡
        summary_parts = []
        # æ­£å¸¸æµ
        if ok_count > 0:
            ok_icon = "ğŸŸ¢" if Colors.supports_color() else ""
            ok_percent = get_percentage(ok_count, total_streams)
            summary_parts.append(f"{c.GREEN}{ok_icon}æ­£å¸¸({ok_count}/{ok_percent}){c.END}")
            
        # å»¶è¿Ÿæµ
        if lagging_count > 0:
            lag_icon = "ğŸŸ¡" if Colors.supports_color() else ""
            lag_percent = get_percentage(lagging_count, total_streams)
            summary_parts.append(f"{c.YELLOW}{lag_icon}å»¶è¿Ÿ({lagging_count}/{lag_percent}){c.END}")
            
        # æœªç”Ÿæˆæ•°æ®çš„æµ     
        if no_data_count > 0:
            no_data_icon = "âŒ" if Colors.supports_color() else ""
            no_data_percent = get_percentage(no_data_count, total_streams)
            summary_parts.append(f"{c.RED}{no_data_icon}æœªç”Ÿæˆæ•°æ®({no_data_count}/{no_data_percent}){c.END}")
            
        # é”™è¯¯çŠ¶æ€çš„æµ    
        if error_count > 0:
            error_icon = "ğŸ’¥" if Colors.supports_color() else ""
            error_percent = get_percentage(error_count, total_streams)
            summary_parts.append(f"{c.RED}{error_icon}è¡¨ä¸å­˜åœ¨({error_count}/{error_percent}){c.END}")
        
        print(f"\n{c.BOLD}ğŸ“Š æ‘˜è¦ (æ€»æµæ•°: {total_streams}): {' '.join(summary_parts)}{c.END}")

        # âœ… æ–°å¢ï¼šæµçŠ¶æ€åˆ†å¸ƒç»Ÿè®¡
        if stream_status_stats:
            print(f"\n{c.CYAN}ğŸ”„ æµçŠ¶æ€åˆ†å¸ƒ:{c.END}")
            for status, count in stream_status_stats.items():
                percentage = get_percentage(count, total_streams)
                # æ ¹æ®çŠ¶æ€ä½¿ç”¨ä¸åŒé¢œè‰²
                if status.lower() == 'running':
                    status_color = c.GREEN
                    status_icon = "âœ…"
                elif status.lower() in ['stopped', 'failed', 'error']:
                    status_color = c.RED
                    status_icon = "âŒ"
                elif status.lower() in ['paused', 'suspended']:
                    status_color = c.YELLOW
                    status_icon = "â¸ï¸"
                else:
                    status_color = c.BLUE
                    status_icon = "â“"
                    
                print(f"  {status_color}{status_icon} {status}: {count} ({percentage}){c.END}")

        # è¯¦ç»†åˆ†å¸ƒç»Ÿè®¡
        if ok_count > 0 or lagging_count > 0:
            print(f"\n{c.CYAN}ğŸ“ˆ å»¶è¿Ÿåˆ†å¸ƒè¯¦æƒ…:{c.END}")
            
            # æ­£å¸¸çŠ¶æ€åˆ†å¸ƒ
            if ok_count > 0:
                print(f"  {c.GREEN}æ­£å¸¸çŠ¶æ€åˆ†å¸ƒ:{c.END}")
                if excellent_count > 0:
                    excellent_percent = get_percentage(excellent_count, total_streams)
                    print(f"    ğŸŸ¢ ä¼˜ç§€: {excellent_count} ({excellent_percent})")
                if good_count > 0:
                    good_percent = get_percentage(good_count, total_streams)
                    print(f"    ğŸŸ¢ è‰¯å¥½: {good_count} ({good_percent})")
                if normal_count > 0:
                    normal_percent = get_percentage(normal_count, total_streams)
                    print(f"    ğŸŸ¡ æ­£å¸¸: {normal_count} ({normal_percent})")
            
            # å»¶è¿ŸçŠ¶æ€åˆ†å¸ƒ
            if lagging_count > 0:
                print(f"  {c.YELLOW}å»¶è¿ŸçŠ¶æ€åˆ†å¸ƒ:{c.END}")
                if mild_delay_count > 0:
                    mild_percent = get_percentage(mild_delay_count, total_streams)
                    print(f"    ğŸŸ¡ è½»å¾®å»¶è¿Ÿ: {mild_delay_count} ({mild_percent})")
                if obvious_delay_count > 0:
                    obvious_percent = get_percentage(obvious_delay_count, total_streams)
                    print(f"    ğŸŸ  æ˜æ˜¾å»¶è¿Ÿ: {obvious_delay_count} ({obvious_percent})")
                if severe_delay_count > 0:
                    severe_percent = get_percentage(severe_delay_count, total_streams)
                    print(f"    ğŸ”´ ä¸¥é‡å»¶è¿Ÿ: {severe_delay_count} ({severe_percent})")
    
        # é—®é¢˜æµç»Ÿè®¡
        if no_data_count > 0 or error_count > 0:
            print(f"\n{c.RED}âš ï¸ é—®é¢˜æµç»Ÿè®¡:{c.END}")
            if no_data_count > 0:
                no_data_percent = get_percentage(no_data_count, total_streams)
                print(f"  âŒ ç›®æ ‡è¡¨æœªç”Ÿæˆæ•°æ®: {no_data_count} ({no_data_percent}) ")
                print(f"    å¯èƒ½åŸå› : æµè®¡ç®—åˆšå¯åŠ¨ã€æµé€»è¾‘é—®é¢˜")
            if error_count > 0:
                error_percent = get_percentage(error_count, total_streams)
                print(f"  ğŸ’¥ ç›®æ ‡è¡¨ä¸å­˜åœ¨: {error_count} ({error_percent}) ")
                print(f"    å¯èƒ½åŸå› : æµåˆ›å»ºå¤±è´¥ã€ç›®æ ‡æ•°æ®åº“é—®é¢˜")
           
        # âœ… æ›´æ–°å»¶è¿Ÿç­‰çº§å‚è€ƒä¿¡æ¯ï¼Œæ˜¾ç¤ºåŠ¨æ€é˜ˆå€¼èŒƒå›´
        print(f"\n{c.CYAN}å»¶è¿Ÿç­‰çº§å‚è€ƒ (åŸºäºå„æµåŠ¨æ€çª—å£é—´éš”):{c.END}")
        if dynamic_threshold_info:
            threshold_values = [info['threshold_ms'] for info in dynamic_threshold_info.values()]
            min_threshold = min(threshold_values)
            max_threshold = max(threshold_values)
            avg_threshold = sum(threshold_values) / len(threshold_values)
            
            print(f"  åŠ¨æ€é˜ˆå€¼èŒƒå›´: {format_delay_time(min_threshold)} - {format_delay_time(max_threshold)} (å¹³å‡: {format_delay_time(avg_threshold)})")
            print(f"  ğŸŸ¢ ä¼˜ç§€: < 0.1å€çª—å£é—´éš”")
            print(f"  ğŸŸ¢ è‰¯å¥½: 0.1-0.5å€çª—å£é—´éš”")
            print(f"  ğŸŸ¡ æ­£å¸¸: 0.5-1å€çª—å£é—´éš”")
            print(f"  ğŸŸ¡ è½»å¾®å»¶è¿Ÿ: 1-6å€çª—å£é—´éš”")
            print(f"  ğŸŸ  æ˜æ˜¾å»¶è¿Ÿ: 6-30å€çª—å£é—´éš”")
            print(f"  ğŸ”´ ä¸¥é‡å»¶è¿Ÿ: >30å€çª—å£é—´éš”")
        else:
            print(f"  âš ï¸  åŠ¨æ€é˜ˆå€¼è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨å›ºå®šé˜ˆå€¼: {format_delay_time(self.max_delay_threshold)}")
        
        print(f"  ğŸ“Š ç›®æ ‡è¡¨æ— æ•°æ®: æµè®¡ç®—å°šæœªç”Ÿæˆç»“æœæˆ–è€…æµçŠ¶æ€å¼‚å¸¸")
        print(f"  ğŸ’¥ ç›®æ ‡è¡¨ä¸å­˜åœ¨: æµåˆ›å»ºå¤±è´¥æˆ–è€…æµçŠ¶æ€å¼‚å¸¸")
        print(f"\n{c.CYAN}ç›‘æ§é¢‘ç‡: æ¯ {self.delay_check_interval}ç§’ æ£€æŸ¥ä¸€æ¬¡å»¶è¿ŸçŠ¶æ€{c.END}")
        
        # çŠ¶æ€è¯„ä¼°
        healthy_count = ok_count  # åªæœ‰æ­£å¸¸çŠ¶æ€æ‰ç®—å¥åº·
        problem_count = lagging_count + error_count # å»¶è¿Ÿã€é”™è¯¯éƒ½æ˜¯é—®é¢˜
        pending_count = no_data_count  # æ— æ•°æ®çŠ¶æ€
        
        # è­¦å‘Šå’Œå»ºè®®ä¿¡æ¯
        if error_count > 0:
            # æœ‰ä¸¥é‡é—®é¢˜ï¼ˆé”™è¯¯ï¼‰
            error_percent = get_percentage(error_count, total_streams)
            warning_icon = "ğŸš¨" if Colors.supports_color() else "âš "
            print_error(f"{warning_icon} ä¸¥é‡: {error_count} ä¸ªæµå­˜åœ¨é”™è¯¯é—®é¢˜ ({error_percent})!")
            
        if no_data_count > 0:
            # æœ‰ä¸¥é‡é—®é¢˜ï¼Œæ— æ•°æ®é—®é¢˜
            no_data_percent = get_percentage(no_data_count, total_streams)
            warning_icon = "ğŸ“Š" if Colors.supports_color() else "â—‹"
            print_warning(f"{warning_icon} ä¸¥é‡: {no_data_count} ä¸ªæµç›®æ ‡è¡¨æ— æ•°æ® ({no_data_percent}) - å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´ç”Ÿæˆç»“æœ")
            
        if lagging_count > 0:
            # æœ‰å»¶è¿Ÿé—®é¢˜
            lag_percent = get_percentage(lagging_count, total_streams)
            warning_icon = "âš ï¸" if Colors.supports_color() else "âš "
            print_warning(f"{warning_icon} å»¶è¿Ÿ: {lagging_count} ä¸ªæµè®¡ç®—å‡ºç°å»¶è¿Ÿ ({lag_percent})!")
            
        # æ•´ä½“çŠ¶æ€è¯„ä¼°
        if error_count > 0:
            # å­˜åœ¨ä¸¥é‡é—®é¢˜
            advice_icon = "ğŸš¨" if Colors.supports_color() else "ğŸ’¡"
            error_ratio = error_count / total_streams * 100
            print_error(f"{advice_icon} å‘Šè­¦: {error_ratio:.1f}% çš„æµå­˜åœ¨ä¸¥é‡é”™è¯¯ - éœ€è¦ç«‹å³æ£€æŸ¥æµåˆ›å»ºé€»è¾‘")
        elif no_data_count == total_streams:
            # å…¨éƒ¨æ— æ•°æ®
            advice_icon = "ğŸ“Š" if Colors.supports_color() else "â—‹"
            print_warning(f"{advice_icon} æç¤º: æ‰€æœ‰æµç›®æ ‡è¡¨éƒ½æ— æ•°æ® - å¯èƒ½æµè®¡ç®—åˆšå¯åŠ¨ï¼Œæˆ–è€…ä¸€ç›´æœªç”Ÿæˆæ•°æ®")
        elif lagging_count > healthy_count and no_data_count == 0:
            # å»¶è¿Ÿé—®é¢˜è¾ƒå¤šä¸”æ— å¾…å¤„ç†
            advice_icon = "ğŸ’¡" if Colors.supports_color() else "ğŸ’¡"
            lag_ratio = lagging_count / total_streams * 100
            print_error(f"{advice_icon} è­¦å‘Š: {lag_ratio:.1f}% çš„æµå‡ºç°å»¶è¿Ÿ - å»ºè®®ä¼˜åŒ–æ€§èƒ½")
        elif lagging_count > 0 and no_data_count == 0:
            # å°‘é‡å»¶è¿Ÿä¸”æ— å¾…å¤„ç†
            tip_icon = "ğŸ’¡" if Colors.supports_color() else "ğŸ’¡"
            lag_ratio = lagging_count / total_streams * 100
            print_warning(f"{tip_icon} æç¤º: {lag_ratio:.1f}% çš„æµå‡ºç°å»¶è¿Ÿ - æŒç»­å…³æ³¨")
        elif healthy_count == total_streams:
            # å…¨éƒ¨æ­£å¸¸
            success_icon = "âœ…" if Colors.supports_color() else "âœ“"
            print_success(f"{success_icon} çŠ¶æ€ä¼˜ç§€: æ‰€æœ‰æµè®¡ç®—éƒ½æ­£å¸¸è¿è¡Œ (100%)")
        elif no_data_count > 0 and error_count == 0 and lagging_count == 0:
            # åªæœ‰æ— æ•°æ®é—®é¢˜ï¼Œæ²¡æœ‰å…¶ä»–é—®é¢˜
            pending_icon = "ğŸ“Š" if Colors.supports_color() else "â—‹"
            no_data_ratio = no_data_count / total_streams * 100
            print_info(f"{pending_icon} çŠ¶æ€: {no_data_ratio:.1f}% çš„æµç›®æ ‡è¡¨æ— æ•°æ®ï¼Œ{(healthy_count/total_streams*100):.1f}% æ­£å¸¸è¿è¡Œ")
            
            
        # è°ƒä¼˜å»ºè®®
        total_problem_count = problem_count + error_count  
        if total_problem_count > 0:
            print(f"\n{c.CYAN}ğŸ’¡ é—®é¢˜åˆ†æä¸å»ºè®®:{c.END}")
            
            if error_count > 0:
                print(f"  ğŸ”´ ç›®æ ‡è¡¨ä¸å­˜åœ¨é—®é¢˜:")
                print(f"    - {error_count} ä¸ªæµçš„ç›®æ ‡è¡¨æ— æ³•è®¿é—®")
                print(f"    - å¯èƒ½åŸå› : æµåˆ›å»ºå¤±è´¥ã€ç›®æ ‡è¡¨è¿˜æœªç”Ÿæˆ")
                
            if no_data_count > 0:
                print(f"  âŒ ç›®æ ‡è¡¨æ— æ•°æ®é—®é¢˜:")
                print(f"    - {no_data_count} ä¸ªæµçš„ç›®æ ‡è¡¨å­˜åœ¨ä½†æ— æ•°æ®")
                print(f"    - å¯èƒ½åŸå› : æµè®¡ç®—é€»è¾‘é—®é¢˜ã€æºæ•°æ®ä¸åŒ¹é…ã€æµæœªå¯åŠ¨")
                print(f"    - å»ºè®®: æ£€æŸ¥æµçŠ¶æ€ã€éªŒè¯æºæ•°æ®ã€æ£€æŸ¥æµè®¡ç®—é€»è¾‘")
                
            if severe_delay_count > 0:
                severe_ratio = severe_delay_count / total_streams * 100
                print(f"  ğŸ”´ ä¸¥é‡å»¶è¿Ÿé—®é¢˜:")
                print(f"    - {severe_delay_count} ä¸ªæµå­˜åœ¨ä¸¥é‡å»¶è¿Ÿ ({severe_ratio:.1f}%)")
                print(f"    - å»ºè®®: ç«‹å³æ£€æŸ¥ç³»ç»Ÿèµ„æºã€ä¼˜åŒ–æµè®¡ç®—é€»è¾‘")
                
            if obvious_delay_count > 0:
                obvious_ratio = obvious_delay_count / total_streams * 100
                print(f"  ğŸŸ  æ˜æ˜¾å»¶è¿Ÿé—®é¢˜:")
                print(f"    - {obvious_delay_count} ä¸ªæµå­˜åœ¨æ˜æ˜¾å»¶è¿Ÿ ({obvious_ratio:.1f}%)")
                print(f"    - å»ºè®®: æ£€æŸ¥ç³»ç»Ÿè´Ÿè½½ã€è€ƒè™‘å¢åŠ èµ„æº")
                
            print(f"  ğŸ“Š ç³»ç»Ÿè°ƒä¼˜å»ºè®®:")
            if problem_count > total_streams * 0.5:
                print(f"    - è¶…è¿‡ä¸€åŠçš„æµå­˜åœ¨é—®é¢˜ï¼Œå»ºè®®å…¨é¢æ£€æŸ¥ç³»ç»Ÿé…ç½®")
            print(f"    - å½“å‰å†™å…¥é—´éš”: {self.real_time_batch_sleep}sï¼Œå¯é€‚å½“å¢åŠ ä»¥å‡è½»å‹åŠ›")
            print(f"    - å¯è°ƒæ•´ --delay-check-interval å‚æ•°æ”¹å˜ç›‘æ§é¢‘ç‡")
            

    def analyze_delay_cleanup_statistics(self, delay_log_file, max_delay_threshold):
        """åˆ†æå»¶è¿Ÿæ¸…ç†ç»Ÿè®¡
        
        ä»å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶ä¸­æå–æŒ‰æ—¶é—´é¡ºåºçš„å»¶è¿Ÿç­‰çº§ï¼Œ
        æ‰¾åˆ°æœ€åè¿ç»­çš„è‰¯å¥½çŠ¶æ€åŒºé—´ï¼Œç”Ÿæˆæ¸…ç†åçš„ç»Ÿè®¡
        
        Args:
            delay_log_file: å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶è·¯å¾„
            max_delay_threshold: æœ€å¤§å»¶è¿Ÿé˜ˆå€¼(æ¯«ç§’)
            
        Returns:
            dict: åŒ…å«åŸå§‹ç»Ÿè®¡å’Œæ¸…ç†åç»Ÿè®¡çš„ç»“æœ
        """
        try:
            if not os.path.exists(delay_log_file):
                print(f"å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨: {delay_log_file}")
                return None
                
            # è¯»å–å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶
            with open(delay_log_file, 'r', encoding='utf-8') as f:
                content = f.read()
                
            # æå–æŒ‰æ—¶é—´é¡ºåºçš„å»¶è¿Ÿè®°å½•
            delay_records = []
            
            import re
            
            # è§£ææ¯æ¬¡æ£€æŸ¥çš„å»¶è¿Ÿç­‰çº§
            # åŒ¹é…æ¨¡å¼ï¼šæ£€æŸ¥æ—¶é—´ + å»¶è¿Ÿç­‰çº§
            check_pattern = r'ç¬¬\s+(\d+)\s+æ¬¡æ£€æŸ¥.*?æ£€æŸ¥æ—¶é—´:\s*([^n]+)'
            delay_level_pattern = r'å»¶è¿Ÿç­‰çº§:\s*([^n]+)'
            
            # æŒ‰æ£€æŸ¥æ¬¡æ•°åˆ†ç»„æå–å»¶è¿Ÿç­‰çº§
            check_sections = re.split(r'ç¬¬\s+\d+\s+æ¬¡æ£€æŸ¥', content)
            
            for i, section in enumerate(check_sections[1:], 1):  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºæ®µ
                # ä»æ¯ä¸ªæ£€æŸ¥æ®µè½ä¸­æå–å»¶è¿Ÿç­‰çº§
                delay_levels = re.findall(delay_level_pattern, section)
                
                if delay_levels:
                    # ç»Ÿè®¡è¿™æ¬¡æ£€æŸ¥ä¸­å„ä¸ªå»¶è¿Ÿç­‰çº§çš„æ•°é‡
                    level_counts = {}
                    for level in delay_levels:
                        level = level.strip()
                        level_counts[level] = level_counts.get(level, 0) + 1
                    
                    # ç¡®å®šè¿™æ¬¡æ£€æŸ¥çš„ä¸»è¦å»¶è¿Ÿç­‰çº§
                    # è§„åˆ™ï¼šæŒ‰ä¼˜å…ˆçº§é€‰æ‹©ï¼ˆä¸¥é‡é—®é¢˜ä¼˜å…ˆï¼‰
                    main_level = self._determine_main_delay_level(level_counts)
                    
                    delay_records.append({
                        'check_number': i,
                        'main_level': main_level,
                        'level_counts': level_counts,
                        'section_content': section[:200] + '...' if len(section) > 200 else section
                    })
            
            #print(f"è°ƒè¯•: ä»å»¶è¿Ÿæ—¥å¿—ä¸­æå–åˆ° {len(delay_records)} æ¬¡æ£€æŸ¥è®°å½•")
            for record in delay_records[:3]:  # æ˜¾ç¤ºå‰3æ¡ä½œä¸ºè°ƒè¯•
                print(f"  æ£€æŸ¥{record['check_number']}: ä¸»è¦ç­‰çº§={record['main_level']}, è¯¦æƒ…={record['level_counts']}")
            
            if len(delay_records) < 3:
                print("å»¶è¿Ÿè®°å½•æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œæ¸…ç†åˆ†æ")
                return None
                
            # è®¡ç®—åŸå§‹ç»Ÿè®¡
            original_stats = self._calculate_original_delay_stats(delay_records)
            
            # è®¡ç®—æ¸…ç†åç»Ÿè®¡
            cleanup_stats = self._calculate_cleanup_delay_stats(delay_records)
            
            return {
                'original_stats': original_stats,
                'cleanup_stats': cleanup_stats,
                'total_checks': len(delay_records),
                'cleanup_removed_checks': len(delay_records) - cleanup_stats['included_checks'],
                'delay_records': delay_records
            }
            
        except Exception as e:
            print(f"åˆ†æå»¶è¿Ÿæ¸…ç†ç»Ÿè®¡æ—¶å‡ºé”™: {str(e)}")
            import traceback
            print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
            return None

    def _calculate_cleanup_delay_stats(self, delay_records):
        """è®¡ç®—æ¸…ç†åå»¶è¿Ÿç»Ÿè®¡
        
        ä»å»¶è¿Ÿè®°å½•ä¸­æå–æŒ‰æ—¶é—´é¡ºåºçš„å»¶è¿Ÿç­‰çº§ï¼Œ
        æ‰¾åˆ°æœ€åè¿ç»­çš„è‰¯å¥½çŠ¶æ€åŒºé—´ï¼Œç”Ÿæˆæ¸…ç†åçš„ç»Ÿè®¡
        
        Args:
            delay_records: å»¶è¿Ÿè®°å½•åˆ—è¡¨
            
        Returns:
            dict: æ¸…ç†åçš„ç»Ÿè®¡ç»“æœ
        """
        try:
            # å®ç°æ¸…ç†é€»è¾‘ï¼šæ‰¾åˆ°æœ€åè¿ç»­çš„è‰¯å¥½çŠ¶æ€åŒºé—´
            good_levels = {'ä¼˜ç§€', 'è‰¯å¥½', 'æ­£å¸¸'}
            
            # æ‰¾åˆ°æœ€åä¸€ä¸ªè‰¯å¥½çŠ¶æ€çš„å¼€å§‹ä½ç½®
            cleanup_start_index = 0
            last_good_sequence_start = 0
            
            # ä»åå¾€å‰æ‰«æï¼Œæ‰¾åˆ°æœ€åä¸€ä¸ªè¿ç»­è‰¯å¥½çŠ¶æ€çš„å¼€å§‹
            for i in range(len(delay_records) - 1, -1, -1):
                if delay_records[i]['main_level'] in good_levels:
                    # æ‰¾åˆ°ä¸€ä¸ªè‰¯å¥½çŠ¶æ€ï¼Œç»§ç»­å¾€å‰æ‰¾è¿ç»­çš„è‰¯å¥½çŠ¶æ€
                    good_sequence_start = i
                    for j in range(i - 1, -1, -1):
                        if delay_records[j]['main_level'] in good_levels:
                            good_sequence_start = j
                        else:
                            break
                    
                    # å¦‚æœè¿™ä¸ªè¿ç»­åºåˆ—é•¿åº¦è¶³å¤Ÿï¼ˆè‡³å°‘3ä¸ªï¼‰ï¼Œä½¿ç”¨å®ƒ
                    if i - good_sequence_start + 1 >= 3:
                        cleanup_start_index = good_sequence_start
                        break
            
            # å¦‚æœæ²¡æ‰¾åˆ°è¶³å¤Ÿé•¿çš„è‰¯å¥½åºåˆ—ï¼Œä½¿ç”¨åä¸€åŠæ•°æ®
            if cleanup_start_index == 0:
                cleanup_start_index = len(delay_records) // 2
            
            # å–æ¸…ç†åçš„è®°å½•
            cleanup_records = delay_records[cleanup_start_index:]
            
            # ç»Ÿè®¡æ¸…ç†åçš„å»¶è¿Ÿç­‰çº§
            level_counts = {
                'ä¼˜ç§€': 0, 'è‰¯å¥½': 0, 'æ­£å¸¸': 0,
                'è½»å¾®å»¶è¿Ÿ': 0, 'æ˜æ˜¾å»¶è¿Ÿ': 0, 'ä¸¥é‡å»¶è¿Ÿ': 0,
                'ç›®æ ‡è¡¨æ— æ•°æ®': 0, 'ç›®æ ‡è¡¨ä¸å­˜åœ¨': 0
            }
            
            for record in cleanup_records:
                main_level = record['main_level']
                if main_level in level_counts:
                    level_counts[main_level] += 1
                else:
                    level_counts['æœªçŸ¥'] = level_counts.get('æœªçŸ¥', 0) + 1
            
            return {
                'total_checks': len(delay_records),
                'included_checks': len(cleanup_records),
                'excluded_checks': len(delay_records) - len(cleanup_records),
                'cleanup_start_index': cleanup_start_index,
                'level_counts': level_counts
            }
            
        except Exception as e:
            print(f"è®¡ç®—æ¸…ç†åç»Ÿè®¡æ—¶å‡ºé”™: {str(e)}")
            return {
                'total_checks': len(delay_records),
                'included_checks': len(delay_records),
                'excluded_checks': 0,
                'cleanup_start_index': 0,
                'level_counts': {'æœªçŸ¥': len(delay_records)}
            }
            
        
    def _determine_main_delay_level(self, level_counts):
        """ç¡®å®šä¸€æ¬¡æ£€æŸ¥çš„ä¸»è¦å»¶è¿Ÿç­‰çº§
        
        Args:
            level_counts: å»¶è¿Ÿç­‰çº§è®¡æ•°å­—å…¸
            
        Returns:
            str: ä¸»è¦å»¶è¿Ÿç­‰çº§
        """
        if not level_counts:
            return "æœªçŸ¥"
        
        # å®šä¹‰ä¼˜å…ˆçº§ï¼ˆä¸¥é‡é—®é¢˜ä¼˜å…ˆï¼‰
        priority_order = [
            'ç›®æ ‡è¡¨ä¸å­˜åœ¨',
            'ç›®æ ‡è¡¨æ— æ•°æ®', 
            'ä¸¥é‡å»¶è¿Ÿ',
            'æ˜æ˜¾å»¶è¿Ÿ',
            'è½»å¾®å»¶è¿Ÿ',
            'æ­£å¸¸',
            'è‰¯å¥½',
            'ä¼˜ç§€'
        ]
        
        # æŒ‰ä¼˜å…ˆçº§æŸ¥æ‰¾å­˜åœ¨çš„ç­‰çº§
        for level in priority_order:
            if level in level_counts and level_counts[level] > 0:
                return level
        
        # å¦‚æœéƒ½æ²¡æ‰¾åˆ°ï¼Œè¿”å›æ•°é‡æœ€å¤šçš„ç­‰çº§
        return max(level_counts.items(), key=lambda x: x[1])[0]

    def _calculate_original_delay_stats(self, delay_records):
        """è®¡ç®—åŸå§‹å»¶è¿Ÿç»Ÿè®¡"""
        total_checks = len(delay_records)
        level_counts = {
            'ä¼˜ç§€': 0, 'è‰¯å¥½': 0, 'æ­£å¸¸': 0,
            'è½»å¾®å»¶è¿Ÿ': 0, 'æ˜æ˜¾å»¶è¿Ÿ': 0, 'ä¸¥é‡å»¶è¿Ÿ': 0,
            'ç›®æ ‡è¡¨æ— æ•°æ®': 0, 'ç›®æ ‡è¡¨ä¸å­˜åœ¨': 0
        }
        
        # ç»Ÿè®¡æ‰€æœ‰æ£€æŸ¥çš„ä¸»è¦ç­‰çº§
        for record in delay_records:
            main_level = record['main_level']
            if main_level in level_counts:
                level_counts[main_level] += 1
            else:
                # å¤„ç†å¯èƒ½çš„å…¶ä»–ç­‰çº§
                level_counts['æœªçŸ¥'] = level_counts.get('æœªçŸ¥', 0) + 1
        
        return {
            'total_checks': total_checks,
            'level_counts': level_counts,
            'included_checks': total_checks
        }
    
    def check_stream_status(self, stream_names, max_wait_time=60):
        """æ£€æŸ¥æµçš„è¿è¡ŒçŠ¶æ€
        
        Args:
            stream_names: æµåç§°åˆ—è¡¨æˆ–å•ä¸ªæµåç§°
            max_wait_time: æœ€å¤§ç­‰å¾…æ—¶é—´(ç§’)ï¼Œé»˜è®¤60ç§’
            
        Returns:
            bool: æ‰€æœ‰æµéƒ½è¿è¡ŒæˆåŠŸè¿”å›Trueï¼Œå¦åˆ™è¿”å›False
        """
        if isinstance(stream_names, str):
            stream_names = [stream_names]
        
        print(f"å¼€å§‹æ£€æŸ¥æµçŠ¶æ€ï¼Œé¢„æœŸæµæ•°é‡: {len(stream_names)}")
        print(f"é¢„æœŸæµåç§°: {', '.join(stream_names)}")
        
        start_time = time.time()
        check_interval = 5  # æ¯5ç§’æ£€æŸ¥ä¸€æ¬¡
        
        while time.time() - start_time < max_wait_time:
            try:
                conn, cursor = self.get_connection()
                
                # æŸ¥è¯¢æ‰€æœ‰æµçš„çŠ¶æ€
                cursor.execute("select stream_name, status, sql from information_schema.ins_streams")
                streams = cursor.fetchall()
                
                cursor.close()
                conn.close()
                
                # æ£€æŸ¥é¢„æœŸçš„æµæ˜¯å¦éƒ½åœ¨è¿è¡Œ
                found_streams = {}
                for stream in streams:
                    stream_name = stream[0]
                    status = stream[1]
                    
                    # æ£€æŸ¥æ˜¯å¦æ˜¯æˆ‘ä»¬åˆ›å»ºçš„æµ
                    for expected_name in stream_names:
                        # å»æ‰å¯èƒ½çš„æ•°æ®åº“å‰ç¼€è¿›è¡ŒåŒ¹é…
                        clean_expected = expected_name.split('.')[-1]
                        clean_actual = stream_name.split('.')[-1]
                        
                        if clean_expected == clean_actual:
                            found_streams[expected_name] = {
                                'actual_name': stream_name,
                                'status': status,
                                'sql': stream[2]
                            }
                
                # æ£€æŸ¥ç»“æœ
                running_count = 0
                not_found = []
                not_running = []
                
                for expected_name in stream_names:
                    if expected_name not in found_streams:
                        not_found.append(expected_name)
                    else:
                        stream_info = found_streams[expected_name]
                        if stream_info['status'] == 'Running':
                            running_count += 1
                        else:
                            not_running.append({
                                'name': expected_name,
                                'status': stream_info['status']
                            })
                
                # æ‰“å°å½“å‰çŠ¶æ€
                elapsed = time.time() - start_time
                print(f"[{elapsed:.0f}s] çŠ¶æ€æ£€æŸ¥: è¿è¡Œä¸­({running_count}) æœªæ‰¾åˆ°({len(not_found)}) éè¿è¡Œ({len(not_running)})")
                
                if not_found:
                    print(f"  æœªæ‰¾åˆ°çš„æµ: {', '.join(not_found)}")
                
                if not_running:
                    for item in not_running:
                        print(f"  æµ {item['name']} çŠ¶æ€: {item['status']}")
                
                # æ£€æŸ¥æ˜¯å¦å…¨éƒ¨æˆåŠŸ
                if running_count == len(stream_names):
                    print(f"âœ… æ‰€æœ‰ {len(stream_names)} ä¸ªæµéƒ½å·²æˆåŠŸè¿è¡Œ!")
                    return True
                
                # å¦‚æœæœ‰æµå¤„äºé”™è¯¯çŠ¶æ€ï¼Œç›´æ¥é€€å‡º
                error_states = ['Error', 'Failed', 'Stopped']
                for expected_name in stream_names:
                    if expected_name in found_streams:
                        status = found_streams[expected_name]['status']
                        if status in error_states:
                            print(f"âŒ æµ {expected_name} å¤„äºé”™è¯¯çŠ¶æ€: {status}")
                            return False
                
                # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                print(f"  ç­‰å¾… {check_interval} ç§’åé‡æ–°æ£€æŸ¥...")
                time.sleep(check_interval)
                
            except Exception as e:
                print(f"æ£€æŸ¥æµçŠ¶æ€æ—¶å‡ºé”™: {str(e)}")
                time.sleep(check_interval)
        
        # è¶…æ—¶
        print(f"âŒ ç­‰å¾…è¶…æ—¶({max_wait_time}ç§’)ï¼")
        print(f"æœ€ç»ˆçŠ¶æ€: è¿è¡Œä¸­({running_count}/{len(stream_names)})")
        return False

    def extract_stream_names_from_sql_simple(self, sql_templates):
        """ä»SQLæ¨¡æ¿ä¸­æå–æµåç§° - ç®€åŒ–ç‰ˆæœ¬
        
        Args:
            sql_templates: SQLæ¨¡æ¿å­—ç¬¦ä¸²æˆ–å­—å…¸
            
        Returns:
            list: æµåç§°åˆ—è¡¨
        """
        stream_names = []
        
        try:
            if isinstance(sql_templates, dict):
                for sql_template in sql_templates.values():
                    match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                    if match:
                        full_name = match.group(1)
                        # åªä¿ç•™æµåç§°éƒ¨åˆ†ï¼Œå»æ‰æ•°æ®åº“å‰ç¼€
                        stream_name = full_name.split('.')[-1]
                        stream_names.append(stream_name)
            else:
                match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                if match:
                    full_name = match.group(1)
                    stream_name = full_name.split('.')[-1]
                    stream_names.append(stream_name)
        except Exception as e:
            print(f"æå–æµåç§°æ—¶å‡ºé”™: {str(e)}")
        
        return stream_names             

    def start_stream_delay_monitor(self):
        """å¯åŠ¨æµå»¶è¿Ÿç›‘æ§çº¿ç¨‹"""
        if not self.check_stream_delay:
            return None
            
        def delay_monitor():
            """å»¶è¿Ÿç›‘æ§çº¿ç¨‹å‡½æ•°"""
            print(f"å¯åŠ¨æµå»¶è¿Ÿç›‘æ§ (é—´éš”: {self.delay_check_interval}ç§’)")
            print(f"å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶: {self.delay_log_file}")
            
            # ç¡®ä¿å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶çš„ç›®å½•å­˜åœ¨
            delay_log_dir = os.path.dirname(self.delay_log_file)
            if not os.path.exists(delay_log_dir):
                try:
                    os.makedirs(delay_log_dir, exist_ok=True)
                    print(f"åˆ›å»ºå»¶è¿Ÿæ—¥å¿—ç›®å½•: {delay_log_dir}")
                except Exception as e:
                    print(f"åˆ›å»ºå»¶è¿Ÿæ—¥å¿—ç›®å½•å¤±è´¥: {str(e)}")
                    return
            
            # åˆå§‹åŒ–æ—¥å¿—æ–‡ä»¶
            try:
                with open(self.delay_log_file, 'w') as f:
                    f.write(f"TDengine æµè®¡ç®—å»¶è¿Ÿç›‘æ§æ—¥å¿—\n")
                    f.write(f"å¼€å§‹æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    f.write(f"æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {self.max_delay_threshold}ms\n")
                    f.write(f"æ£€æŸ¥é—´éš”: {self.delay_check_interval}ç§’\n")
                    f.write(f"æ•°æ®å†™å…¥é—´éš”: {self.real_time_batch_sleep}ç§’\n") 
                    f.write(f"æ¯è½®å†™å…¥è®°å½•æ•°: {self.real_time_batch_rows}\n")
                    f.write(f"å­è¡¨æ•°é‡: {self.table_count}\n")
                    f.write(f"è¿è¡Œæ—¶é—´: {self.runtime}åˆ†é’Ÿ\n")
                    f.write(f"SQLç±»å‹: {self.sql_type}\n")
                    f.write(f"="*80 + "\n")
            except Exception as e:
                print(f"åˆå§‹åŒ–å»¶è¿Ÿæ—¥å¿—æ–‡ä»¶å¤±è´¥: {str(e)}")
            
            start_time = time.time()
            check_count = 0
            
            # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©æµåˆ›å»ºå®Œæˆ
            initial_wait = 15  # ç­‰å¾…15ç§’
            print(f"ç­‰å¾… {initial_wait} ç§’è®©æµè®¡ç®—å¯åŠ¨...")
            time.sleep(initial_wait)
        
            while time.time() - start_time < self.runtime * 60:
                check_count += 1
                try:
                    print(f"\n--- ç¬¬ {check_count} æ¬¡å»¶è¿Ÿæ£€æŸ¥ ---")
                    
                    # è®°å½•æ£€æŸ¥å¼€å§‹
                    with open(self.delay_log_file, 'a') as f:
                        f.write(f"\nç¬¬ {check_count} æ¬¡æ£€æŸ¥å¼€å§‹: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                    
                    # æ‰§è¡Œå»¶è¿Ÿæ£€æŸ¥
                    delay_results = self.check_stream_computation_delay()
                    
                    if delay_results:
                        # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
                        self.log_stream_delay_results(delay_results)
                        
                        # æ‰“å°æ‘˜è¦
                        self.print_stream_delay_summary(delay_results)
                    else:
                        error_msg = f"ç¬¬ {check_count} æ¬¡æ£€æŸ¥å¤±è´¥: æ— æ³•è·å–å»¶è¿Ÿç»“æœ"
                        print(error_msg)
                        with open(self.delay_log_file, 'a') as f:
                            f.write(f"{error_msg}\n")
                    
                    # ç­‰å¾…ä¸‹æ¬¡æ£€æŸ¥
                    print(f"ç­‰å¾… {self.delay_check_interval} ç§’åè¿›è¡Œä¸‹æ¬¡æ£€æŸ¥...")
                    time.sleep(self.delay_check_interval)
                    
                except Exception as e:
                    error_msg = f"ç¬¬ {check_count} æ¬¡å»¶è¿Ÿç›‘æ§å‡ºé”™: {str(e)}"
                    print(error_msg)
                    with open(self.delay_log_file, 'a') as f:
                        f.write(f"{error_msg}\n")
                    time.sleep(self.delay_check_interval)
            
            final_msg = f"æµå»¶è¿Ÿç›‘æ§ç»“æŸï¼Œå…±æ‰§è¡Œäº† {check_count} æ¬¡æ£€æŸ¥"
            print(final_msg)
            try:
                with open(self.delay_log_file, 'a') as f:
                    f.write(f"\n{final_msg}\n")
                    f.write(f"ç»“æŸæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
            except Exception as e:
                print(f"å†™å…¥å»¶è¿Ÿæ—¥å¿—ç»“æŸä¿¡æ¯å¤±è´¥: {str(e)}")
        
        # åˆ›å»ºå¹¶å¯åŠ¨ç›‘æ§çº¿ç¨‹
        monitor_thread = threading.Thread(target=delay_monitor, name="StreamDelayMonitor")
        monitor_thread.daemon = True
        monitor_thread.start()
        
        return monitor_thread
            
    def do_test_stream_with_realtime_data_old(self):
        self.prepare_env()
        self.prepare_source_from_data()
        self.insert_source_from_data()
        
        conn = taos.connect(
            host=self.host,
            user=self.user,
            password=self.passwd,
            config=self.conf
        )
        cursor = conn.cursor()

        try:
            # è¿è¡Œsource_fromçš„æ•°æ®ç”Ÿæˆ
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)
            
            # åˆ›å»ºstream_toæ•°æ®åº“
            if not self.create_database('stream_to'):
                raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
            
            time.sleep(5)
            print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")
            
            # ç­‰å¾…æ•°æ®å‡†å¤‡å°±ç»ª
            if not self.wait_for_data_ready(cursor, self.table_count, self.histroy_rows):
                print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
                return
            
            
            # âœ… è®¡ç®—é¢„çƒ­æ—¶é—´å’Œæµåˆ›å»ºå»¶è¿Ÿ
            if hasattr(self, 'monitor_warm_up_time') and self.monitor_warm_up_time is not None:
                warm_up_time = self.monitor_warm_up_time
                stream_creation_delay = self.monitor_warm_up_time  # æµåˆ›å»ºå»¶è¿Ÿç­‰äºé¢„çƒ­æ—¶é—´
                print(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
                print(f"âœ¨ æµåˆ›å»ºå»¶è¿Ÿ: {stream_creation_delay}ç§’ (å°†åœ¨é¢„çƒ­ç»“æŸååˆ›å»ºæµ)")
            else:
                warm_up_time = 60 if self.runtime >= 2 else 0
                stream_creation_delay = warm_up_time  # æµåˆ›å»ºå»¶è¿Ÿç­‰äºé¢„çƒ­æ—¶é—´
                if warm_up_time > 0:
                    print(f"ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
                    print(f"âœ¨ æµåˆ›å»ºå»¶è¿Ÿ: {stream_creation_delay}ç§’ (å°†åœ¨é¢„çƒ­ç»“æŸååˆ›å»ºæµ)")
                else:
                    print(f"è¿è¡Œæ—¶é—´è¾ƒçŸ­({self.runtime}åˆ†é’Ÿ)ï¼Œè·³è¿‡é¢„çƒ­ï¼Œç«‹å³åˆ›å»ºæµ")
                    
                    
            # è·å–æ–°è¿æ¥æ‰§è¡Œæµå¼æŸ¥è¯¢
            conn, cursor = self.get_connection()
            
            print("å¼€å§‹è¿æ¥æ•°æ®åº“")
            cursor.execute('use stream_from')
            
            # # æ‰§è¡Œæµå¼æŸ¥è¯¢
            # print(f"æ‰§è¡Œæµå¼æŸ¥è¯¢SQL:\n{self.stream_sql}")
            # cursor.execute(self.stream_sql)
            
            # è·å– SQL æ¨¡æ¿
            sql_templates = self.stream_sql 
            
            # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰¹é‡æ‰§è¡Œ
            if isinstance(sql_templates, dict):
                print("\n=== å¼€å§‹æ‰¹é‡åˆ›å»ºæµ ===")
                total_streams = len(sql_templates)
                success_count = 0
                failed_count = 0
                failed_errors = [] 
                
                for index, (sql_name, sql_template) in enumerate(sql_templates.items(), 1):
                    try:
                        print(f"\n[{index}/{total_streams}] åˆ›å»ºæµ: {sql_name}")
                        cursor.execute(sql_template)
                        
                        # æå–å®é™…çš„æµåç§°ï¼ˆä»SQLä¸­è§£æï¼‰
                        import re
                        match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                        actual_stream_name = match.group(1) if match else sql_name
                        
                        print(f"  SQLæµåç§°: {actual_stream_name}")
                        # æ˜¾ç¤ºå®Œæ•´çš„æµSQLè¯­å¥
                        print(f"  æµSQLè¯­å¥:")
                        # æ ¼å¼åŒ–SQLæ˜¾ç¤ºï¼Œå»æ‰å¤šä½™çš„ç©ºè¡Œå’Œç¼©è¿›
                        formatted_sql = '\n'.join([
                            '    ' + line.strip() 
                            for line in sql_template.strip().split('\n') 
                            if line.strip()
                        ])
                        print(formatted_sql)
                        
                        print(f"  æ‰§è¡Œåˆ›å»º...")
                        cursor.execute(sql_template)
                        success_count += 1
                        print(f"  âœ“ åˆ›å»ºæˆåŠŸ")
                        
                    except Exception as e:
                        failed_count += 1
                        
                        # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                        error_message = str(e)
                        tdengine_error = extract_stream_creation_error(error_message)
                        
                        print(f"æ‰§è¡Œé”™è¯¯: {tdengine_error}")
                        failed_errors.append(f"{sql_name}: {tdengine_error}")
                
                # æ˜¾ç¤ºæ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦
                print(f"\n=== æ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦ ===")
                print(f"æ€»æµæ•°: {total_streams}")
                print(f"æˆåŠŸ: {success_count}")
                print(f"å¤±è´¥: {failed_count}")
                print(f"æˆåŠŸç‡: {(success_count/total_streams*100):.1f}%")
            
                if failed_count > 0:
                    # æ„å»ºè¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                    error_summary = f"æµåˆ›å»ºå¤±è´¥ç»Ÿè®¡: {failed_count}/{total_streams} ä¸ªæµå¤±è´¥"
                    if len(failed_errors) > 0:
                        # åªä¿ç•™å‰5ä¸ªé”™è¯¯è¯¦æƒ…ï¼Œé¿å…ä¿¡æ¯è¿‡é•¿
                        error_details = "; ".join(failed_errors[:5])
                        if len(failed_errors) > 5:
                            error_details += f"; è¿˜æœ‰{len(failed_errors)-5}ä¸ªé”™è¯¯..."
                        error_summary += f" | é”™è¯¯è¯¦æƒ…: {error_details}"
                    print(f"âš ï¸  {failed_count} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                    
                    if success_count == 0:
                        # å¦‚æœæ‰€æœ‰æµéƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºå¼‚å¸¸
                        raise Exception(f"æ‰€æœ‰ {total_streams} ä¸ªæµåˆ›å»ºéƒ½å¤±è´¥äº†")
                    else:
                        # å¦‚æœéƒ¨åˆ†å¤±è´¥ï¼Œè®°å½•è­¦å‘Šä½†ç»§ç»­æ‰§è¡Œ
                        print(f"âš ï¸  æ³¨æ„: {failed_count}/{total_streams} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œå°†ä½¿ç”¨ {success_count} ä¸ªæˆåŠŸçš„æµç»§ç»­æµ‹è¯•")
                else:
                    print("æ‰€æœ‰æµåˆ›å»ºæˆåŠŸï¼")
                
            else:
                # å•ä¸ªæµçš„åˆ›å»º
                print("\n=== å¼€å§‹åˆ›å»ºæµ ===")
                
                # æå–å®é™…çš„æµåç§°
                import re
                match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                actual_stream_name = match.group(1) if match else "æœªçŸ¥æµåç§°"
                
                print(f"æµåç§°: {actual_stream_name}")
                print("æµSQLè¯­å¥:")
                print("-" * 80)
                print(sql_templates)
                print("-" * 80)
                
                try:
                    start_time = time.time()
                    cursor.execute(sql_templates)
                    create_time = time.time() - start_time
                    
                    print(f"âœ“ æµ {actual_stream_name} åˆ›å»ºå®Œæˆ! è€—æ—¶: {create_time:.2f}ç§’")
                    
                except Exception as e:
                    # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                    error_message = str(e)
                    tdengine_error = extract_stream_creation_error(error_message)
                    
                    print(f"realtime_dataæå–TDengineæ‰§è¡Œé”™è¯¯2: {tdengine_error}")
                    raise Exception(tdengine_error)
            
            print("æµå¼æŸ¥è¯¢å·²åˆ›å»º,å¼€å§‹ç›‘æ§ç³»ç»Ÿè´Ÿè½½")
            cursor.close()
            conn.close()
            
            # æ£€æŸ¥æµçŠ¶æ€
            if actual_stream_name:
                print(f"æ£€æŸ¥ {len(actual_stream_name)} ä¸ªæµçš„è¿è¡ŒçŠ¶æ€...")
                if not self.check_stream_status(actual_stream_name, max_wait_time=60):
                    raise Exception("æµåˆ›å»ºå¤±è´¥æˆ–æœªèƒ½æ­£å¸¸è¿è¡Œ")
                
                print("âœ… æ‰€æœ‰æµéƒ½å·²æ­£å¸¸è¿è¡Œ")
            else:
                print("âŒ æ²¡æœ‰æˆåŠŸåˆ›å»ºä»»ä½•æµ")
                raise Exception("æµåˆ›å»ºå¤±è´¥")
            
            # ç›‘æ§ç³»ç»Ÿè´Ÿè½½ - åŒæ—¶ç›‘æ§ä¸‰ä¸ªèŠ‚ç‚¹
            print(f"è°ƒè¯•: ä½¿ç”¨æ€§èƒ½æ–‡ä»¶è·¯å¾„: {self.perf_file}")
            
            # ä¼˜å…ˆä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å€¼
            if hasattr(self, 'monitor_warm_up_time') and self.monitor_warm_up_time is not None:
                # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº†é¢„çƒ­æ—¶é—´ï¼Œä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„å€¼
                warm_up_time = self.monitor_warm_up_time
                print(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
            else:
                # å¦‚æœç”¨æˆ·æœªè®¾ç½®ï¼Œä½¿ç”¨è‡ªåŠ¨è®¡ç®—é€»è¾‘
                warm_up_time = 60 if self.runtime >= 2 else 0
                if warm_up_time > 0:
                    print(f"ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’ (è¿è¡Œæ—¶é—´>=2åˆ†é’Ÿ)")
                else:
                    print(f"è¿è¡Œæ—¶é—´è¾ƒçŸ­({self.runtime}åˆ†é’Ÿ)ï¼Œè·³è¿‡é¢„çƒ­ç›´æ¥å¼€å§‹ç›‘æ§")
            
            if warm_up_time > 0:
                print(f"\n=== å¯åŠ¨æ€§èƒ½ç›‘æ§ (åŒ…å«{warm_up_time}ç§’é¢„çƒ­æœŸ) ===")
                print(f"ç›‘æ§é˜¶æ®µåˆ’åˆ†:")
                print(f"  ğŸ“Š é¢„çƒ­æœŸ (0-{warm_up_time}ç§’): çº¯æ•°æ®å†™å…¥ + ç³»ç»Ÿç¨³å®š")
                print(f"  ğŸ”„ æµè®¡ç®—æœŸ ({warm_up_time}ç§’-{self.runtime*60}ç§’): æ•°æ®å†™å…¥ + æµè®¡ç®—")
                print(f"æ€»è¿è¡Œæ—¶é—´: {self.runtime}åˆ†é’Ÿ")
            else:
                print(f"è¿è¡Œæ—¶é—´è¾ƒçŸ­({self.runtime}åˆ†é’Ÿ)ï¼Œè·³è¿‡é¢„çƒ­ç›´æ¥å¼€å§‹ç›‘æ§")
                
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file=self.perf_file,  # åŸºç¡€æ–‡ä»¶å,ä¼šè‡ªåŠ¨æ·»åŠ dnodeç¼–å·
                interval=self.monitor_interval,
                deployment_mode=self.deployment_mode,
                warm_up_time=warm_up_time
            )
                        
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
            monitor_thread = threading.Thread(
                target=loader.get_proc_status,
                name="TaosdMonitor"
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            print("å¼€å§‹ç›‘æ§taosdè¿›ç¨‹èµ„æºä½¿ç”¨æƒ…å†µ...")
            
            # å¯åŠ¨æµå»¶è¿Ÿç›‘æ§
            delay_monitor_thread = self.start_stream_delay_monitor()    
          
            try:            
                # å¾ªç¯æ‰§è¡Œå†™å…¥å’Œè®¡ç®—
                cycle_count = 0
                start_time = time.time()
                
                while True:
                    cycle_count += 1
                    print(f"\n=== å¼€å§‹ç¬¬ {cycle_count} è½®å†™å…¥å’Œè®¡ç®— ===")
                    
                    if cycle_count > 1:
                        # ä»ç¬¬äºŒè½®å¼€å§‹ï¼Œå…ˆå†™å…¥æ–°æ•°æ®
                        print(f"\nå†™å…¥æ–°ä¸€æ‰¹æµ‹è¯•æ•°æ® (æ¯è½® {self.real_time_batch_rows} æ¡è®°å½•)...")
                        
                        # åº”ç”¨å†™å…¥é—´éš”æ§åˆ¶
                        if self.real_time_batch_sleep > 0:
                            print(f"ç­‰å¾… {self.real_time_batch_sleep} ç§’åå¼€å§‹å†™å…¥æ•°æ®...")
                            time.sleep(self.real_time_batch_sleep)
                        
                        write_start_time = time.time()
                        
                        if not self.update_insert_config():
                            raise Exception("æ›´æ–°å†™å…¥é…ç½®å¤±è´¥")
                        
                        cmd = "taosBenchmark -f /tmp/stream_from_insertdata.json"
                        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)
                        
                        write_end_time = time.time()
                        write_duration = write_end_time - write_start_time
                        
                        if result.returncode != 0:
                            print(f"å†™å…¥æ•°æ®å¤±è´¥: {result.stderr}")
                            raise Exception("å†™å…¥æ–°æ•°æ®å¤±è´¥")
                        else:
                            total_records = self.table_count * self.real_time_batch_rows
                            write_speed = total_records / write_duration if write_duration > 0 else 0
                            print(f"æ•°æ®å†™å…¥å®Œæˆ: {total_records} æ¡è®°å½•, è€—æ—¶ {write_duration:.2f}ç§’, é€Ÿåº¦ {write_speed:.0f} æ¡/ç§’")
                            
                            # å¦‚æœè®¾ç½®äº†å†™å…¥é—´éš”ï¼Œæ˜¾ç¤ºå†™å…¥æ§åˆ¶ä¿¡æ¯
                            if self.real_time_batch_sleep > 0:
                                print(f"å†™å…¥é—´éš”æ§åˆ¶: {self.real_time_batch_sleep}ç§’ (ç”¨äºæ§åˆ¶æµè®¡ç®—å‹åŠ›)")
                                           
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶
                    if time.time() - start_time >= self.runtime * 60:
                        print(f"\n\nå·²è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶ ({self.runtime} åˆ†é’Ÿ)ï¼Œåœæ­¢æ‰§è¡Œ")
                        break
                        
                    print(f"\n=== ç¬¬ {cycle_count} è½®å¤„ç†å®Œæˆ ===")
             
            except Exception as e:
                print(f"æŸ¥è¯¢å†™å…¥æ“ä½œå‡ºé”™: {str(e)}")
            finally:
                cursor.close()
                conn.close()
                print("æŸ¥è¯¢å†™å…¥æ“ä½œå®Œæˆ")
        
                # ä¸»åŠ¨åœæ­¢ç›‘æ§
                print("ä¸»åŠ¨åœæ­¢ç³»ç»Ÿç›‘æ§...")
                loader.stop()
                
            # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            print("ç­‰å¾…ç›‘æ§æ•°æ®æ”¶é›†å®Œæˆ...")
            monitor_thread.join(timeout=15)  # æœ€å¤šç­‰å¾…15ç§’
                
            if monitor_thread.is_alive():
                print("ç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
            else:
                print("ç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
        
            if delay_monitor_thread:
                print("ç­‰å¾…å»¶è¿Ÿç›‘æ§å®Œæˆ...")
                delay_monitor_thread.join(timeout=10)  # æœ€å¤šç­‰å¾…10ç§’
                if delay_monitor_thread.is_alive():
                    print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
                else:
                    print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
                
            # æ‰“å°æœ€ç»ˆæŠ¥å‘Š
            if self.check_stream_delay:
                print(f"\næµå»¶è¿Ÿç›‘æ§æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.delay_log_file}")
                self.print_final_delay_summary()
                
                            
            try:
                loader.get_proc_status()
            except KeyboardInterrupt:
                print("\nç›‘æ§è¢«ä¸­æ–­")
            finally:
                # æ£€æŸ¥taosdè¿›ç¨‹
                result = subprocess.run('ps -ef | grep taosd | grep -v grep', 
                                    shell=True, capture_output=True, text=True)
                if result.stdout:
                    print("\ntaosdè¿›ç¨‹ä»åœ¨è¿è¡Œ")
                    print("å¦‚éœ€åœæ­¢taosdè¿›ç¨‹ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: pkill taosd")
                    
                    
        
            print("\næµè®¡ç®—æµ‹è¯•å®Œæˆ!")
            
            # å¦‚æœæœ‰éƒ¨åˆ†æµåˆ›å»ºå¤±è´¥ï¼Œåœ¨æµ‹è¯•å®Œæˆæ—¶æŠ¥å‘Š
            if hasattr(self, 'partial_stream_creation_errors'):
                print(f"\nâš ï¸  æµ‹è¯•å®Œæˆï¼Œä½†å­˜åœ¨æµåˆ›å»ºé—®é¢˜:")
                print(f"    {self.partial_stream_creation_errors}")
                # ä½œä¸ºè­¦å‘Šè€Œä¸æ˜¯é”™è¯¯ï¼Œä¸ä¸­æ–­æµ‹è¯•ä½†è®°å½•é—®é¢˜
                # å¯ä»¥é€‰æ‹©æ˜¯å¦æŠ›å‡ºå¼‚å¸¸
                # raise Exception(self.partial_stream_creation_errors)
                
        except Exception as e:
            print(f"æµè®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")      
            raise      


    def do_test_stream_with_realtime_data(self):
        self.prepare_env()
        self.prepare_source_from_data()
        self.insert_source_from_data()
        
        conn = taos.connect(
            host=self.host,
            user=self.user,
            password=self.passwd,
            config=self.conf
        )
        cursor = conn.cursor()

        try:
            # âœ… å¯åŠ¨åˆå§‹æ•°æ®ç”Ÿæˆè¿›ç¨‹
            print("å¯åŠ¨åˆå§‹æ•°æ®ç”Ÿæˆ...")
            data_process = subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)
            
            # åˆ›å»ºstream_toæ•°æ®åº“
            if not self.create_database('stream_to'):
                raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
            
            time.sleep(5)
            print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")
            
            # ç­‰å¾…æ•°æ®å‡†å¤‡å°±ç»ª
            if not self.wait_for_data_ready(cursor, self.table_count, self.histroy_rows):
                print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
                return
        
            # âœ… æ•°æ®å‡†å¤‡å®Œæˆåï¼Œç«‹å³åˆ›å»ºè™šæ‹Ÿè¡¨
            if self.use_virtual_table:
                print("\n=== åˆ›å»ºè™šæ‹Ÿè¡¨æ˜ å°„ ===")
                if not self.create_virtual_tables():
                    print("è™šæ‹Ÿè¡¨åˆ›å»ºå¤±è´¥")
                    return False
                print("âœ… è™šæ‹Ÿè¡¨åˆ›å»ºå®Œæˆ")            
                
            # âœ… è®¡ç®—é¢„çƒ­æ—¶é—´å’Œæµåˆ›å»ºå»¶è¿Ÿ
            if hasattr(self, 'monitor_warm_up_time') and self.monitor_warm_up_time is not None:
                warm_up_time = self.monitor_warm_up_time
                stream_creation_delay = self.monitor_warm_up_time
                print(f"ä½¿ç”¨ç”¨æˆ·è®¾ç½®çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
                print(f"âœ¨ æµåˆ›å»ºå»¶è¿Ÿ: {stream_creation_delay}ç§’ (å°†åœ¨é¢„çƒ­ç»“æŸååˆ›å»ºæµ)")
            else:
                warm_up_time = 60 if self.runtime >= 2 else 0
                stream_creation_delay = warm_up_time
                if warm_up_time > 0:
                    print(f"ä½¿ç”¨è‡ªåŠ¨è®¡ç®—çš„é¢„çƒ­æ—¶é—´: {warm_up_time}ç§’")
                    print(f"âœ¨ æµåˆ›å»ºå»¶è¿Ÿ: {stream_creation_delay}ç§’ (å°†åœ¨é¢„çƒ­ç»“æŸååˆ›å»ºæµ)")
                else:
                    print(f"è¿è¡Œæ—¶é—´è¾ƒçŸ­({self.runtime}åˆ†é’Ÿ)ï¼Œè·³è¿‡é¢„çƒ­ï¼Œç«‹å³åˆ›å»ºæµ")
            
            # âœ… å¯åŠ¨ç³»ç»Ÿç›‘æ§ (åŒ…å«é¢„çƒ­æœŸ)
            print(f"è°ƒè¯•: ä½¿ç”¨æ€§èƒ½æ–‡ä»¶è·¯å¾„: {self.perf_file}")
            
            if warm_up_time > 0:
                print(f"\n=== å¯åŠ¨æ€§èƒ½ç›‘æ§ (åŒ…å«{warm_up_time}ç§’é¢„çƒ­æœŸ) ===")
                print(f"ç›‘æ§é˜¶æ®µåˆ’åˆ†:")
                print(f"  ğŸ“Š é¢„çƒ­æœŸ (0-{warm_up_time}ç§’): æŒç»­æ•°æ®å†™å…¥ + ç³»ç»Ÿç¨³å®š + ä¸åˆ›å»ºæµ")
                print(f"  ğŸ”„ æµè®¡ç®—æœŸ ({warm_up_time}ç§’-{self.runtime*60}ç§’): åˆ›å»ºæµ + æ•°æ®å†™å…¥ + æµè®¡ç®—")
                print(f"æ€»è¿è¡Œæ—¶é—´: {self.runtime}åˆ†é’Ÿ")
                print(f"âš ï¸  é¢„çƒ­æœŸç›®çš„: è§‚å¯Ÿçº¯æ•°æ®å†™å…¥æ€§èƒ½åŸºçº¿ï¼Œä¸æµè®¡ç®—æœŸå¯¹æ¯”")
            else:
                print(f"è¿è¡Œæ—¶é—´è¾ƒçŸ­({self.runtime}åˆ†é’Ÿ)ï¼Œè·³è¿‡é¢„çƒ­ç›´æ¥å¼€å§‹ç›‘æ§")
                
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file=self.perf_file,
                interval=self.monitor_interval,
                deployment_mode=self.deployment_mode,
                warm_up_time=warm_up_time
            )
                        
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
            monitor_thread = threading.Thread(
                target=loader.get_proc_status,
                name="TaosdMonitor"
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            print("âœ… ç³»ç»Ÿèµ„æºç›‘æ§å·²å¯åŠ¨...")
            
            # âœ… ç”¨äºæ ‡è®°æµåˆ›å»ºæ˜¯å¦æˆåŠŸçš„å˜é‡
            stream_creation_success = False
            stream_creation_error = None
            
            # âœ… å»¶è¿Ÿåˆ›å»ºæµçš„çº¿ç¨‹
            stream_creation_thread = None
            if stream_creation_delay > 0:
                def delayed_stream_creation():
                    """å»¶è¿Ÿåˆ›å»ºæµçš„å‡½æ•°"""
                    nonlocal stream_creation_success, stream_creation_error
                    
                    print(f"\nâ° ç­‰å¾… {stream_creation_delay} ç§’ååˆ›å»ºæµ...")
                    print(f"ğŸ“Š é¢„çƒ­æœŸ: æŒç»­æ•°æ®å†™å…¥é˜¶æ®µ ({stream_creation_delay}ç§’)")
                    print(f"   åœ¨æ­¤æœŸé—´æŒç»­å†™å…¥æ•°æ®è§‚å¯Ÿçº¯å†™å…¥æ€§èƒ½åŸºçº¿")
                    time.sleep(stream_creation_delay)
                    
                    print(f"\nğŸ”„ é¢„çƒ­æœŸç»“æŸï¼Œå¼€å§‹åˆ›å»ºæµ...")
                    print(f"=" * 80)
                    
                    try:
                        # è·å–æ–°çš„æ•°æ®åº“è¿æ¥ç”¨äºåˆ›å»ºæµ
                        stream_conn, stream_cursor = self.get_connection()
                        stream_cursor.execute('use stream_from')
                        
                        # è·å– SQL æ¨¡æ¿å¹¶åˆ›å»ºæµ
                        sql_templates = self.stream_sql 
                        
                        # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰¹é‡æ‰§è¡Œ
                        if isinstance(sql_templates, dict):
                            print("\n=== å¼€å§‹æ‰¹é‡åˆ›å»ºæµ ===")
                            total_streams = len(sql_templates)
                            success_count = 0
                            failed_count = 0
                            failed_errors = [] 
                            
                            for index, (sql_name, sql_template) in enumerate(sql_templates.items(), 1):
                                try:
                                    print(f"\n[{index}/{total_streams}] åˆ›å»ºæµ: {sql_name}")
                                    
                                    # æå–å®é™…çš„æµåç§°ï¼ˆä»SQLä¸­è§£æï¼‰
                                    import re
                                    match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                                    actual_stream_name = match.group(1) if match else sql_name
                                    
                                    print(f"  SQLæµåç§°: {actual_stream_name}")
                                    # æ˜¾ç¤ºå®Œæ•´çš„æµSQLè¯­å¥
                                    print(f"  æµSQLè¯­å¥:")
                                    # æ ¼å¼åŒ–SQLæ˜¾ç¤ºï¼Œå»æ‰å¤šä½™çš„ç©ºè¡Œå’Œç¼©è¿›
                                    formatted_sql = '\n'.join([
                                        '    ' + line.strip() 
                                        for line in sql_template.strip().split('\n') 
                                        if line.strip()
                                    ])
                                    print(formatted_sql)
                                    
                                    print(f"  æ‰§è¡Œåˆ›å»º...")
                                    stream_cursor.execute(sql_template)
                                    success_count += 1
                                    print(f"  âœ“ åˆ›å»ºæˆåŠŸ")
                                    
                                except Exception as e:
                                    failed_count += 1
                                    
                                    # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                                    error_message = str(e)
                                    tdengine_error = extract_stream_creation_error(error_message)
                                    
                                    print(f"æ‰§è¡Œé”™è¯¯: {tdengine_error}")
                                    failed_errors.append(f"{sql_name}: {tdengine_error}")
                            
                            # æ˜¾ç¤ºæ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦
                            print(f"\n=== æ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦ ===")
                            print(f"æ€»æµæ•°: {total_streams}")
                            print(f"æˆåŠŸ: {success_count}")
                            print(f"å¤±è´¥: {failed_count}")
                            print(f"æˆåŠŸç‡: {(success_count/total_streams*100):.1f}%")
                        
                            if failed_count > 0:
                                error_summary = f"æµåˆ›å»ºå¤±è´¥ç»Ÿè®¡: {failed_count}/{total_streams} ä¸ªæµå¤±è´¥"
                                if len(failed_errors) > 0:
                                    error_details = "; ".join(failed_errors[:5])
                                    if len(failed_errors) > 5:
                                        error_details += f"; è¿˜æœ‰{len(failed_errors)-5}ä¸ªé”™è¯¯..."
                                    error_summary += f" | é”™è¯¯è¯¦æƒ…: {error_details}"
                                print(f"âš ï¸  {failed_count} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                                
                                if success_count == 0:
                                    # âœ… å¦‚æœæ‰€æœ‰æµéƒ½å¤±è´¥äº†ï¼Œè®¾ç½®é”™è¯¯æ ‡è®°å¹¶è¿”å›
                                    stream_creation_error = f"æ‰€æœ‰ {total_streams} ä¸ªæµåˆ›å»ºéƒ½å¤±è´¥äº†"
                                    stream_creation_success = False
                                    print(f"âŒ æ‰€æœ‰æµåˆ›å»ºå¤±è´¥ï¼Œåœæ­¢æµ‹è¯•")
                                    return
                                else:
                                    # éƒ¨åˆ†å¤±è´¥ï¼Œä»ç„¶ç®—ä½œæˆåŠŸï¼Œç»§ç»­æµ‹è¯•
                                    stream_creation_success = True
                                    print(f"âš ï¸  æ³¨æ„: {failed_count}/{total_streams} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œå°†ä½¿ç”¨ {success_count} ä¸ªæˆåŠŸçš„æµç»§ç»­æµ‹è¯•")
                            else:
                                stream_creation_success = True
                                print("âœ… æ‰€æœ‰æµåˆ›å»ºæˆåŠŸï¼")
                            
                        else:
                            # å•ä¸ªæµçš„åˆ›å»º
                            print("\n=== å¼€å§‹åˆ›å»ºæµ ===")
                            
                            # æå–å®é™…çš„æµåç§°
                            import re
                            match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                            actual_stream_name = match.group(1) if match else "æœªçŸ¥æµåç§°"
                            
                            print(f"æµåç§°: {actual_stream_name}")
                            print("æµSQLè¯­å¥:")
                            print("-" * 80)
                            print(sql_templates)
                            print("-" * 80)
                            
                            try:
                                start_time = time.time()
                                stream_cursor.execute(sql_templates)
                                create_time = time.time() - start_time
                                
                                print(f"âœ… æµ {actual_stream_name} åˆ›å»ºå®Œæˆ! è€—æ—¶: {create_time:.2f}ç§’")
                                stream_creation_success = True
                                
                            except Exception as e:
                                # âœ… å•ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè®¾ç½®é”™è¯¯æ ‡è®°
                                error_message = str(e)
                                tdengine_error = extract_stream_creation_error(error_message)
                                
                                print(f"âŒ æµåˆ›å»ºå¤±è´¥: {tdengine_error}")
                                stream_creation_error = tdengine_error
                                stream_creation_success = False
                                return
                        
                        if stream_creation_success:
                            print(f"\nğŸ”„ æµè®¡ç®—æœŸå¼€å§‹ - æ•°æ®å†™å…¥ + æµè®¡ç®—")
                            print(f"=" * 80)
                        
                        # å…³é—­æµåˆ›å»ºè¿æ¥
                        stream_cursor.close()
                        stream_conn.close()
                        
                    except Exception as e:
                        print(f"âŒ å»¶è¿Ÿåˆ›å»ºæµæ—¶å‡ºé”™: {str(e)}")
                        stream_creation_error = str(e)
                        stream_creation_success = False
                
                # åˆ›å»ºå¹¶å¯åŠ¨å»¶è¿Ÿæµåˆ›å»ºçº¿ç¨‹
                stream_creation_thread = threading.Thread(
                    target=delayed_stream_creation,
                    name="DelayedStreamCreation"
                )
                stream_creation_thread.daemon = True
                stream_creation_thread.start()
                print(f"âœ… å»¶è¿Ÿæµåˆ›å»ºçº¿ç¨‹å·²å¯åŠ¨ (å°†åœ¨{stream_creation_delay}ç§’åæ‰§è¡Œ)")
                
            else:
                # ç«‹å³åˆ›å»ºæµ (åŸæœ‰é€»è¾‘ä¿æŒä¸å˜)
                print("\n=== ç«‹å³åˆ›å»ºæµ ===")
    
                try:
                    # è·å–æ–°çš„æ•°æ®åº“è¿æ¥ç”¨äºåˆ›å»ºæµ
                    stream_conn, stream_cursor = self.get_connection()
                    stream_cursor.execute('use stream_from')
                    
                    # è·å– SQL æ¨¡æ¿å¹¶åˆ›å»ºæµ
                    sql_templates = self.stream_sql 
                    
                    # åˆ¤æ–­æ˜¯å¦ä¸ºæ‰¹é‡æ‰§è¡Œ
                    if isinstance(sql_templates, dict):
                        print("\n=== å¼€å§‹æ‰¹é‡åˆ›å»ºæµ ===")
                        total_streams = len(sql_templates)
                        success_count = 0
                        failed_count = 0
                        failed_errors = [] 
                        
                        for index, (sql_name, sql_template) in enumerate(sql_templates.items(), 1):
                            try:
                                print(f"\n[{index}/{total_streams}] åˆ›å»ºæµ: {sql_name}")
                                
                                # æå–å®é™…çš„æµåç§°ï¼ˆä»SQLä¸­è§£æï¼‰
                                import re
                                match = re.search(r'create\s+stream\s+([^\s]+)', sql_template, re.IGNORECASE)
                                actual_stream_name = match.group(1) if match else sql_name
                                
                                print(f"  SQLæµåç§°: {actual_stream_name}")
                                # æ˜¾ç¤ºå®Œæ•´çš„æµSQLè¯­å¥
                                print(f"  æµSQLè¯­å¥:")
                                # æ ¼å¼åŒ–SQLæ˜¾ç¤ºï¼Œå»æ‰å¤šä½™çš„ç©ºè¡Œå’Œç¼©è¿›
                                formatted_sql = '\n'.join([
                                    '    ' + line.strip() 
                                    for line in sql_template.strip().split('\n') 
                                    if line.strip()
                                ])
                                print(formatted_sql)
                                
                                print(f"  æ‰§è¡Œåˆ›å»º...")
                                stream_cursor.execute(sql_template)
                                success_count += 1
                                print(f"  âœ“ åˆ›å»ºæˆåŠŸ")
                                
                            except Exception as e:
                                failed_count += 1
                                
                                # æå–TDengineçš„å…·ä½“é”™è¯¯ä¿¡æ¯
                                error_message = str(e)
                                tdengine_error = extract_stream_creation_error(error_message)
                                
                                print(f"âŒ æ‰§è¡Œé”™è¯¯: {tdengine_error}")
                                failed_errors.append(f"{sql_name}: {tdengine_error}")
                        
                        # æ˜¾ç¤ºæ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦
                        print(f"\n=== æ‰¹é‡åˆ›å»ºç»“æœæ‘˜è¦ ===")
                        print(f"æ€»æµæ•°: {total_streams}")
                        print(f"æˆåŠŸ: {success_count}")
                        print(f"å¤±è´¥: {failed_count}")
                        print(f"æˆåŠŸç‡: {(success_count/total_streams*100):.1f}%")
                    
                        if failed_count > 0:
                            error_summary = f"æµåˆ›å»ºå¤±è´¥ç»Ÿè®¡: {failed_count}/{total_streams} ä¸ªæµå¤±è´¥"
                            if len(failed_errors) > 0:
                                error_details = "; ".join(failed_errors[:5])
                                if len(failed_errors) > 5:
                                    error_details += f"; è¿˜æœ‰{len(failed_errors)-5}ä¸ªé”™è¯¯..."
                                error_summary += f" | é”™è¯¯è¯¦æƒ…: {error_details}"
                            print(f"âš ï¸  {failed_count} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")
                            
                            if success_count == 0:
                                # å¦‚æœæ‰€æœ‰æµéƒ½å¤±è´¥äº†ï¼Œè®¾ç½®é”™è¯¯æ ‡è®°å¹¶æŠ›å‡ºå¼‚å¸¸
                                stream_creation_error = f"æ‰€æœ‰ {total_streams} ä¸ªæµåˆ›å»ºéƒ½å¤±è´¥äº†"
                                stream_creation_success = False
                                print(f"âŒ æ‰€æœ‰æµåˆ›å»ºå¤±è´¥ï¼Œåœæ­¢æµ‹è¯•")
                                raise Exception(stream_creation_error)
                            else:
                                # éƒ¨åˆ†å¤±è´¥ï¼Œä»ç„¶ç®—ä½œæˆåŠŸï¼Œç»§ç»­æµ‹è¯•
                                stream_creation_success = True
                                print(f"âš ï¸  æ³¨æ„: {failed_count}/{total_streams} ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œå°†ä½¿ç”¨ {success_count} ä¸ªæˆåŠŸçš„æµç»§ç»­æµ‹è¯•")
                        else:
                            stream_creation_success = True
                            print("âœ… æ‰€æœ‰æµåˆ›å»ºæˆåŠŸï¼")
                        
                    else:
                        # å•ä¸ªæµçš„åˆ›å»º
                        print("\n=== å¼€å§‹åˆ›å»ºå•ä¸ªæµ ===")
                        
                        # æå–å®é™…çš„æµåç§°
                        import re
                        match = re.search(r'create\s+stream\s+([^\s]+)', sql_templates, re.IGNORECASE)
                        actual_stream_name = match.group(1) if match else "æœªçŸ¥æµåç§°"
                        
                        print(f"æµåç§°: {actual_stream_name}")
                        print("æµSQLè¯­å¥:")
                        print("-" * 80)
                        print(sql_templates)
                        print("-" * 80)
                        
                        try:
                            start_time = time.time()
                            stream_cursor.execute(sql_templates)
                            create_time = time.time() - start_time
                            
                            print(f"âœ… æµ {actual_stream_name} åˆ›å»ºå®Œæˆ! è€—æ—¶: {create_time:.2f}ç§’")
                            stream_creation_success = True
                            
                        except Exception as e:
                            # å•ä¸ªæµåˆ›å»ºå¤±è´¥ï¼Œè®¾ç½®é”™è¯¯æ ‡è®°å¹¶æŠ›å‡ºå¼‚å¸¸
                            error_message = str(e)
                            tdengine_error = extract_stream_creation_error(error_message)
                            
                            print(f"âŒ æµåˆ›å»ºå¤±è´¥: {tdengine_error}")
                            stream_creation_error = tdengine_error
                            stream_creation_success = False
                            raise Exception(tdengine_error)
                    
                    if stream_creation_success:
                        print(f"\nğŸ”„ æµè®¡ç®—å¼€å§‹ - æ•°æ®å†™å…¥ + æµè®¡ç®—")
                        print(f"=" * 80)
                    
                    # å…³é—­æµåˆ›å»ºè¿æ¥
                    stream_cursor.close()
                    stream_conn.close()
                    
                except Exception as e:
                    print(f"âŒ ç«‹å³åˆ›å»ºæµæ—¶å‡ºé”™: {str(e)}")
                    stream_creation_error = str(e)
                    stream_creation_success = False
                    # å¯¹äºç«‹å³åˆ›å»ºæµçš„æƒ…å†µï¼Œå¦‚æœå¤±è´¥å°±ç›´æ¥æŠ›å‡ºå¼‚å¸¸
                    raise Exception(f"æµåˆ›å»ºå¤±è´¥: {str(e)}")
            
            # âœ… ç«‹å³å¯åŠ¨æ•°æ®å†™å…¥çº¿ç¨‹ï¼ˆé¢„çƒ­æœŸæ•°æ®å†™å…¥ï¼‰
            write_thread = None
            write_stop_flag = threading.Event()
            
            def continuous_data_writing():
                """æŒç»­æ•°æ®å†™å…¥çº¿ç¨‹å‡½æ•°"""
                write_cycle = 0
                while not write_stop_flag.is_set():
                    write_cycle += 1
                    current_time = time.time()
                    
                    # åˆ¤æ–­å½“å‰é˜¶æ®µ
                    if stream_creation_delay > 0:
                        if current_time - test_start_time <= stream_creation_delay:
                            stage = "é¢„çƒ­æœŸ"
                            stage_desc = "çº¯æ•°æ®å†™å…¥è´Ÿè½½ (è§‚å¯ŸåŸºçº¿æ€§èƒ½)"
                        else:
                            stage = "æµè®¡ç®—æœŸ"
                            stage_desc = "æ•°æ®å†™å…¥ + æµè®¡ç®—è´Ÿè½½"
                    else:
                        stage = "æ­£å¸¸æœŸ"
                        stage_desc = "æ•°æ®å†™å…¥ + æµè®¡ç®—"
                    
                    print(f"\n=== ç¬¬ {write_cycle} è½®æ•°æ®å†™å…¥ - {stage} ===")
                    print(f"ğŸ“ {stage_desc}")
                    
                    # åº”ç”¨å†™å…¥é—´éš”æ§åˆ¶
                    if self.real_time_batch_sleep > 0:
                        print(f"ç­‰å¾… {self.real_time_batch_sleep} ç§’åå¼€å§‹å†™å…¥æ•°æ®...")
                        if write_stop_flag.wait(self.real_time_batch_sleep):
                            break  # å¦‚æœæ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡º
                    
                    write_start_time = time.time()
                    
                    try:
                        # æ›´æ–°å†™å…¥é…ç½®
                        if not self.update_insert_config():
                            print("âŒ æ›´æ–°å†™å…¥é…ç½®å¤±è´¥")
                            break
                        
                        # æ‰§è¡Œæ•°æ®å†™å…¥
                        cmd = "taosBenchmark -f /tmp/stream_from_insertdata.json"
                        result = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)
                        
                        write_end_time = time.time()
                        write_duration = write_end_time - write_start_time
                        
                        if result.returncode != 0:
                            print(f"âŒ å†™å…¥æ•°æ®å¤±è´¥: {result.stderr}")
                            break
                        else:
                            total_records = self.table_count * self.real_time_batch_rows
                            write_speed = total_records / write_duration if write_duration > 0 else 0
                            print(f"âœ… æ•°æ®å†™å…¥å®Œæˆ: {total_records} æ¡è®°å½•, è€—æ—¶ {write_duration:.2f}ç§’, é€Ÿåº¦ {write_speed:.0f} æ¡/ç§’")
                            
                            # æ˜¾ç¤ºå†™å…¥æ§åˆ¶ä¿¡æ¯
                            if self.real_time_batch_sleep > 0:
                                print(f"â³ å†™å…¥é—´éš”æ§åˆ¶: {self.real_time_batch_sleep}ç§’")
                    
                    except Exception as e:
                        print(f"âŒ æ•°æ®å†™å…¥å‡ºé”™: {str(e)}")
                        break
                    
                    # æ£€æŸ¥æ˜¯å¦åº”è¯¥åœæ­¢
                    if write_stop_flag.is_set():
                        break
            
            # å¯åŠ¨æ•°æ®å†™å…¥çº¿ç¨‹
            test_start_time = time.time()
            write_thread = threading.Thread(target=continuous_data_writing, name="ContinuousDataWriter")
            write_thread.daemon = True
            write_thread.start()
            print("âœ… æŒç»­æ•°æ®å†™å…¥çº¿ç¨‹å·²å¯åŠ¨...")
            
            # âœ… ç­‰å¾…æµåˆ›å»ºå®Œæˆï¼ˆå¦‚æœæ˜¯å»¶è¿Ÿåˆ›å»ºï¼‰
            if stream_creation_thread:
                print("ç­‰å¾…æµåˆ›å»ºå®Œæˆ...")
                # ç­‰å¾…è¶³å¤Ÿçš„æ—¶é—´è®©æµåˆ›å»ºå®Œæˆ
                max_wait_time = stream_creation_delay + 60  # é¢„çƒ­æ—¶é—´ + 60ç§’ç¼“å†²æ—¶é—´
                stream_creation_thread.join(timeout=max_wait_time)
                
                # æ£€æŸ¥æµåˆ›å»ºç»“æœ
                if not stream_creation_success:
                    if stream_creation_error:
                        print(f"âŒ æµåˆ›å»ºå¤±è´¥ï¼Œåœæ­¢æµ‹è¯•: {stream_creation_error}")
                        raise Exception(f"æµåˆ›å»ºå¤±è´¥: {stream_creation_error}")
                    else:
                        print("âŒ æµåˆ›å»ºçŠ¶æ€æœªçŸ¥ï¼Œåœæ­¢æµ‹è¯•")
                        raise Exception("æµåˆ›å»ºçŠ¶æ€æœªçŸ¥")
                
                print("âœ… æµåˆ›å»ºå®Œæˆï¼Œç»§ç»­æ•°æ®å†™å…¥å’Œæµè®¡ç®—æµ‹è¯•")
            
            # âœ… åªæœ‰åœ¨æµåˆ›å»ºæˆåŠŸåæ‰å¯åŠ¨å»¶è¿Ÿç›‘æ§
            delay_monitor_thread = None
            if stream_creation_success and self.check_stream_delay:
                print("æµåˆ›å»ºæˆåŠŸï¼Œå¯åŠ¨å»¶è¿Ÿç›‘æ§...")
                delay_monitor_thread = self.start_stream_delay_monitor()
            elif not stream_creation_success:
                print("âš ï¸  æµåˆ›å»ºå¤±è´¥ï¼Œè·³è¿‡å»¶è¿Ÿç›‘æ§")
            elif not self.check_stream_delay:
                print("âš ï¸  å»¶è¿Ÿç›‘æ§æœªå¯ç”¨")
            else:
                print("âš ï¸  æœªçŸ¥çŠ¶æ€ï¼Œè·³è¿‡å»¶è¿Ÿç›‘æ§")
        
            try:            
                # âœ… ç­‰å¾…æµ‹è¯•å®Œæˆ
                total_test_time = self.runtime * 60
                print(f"\n=== å¼€å§‹ç­‰å¾…æµ‹è¯•å®Œæˆ (æ€»æ—¶é—´: {self.runtime}åˆ†é’Ÿ) ===")
                
                time.sleep(total_test_time)
                
                print(f"\nâœ… å·²è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶ ({self.runtime} åˆ†é’Ÿ)ï¼Œåœæ­¢æµ‹è¯•")
            
            except Exception as e:
                print(f"æµ‹è¯•æ‰§è¡Œå‡ºé”™: {str(e)}")
            finally:
                # åœæ­¢æ•°æ®å†™å…¥çº¿ç¨‹
                if write_thread and write_thread.is_alive():
                    print("åœæ­¢æ•°æ®å†™å…¥çº¿ç¨‹...")
                    write_stop_flag.set()
                    write_thread.join(timeout=10)
                    if write_thread.is_alive():
                        print("æ•°æ®å†™å…¥çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸ")
                    else:
                        print("æ•°æ®å†™å…¥çº¿ç¨‹å·²åœæ­¢")
                
                print("æµ‹è¯•ä¸»ä½“æ“ä½œå®Œæˆ")
        
                # ä¸»åŠ¨åœæ­¢ç›‘æ§
                print("ä¸»åŠ¨åœæ­¢ç³»ç»Ÿç›‘æ§...")
                loader.stop()
                
            # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            print("ç­‰å¾…ç›‘æ§æ•°æ®æ”¶é›†å®Œæˆ...")
            monitor_thread.join(timeout=15)  # æœ€å¤šç­‰å¾…15ç§’
                
            if monitor_thread.is_alive():
                print("ç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
            else:
                print("ç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
        
            if delay_monitor_thread:
                print("ç­‰å¾…å»¶è¿Ÿç›‘æ§å®Œæˆ...")
                delay_monitor_thread.join(timeout=10)  # æœ€å¤šç­‰å¾…10ç§’
                if delay_monitor_thread.is_alive():
                    print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œå¼ºåˆ¶ç»§ç»­...")
                else:
                    print("å»¶è¿Ÿç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
                
            # âœ… å¢å¼ºçš„æœ€ç»ˆæŠ¥å‘Š
            if self.check_stream_delay and stream_creation_success:
                print(f"\næµå»¶è¿Ÿç›‘æ§æŠ¥å‘Šå·²ä¿å­˜åˆ°: {self.delay_log_file}")
                self.print_final_delay_summary_enhanced(stream_creation_delay)
            else:
                self.print_final_test_summary_enhanced(stream_creation_delay)
                            
            print("\næµè®¡ç®—æµ‹è¯•å®Œæˆ!")
            
        except Exception as e:
            print(f"æµè®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")      
            raise    
        finally:
            if not self.keep_taosd_alive:
                print("æµ‹è¯•å®Œæˆï¼Œæ­£åœ¨æ¸…ç† taosd è¿›ç¨‹...")
                # åŸæœ‰çš„æ¸…ç†é€»è¾‘
                try:
                    # å¼ºåˆ¶åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹
                    print("  â†’ åœæ­¢æ‰€æœ‰taosdè¿›ç¨‹")
                    subprocess.run('pkill -9 taosd', shell=True)
                    time.sleep(2)
                except Exception as cleanup_e:
                    print(f"  âš ï¸  æ¸…ç†è¿‡ç¨‹å‡ºé”™: {str(cleanup_e)}")
            else:
                print("âœ… æµ‹è¯•å®Œæˆï¼Œä¿ç•™ taosd è¿›ç¨‹ç»§ç»­è¿è¡Œ")
                # print("ğŸ”— å¯ä»¥ç»§ç»­ä½¿ç”¨ä»¥ä¸‹è¿æ¥ä¿¡æ¯è®¿é—®æ•°æ®åº“:")
                # print(f"   ä¸»æœº: {self.host}")
                # print(f"   ç«¯å£: {self.instances[0]['port']}")
                # print(f"   ç”¨æˆ·: {self.user}")
                # print(f"   å¯†ç : {self.passwd}")
                # print(f"   é…ç½®æ–‡ä»¶: {self.conf}")
                # print("ğŸ“‚ æ•°æ®ç›®å½•:")
                for instance in self.instances:
                    print(f"   {instance['name']}: {instance['data_dir']}")
                print("ğŸ“ è¦æ‰‹åŠ¨åœæ­¢ taosdï¼Œè¯·æ‰§è¡Œ: pkill taosd")
                print("ğŸ’¡ å»ºè®®: å¯ä»¥ä½¿ç”¨ taos å‘½ä»¤è¡Œå·¥å…·è¿æ¥æ•°æ®åº“è¿›è¡Œåˆ†æ")   

    def print_final_delay_summary_enhanced(self, stream_creation_delay):
        """å¢å¼ºçš„æœ€ç»ˆå»¶è¿Ÿæµ‹è¯•æ‘˜è¦ï¼ŒåŒ…å«é˜¶æ®µåˆ’åˆ†ä¿¡æ¯"""
        try:
            c = Colors.get_colors()
            
            print_title("\n=== æµè®¡ç®—å»¶è¿Ÿæµ‹è¯•æ€»ç»“ (å¢å¼ºç‰ˆ) ===")
            
            # âœ… æ˜¾ç¤ºæµ‹è¯•é˜¶æ®µä¿¡æ¯
            if stream_creation_delay > 0:
                print(f"ğŸ”„ æµ‹è¯•é˜¶æ®µåˆ’åˆ†:")
                print(f"  ğŸ“Š é¢„çƒ­æœŸ (0-{stream_creation_delay}ç§’): æŒç»­æ•°æ®å†™å…¥ + ç³»ç»Ÿç¨³å®š + ä¸åˆ›å»ºæµ")
                print(f"      - ç³»ç»Ÿèµ„æºç›‘æ§: å¯åŠ¨")
                print(f"      - æ•°æ®å†™å…¥: å¯åŠ¨ (è§‚å¯Ÿçº¯å†™å…¥æ€§èƒ½åŸºçº¿)")
                print(f"      - æµè®¡ç®—: æœªå¯åŠ¨")
                print(f"      - å»¶è¿Ÿç›‘æ§: æœªå¼€å§‹")
                print(f"  ğŸ”„ æµè®¡ç®—æœŸ ({stream_creation_delay}-{self.runtime*60}ç§’): åˆ›å»ºæµ + æ•°æ®å†™å…¥ + æµè®¡ç®—")
                print(f"      - ç³»ç»Ÿèµ„æºç›‘æ§: ç»§ç»­")
                print(f"      - æ•°æ®å†™å…¥: ç»§ç»­")
                print(f"      - æµè®¡ç®—: å¯åŠ¨")
                print(f"      - å»¶è¿Ÿç›‘æ§: å¼€å§‹")
                print(f"  ğŸ“ æ€»è¿è¡Œæ—¶é—´: {self.runtime*60}ç§’ ({self.runtime}åˆ†é’Ÿ)")
                
                # è®¡ç®—å®é™…æµè®¡ç®—æ—¶é—´
                actual_stream_time = self.runtime * 60 - stream_creation_delay
                print(f"  â±ï¸  å®é™…æµè®¡ç®—æ—¶é—´: {actual_stream_time}ç§’ ({actual_stream_time/60:.1f}åˆ†é’Ÿ)")
                print(f"  ğŸ” æ€§èƒ½å¯¹æ¯”: é¢„çƒ­æœŸä¸ºçº¯å†™å…¥åŸºçº¿ï¼Œæµè®¡ç®—æœŸä¸ºå†™å…¥+æµè®¡ç®—è´Ÿè½½")
            else:
                print(f"ğŸ”„ æµ‹è¯•æ¨¡å¼: ç«‹å³å¯åŠ¨æµè®¡ç®— (æ— é¢„çƒ­å»¶è¿Ÿ)")
                print(f"  ğŸ“ æ€»è¿è¡Œæ—¶é—´: {self.runtime*60}ç§’ ({self.runtime}åˆ†é’Ÿ)")
                print(f"  â±ï¸  æµè®¡ç®—æ—¶é—´: {self.runtime*60}ç§’ ({self.runtime}åˆ†é’Ÿ)")
            
            # ... å…¶ä½™ä»£ç ä¿æŒä¸å˜ ...
            
        except Exception as e:
            print(f"ç”Ÿæˆå¢å¼ºæ‘˜è¦æ—¶å‡ºé”™: {str(e)}")

    def print_final_test_summary_enhanced(self, stream_creation_delay):
        """å¢å¼ºçš„æœ€ç»ˆæµ‹è¯•æ‘˜è¦ï¼ˆæ— å»¶è¿Ÿç›‘æ§æ—¶ä½¿ç”¨ï¼‰"""
        try:
            c = Colors.get_colors()
            
            print_title("\n=== æµè®¡ç®—æ€§èƒ½æµ‹è¯•æ€»ç»“ ===")
            
            # æ˜¾ç¤ºæµ‹è¯•é˜¶æ®µä¿¡æ¯
            if stream_creation_delay > 0:
                print(f"ğŸ”„ æµ‹è¯•é˜¶æ®µåˆ’åˆ†:")
                print(f"  ğŸ“Š é¢„çƒ­æœŸ (0-{stream_creation_delay}ç§’): çº¯æ•°æ®å†™å…¥é˜¶æ®µ")
                print(f"  ğŸ”„ æµè®¡ç®—æœŸ ({stream_creation_delay}-{self.runtime*60}ç§’): æ•°æ®å†™å…¥ + æµè®¡ç®—é˜¶æ®µ")
                actual_stream_time = self.runtime * 60 - stream_creation_delay
                print(f"  â±ï¸  å®é™…æµè®¡ç®—æ—¶é—´: {actual_stream_time}ç§’ ({actual_stream_time/60:.1f}åˆ†é’Ÿ)")
            else:
                print(f"ğŸ”„ æµ‹è¯•æ¨¡å¼: ç«‹å³å¯åŠ¨æµè®¡ç®—")
                print(f"  â±ï¸  æµè®¡ç®—æ—¶é—´: {self.runtime*60}ç§’ ({self.runtime}åˆ†é’Ÿ)")
            
            print(f"\nâœ… æµ‹è¯•å·²å®Œæˆ!")
            print(f"ğŸ“„ æ€§èƒ½ç›‘æ§æ•°æ®: /tmp/perf-taosd-*.log")
            print(f"ğŸ” å»ºè®®å¯ç”¨ --check-stream-delay å‚æ•°è·å¾—å»¶è¿Ÿåˆ†æ")
            
        except Exception as e:
            print(f"ç”Ÿæˆæµ‹è¯•æ‘˜è¦æ—¶å‡ºé”™: {str(e)}")
    

    def print_final_delay_summary(self):
        """æ‰“å°æœ€ç»ˆçš„å»¶è¿Ÿæµ‹è¯•æ‘˜è¦"""
        try:
            c = Colors.get_colors()
            
            print_title("\n=== æµè®¡ç®—å»¶è¿Ÿæµ‹è¯•æ€»ç»“ ===")
            print(f"æµ‹è¯•é…ç½®:")
            print(f"  å­è¡¨æ•°é‡: {self.table_count}")
            print(f"  æ¯è½®æ’å…¥è®°å½•æ•°: {self.real_time_batch_rows}")
            print(f"  æ•°æ®å†™å…¥é—´éš”: {self.real_time_batch_sleep}ç§’")
            print(f"  å»¶è¿Ÿæ£€æŸ¥é—´éš”: {self.delay_check_interval}ç§’")
            print(f"  æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {format_delay_time(self.max_delay_threshold)}")
            print(f"  è¿è¡Œæ—¶é—´: {self.runtime}åˆ†é’Ÿ")
            print(f"  SQLç±»å‹: {self.sql_type}")
            print(f"  æµæ•°é‡: {self.stream_num}")
            
            # åˆ†æå†™å…¥å‹åŠ›
            total_records_per_round = self.table_count * self.real_time_batch_rows
            estimated_rounds = (self.runtime * 60) / max(self.delay_check_interval, 1)
            total_estimated_records = total_records_per_round * estimated_rounds
            
            print(f"\nå†™å…¥å‹åŠ›åˆ†æ:")
            print(f"  æ¯è½®æ€»è®°å½•æ•°: {total_records_per_round:,}")
            print(f"  é¢„è®¡è½®æ¬¡: {estimated_rounds:.0f}")
            print(f"  é¢„è®¡æ€»è®°å½•æ•°: {total_estimated_records:,.0f}")
            
            if self.real_time_batch_sleep > 0:
                effective_write_interval = self.delay_check_interval + self.real_time_batch_sleep
                print(f"  å®é™…å†™å…¥é—´éš”: {effective_write_interval}ç§’ (æ£€æŸ¥é—´éš” + å†™å…¥ç­‰å¾…)")
                write_rate = total_records_per_round / effective_write_interval
                print(f"  å¹³å‡å†™å…¥é€Ÿç‡: {write_rate:.0f} æ¡/ç§’")
            else:
                print(f"  å†™å…¥æ¨¡å¼: æ— é—´éš”æ§åˆ¶ (æœ€å¤§é€Ÿåº¦å†™å…¥)")
            
            print(f"\nä¼˜åŒ–å»ºè®®:")
            if self.real_time_batch_sleep == 0:
                print_warning("  - å½“å‰æ— å†™å…¥é—´éš”æ§åˆ¶ï¼Œå¦‚æœå»¶è¿Ÿè¾ƒå¤§å¯ä»¥å°è¯•å¢åŠ  --real-time-batch-sleep å‚æ•°")
            else:
                print_info(f"  - å½“å‰å†™å…¥é—´éš”: {self.real_time_batch_sleep}ç§’")
                print_info("  - å¦‚æœå»¶è¿Ÿä»ç„¶è¾ƒå¤§ï¼Œå¯ä»¥è¿›ä¸€æ­¥å¢åŠ å†™å…¥é—´éš”")
                print_info("  - å¦‚æœå»¶è¿Ÿè¾ƒå°ï¼Œå¯ä»¥å‡å°‘å†™å…¥é—´éš”ä»¥å¢åŠ æµ‹è¯•å‹åŠ›")
            
            print(f"  - å¯ä»¥è°ƒæ•´ --real-time-batch-rows å‚æ•°æ”¹å˜æ¯è½®å†™å…¥é‡")
            print(f"  - å¯ä»¥è°ƒæ•´ --delay-check-interval å‚æ•°æ”¹å˜ç›‘æ§é¢‘ç‡")
            
            print(f"\nå»¶è¿Ÿç›‘æ§æ—¥å¿—: {self.delay_log_file}")
            print(f"æ€§èƒ½ç›‘æ§æ—¥å¿—: /tmp/perf-taosd-*.log")
            
        except Exception as e:
            print(f"ç”Ÿæˆæœ€ç»ˆæ‘˜è¦æ—¶å‡ºé”™: {str(e)}")
            
            
    def do_start_bak(self):
        self.prepare_env()
        self.prepare_source_from_data()
        
        conn = taos.connect(
            host=self.host,
            user=self.user,
            password=self.passwd,
            config=self.conf
        )
        cursor = conn.cursor()

        try:
            # è¿è¡Œsource_fromçš„æ•°æ®ç”Ÿæˆ
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, shell=True, text=True)
            
            # åˆ›å»ºstream_toæ•°æ®åº“
            if not self.create_database('stream_to'):
                raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
            
            time.sleep(5)
            print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")
            
            # ç­‰å¾…æ•°æ®å‡†å¤‡å°±ç»ª
            if not self.wait_for_data_ready(cursor, self.table_count, self.histroy_rows):
                print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
                return
            
            # è·å–æ–°è¿æ¥æ‰§è¡Œæµå¼æŸ¥è¯¢
            conn, cursor = self.get_connection()
            
            print("å¼€å§‹è¿æ¥æ•°æ®åº“")
            cursor.execute('use stream_from')
            
            # æ‰§è¡Œæµå¼æŸ¥è¯¢
            print(f"æ‰§è¡Œæµå¼æŸ¥è¯¢SQL:\n{self.stream_sql}")
            cursor.execute(self.stream_sql)
            
            print("æµå¼æŸ¥è¯¢å·²åˆ›å»º,å¼€å§‹ç›‘æ§ç³»ç»Ÿè´Ÿè½½")
            cursor.close()
            conn.close()
            
            # ç›‘æ§ç³»ç»Ÿè´Ÿè½½ - åŒæ—¶ç›‘æ§ä¸‰ä¸ªèŠ‚ç‚¹
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file='/tmp/perf-taosd.log',  # åŸºç¡€æ–‡ä»¶å,ä¼šè‡ªåŠ¨æ·»åŠ dnodeç¼–å·
                interval=self.monitor_interval
            )
        
            try:
                loader.get_proc_status()
            except KeyboardInterrupt:
                print("\nç›‘æ§è¢«ä¸­æ–­")
            finally:
                # æ£€æŸ¥taosdè¿›ç¨‹
                result = subprocess.run('ps -ef | grep taosd | grep -v grep', 
                                    shell=True, capture_output=True, text=True)
                if result.stdout:
                    print("\ntaosdè¿›ç¨‹ä»åœ¨è¿è¡Œ")
                    print("å¦‚éœ€åœæ­¢taosdè¿›ç¨‹ï¼Œè¯·æ‰‹åŠ¨æ‰§è¡Œ: pkill taosd")
                
        except Exception as e:
            print(f"æ‰§è¡Œé”™è¯¯: {str(e)}")            
                                    
    def format_timestamp(self, ts):
        """æ ¼å¼åŒ–æ—¶é—´æˆ³ä¸ºå¯è¯»å­—ç¬¦ä¸²
        Args:
            ts: æ¯«ç§’çº§æ—¶é—´æˆ³
        Returns:
            str: æ ¼å¼åŒ–åçš„æ—¶é—´å­—ç¬¦ä¸² (YYYY-MM-DD HH:mm:ss)
        """
        return time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(ts/1000))

         
    def do_query_then_insert(self):
        self.prepare_env()
        self.prepare_source_from_data()
        self.insert_source_from_data()
        
        conn = taos.connect(
            host=self.host,
            user=self.user,
            password=self.passwd,
            config=self.conf
        )
        cursor = conn.cursor()

        try:
            # è¿è¡Œsource_fromçš„æ•°æ®ç”Ÿæˆ
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"Error running Bash command: {e}")

        # åˆ›å»ºstream_toæ•°æ®åº“
        if not self.create_database('stream_to'):
            raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
        
        time.sleep(5)
        print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")
        # ç­‰å¾…æ•°æ®å‡†å¤‡å°±ç»ª
        if not self.wait_for_data_ready(cursor, self.table_count, self.histroy_rows):
            print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        try:
            # å¯åŠ¨æ€§èƒ½ç›‘æ§çº¿ç¨‹
            if hasattr(self, 'monitor_warm_up_time') and self.monitor_warm_up_time is not None:
                warm_up_time = self.monitor_warm_up_time
            else:
                warm_up_time = 60 if self.runtime >= 2 else 0
        
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file='/tmp/perf-taosd-query.log',
                interval=self.monitor_interval,
                deployment_mode=self.deployment_mode,
                warm_up_time=warm_up_time  
            )
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
            monitor_thread = threading.Thread(
                target=loader.get_proc_status,
                name="TaosdMonitor"
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            print("å¼€å§‹ç›‘æ§taosdè¿›ç¨‹èµ„æºä½¿ç”¨æƒ…å†µ...")

            # æ•°æ®åº“è¿æ¥å’ŒæŸ¥è¯¢æ“ä½œ
            conn = taos.connect(
                host=self.host, 
                user=self.user, 
                password=self.passwd, 
                config=self.conf, 
                timezone=self.tz
            )
            cursor = conn.cursor()
            cursor.execute('use stream_to')
            
            print("å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢å’Œå†™å…¥æ“ä½œ...")

            cursor.execute("create stable if not exists stream_to.stb_result(wstart timestamp, avg_c0 float, avg_c1 float, avg_c2 float,avg_c3 float, max_c0 float, max_c1 float, max_c2 float,max_c3 float, min_c0 float, min_c1 float, min_c2 float,min_c3 float) tags(gid bigint unsigned)")

            try:
                t = threading.Thread(target=do_monitor, args=(self.runtime * 60, self.perf_file))
                t.daemon = True 
                t.start()
            except Exception as e:
                print("Error: unable to start thread, %s" % e)
            finally:
                print("Execution completed")

            print("start to query")

            list = get_table_list(cursor)
            print("there are %d tables" % len(list))

            try:
                # å¾ªç¯æ‰§è¡Œå†™å…¥å’Œè®¡ç®—
                cycle_count = 0
                start_time = time.time()
                
                while True:
                    cycle_count += 1
                    print(f"\n=== å¼€å§‹ç¬¬ {cycle_count} è½®å†™å…¥å’Œè®¡ç®— ===")
                    
                    if cycle_count > 1:
                        # ä»ç¬¬äºŒè½®å¼€å§‹ï¼Œå…ˆå†™å…¥æ–°æ•°æ®
                        print(f"\nå†™å…¥æ–°ä¸€æ‰¹æµ‹è¯•æ•°æ® (æ¯è½® {self.real_time_batch_rows} æ¡è®°å½•)...")
                        
                        # åº”ç”¨å†™å…¥é—´éš”æ§åˆ¶
                        if self.real_time_batch_sleep > 0:
                            print(f"ç­‰å¾… {self.real_time_batch_sleep} ç§’åå¼€å§‹å†™å…¥æ•°æ®...")
                            time.sleep(self.real_time_batch_sleep)
                
                        if not self.update_insert_config():
                            raise Exception("å†™å…¥æ–°æ•°æ®å¤±è´¥")
                        
                        cmd = "taosBenchmark -f /tmp/stream_from_insertdata.json"
                        if subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True, text=True).returncode != 0:
                            raise Exception("å†™å…¥æ–°æ•°æ®å¤±è´¥")
                
                        if self.real_time_batch_sleep > 0:
                            print(f"æ•°æ®å†™å…¥å®Œæˆï¼Œå†™å…¥é—´éš”æ§åˆ¶: {self.real_time_batch_sleep}ç§’")
                
                    for index, table in enumerate(list):
                        table_name = table[0]
                        print(f"\nå¼€å§‹å¤„ç†è¡¨ {table_name} ({index+1}/{len(list)})")
                        window_count = 0
                        
                        count_sql = f"select count(*) from stream_from.{table_name}"
                        cursor.execute(count_sql)
                        count_res = cursor.fetchall()
                        if count_res and count_res[0][0] >= 0:
                            print(f"è¡¨ {table_name} åŒ…å« {count_res[0][0]} æ¡è®°å½•")
                            cursor.execute(f"create table if not exists stream_to.{table_name}_1 using stream_to.stb_result tags(1)")
                            
                            # æŸ¥è¯¢è¡¨çš„æ—¶é—´èŒƒå›´
                            range_sql = f"select first(ts), last(ts) from stream_from.{table_name}"
                            print(f"æŸ¥è¯¢æ—¶é—´èŒƒå›´SQL: {range_sql}")
                            cursor.execute(range_sql)
                            time_range = cursor.fetchall()
                            
                            if time_range and len(time_range) > 0 and time_range[0][0]:
                                start_ts = int(time_range[0][0].timestamp() * 1000)
                                end_ts = int(time_range[0][1].timestamp() * 1000)
                                step = 15 * 1000  # 15ç§’
                                
                                # è®¡ç®—æ€»æ—¶é—´çª—å£æ•°
                                total_windows = ((end_ts - start_ts) // step) + 1
                                print(f"æ•°æ®æ—¶é—´èŒƒå›´: {self.format_timestamp(start_ts)} -> {self.format_timestamp(end_ts)}")
                                print(f"é¢„è®¡å¤„ç† {total_windows} ä¸ªæ—¶é—´çª—å£")
                                
                                # ä½¿ç”¨åˆ—è¡¨ä¿å­˜æ‰€æœ‰æ—¶é—´çª—å£
                                time_windows = []
                                current_ts = start_ts
                                while current_ts < end_ts:
                                    next_ts = min(current_ts + step, end_ts)
                                    time_windows.append((current_ts, next_ts))
                                    current_ts = next_ts
                            
                                for window_idx, (window_start, window_end) in enumerate(time_windows, 1):                                
                                    window_sql = (f"select cast({current_ts} as timestamp), "
                                        f"avg(c0), avg(c1), avg(c2), avg(c3), "
                                        f"max(c0), max(c1), max(c2), max(c3), "
                                        f"min(c0), min(c1), min(c2), min(c3) "
                                        f"from stream_from.{table_name} "
                                        f"where ts >= {window_start} and ts < {window_end}")
                                    
                                    #print(f"æ‰§è¡ŒSQLæŸ¥è¯¢: {window_sql}")
                                    cursor.execute(window_sql)
                                    window_data = cursor.fetchall()
                                    
                                    if window_data and len(window_data) > 0:
                                        # å†™å…¥æ•°æ®
                                        insert_sql = f"insert into stream_to.{table_name}_1 values ({current_ts}, {window_data[0][1]}, {window_data[0][2]}, {window_data[0][3]}, {window_data[0][4]}, {window_data[0][5]}, {window_data[0][6]}, {window_data[0][7]}, {window_data[0][8]}, {window_data[0][9]}, {window_data[0][10]}, {window_data[0][11]}, {window_data[0][12]})"
                                        
                                        cursor.execute(insert_sql)
                                        window_count += 1
                                        
                                        # æ˜¾ç¤ºè¿›åº¦
                                        print(f"\rè¿›åº¦: {(window_count/total_windows)*100:.2f}% - "
                                            f"çª—å£ [{window_count}/{total_windows}]: "
                                            f"{self.format_timestamp(current_ts)} -> "
                                            f"{self.format_timestamp(window_end)}", end='')
                                    else:
                                        print(f" stream_from.{table_name} æ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_ts/1000))} -> {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(query_end/1000))}")
                                        break
                                    
                                    # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´çª—å£
                                    current_ts = window_end
                                    
                                print(f"è¡¨ {table_name} å¤„ç†å®Œæˆ, å…±å†™å…¥ {window_count} ä¸ªæ—¶é—´çª—å£çš„æ•°æ®")
                                
                            else:
                                print(f"è¡¨ {table_name} æ— æ•°æ®è®°å½•ï¼Œè·³è¿‡å¤„ç†")
                
                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶
                    if time.time() - start_time >= self.runtime * 60:
                        print(f"\n\nå·²è¾¾åˆ°è¿è¡Œæ—¶é—´é™åˆ¶ ({self.runtime} åˆ†é’Ÿ)ï¼Œåœæ­¢æ‰§è¡Œ")
                        break
                        
                    print(f"\n=== ç¬¬ {cycle_count} è½®å¤„ç†å®Œæˆ ===")
                        
            except Exception as e:
                print(f"æŸ¥è¯¢å†™å…¥æ“ä½œå‡ºé”™: {str(e)}")
            finally:
                cursor.close()
                conn.close()
                print("æŸ¥è¯¢å†™å…¥æ“ä½œå®Œæˆ")
        
                # ä¸»åŠ¨åœæ­¢ç›‘æ§
                print("ä¸»åŠ¨åœæ­¢ç³»ç»Ÿç›‘æ§...")
                loader.stop()
                
            # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            print("ç­‰å¾…ç›‘æ§æ•°æ®æ”¶é›†å®Œæˆ...")
            monitor_thread.join(timeout=15)  # æœ€å¤šç­‰å¾…15ç§’
    
            if monitor_thread.is_alive():
                print("ç›‘æ§çº¿ç¨‹æœªåœ¨é¢„æœŸæ—¶é—´å†…ç»“æŸï¼Œç¨‹åºå°†ç»§ç»­...")
            else:
                print("ç›‘æ§çº¿ç¨‹å·²æ­£å¸¸ç»“æŸ")
            
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
            print("åœæ­¢ç›‘æ§å’ŒæŸ¥è¯¢æ“ä½œ...")
        except Exception as e:
            print(f"æ‰§è¡Œå‡ºé”™: {str(e)}")
        finally:
            print("\næ‰§è¡Œå®Œæˆ")
            print("ç›‘æ§æ•°æ®å·²ä¿å­˜åˆ°: /tmp/perf-taosd-query-*.log")
            print("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç›‘æ§æ•°æ®:")
            print("cat /tmp/perf-taosd-query-all.log")
                     
    def do_query_then_insert_bak(self):
        self.prepare_env()
        self.prepare_source_from_data()
        
        conn = taos.connect(
            host=self.host,
            user=self.user,
            password=self.passwd,
            config=self.conf
        )
        cursor = conn.cursor()

        try:
            # è¿è¡Œsource_fromçš„æ•°æ®ç”Ÿæˆ
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, shell=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"Error running Bash command: {e}")

        # åˆ›å»ºstream_toæ•°æ®åº“
        if not self.create_database('stream_to'):
            raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
        
        time.sleep(5)
        print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")
        # ç­‰å¾…æ•°æ®å‡†å¤‡å°±ç»ª
        if not self.wait_for_data_ready(cursor, self.table_count, self.histroy_rows):
            print("æ•°æ®å‡†å¤‡å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
            return
        
        try:
            # å¯åŠ¨æ€§èƒ½ç›‘æ§çº¿ç¨‹
            loader = MonitorSystemLoad(
                name_pattern='taosd -c', 
                count=self.runtime * 60,
                perf_file='/tmp/perf-taosd-query.log',
                interval=self.monitor_interval
            )
            
            # åœ¨æ–°çº¿ç¨‹ä¸­è¿è¡Œç›‘æ§
            monitor_thread = threading.Thread(
                target=loader.get_proc_status,
                name="TaosdMonitor"
            )
            monitor_thread.daemon = True
            monitor_thread.start()
            print("å¼€å§‹ç›‘æ§taosdè¿›ç¨‹èµ„æºä½¿ç”¨æƒ…å†µ...")

            # æ•°æ®åº“è¿æ¥å’ŒæŸ¥è¯¢æ“ä½œ
            conn = taos.connect(
                host=self.host, 
                user=self.user, 
                password=self.passwd, 
                config=self.conf, 
                timezone=self.tz
            )
            cursor = conn.cursor()
            cursor.execute('use stream_to')
            
            print("å¼€å§‹æ‰§è¡ŒæŸ¥è¯¢å’Œå†™å…¥æ“ä½œ...")

            cursor.execute("create stable if not exists stream_to.stb_result(wstart timestamp, avg_c0 float, avg_c1 float, avg_c2 float,avg_c3 float, max_c0 float, max_c1 float, max_c2 float,max_c3 float, min_c0 float, min_c1 float, min_c2 float,min_c3 float) tags(gid bigint unsigned)")

            try:
                t = threading.Thread(target=do_monitor, args=(self.runtime * 60, self.perf_file))
                t.daemon = True 
                t.start()
            except Exception as e:
                print("Error: unable to start thread, %s" % e)
            finally:
                print("Execution completed")

            print("start to query")

            list = get_table_list(cursor)
            print("there are %d tables" % len(list))

            try:
                for index, table in enumerate(list):
                    table_name = table[0]
                    print(f"\nå¼€å§‹å¤„ç†è¡¨ {table_name} ({index+1}/{len(list)})")
                    window_count = 0
                    
                    count_sql = f"select count(*) from stream_from.{table_name}"
                    cursor.execute(count_sql)
                    count_res = cursor.fetchall()
                    if count_res and count_res[0][0] >= 0:
                        print(f"è¡¨ {table_name} åŒ…å« {count_res[0][0]} æ¡è®°å½•")
                        cursor.execute(f"create table if not exists stream_to.{table_name}_1 using stream_to.stb_result tags(1)")
                        
                        # æŸ¥è¯¢è¡¨çš„æ—¶é—´èŒƒå›´
                        range_sql = f"select first(ts), last(ts) from stream_from.{table_name}"
                        print(f"æŸ¥è¯¢æ—¶é—´èŒƒå›´SQL: {range_sql}")
                        cursor.execute(range_sql)
                        time_range = cursor.fetchall()
                        
                        if time_range and len(time_range) > 0 and time_range[0][0]:
                            start_ts = int(time_range[0][0].timestamp() * 1000)
                            end_ts = int(time_range[0][1].timestamp() * 1000)
                            step = 15 * 1000  # 15ç§’
                            
                            # è®¡ç®—æ€»æ—¶é—´çª—å£æ•°
                            total_windows = ((end_ts - start_ts) // step) + 1
                            print(f"æ•°æ®æ—¶é—´èŒƒå›´: {self.format_timestamp(start_ts)} -> {self.format_timestamp(end_ts)}")
                            print(f"é¢„è®¡å¤„ç† {total_windows} ä¸ªæ—¶é—´çª—å£")
                            
                            # ä½¿ç”¨åˆ—è¡¨ä¿å­˜æ‰€æœ‰æ—¶é—´çª—å£
                            time_windows = []
                            current_ts = start_ts
                            while current_ts < end_ts:
                                next_ts = min(current_ts + step, end_ts)
                                time_windows.append((current_ts, next_ts))
                                current_ts = next_ts
                        
                            for window_idx, (window_start, window_end) in enumerate(time_windows, 1):                                
                                window_sql = (f"select cast({current_ts} as timestamp), "
                                    f"avg(c0), avg(c1), avg(c2), avg(c3), "
                                    f"max(c0), max(c1), max(c2), max(c3), "
                                    f"min(c0), min(c1), min(c2), min(c3) "
                                    f"from stream_from.{table_name} "
                                    f"where ts >= {window_start} and ts < {window_end}")
                                
                                #print(f"æ‰§è¡ŒSQLæŸ¥è¯¢: {window_sql}")
                                cursor.execute(window_sql)
                                window_data = cursor.fetchall()
                                
                                if window_data and len(window_data) > 0:
                                    # å†™å…¥æ•°æ®
                                    insert_sql = f"insert into stream_to.{table_name}_1 values ({current_ts}, {window_data[0][1]}, {window_data[0][2]}, {window_data[0][3]}, {window_data[0][4]}, {window_data[0][5]}, {window_data[0][6]}, {window_data[0][7]}, {window_data[0][8]}, {window_data[0][9]}, {window_data[0][10]}, {window_data[0][11]}, {window_data[0][12]})"
                                    
                                    cursor.execute(insert_sql)
                                    window_count += 1
                                    
                                    # æ˜¾ç¤ºè¿›åº¦
                                    print(f"\rè¿›åº¦: {(window_count/total_windows)*100:.2f}% - "
                                        f"çª—å£ [{window_count}/{total_windows}]: "
                                        f"{self.format_timestamp(current_ts)} -> "
                                        f"{self.format_timestamp(window_end)}", end='')
                                else:
                                    print(f" stream_from.{table_name} æ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(current_ts/1000))} -> {time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(query_end/1000))}")
                                    break
                                
                                # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´çª—å£
                                current_ts = window_end
                                
                            print(f"è¡¨ {table_name} å¤„ç†å®Œæˆ, å…±å†™å…¥ {window_count} ä¸ªæ—¶é—´çª—å£çš„æ•°æ®")
                            
                        else:
                            print(f"è¡¨ {table_name} æ— æ•°æ®è®°å½•ï¼Œè·³è¿‡å¤„ç†")
                        
            except Exception as e:
                print(f"æŸ¥è¯¢å†™å…¥æ“ä½œå‡ºé”™: {str(e)}")
            finally:
                cursor.close()
                conn.close()
                print("æŸ¥è¯¢å†™å…¥æ“ä½œå®Œæˆ")
                
            # ç­‰å¾…ç›‘æ§çº¿ç¨‹ç»“æŸ
            print("ç­‰å¾…ç›‘æ§æ•°æ®æ”¶é›†å®Œæˆ...")
            monitor_thread.join()
            
        except KeyboardInterrupt:
            print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
            print("åœæ­¢ç›‘æ§å’ŒæŸ¥è¯¢æ“ä½œ...")
        except Exception as e:
            print(f"æ‰§è¡Œå‡ºé”™: {str(e)}")
        finally:
            print("\næ‰§è¡Œå®Œæˆ")
            print("ç›‘æ§æ•°æ®å·²ä¿å­˜åˆ°: /tmp/perf-taosd-query-*.log")
            print("å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹ç›‘æ§æ•°æ®:")
            print("cat /tmp/perf-taosd-query-all.log")
        
    def do_query_then_insert_no_monitor(self):
        self.prepare_env()
        self.prepare_source_from_data()

        try:
            # è¿è¡Œsource_fromçš„æ•°æ®ç”Ÿæˆ
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', 
                            stdout=subprocess.PIPE, shell=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"Error running Bash command: {e}")

        # åˆ›å»ºstream_toæ•°æ®åº“
        if not self.create_database('stream_to'):
            raise Exception("åˆ›å»ºstream_toæ•°æ®åº“å¤±è´¥")
        
        time.sleep(10)
        print("æ•°æ®åº“å·²åˆ›å»º,ç­‰å¾…æ•°æ®å†™å…¥...")

        conn = taos.connect(
            host=self.host, user=self.user, password=self.passwd, config=self.conf, timezone=self.tz
        )

        cursor = conn.cursor()
        cursor.execute('use stream_to')

        start_ts = 1748707200000
        step = 300 # å°†æ­¥é•¿æ”¹ä¸º300ç§’

        cursor.execute("create stable if not exists stream_to.stb_result(wstart timestamp, avg_c0 float, avg_c1 float, avg_c2 float,avg_c3 float, max_c0 float, max_c1 float, max_c2 float,max_c3 float, min_c0 float, min_c1 float, min_c2 float,min_c3 float) tags(gid bigint unsigned)")

        try:
            t = threading.Thread(target=do_monitor, args=(self.runtime * 60, self.perf_file))
            t.daemon = True 
            t.start()
        except Exception as e:
            print("Error: unable to start thread, %s" % e)
        finally:
            print("Execution completed")

        print("start to query")

        list = get_table_list(cursor)
        print("there are %d tables" % len(list))

        for index, n in enumerate(list):
            cursor.execute(f"create table if not exists stream_to.{n[0]}_1 using stream_to.stb_result tags(1)")
            count = 1
            while True:
                sql = (f"select cast({start_ts + step * 1000 * (count - 1)} as timestamp), "
                        f"avg(c0), avg(c1), avg(c2), avg(c3), "
                        f"max(c0), max(c1), max(c2), max(c3), "
                        f"min(c0), min(c1), min(c2), min(c3) "
                        f"from stream_from.{n[0]} "
                        f"where ts >= {start_ts + step * 1000 * (count - 1)} "
                        f"and ts < {start_ts + step * 1000 * count}")
                print(f"æ‰§è¡ŒSQLæŸ¥è¯¢: {sql}")
                cursor.execute(sql)

                res = cursor.fetchall()
                if not res or len(res) == 0:  # æ£€æŸ¥æ˜¯å¦æœ‰ç»“æœ
                    print(f"æ²¡æœ‰æŸ¥è¯¢åˆ°æ•°æ®ï¼Œæ—¶é—´èŒƒå›´: {start_ts + step * 1000 * (count - 1)} -> {start_ts + step * 1000 * count}")
                    break

                insert = f"insert into stream_to.{n[0]}_1 values ({start_ts + step * 1000 * (count - 1)}, {res[0][1]}, {res[0][2]}, {res[0][3]}, {res[0][4]}, {res[0][5]}, {res[0][6]}, {res[0][7]}, {res[0][8]}, {res[0][9]}, {res[0][10]}, {res[0][11]}, {res[0][12]})"
                print(f"Inserting: {insert}")
                cursor.execute(insert)
                count += 1
        conn.close()

    def multi_insert(self):
        self.prepare_env()
        self.prepare_source_from_data()

        try:
            subprocess.Popen('taosBenchmark --f /tmp/stream_from.json', stdout=subprocess.PIPE, shell=True, text=True)
            subprocess.Popen('taosBenchmark --f /tmp/stream_to.json', stdout=subprocess.PIPE, shell=True, text=True)
        except subprocess.CalledProcessError as e:
            print(f"Error running Bash command: {e}")

        time.sleep(10)

        for n in range(5):
            try:
                print(f"start query_insert thread {n}")
                t = threading.Thread(target=do_multi_insert, args=(n, 100, self.host, self.user, self.passwd, self.conf, self.tz))
                t.start()
            except Exception as e:
                print("Error: unable to start thread, %s" % e)

        loader = MonitorSystemLoad('taosd', self.runtime * 60, self.perf_file)
        loader.get_proc_status()

    
def main():
    def signal_handler(signum, frame):
        """ä¸»ç¨‹åºçš„ä¿¡å·å¤„ç†å™¨"""
        print("\næ”¶åˆ°ä¸­æ–­ä¿¡å·")
        print("æ­£åœ¨åœæ­¢ç›‘æ§,ä½†ä¿æŒtaosdè¿›ç¨‹è¿è¡Œ...")
        return  # ç›´æ¥è¿”å›ï¼Œä¸æ‰§è¡Œä»»ä½•åœæ­¢æ“ä½œ

    # æ³¨å†Œä¿¡å·å¤„ç†å™¨
    signal.signal(signal.SIGINT, signal_handler)
    signal.signal(signal.SIGTERM, signal_handler)
    
    # ä½¿ç”¨è‡ªå®šä¹‰æ ¼å¼åŒ–å™¨æ¥æ”¹å–„å¸®åŠ©ä¿¡æ¯æ˜¾ç¤º
    class CustomHelpFormatter(argparse.RawDescriptionHelpFormatter):
        def __init__(self, prog):
            super().__init__(prog, max_help_position=50, width=150)
            
        def _format_action_invocation(self, action):
            # ä¿æŒåŸæœ‰çš„è°ƒç”¨æ ¼å¼
            return super()._format_action_invocation(action)
        
        def _format_usage(self, usage, actions, groups, prefix):
            """é‡å†™ usage æ ¼å¼åŒ–ï¼Œæ”¯æŒå¤šè¡Œæ˜¾ç¤º"""
            if prefix is None:
                prefix = 'usage: '
            
            # è·å–ç¨‹åºå
            prog = usage or self._prog
            
            # æ„å»ºå‚æ•°åˆ—è¡¨
            parts = [prog]
            
            # åˆ†ç»„æ˜¾ç¤ºå‚æ•°
            optional_parts = []
            positional_parts = []
            
            for action in actions:
                if action.option_strings:
                    # å¯é€‰å‚æ•°
                    if action.option_strings:
                        opt_str = '/'.join(action.option_strings)
                        if action.nargs != 0:
                            opt_str += f' {action.dest.upper()}'
                        optional_parts.append(f'[{opt_str}]')
                else:
                    # ä½ç½®å‚æ•°
                    positional_parts.append(action.dest.upper())
            
            # ç»„åˆæ‰€æœ‰éƒ¨åˆ†
            all_parts = parts + positional_parts + optional_parts
            
            # æŒ‰è¡Œåˆ†ç»„æ˜¾ç¤º
            lines = [prefix + prog]
            current_line = ''
            max_line_length = 80
            
            for part in optional_parts:
                if len(current_line + ' ' + part) > max_line_length:
                    if current_line:
                        lines.append(' ' * len(prefix) + current_line)
                        current_line = part
                    else:
                        lines.append(' ' * len(prefix) + part)
                else:
                    current_line = current_line + ' ' + part if current_line else part
            
            if current_line:
                lines.append(' ' * len(prefix) + current_line)
                
            return '\n'.join(lines) + '\n\n'
        
        def _fill_text(self, text, width, indent):
            # ä¿æŒæ–‡æœ¬çš„åŸå§‹æ ¼å¼ï¼Œä¸è¿›è¡Œè‡ªåŠ¨æ¢è¡Œ
            return ''.join(indent + line for line in text.splitlines(keepends=True))
        
        def _split_lines(self, text, width):
            # æŒ‰ç…§ \n åˆ†å‰²è¡Œï¼Œä¿æŒæ‰‹åŠ¨æ¢è¡Œ
            if '\n' in text:
                return text.splitlines()
            else:
                # å¯¹äºæ²¡æœ‰æ¢è¡Œç¬¦çš„æ–‡æœ¬ï¼Œä½¿ç”¨é»˜è®¤å¤„ç†
                return argparse.HelpFormatter._split_lines(self, text, width)
    
    parser = argparse.ArgumentParser(
        prog=' python3 stream_perf_test.py -m 1 --stream-perf-test-dir /home/stream_perf_test_dir',
        description='TDengine Stream Perf Test',
        formatter_class=CustomHelpFormatter,
        epilog="""
ä¸Šé¢å‚æ•°å¯ä»¥è¿›è¡Œæ­é…ç»„åˆè¿›è¡Œæµ‹è¯•
        """
    )
    
    # åŸºç¡€è¿è¡Œå‚æ•°
    basic_group = parser.add_argument_group('åŸºç¡€å‚æ•°ï¼Œæ§åˆ¶æµ‹è¯•æ¨¡å¼ã€è¿è¡Œæ—¶é—´ç­‰æ ¸å¿ƒå‚æ•°')
    # basic_group.add_argument('-m', '--mode', type=int, default=0,
    #                         help='è¿è¡Œæ¨¡å¼:\n'
    #                             '  1: do_test_stream_with_realtime_data (å†™å…¥æ•°æ®å¹¶æ‰§è¡Œå®æ—¶æ•°æ®æµè®¡ç®—)\n'
    #                             '  2: do_query_then_insert (æŒç»­æŸ¥è¯¢å†™å…¥)\n'
    #                             '  3: multi_insert (å¤šçº¿ç¨‹æ’å…¥)')
    basic_group.add_argument('-m', '--mode', type=int, default=0,
                            # help='è¿è¡Œæ¨¡å¼:\n'
                            #     '  1: do_test_stream_with_realtime_data (å†™å…¥æ•°æ®å¹¶æ‰§è¡Œå®æ—¶æ•°æ®æµè®¡ç®—)\n'
                            #     '  2: do_query_then_insert (æŒç»­æŸ¥è¯¢å†™å…¥)(å’Œæµè®¡ç®—æ— å…³)\n'
                            #     '  3: do_test_stream_with_restored_data (æ¢å¤å†å²æ•°æ®å¹¶æµ‹è¯•æŒ‡å®šæµè®¡ç®—)')
                            help='''è¿è¡Œæ¨¡å¼ (å¿…é€‰):
  1 = do_test_stream_with_realtime_data: åˆ›å»ºæ•°æ®å¹¶æ‰§è¡Œå®æ—¶æµè®¡ç®—æµ‹è¯•
      â”œâ”€ è‡ªåŠ¨ç”Ÿæˆæµ‹è¯•æ•°æ®
      â”œâ”€ åˆ›å»ºå¹¶å¯åŠ¨æµè®¡ç®—  
      â”œâ”€ æ¨¡æ‹ŸæŒç»­å®æ—¶å†™å…¥æ•°æ®
      â””â”€ å…¨ç¨‹æ€§èƒ½ç›‘æ§
      
  2 = do_test_stream_with_restored_data: åŠ è½½å†å²æ•°æ®å¹¶æ‰§è¡Œæµè®¡ç®—æµ‹è¯•
      â”œâ”€ ä»å¤‡ä»½æ¢å¤å†å²æ•°æ®
      â”œâ”€ æµ‹è¯•æŒ‡å®šçš„æµè®¡ç®—SQL  
      â””â”€ é¿å…é‡å¤æ•°æ®ç”Ÿæˆï¼ŒèŠ‚çœæ—¶é—´
      
  3 = do_query_then_insert: æŒç»­æŸ¥è¯¢å†™å…¥(å’Œæµè®¡ç®—æ— å…³)
      â”œâ”€ æŒç»­å†™å…¥æ•°æ®
      â”œâ”€ æŒç»­æ‰§è¡ŒèšåˆæŸ¥è¯¢
      â””â”€ ç”¨äºå¯¹æ¯”æµè®¡ç®—ä¸æŸ¥è¯¢æ€§èƒ½å·®å¼‚
      
é»˜è®¤: 0 (æ˜¾ç¤ºå¸®åŠ©)\n''')
    basic_group.add_argument('-t', '--time', type=int, default=10,
                            help='è¿è¡Œæ—¶é—´(åˆ†é’Ÿ), é»˜è®¤10åˆ†é’Ÿ\n')
    basic_group.add_argument('-f', '--file', type=str, default='/tmp/perf.log',
                            help='æ€§èƒ½æ•°æ®è¾“å‡ºæ–‡ä»¶è·¯å¾„, é»˜è®¤/tmp/perf.log')
    
    # æ•°æ®ç›¸å…³å‚æ•°
    data_group = parser.add_argument_group('æ•°æ®å‚æ•°, æ§åˆ¶æ•°æ®è§„æ¨¡å’Œå†™å…¥é€Ÿåº¦')
    data_group.add_argument('--table-count', type=int, default=500,
                            help='å­è¡¨æ•°é‡, é»˜è®¤500, æµ‹è¯•å¤§æ•°æ®æ—¶éœ€è°ƒå¤§æ­¤å‚æ•°')
    data_group.add_argument('--histroy-rows', type=int, default=1,
                            help='æ¯ä¸ªå­è¡¨æ’å…¥å†å²æ•°æ®æ•°, é»˜è®¤1')
    data_group.add_argument('--real-time-batch-rows', type=int, default=200,
                            help='åç»­æ¯ä¸ªå­è¡¨æ¯è½®æ’å…¥å®æ—¶æ•°æ®æ•°, é»˜è®¤200ã€timestamp_step = 50ã€‘')
    data_group.add_argument('--real-time-batch-sleep', type=float, default=0,
                            help='æ•°æ®å†™å…¥é—´éš”æ—¶é—´(ç§’), é»˜è®¤0ç§’\n'
                                '    æ§åˆ¶æ¯è½®æ•°æ®å†™å…¥ä¹‹é—´çš„ç­‰å¾…æ—¶é—´\n'
                                '    ç”¨äºè°ƒèŠ‚å†™å…¥å‹åŠ›ï¼Œè§‚å¯Ÿæµè®¡ç®—å»¶è¿Ÿå˜åŒ–\n'
                                '    å»ºè®®å€¼: 0(æ— æ§åˆ¶), 1-10(è½»åº¦æ§åˆ¶), 10+(é‡åº¦æ§åˆ¶)\n'
                                '    ä¾‹å¦‚: --real-time-batch-sleep 5')
    data_group.add_argument('--disorder-ratio', type=int, default=0,
                            help='æ•°æ®ä¹±åºç‡, é»˜è®¤0æ— ä¹±åº, ä¹±åºè¿‡å¤šå½±å“æµè®¡ç®—é€Ÿåº¦')
    data_group.add_argument('--vgroups', type=int, default=10,
                            help='''vgroupsæ•°é‡, é»˜è®¤10\n
ç¤ºä¾‹ç”¨æ³•:%(prog)s --table-count 10000 --histroy-rows 1000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --disorder-ratio 1 --vgroups 20 --sql-type intervalsliding_stb --time 60\n\n''')
    
    # SQLç›¸å…³å‚æ•°
    sql_group = parser.add_argument_group('æµè®¡ç®—SQLé…ç½®')
    
    # old for phase 1
    # sql_group.add_argument('--sql-type', type=str, default='s2_7',
    #                     choices=['s2_2', 's2_3', 's2_4', 's2_5', 's2_6', 
    #                              's2_7', 's2_8', 's2_9', 's2_10', 's2_11', 
    #                              's2_12', 's2_13', 's2_14', 's2_15', 'all'],
    #                      help='å®æ—¶æµè®¡ç®—SQLç±»å‹:\n'
    #                           '  s2_2: trigger at_once\n'
    #                           '  s2_3: trigger window_close\n'
    #                           '  s2_4: trigger max_delay 5s\n'
    #                           '  s2_5: trigger FORCE_WINDOW_CLOSE\n'
    #                           '  s2_6: trigger CONTINUOUS_WINDOW_CLOSE\n'
    #                           '  s2_7: INTERVAL(15s) çª—å£\n'
    #                           '  s2_8: INTERVAL with %%trows\n'
    #                           '  s2_9: INTERVAL with MAX_DELAY\n'
    #                           '  s2_10: INTERVAL with MAX_DELAY and %%trows\n'
    #                           '  s2_11: PERIOD(15s) å®šæ—¶è§¦å‘\n'
    #                           '  s2_12: SESSION(ts,10a) ä¼šè¯çª—å£\n'
    #                           '  s2_13: COUNT_WINDOW(1000) è®¡æ•°çª—å£\n'
    #                           '  s2_14: EVENT_WINDOW äº‹ä»¶çª—å£\n'
    #                           '  s2_15: STATE_WINDOW çŠ¶æ€çª—å£\n'
    #                           '  all: æ‰¹é‡æ‰§è¡Œå¤šç§æµç±»å‹')
    
    def validate_sql_type(value):
        """éªŒè¯ SQL ç±»å‹å‚æ•°"""
        valid_choices = [
            'select_stream', 'all_detailed',
            'tbname_agg', 'tbname_select', 'trows_agg', 'trows_select',
            'sourcetable_agg', 'sourcetable_select',
            'intervalsliding_stb', 'intervalsliding_stb_partition_by_tbname', 'intervalsliding_stb_partition_by_tag', 'intervalsliding_tb',
            'sliding_stb', 'sliding_stb_partition_by_tbname', 'sliding_stb_partition_by_tag', 'sliding_tb', 
            'session_stb', 'session_stb_partition_by_tbname', 'session_stb_partition_by_tag', 'session_tb',
            'count_stb', 'count_stb_partition_by_tbname', 'count_stb_partition_by_tag', 'count_tb',
            'event_stb', 'event_stb_partition_by_tbname', 'event_stb_partition_by_tag', 'event_tb',
            'state_stb', 'state_stb_partition_by_tbname', 'state_stb_partition_by_tag', 'state_tb',
            'period_stb', 'period_stb_partition_by_tbname', 'period_stb_partition_by_tag', 'period_tb',
            'intervalsliding_detailed', 'sliding_detailed', 'session_detailed', 'count_detailed',
            'event_detailed', 'state_detailed', 'period_detailed'
        ]
        
        if value not in valid_choices:
            # æŒ‰ç±»åˆ«æ ¼å¼åŒ–é”™è¯¯ä¿¡æ¯
            error_msg = f"invalid choice: '{value}'\n\næœ‰æ•ˆé€‰æ‹©é¡¹:\n"
            error_msg += "è¯´æ˜: stb(è¶…çº§è¡¨), tb(å­è¡¨), by_tbname(tbnameåˆ†ç»„), by_tag(tagåˆ†ç»„,ç¬¬ä¸€åˆ—tag)\n"
            error_msg += "æŸ¥è¯¢ç±»å‹: select_stream æŸ¥è¯¢æ‰€æœ‰æµä¿¡æ¯\n"
            error_msg += "å›ºå®šå‚æ•°ç»„åˆ: tbname_agg, tbname_select, trows_agg, trows_select, sourcetable_agg, sourcetable_select,\n"
            error_msg += "æ—¶é—´çª—å£: intervalsliding_stb, intervalsliding_stb_partition_by_tbname, intervalsliding_stb_partition_by_tag, intervalsliding_tb\n"
            error_msg += "æ»‘åŠ¨çª—å£: sliding_stb, sliding_stb_partition_by_tbname, sliding_stb_partition_by_tag, sliding_tb\n"
            error_msg += "ä¼šè¯çª—å£: session_stb, session_stb_partition_by_tbname, session_stb_partition_by_tag, session_tb\n"
            error_msg += "è®¡æ•°çª—å£: count_stb, count_stb_partition_by_tbname, count_stb_partition_by_tag, count_tb\n"
            error_msg += "äº‹ä»¶çª—å£: event_stb, event_stb_partition_by_tbname, event_stb_partition_by_tag, event_tb\n"
            error_msg += "çŠ¶æ€çª—å£: state_stb, state_stb_partition_by_tbname, state_stb_partition_by_tag, state_tb\n"
            error_msg += "å®šæ—¶è§¦å‘: period_stb, period_stb_partition_by_tbname, period_stb_partition_by_tag, period_tb\n"
            error_msg += "ç»„åˆæ¨¡æ¿: intervalsliding_detailed, session_detailed, count_detailed, event_detailed, state_detailed, period_detailed, all_detailed"
            
            raise argparse.ArgumentTypeError(error_msg)
        return value

    # ä½¿ç”¨æ—¶ä¸è®¾ç½® choicesï¼Œè€Œæ˜¯ä½¿ç”¨ type å‚æ•°è¿›è¡ŒéªŒè¯
    sql_group.add_argument('--sql-type', type=validate_sql_type, default='select_stream',
                        help='''å®æ—¶æµè®¡ç®—SQLç±»å‹:
    è¯´æ˜:
        stb(è¶…çº§è¡¨), tb(å­è¡¨), by_tbname(tbnameåˆ†ç»„), by_tag(tagåˆ†ç»„,ç¬¬ä¸€åˆ—tag)
    æŸ¥è¯¢ç±»å‹:
        select_stream: æŸ¥è¯¢æ‰€æœ‰æµä¿¡æ¯ (é»˜è®¤æŸ¥è¯¢information_schema.ins_streamsçš„æ•°æ®)
    å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿(å¿½ç•¥ --tbname-or-trows-or-sourcetable å’Œ --agg-or-select å‚æ•°):
        tbname_agg:    æ‰€æœ‰çª—å£ç±»å‹ + tbname + èšåˆæŸ¥è¯¢
        tbname_select: æ‰€æœ‰çª—å£ç±»å‹ + tbname + æŠ•å½±æŸ¥è¯¢  
        trows_agg:     æ‰€æœ‰çª—å£ç±»å‹ + trows +  èšåˆæŸ¥è¯¢
        trows_select:  æ‰€æœ‰çª—å£ç±»å‹ + trows +  æŠ•å½±æŸ¥è¯¢
        sourcetable_agg:   æ‰€æœ‰çª—å£ç±»å‹ + sourcetable + èšåˆæŸ¥è¯¢
        sourcetable_select: æ‰€æœ‰çª—å£ç±»å‹ + sourcetable + æŠ•å½±æŸ¥è¯¢
    æ—¶é—´çª—å£æ¨¡æ¿(INTERVAL(15s) SLIDING(15s)):
        intervalsliding_stb, intervalsliding_stb_partition_by_tbname, intervalsliding_stb_partition_by_tag, intervalsliding_tb
    æ»‘åŠ¨çª—å£æ¨¡æ¿(SLIDING(15s)):
        sliding_stb, sliding_stb_partition_by_tbname, sliding_stb_partition_by_tag, sliding_tb
    ä¼šè¯çª—å£æ¨¡æ¿(SESSION(ts,10a)):
        session_stb, session_stb_partition_by_tbname, session_stb_partition_by_tag, session_tb
    è®¡æ•°çª—å£æ¨¡æ¿(COUNT_WINDOW(1000)):
        count_stb, count_stb_partition_by_tbname, count_stb_partition_by_tag, count_tb
    äº‹ä»¶çª—å£æ¨¡æ¿(EVENT_WINDOW(START WITH c0 > 5 END WITH c0 < 5)):
        event_stb, event_stb_partition_by_tbname, event_stb_partition_by_tag, event_tb
    çŠ¶æ€çª—å£æ¨¡æ¿(STATE_WINDOW(c0)):
        state_stb, state_stb_partition_by_tbname, state_stb_partition_by_tag, state_tb
    å®šæ—¶è§¦å‘æ¨¡æ¿(PERIOD(15s)):
        period_stb, period_stb_partition_by_tbname, period_stb_partition_by_tag, period_tb
    ç»„åˆæ¨¡æ¿(æ¯ç»„åŒ…å«ä¸Šè¿°4ä¸ªç»„åˆ,allåŒ…å«ä¸Šè¿°æ‰€æœ‰ç»„åˆ):
        intervalsliding_detailed, sliding_detailed, session_detailed, count_detailed, event_detailed, 
        state_detailed, period_detailed, all_detailed''')
    
    sql_group.add_argument('--stream-num', type=int, default=1,
                        help='æµæ•°é‡: å½“ sql-type ä¸ºéç»„åˆæ¨¡ç‰ˆæ—¶ï¼Œåˆ›å»ºæŒ‡å®šæ•°é‡çš„ç›¸åŒæµ\n'
                                '    å¹¶å‘æµæ•°é‡, é»˜è®¤1ä¸ªæµ\n'
                                '    è®¾ç½®ä¸ºNæ—¶ï¼Œä¼šåˆ›å»ºNä¸ªç¼–å·ä¸º1åˆ°Nçš„ç›¸åŒæµï¼Œå¦‚æœæ˜¯ä»å­è¡¨è·å–æ•°æ®åˆ™ä»ç¬¬ä¸€ä¸ªå­è¡¨åˆ°ç¬¬Nä¸ªå­è¡¨\n'
                                '    éœ€è¦å’Œ --sql-type æ­é…ä½¿ç”¨ï¼Œé€‚åˆæµ‹è¯•å¤šä¸ªæµçš„å‹åŠ›\n'
                                '    ç¤ºä¾‹: --sql-type intervalsliding_stb --stream-num 100')
    
    sql_group.add_argument('--stream-sql', type=str,
                        help='è‡ªå®šä¹‰æµè®¡ç®—SQL (ä¼˜å…ˆçº§æœ€é«˜)\n'
                                '    ç¤ºä¾‹: "create stream test_stream..."')
    
    sql_group.add_argument('--agg-or-select', type=str, default='agg',
                        choices=['agg', 'select'],
                        help='æŸ¥è¯¢ç±»å‹:\n'
                            '    agg: èšåˆæŸ¥è¯¢ (avg,max,min)\n'
                            '         avg(c0), avg(c1), avg(c2), avg(c3), max(c0), max(c1), max(c2), max(c3), min(c0), min(c1), min(c2), min(c3)\n'
                            '    select: æŠ•å½±æŸ¥è¯¢ (c0,c1,c2,c3)')
    sql_group.add_argument('--custom-columns', type=str,
                        help='è‡ªå®šä¹‰æŸ¥è¯¢åˆ— (é€—å·åˆ†éš”):\n'
                                '    ç¤ºä¾‹: "sum(c0),count(*),avg(c1)"\n'
                                '          "c0,c1,c2" (æŠ•å½±æŸ¥è¯¢)\n'
                                '    æ³¨æ„: ä¼šè¦†ç›– --agg-or-select è®¾ç½®')
    
    sql_group.add_argument('--use-virtual-table', 
                        action='store_true', 
                        default=False,
                        help='å¯ç”¨è™šæ‹Ÿè¡¨æ¨¡å¼ï¼šæºæ•°æ®è¡¨ä½¿ç”¨forvt_å‰ç¼€ï¼Œåˆ›å»ºè™šæ‹Ÿè¡¨æ˜ å°„ (é»˜è®¤: False)')
    sql_group.add_argument('--tbname-or-trows-or-sourcetable', type=str, default='sourcetable',
                        choices=['tbname', 'trows', 'sourcetable'],
                        help='FROMå­å¥ç±»å‹ï¼Œé»˜è®¤sourcetable:\n'
                            '    sourcetable - è¶…çº§è¡¨: from stream_from.stb where ts >= _twstart and ts <= _twend\n'
                            '    sourcetable - å­è¡¨: from stream_from.ctb0_N where ts >= _twstart and ts <= _twend\n'
                            '    tbname: from %%tbname where ts >= _twstart and ts <= _twend\n'
                            '    trows:  from %%trows ')
    
    sql_group.add_argument('--auto-combine', action='store_true',
                    help='''è‡ªåŠ¨ç”Ÿæˆå‚æ•°ç»„åˆï¼Œåˆ›å»º6ä¸ªæµ(å¿½ç•¥ --agg-or-select å’Œ --tbname-or-trows-or-sourcetable å‚æ•°):
  
åŠŸèƒ½: å¯¹æŒ‡å®šçš„å•ä¸ªæµç±»å‹ï¼Œè‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰å‚æ•°ç»„åˆ
  â”œâ”€ tbname + agg:         ä½¿ç”¨ %%tbname + èšåˆæŸ¥è¯¢
  â”œâ”€ tbname + select:      ä½¿ç”¨ %%tbname + æŠ•å½±æŸ¥è¯¢  
  â”œâ”€ trows + agg:          ä½¿ç”¨ %%trows + èšåˆæŸ¥è¯¢
  â”œâ”€ trows + select:       ä½¿ç”¨ %%trows + æŠ•å½±æŸ¥è¯¢
  â”œâ”€ sourcetable + agg:    ä½¿ç”¨å…·ä½“è¡¨å + èšåˆæŸ¥è¯¢
  â””â”€ sourcetable + select: ä½¿ç”¨å…·ä½“è¡¨å + æŠ•å½±æŸ¥è¯¢

é€‚ç”¨èŒƒå›´: ä»…å¯¹å•ä¸ªæµç±»å‹æœ‰æ•ˆ (å¦‚ intervalsliding_stb)
ä¸é€‚ç”¨äº: ç»„åˆæ¨¡æ¿ (*_detailed) å’Œå›ºå®šå‚æ•°æ¨¡æ¿ (tbname_aggç­‰)

ç¤ºä¾‹ç”¨æ³•:
  --sql-type intervalsliding_stb --auto-combine    # ç”Ÿæˆ6ä¸ªç»„åˆ
  --sql-type session_stb --auto-combine           # ç”Ÿæˆ6ä¸ªç»„åˆ
  
æ³¨æ„: ä½¿ç”¨æ­¤å‚æ•°æ—¶ä¼šå¿½ç•¥ --agg-or-select å’Œ --tbname-or-trows-or-sourcetable è®¾ç½®''')
    
    # todo
    sql_group.add_argument('--sql-file', type=str,
                        help='ä»æ–‡ä»¶è¯»å–æµå¼æŸ¥è¯¢SQLï¼Œtodo\n'
                            '''    ç¤ºä¾‹: --sql-file ./my_stream.sql\n
ç¤ºä¾‹ç”¨æ³•1:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_stb --time 60\n
ç¤ºä¾‹ç”¨æ³•2:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_stb --auto-combine --time 60\n
ç¤ºä¾‹ç”¨æ³•3:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_detailed --time 60\n
ç¤ºä¾‹ç”¨æ³•4:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type tbname_agg --time 60\n
ç¤ºä¾‹ç”¨æ³•5:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_detailed --tbname-or-trows-or-sourcetable trows\n
ç¤ºä¾‹ç”¨æ³•6:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_detailed --agg-or-select select\n
ç¤ºä¾‹ç”¨æ³•7:%(prog)s --table-count 10000 \n --real-time-batch-rows 500 --real-time-batch-sleep 5 --sql-type intervalsliding_stb --stream-num 100\n\n''')
    
    # æµæ€§èƒ½ç›‘æ§å‚æ•°
    stream_monitor_group = parser.add_argument_group('æµæ€§èƒ½ç›‘æ§å’Œæµè®¡ç®—å»¶è¿Ÿæ£€æµ‹')
    stream_monitor_group.add_argument('--check-stream-delay', action='store_true',
                                    help='''å¯ç”¨æµè®¡ç®—å»¶è¿Ÿç›‘æ§,é»˜è®¤ä¸å¼€å¯,åŠ ä¸Šæ­¤å‚æ•°åä¼šè‡ªåŠ¨ç›‘æ§æµè®¡ç®—å»¶è¿Ÿ:  
åŠŸèƒ½: å®æ—¶ç›‘æµ‹æºè¡¨ä¸ç›®æ ‡è¡¨çš„æ•°æ®å»¶è¿Ÿ
  â”œâ”€ æ™ºèƒ½å»¶è¿Ÿåˆ†çº§: ä¼˜ç§€/è‰¯å¥½/æ­£å¸¸/è½»å¾®/æ˜æ˜¾/ä¸¥é‡
  â”œâ”€ åŠ¨æ€é˜ˆå€¼è®¡ç®—: åŸºäºæ£€æŸ¥é—´éš”è‡ªåŠ¨è°ƒæ•´  
  â”œâ”€ é—®é¢˜è¯Šæ–­: è‡ªåŠ¨è¯†åˆ«æ— æ•°æ®/è¡¨ä¸å­˜åœ¨ç­‰é—®é¢˜
  â””â”€ ä¼˜åŒ–å»ºè®®: æä¾›å…·ä½“çš„æ€§èƒ½è°ƒä¼˜å»ºè®®

è¾“å‡º: è¯¦ç»†å»¶è¿ŸæŠ¥å‘Šä¿å­˜ä¸º /tmp/*-stream-delay.log''')
    stream_monitor_group.add_argument('--max-delay-threshold', type=int, default=30000,
                                    help='æœ€å¤§å…è®¸å»¶è¿Ÿæ—¶é—´(æ¯«ç§’), é»˜è®¤30000ms(30ç§’)\n'
                                        'è¶…è¿‡æ­¤é˜ˆå€¼è®¤ä¸ºæµè®¡ç®—è·Ÿä¸ä¸Šæ•°æ®å†™å…¥é€Ÿåº¦ï¼Œå¯ä»¥é’ˆå¯¹å…·ä½“çš„æµå’Œé—´éš”è°ƒæ•´')

    stream_monitor_group.add_argument('--delay-trends-analysis', action='store_true',
                                help='''å¯ç”¨å»¶è¿Ÿè¶‹åŠ¿åˆ†æï¼Œé»˜è®¤ä¸å¼€å¯:
åŠŸèƒ½: åœ¨å»¶è¿Ÿç›‘æ§åŸºç¡€ä¸Šå¢åŠ è¶‹åŠ¿åˆ†æ
  â”œâ”€ æ—¶é—´åºåˆ—åˆ†æ: è®°å½•å„æ¬¡æ£€æŸ¥çš„å»¶è¿Ÿå˜åŒ–è¶‹åŠ¿
  â”œâ”€ è¶‹åŠ¿å¯è§†åŒ–: åœ¨HTMLæŠ¥å‘Šä¸­æ˜¾ç¤ºå»¶è¿Ÿå˜åŒ–
  â””â”€ æ€§èƒ½å»ºè®®: åŸºäºè¶‹åŠ¿æä¾›ä¼˜åŒ–å»ºè®®
è¾“å‡º: å»¶è¿Ÿè¶‹åŠ¿æ•°æ®æ•´åˆåˆ°å»¶è¿Ÿæ—¥å¿—å’ŒHTMLæŠ¥å‘Šä¸­
æ³¨æ„: éœ€è¦é…åˆ --check-stream-delay ä½¿ç”¨''')

    stream_monitor_group.add_argument('--delay-check-interval', type=int, default=10,
                                    help='''å»¶è¿Ÿæ£€æŸ¥é—´éš”(ç§’), é»˜è®¤10ç§’, ç›®å‰æ˜¯ç²—ç²’åº¦çš„æ£€æŸ¥ç”Ÿæˆç›®æ ‡è¡¨è¶…çº§è¡¨çš„last(ts), è€Œéæ¯ä¸ªç”Ÿæˆå­è¡¨çš„last(ts)\n
ç¤ºä¾‹ç”¨æ³•:%(prog)s --check-stream-delay \n--max-delay-threshold 60000 --delay-check-interval 5 --sql-type intervalsliding_stb \n\n''')
 
    # æ‰¹é‡æµ‹è¯•å‚æ•°
    batch_group = parser.add_argument_group('æ‰¹é‡æµ‹è¯•ï¼Œè‡ªåŠ¨æ‰§è¡Œå¤šç§å‚æ•°ç»„åˆ')
    batch_group.add_argument('--batch-test', action='store_true',
                            help='''å¯ç”¨æ‰¹é‡æµ‹è¯•æ¨¡å¼:
æ‰§è¡Œæµç¨‹:
  1. è‡ªåŠ¨ç”Ÿæˆæ‰€æœ‰æœ‰æ•ˆçš„å‚æ•°ç»„åˆ (çº¦168ç§ï¼Œå…¶ä¸­æˆåŠŸ102ç§ï¼Œå¤±è´¥66ç§ï¼Œæ€§èƒ½å¿½ç•¥58ç§)
  2. ä¸ºæ¯ä¸ªç»„åˆä¾æ¬¡æ‰§è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹
  3. æ¯æ¬¡æµ‹è¯•å‰è‡ªåŠ¨æ¸…ç†ç¯å¢ƒå’Œé‡å¯æœåŠ¡
  4. ç”Ÿæˆè¯¦ç»†çš„HTMLæµ‹è¯•æŠ¥å‘Šå’Œæ€§èƒ½æ•°æ®
  5. æ”¯æŒæµ‹è¯•ä¸­æ–­åä»æŒ‡å®šä½ç½®ç»§ç»­

ç‰¹ç‚¹:
  â”œâ”€ å…¨è‡ªåŠ¨åŒ–: æ— éœ€äººå·¥å¹²é¢„ï¼Œè‡ªåŠ¨å¤„ç†æ‰€æœ‰ç»„åˆ
  â”œâ”€ ç¯å¢ƒéš”ç¦»: æ¯æ¬¡æµ‹è¯•å‰å®Œå…¨æ¸…ç†ç¯å¢ƒï¼Œé¿å…å¹²æ‰°
  â”œâ”€ è¯¦ç»†æŠ¥å‘Š: HTMLæ ¼å¼æŠ¥å‘Šï¼ŒåŒ…å«æˆåŠŸç‡ã€è€—æ—¶ç­‰ç»Ÿè®¡
  â”œâ”€ æµå»¶è¿Ÿç›‘æ§: æ‰¹é‡æµ‹è¯•è‡ªåŠ¨å¯ç”¨æµå»¶è¿Ÿæ£€æŸ¥ 
  â””â”€ æ–­ç‚¹ç»­ä¼ : æ”¯æŒä»æŒ‡å®šæµ‹è¯•ç¼–å·å¼€å§‹æ‰§è¡Œ

æ³¨æ„: æ‰¹é‡æµ‹è¯•ä¼šè¦†ç›–å…¶ä»–ç›¸å…³å‚æ•°è®¾ç½®ï¼Œå¹¶å¼ºåˆ¶å¯ç”¨æµå»¶è¿Ÿç›‘æ§''')
    
    batch_group.add_argument('--batch-sql-types', type=str, nargs='+',
                        help='''æŒ‡å®šæ‰¹é‡æµ‹è¯•çš„SQLç±»å‹ï¼Œæ”¯æŒå¤šä¸ªç±»å‹ç©ºæ ¼åˆ†éš”:

å•ä¸ªçª—å£ç±»å‹æ¨¡æ¿:
  intervalsliding_stb, intervalsliding_stb_partition_by_tbname, intervalsliding_stb_partition_by_tag, intervalsliding_tb
  sliding_stb, sliding_stb_partition_by_tbname, sliding_stb_partition_by_tag, sliding_tb
  session_stb, session_stb_partition_by_tbname, session_stb_partition_by_tag, session_tb
  count_stb, count_stb_partition_by_tbname, count_stb_partition_by_tag, count_tb
  event_stb, event_stb_partition_by_tbname, event_stb_partition_by_tag, event_tb
  state_stb, state_stb_partition_by_tbname, state_stb_partition_by_tag, state_tb
  period_stb, period_stb_partition_by_tbname, period_stb_partition_by_tag, period_tb

å›ºå®šå‚æ•°ç»„åˆæ¨¡æ¿(æ‰€æœ‰çª—å£ç±»å‹):
  tbname_agg:        æ‰€æœ‰çª—å£ç±»å‹ + tbname + èšåˆæŸ¥è¯¢ (28ç§ç»„åˆ)
  tbname_select:     æ‰€æœ‰çª—å£ç±»å‹ + tbname + æŠ•å½±æŸ¥è¯¢ (28ç§ç»„åˆ)
  trows_agg:         æ‰€æœ‰çª—å£ç±»å‹ + trows + èšåˆæŸ¥è¯¢ (28ç§ç»„åˆ)
  trows_select:      æ‰€æœ‰çª—å£ç±»å‹ + trows + æŠ•å½±æŸ¥è¯¢ (28ç§ç»„åˆ)
  sourcetable_agg:   æ‰€æœ‰çª—å£ç±»å‹ + sourcetable + èšåˆæŸ¥è¯¢ (28ç§ç»„åˆ)
  sourcetable_select: æ‰€æœ‰çª—å£ç±»å‹ + sourcetable + æŠ•å½±æŸ¥è¯¢ (28ç§ç»„åˆ)

ç»„åˆæ¨¡æ¿(æ¯ç»„4ç§ç»„åˆ):
  intervalsliding_detailed: æ—¶é—´çª—å£çš„24ç§ç»„åˆ
  sliding_detailed:        æ»‘åŠ¨çª—å£çš„24ç§ç»„åˆ  
  session_detailed:        ä¼šè¯çª—å£çš„24ç§ç»„åˆ
  count_detailed:          è®¡æ•°çª—å£çš„24ç§ç»„åˆ
  event_detailed:          äº‹ä»¶çª—å£çš„24ç§ç»„åˆ
  state_detailed:          çŠ¶æ€çª—å£çš„24ç§ç»„åˆ
  period_detailed:         å®šæ—¶è§¦å‘çš„24ç§ç»„åˆ

ç‰¹æ®Šç±»å‹:
  all_detailed:            æ‰€æœ‰çª—å£ç±»å‹çš„detailedç»„åˆ (168ç§)

ç¤ºä¾‹ç”¨æ³•:
  --batch-sql-types tbname_agg                    # åªæµ‹è¯•tbname+aggçš„æ‰€æœ‰çª—å£ç±»å‹
  --batch-sql-types intervalsliding_detailed      # åªæµ‹è¯•æ—¶é—´çª—å£çš„24ç§ç»„åˆ
  --batch-sql-types tbname_agg trows_agg          # æµ‹è¯•tbname_aggå’Œtrows_agg
  --batch-sql-types sliding_stb session_stb       # æµ‹è¯•æŒ‡å®šçš„ä¸¤ä¸ªå•ä¸ªæ¨¡æ¿
  
é»˜è®¤: å¦‚æœä¸æŒ‡å®šæ­¤å‚æ•°ï¼Œåˆ™æµ‹è¯•æ‰€æœ‰æœ‰æ•ˆç»„åˆ(168ç§)''')
    
    batch_group.add_argument('--batch-single-template-mode', type=str, 
                        choices=['default', 'all-combinations'], 
                        default='default',
                        help='''æ‰¹é‡æµ‹è¯•ä¸­å•ä¸ªæ¨¡æ¿çš„å¤„ç†æ–¹å¼:
    default: åªæµ‹è¯•é»˜è®¤å‚æ•°ç»„åˆ (sourcetable + agg)
    all-combinations: æµ‹è¯•æ‰€æœ‰6ç§å‚æ•°ç»„åˆ (3ä¸ªfromç±»å‹ Ã— 2ä¸ªæŸ¥è¯¢ç±»å‹)
    
ç¤ºä¾‹:
    --batch-sql-types intervalsliding_stb --batch-single-template-mode default
        åªæµ‹è¯• 1 ä¸ªç»„åˆ: intervalsliding_stb + sourcetable + agg        
    --batch-sql-types intervalsliding_stb --batch-single-template-mode all-combinations  
        æµ‹è¯• 6 ä¸ªç»„åˆ: intervalsliding_stb çš„æ‰€æœ‰å‚æ•°ç»„åˆ
        
æ³¨æ„: è¯¦ç»†æ¨¡æ¿ (*_detailed) å’Œå›ºå®šå‚æ•°æ¨¡æ¿ (tbname_aggç­‰) ä¸å—æ­¤å‚æ•°å½±å“''')
    
    batch_group.add_argument('--batch-test-time', type=int, default=5,
                            help='æ‰¹é‡æµ‹è¯•ä¸­æ¯ä¸ªæµ‹è¯•çš„è¿è¡Œæ—¶é—´(åˆ†é’Ÿ), é»˜è®¤5åˆ†é’Ÿ\n'
                                'æ€»è€—æ—¶ = ç»„åˆæ•° Ã— æ¯ä¸ªæµ‹è¯•æ—¶é—´\n'
                                'ä¾‹å¦‚168ä¸ªç»„åˆÃ—5åˆ†é’Ÿ = 14å°æ—¶')
    
    batch_group.add_argument('--batch-start-from', type=int, default=0,
                            help='ä»ç¬¬å‡ ä¸ªæµ‹è¯•å¼€å§‹(ä»0å¼€å§‹è®¡æ•°), é»˜è®¤0\n'
                                'ç”¨äºæ–­ç‚¹ç»­ä¼ ï¼Œä¾‹å¦‚ --batch-start-from 50')
    
    batch_group.add_argument('--batch-filter-mode', type=str, choices=['all', 'skip-known-failures', 'only-known-failures', 'skip-known-case'], default='all',
                        help='''æ‰¹é‡æµ‹è¯•è¿‡æ»¤æ¨¡å¼ï¼Œæ§åˆ¶æ˜¯å¦è¿è¡Œå·²çŸ¥å¤±è´¥çš„æµ‹è¯•åœºæ™¯:
    all: è¿è¡Œæ‰€æœ‰168ä¸ªæµ‹è¯•åœºæ™¯ (é»˜è®¤)
    skip-known-failures: è·³è¿‡å·²çŸ¥ä¼šå¤±è´¥çš„66ä¸ªåœºæ™¯ï¼Œåªè¿è¡Œ102ä¸ªæˆåŠŸåœºæ™¯
    only-known-failures: åªè¿è¡Œå·²çŸ¥ä¼šå¤±è´¥çš„66ä¸ªåœºæ™¯ï¼Œç”¨äºè°ƒè¯•å¤±è´¥åŸå› 
    skip-known-case: è·³è¿‡å·²çŸ¥å¤±è´¥çš„66ä¸ªåœºæ™¯ + å·²çŸ¥æ²¡æœ‰å®é™…æ„ä¹‰çš„åœºæ™¯ï¼Œä¸“æ³¨äºä¼˜è´¨åœºæ™¯
  
è¯´æ˜: åŸºäºå†å²æµ‹è¯•æ•°æ®ç»Ÿè®¡ï¼ŒæŸäº›å‚æ•°ç»„åˆç”±äºTDengineé™åˆ¶ä¼šå›ºå®šå¤±è´¥
      æŸäº›ç»„åˆè™½ç„¶èƒ½æˆåŠŸä½†æ€§èƒ½è¡¨ç°ä¸ä½³ï¼Œéœ€è¦åæœŸä¼˜åŒ–
      ä½¿ç”¨æ­¤å‚æ•°å¯ä»¥é¿å…æµªè´¹æ—¶é—´åœ¨å·²çŸ¥é—®é¢˜ä¸Šï¼Œä¸“æ³¨æµ‹è¯•æœ‰æ•ˆåœºæ™¯''')
    
    batch_group.add_argument('--batch-test-limit', type=int,
                            help='''é™åˆ¶æµ‹è¯•æ•°é‡ï¼Œç”¨äºæµ‹è¯•éƒ¨åˆ†ç»„åˆ\n
ç¤ºä¾‹ç”¨æ³•1:æµ‹è¯•æ‰€æœ‰ç»„åˆ (168ç§)%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-test-time 3\n
ç¤ºä¾‹ç”¨æ³•2:æµ‹è¯•ç‰¹å®šçš„å›ºå®šå‚æ•°ç»„åˆ%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types tbname_agg \n
ç¤ºä¾‹ç”¨æ³•3:æµ‹è¯•ç‰¹å®šçš„å›ºå®šå‚æ•°ç»„åˆ%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types tbname_agg trows_agg \n
ç¤ºä¾‹ç”¨æ³•4:æµ‹è¯•ç‰¹å®šçª—å£ç±»å‹çš„è¯¦ç»†ç»„åˆ%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types intervalsliding_detailed --batch-test-time 3\n
ç¤ºä¾‹ç”¨æ³•5:æµ‹è¯•ç‰¹å®šçª—å£ç±»å‹çš„è¯¦ç»†ç»„åˆ%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types sliding_detailed session_detailed --batch-test-time 3\n
ç¤ºä¾‹ç”¨æ³•6:æµ‹è¯•æŒ‡å®šçš„å•ä¸ªæ¨¡æ¿%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types intervalsliding_stb sliding_stb \n
ç¤ºä¾‹ç”¨æ³•7:æ··åˆæµ‹è¯•æ¨¡å¼%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types tbname_agg intervalsliding_detailed sliding_stb \n
ç¤ºä¾‹ç”¨æ³•8:æ–­ç‚¹ç»­ä¼ %(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-start-from 50 --batch-test-limit 20 --batch-test-time 3\n
ç¤ºä¾‹ç”¨æ³•9:é™åˆ¶æµ‹è¯•æ•°é‡%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types all_detailed --batch-test-limit 10\n
ç¤ºä¾‹ç”¨æ³•10:åªè¿è¡ŒæˆåŠŸçš„æµ‹è¯•%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-filter-mode skip-known-failures \n
ç¤ºä¾‹ç”¨æ³•11:åªè¿è¡Œå¤±è´¥çš„æµ‹è¯•%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-filter-mode only-known-failures \n
ç¤ºä¾‹ç”¨æ³•12:æˆåŠŸ/å¤±è´¥çš„ç»„åˆ%(prog)s --monitor-interval 10 \n--deployment-mode single --batch-test --batch-sql-types intervalsliding_detailed --batch-filter-mode skip-known-failures\n\n''')
     

   
    # ç³»ç»Ÿé…ç½®å‚æ•°
    system_group = parser.add_argument_group('ç³»ç»Ÿé…ç½®ï¼Œé…ç½®TDengineéƒ¨ç½²æ¶æ„å’Œç³»ç»Ÿå‚æ•°')
    system_group.add_argument('--stream-perf-test-dir', type=str, 
                            default='/home/stream_perf_test_dir',
                            help='å•æœºæˆ–è€…é›†ç¾¤æµ‹è¯•æ ¹ç›®å½•, é»˜è®¤/home/stream_perf_test_dir, å°½é‡é…ç½®æ­¤å‚æ•°é¿å…è¯¯åˆ ç›®å½•å¤–çš„æ–‡ä»¶\n'
                                 'å­˜å‚¨é…ç½®æ–‡ä»¶ã€æ•°æ®æ–‡ä»¶ã€æ—¥å¿—æ–‡ä»¶\n'
                                 'ç¡®ä¿ç›®å½•æœ‰è¶³å¤Ÿç©ºé—´å’Œè¯»å†™æƒé™')
    system_group.add_argument('--monitor-interval', type=int, default=5,
                            help='æ€§èƒ½æ•°æ®é‡‡é›†é—´éš”(ç§’), é»˜è®¤5ç§’\n'
                                  'ç›‘æ§CPUã€å†…å­˜ã€ç£ç›˜IOä½¿ç”¨æƒ…å†µ\nè¿™ä¸ªæ˜¯ç›‘æ§taosdå ç”¨èµ„æºçš„ï¼Œdelay-check-intervalæ˜¯æ£€æŸ¥æµæ•°æ®ç”Ÿæˆçš„\n'
                                  'å»ºè®®å€¼: 1(è¯¦ç»†), 5(æ ‡å‡†), 10(ç²—ç•¥)')
    system_group.add_argument('--deployment-mode', type=str, default='single',
                            choices=['single', 'cluster'],
                            help='éƒ¨ç½²æ¨¡å¼:é»˜è®¤single\n'
                                '    single:  å•èŠ‚ç‚¹æ¨¡å¼ï¼Œdnode+mnode+snode éƒ½åœ¨ä¸€ä¸ªèŠ‚ç‚¹\n'
                                '    cluster: ä¸‰èŠ‚ç‚¹é›†ç¾¤æ¨¡å¼ï¼Œ3ä¸ªdnodeï¼Œ3ä¸ªmnodeï¼Œæºæ•°æ®åº“vgroupséƒ½åœ¨dnode1ï¼Œç›®æ ‡æ•°æ®åº“vgroupséƒ½åœ¨dnode2ï¼Œsnodeç‹¬ç«‹åœ¨dnode3')
    system_group.add_argument('--perf-node', type=str, default='dnode1',
                            choices=['dnode1', 'dnode2', 'dnode3'],
                            help='é›†ç¾¤æ¨¡å¼ä¸‹æ€§èƒ½å±•ç¤ºèŠ‚ç‚¹:é»˜è®¤dnode1')
    system_group.add_argument('--debug-flag', type=int, default=131,
                            help='TDengineè°ƒè¯•çº§åˆ«, é»˜è®¤131\n'
                                '    å¸¸ç”¨å€¼: 131(é»˜è®¤), 135, 143')
    system_group.add_argument('--use-tcmalloc',  action='store_true', default=False,
                            help='ä½¿ç”¨tcmallocå¯åŠ¨taosdè¿›ç¨‹ (é»˜è®¤: False, å¯èƒ½å½±å“æ€§èƒ½ä½†æä¾›å†…å­˜åˆ†æåŠŸèƒ½)')
    system_group.add_argument('--keep-taosd-alive', action='store_true', default=True,
                              help='æµ‹è¯•å®Œæˆåæ˜¯å¦ä¿æŒtaosdè¿›ç¨‹è¿è¡Œ, é»˜è®¤True')
    system_group.add_argument('--monitor-warm-up-time', type=int, default=0,
                            help='æ€§èƒ½ç›‘æ§é¢„çƒ­æ—¶é—´(ç§’), é»˜è®¤0ç§’\n'
                             '    åœ¨æ­¤æœŸé—´æ”¶é›†æ•°æ®ä½†ä¸æ‰“å°åˆ°æ§åˆ¶å°ï¼Œç­‰å¾…ç³»ç»Ÿç¨³å®š\n'
                             '    å½“è¿è¡Œæ—¶é—´ >= 2åˆ†é’Ÿæ—¶ï¼Œè‡ªåŠ¨è®¾ç½®ä¸º60ç§’\n'
                             '    å½“è¿è¡Œæ—¶é—´ < 2åˆ†é’Ÿæ—¶ï¼Œè‡ªåŠ¨è®¾ç½®ä¸º0ç§’\n'
                             '    ä¹Ÿå¯æ‰‹åŠ¨æŒ‡å®š: --monitor-warm-up-time 120')
    system_group.add_argument('--num-of-log-lines', type=int, default=5000000,
                            help='''TDengineæ—¥å¿—æ–‡ä»¶æœ€å¤§è¡Œæ•°, é»˜è®¤5000000,æœ€å¤§å€¼ä¸èƒ½è¶…è¿‡2000000000\n
ç¤ºä¾‹ç”¨æ³•:%(prog)s --monitor-interval 10 \n--deployment-mode single --debug-flag 135 --num-of-log-lines 1000\n\n''')
    
    # æ•°æ®ç®¡ç†å‚æ•°
    data_mgmt_group = parser.add_argument_group('æ•°æ®ç®¡ç†')
    data_mgmt_group.add_argument('--create-data', action='store_true',
                                help='''åˆ›å»ºæµ‹è¯•æ•°æ®å¹¶è‡ªåŠ¨å¤‡ä»½:  
æ‰§è¡Œæµç¨‹:
  1. å‡†å¤‡TDengineç¯å¢ƒ (å¯åŠ¨æœåŠ¡ã€é…ç½®å•èŠ‚ç‚¹æˆ–è€…é›†ç¾¤)
  2. åˆ›å»ºæŒ‡å®šè§„æ¨¡çš„æµ‹è¯•æ•°æ®  
  3. è‡ªåŠ¨å¤‡ä»½åˆ° --stream-perf-test-dir/data_bak
  4. ä¿ç•™ç¯å¢ƒä¾›åç»­æµ‹è¯•å†å²æ•°æ®æµè®¡ç®—ä½¿ç”¨
å»ºè®®: æµ‹è¯•å¤šç»„å†å²æ•°æ®æµè®¡ç®—å‰å…ˆæ‰§è¡Œæ­¤æ“ä½œ\n
ç¤ºä¾‹ç”¨æ³•:åˆ›å»ºå¹¶å¤‡ä»½æµ‹è¯•æ•°æ®%(prog)s --create-data 
--deployment-mode single --table-count 500 --histroy-rows 10000000\n\n''')
    
    data_mgmt_group.add_argument('--restore-data', action='store_true',
                                help='''ä»å¤‡ä»½æ¢å¤æµ‹è¯•æ•°æ®: 
æ‰§è¡Œæµç¨‹:
  1. æ£€æŸ¥å¤‡ä»½æ•°æ®å®Œæ•´æ€§
  2. åœæ­¢ç°æœ‰TDengineæœåŠ¡
  3. æ¢å¤æ•°æ®æ–‡ä»¶
  4. é‡å¯æœåŠ¡å¹¶éªŒè¯
é€‚ç”¨: å¿«é€Ÿæ¢å¤åˆ°å·²çŸ¥æ•°æ®çŠ¶æ€ï¼Œé¿å…é‡å¤æ•°æ®ç”Ÿæˆï¼ŒèŠ‚çœæ—¶é—´\nå¦‚æœæµ‹è¯•å†å²æ•°æ®è¿›è¡Œæµè®¡ç®—ï¼Œå»ºè®®ç”¨-m 2æ¨¡å¼\n
ç¤ºä¾‹ç”¨æ³•:æ¢å¤æ•°æ®å¹¶æµ‹è¯•%(prog)s --restore-data --deployment-mode single''')
    
    args = parser.parse_args()
    
    # æ‰“å°è¿è¡Œå‚æ•°
    print("è¿è¡Œå‚æ•°:")
    print(f"è¿è¡Œæ¨¡å¼: {args.mode}")
    print(f"è¿è¡Œæ—¶é—´: {args.time}åˆ†é’Ÿ")
    print(f"æ€§èƒ½æ–‡ä»¶: {args.file}")
    print(f"å­è¡¨æ•°é‡: {args.table_count}")
    print(f"åˆå§‹æ’å…¥è®°å½•æ•°: {args.histroy_rows}")
    print(f"åç»­æ¯è½®æ’å…¥è®°å½•æ•°: {args.real_time_batch_rows}")
    print(f"æ•°æ®å†™å…¥é—´éš”: {args.real_time_batch_sleep}ç§’")
    print(f"æ•°æ®ä¹±åº: {args.disorder_ratio}")
    print(f"vgroupsæ•°: {args.vgroups}")
    print(f"æµç±»å‹: {args.sql_type}")
    print(f"æµæ•°é‡: {args.stream_num}")
    print(f"é›†ç¾¤ç›®å½•: {args.stream_perf_test_dir}")
    print(f"æ€§èƒ½æš‚æ—¶èŠ‚ç‚¹: {args.stream_perf_test_dir}")
    print(f"æ€§èƒ½æ•°æ®é‡‡é›†é—´éš”: {args.perf_node}ç§’")
    print(f"éƒ¨ç½²æ¨¡å¼: {args.deployment_mode}")
    print(f"è°ƒè¯•æ ‡å¿—: {args.debug_flag}")
    print(f"æ—¥å¿—è¡Œæ•°: {args.num_of_log_lines}")
    
    print(f"æµå»¶è¿Ÿæ£€æŸ¥: {'å¯ç”¨' if args.check_stream_delay else 'ç¦ç”¨'}")
    if args.check_stream_delay:
        print(f"æœ€å¤§å»¶è¿Ÿé˜ˆå€¼: {args.max_delay_threshold}ms")
        print(f"å»¶è¿Ÿæ£€æŸ¥é—´éš”: {args.delay_check_interval}ç§’")
        
    
    if args.use_virtual_table:
        print(f"  â†’ æºæ•°æ®è¡¨: forvt_stb (å­è¡¨å‰ç¼€: forvt_ctb0_)")
        print(f"  â†’ è™šæ‹Ÿè¶…çº§è¡¨: stb")
        print(f"  â†’ è™šæ‹Ÿå­è¡¨: ctb0_0 åˆ° ctb0_{args.table_count-1}")
        print(f"  â†’ æ˜ å°„å…³ç³»: è™šæ‹Ÿè¡¨ç›´æ¥æ˜ å°„ç‰©ç†è¡¨")
    
    # å¤„ç†SQLå‚æ•°
    stream_sql = None
    if args.sql_file:
        try:
            with open(args.sql_file, 'r') as f:
                stream_sql = f.read().strip()
                print(f"ä»æ–‡ä»¶åŠ è½½SQL: {args.sql_file}")
        except Exception as e:
            print(f"è¯»å–SQLæ–‡ä»¶å¤±è´¥: {e}")
            return
    elif args.stream_sql:
        stream_sql = args.stream_sql
        print("ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šSQL")
    else:
        print("ä½¿ç”¨é»˜è®¤SQL")
        
    custom_columns = None
    if args.custom_columns:
        custom_columns = [col.strip() for col in args.custom_columns.split(',')]
    
    # åˆ›å»ºStreamStarterå®ä¾‹
    try:
        starter = StreamStarter(
            runtime=args.time,
            perf_file=args.file,
            table_count=args.table_count,
            histroy_rows=args.histroy_rows,
            real_time_batch_rows=args.real_time_batch_rows,
            real_time_batch_sleep=args.real_time_batch_sleep,
            disorder_ratio=args.disorder_ratio,
            vgroups=args.vgroups,
            stream_sql=stream_sql,
            sql_type=args.sql_type,
            stream_num=args.stream_num, 
            stream_perf_test_dir=args.stream_perf_test_dir,
            monitor_interval=args.monitor_interval,
            deployment_mode=args.deployment_mode,
            debug_flag=args.debug_flag, 
            num_of_log_lines=args.num_of_log_lines,            
            agg_or_select=args.agg_or_select,
            tbname_or_trows_or_sourcetable=args.tbname_or_trows_or_sourcetable,
            custom_columns=custom_columns,
            check_stream_delay=args.check_stream_delay,
            max_delay_threshold=args.max_delay_threshold,
            delay_check_interval=args.delay_check_interval,
            auto_combine=args.auto_combine,
            monitor_warm_up_time=args.monitor_warm_up_time,
            delay_trends_analysis  =args.delay_trends_analysis,
            keep_taosd_alive=args.keep_taosd_alive,
            use_tcmalloc=args.use_tcmalloc,
            perf_node=args.perf_node,
            use_virtual_table=args.use_virtual_table
        )
        
        # å¤„ç†æ‰¹é‡æµ‹è¯•
        if args.batch_test:
            print("å¯åŠ¨æ‰¹é‡æµ‹è¯•æ¨¡å¼...")
            
            # å‡†å¤‡åŸºç¡€å‚æ•°
            base_args = {
                'time': args.batch_test_time,
                'stream_perf_test_dir': args.stream_perf_test_dir,
                'table_count': args.table_count,
                'histroy_rows': args.histroy_rows,
                'real_time_batch_rows': args.real_time_batch_rows,
                'real_time_batch_sleep': args.real_time_batch_sleep,
                'disorder_ratio': args.disorder_ratio,
                'vgroups': args.vgroups,
                'monitor_interval': args.monitor_interval,
                'deployment_mode': args.deployment_mode,
                'debug_flag': args.debug_flag,
                'num_of_log_lines': args.num_of_log_lines,
                'max_delay_threshold': args.max_delay_threshold,
                'delay_check_interval': args.delay_check_interval,
                'stream_num': args.stream_num,
                'monitor_warm_up_time': args.monitor_warm_up_time,
                'tbname_or_trows_or_sourcetable': args.tbname_or_trows_or_sourcetable,
                'agg_or_select': args.agg_or_select,
                'delay_trends_analysis': args.delay_trends_analysis,
                'keep_taosd_alive': args.keep_taosd_alive,
                'use_tcmalloc': args.use_tcmalloc,
                'perf_node':args.perf_node,
                'use_virtual_table': args.use_virtual_table  
            }
        
            print(f"æ‰¹é‡æµ‹è¯•åŸºç¡€é…ç½®:")
            print(f"  æ¯ä¸ªæµ‹è¯•è¿è¡Œæ—¶é—´: {args.batch_test_time}åˆ†é’Ÿ")
            print(f"  å­è¡¨æ•°é‡: {args.table_count}")
            print(f"  æ¯è½®å†™å…¥è®°å½•æ•°: {args.real_time_batch_rows}")
            print(f"  æ•°æ®å†™å…¥é—´éš”: {args.real_time_batch_sleep}ç§’")
            print(f"  éƒ¨ç½²æ¨¡å¼: {args.deployment_mode}")
            print(f"  è¿‡æ»¤æ¨¡å¼: {args.batch_filter_mode}")
            print(f"  æµæ•°é‡: {args.stream_num}") 
            print(f"  ç›‘æ§é¢„çƒ­æ—¶é—´: {args.monitor_warm_up_time}ç§’") 
            print(f"  FROMå­å¥ç±»å‹: {args.tbname_or_trows_or_sourcetable}")
            print(f"  æŸ¥è¯¢ç±»å‹: {args.agg_or_select}")
            print(f"  è™šæ‹Ÿè¡¨æ¨¡å¼: {'å¯ç”¨' if args.use_virtual_table else 'ç¦ç”¨'}")
            
            # å¤„ç†SQLç±»å‹å‚æ•°
            if args.batch_sql_types:
                print(f"  æŒ‡å®šSQLç±»å‹: {', '.join(args.batch_sql_types)}")
                # éªŒè¯æŒ‡å®šçš„SQLç±»å‹æ˜¯å¦æœ‰æ•ˆ
                valid_types = [
                    'tbname_agg', 'tbname_select', 'trows_agg', 'trows_select', 
                    'sourcetable_agg', 'sourcetable_select',
                    'intervalsliding_detailed', 'sliding_detailed', 'session_detailed', 
                    'count_detailed', 'event_detailed', 'state_detailed', 'period_detailed',
                    'all_detailed',
                    'intervalsliding_stb', 'intervalsliding_stb_partition_by_tbname', 
                    'intervalsliding_stb_partition_by_tag', 'intervalsliding_tb',
                    'sliding_stb', 'sliding_stb_partition_by_tbname',
                    'sliding_stb_partition_by_tag', 'sliding_tb',
                    'session_stb', 'session_stb_partition_by_tbname',
                    'session_stb_partition_by_tag', 'session_tb',
                    'count_stb', 'count_stb_partition_by_tbname',
                    'count_stb_partition_by_tag', 'count_tb',
                    'event_stb', 'event_stb_partition_by_tbname',
                    'event_stb_partition_by_tag', 'event_tb',
                    'state_stb', 'state_stb_partition_by_tbname',
                    'state_stb_partition_by_tag', 'state_tb',
                    'period_stb', 'period_stb_partition_by_tbname',
                    'period_stb_partition_by_tag', 'period_tb'
                ]
                
                invalid_types = [t for t in args.batch_sql_types if t not in valid_types]
                if invalid_types:
                    print(f"é”™è¯¯: æ— æ•ˆçš„SQLç±»å‹: {', '.join(invalid_types)}")
                    print(f"æœ‰æ•ˆç±»å‹è¯·å‚è€ƒ --help ä¸­çš„ --batch-sql-types è¯´æ˜")
                    return
            else:
                print(f"  SQLç±»å‹: å…¨éƒ¨ç»„åˆ (é»˜è®¤)")
            
            # åˆ›å»ºæ‰¹é‡æµ‹è¯•å™¨
            batch_tester = StreamBatchTester(
                base_args, 
                args.batch_sql_types,
                filter_mode=args.batch_filter_mode,
                single_template_mode=args.batch_single_template_mode,
                perf_node=args.perf_node
            )
            
            # æ‰§è¡Œæ‰¹é‡æµ‹è¯•
            batch_tester.run_batch_tests(
                test_time_minutes=args.batch_test_time,
                start_from=args.batch_start_from,
                test_limit=args.batch_test_limit
            )
            
            return
        
        if args.create_data:
            print("\n=== å¼€å§‹åˆ›å»ºæµ‹è¯•æ•°æ® ===")
            print(f"å­è¡¨æ•°é‡: {args.table_count}")
            print(f"æ¯è¡¨è®°å½•æ•°: {args.histroy_rows}")
            print(f"æ•°æ®ä¹±åºç‡: {args.disorder_ratio}")
            print(f"vgroupsæ•°: {args.vgroups}\n")
            
            if starter.create_test_data():
                print("\næµ‹è¯•æ•°æ®åˆ›å»ºå®Œæˆ!")
            return
            
        if args.restore_data:
            print("\n=== å¼€å§‹æ¢å¤æµ‹è¯•æ•°æ® ===")
            if starter.restore_cluster_data():
                print("\næ•°æ®æ¢å¤å®Œæˆ!")
                
                # å¦‚æœæŒ‡å®šäº†SQLç±»å‹ä¸”ä¸æ˜¯é»˜è®¤å€¼ï¼Œæç¤ºå¯ä»¥è¿›è¡Œæµè®¡ç®—æµ‹è¯•
                if args.sql_type != 'select_stream' or args.stream_sql or args.sql_file:
                    print(f"\næç¤º: æ•°æ®å·²æ¢å¤ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤æµ‹è¯•æµè®¡ç®—:")
                    print(f"python3 {sys.argv[0]} -m 2 --sql-type {args.sql_type} --time {args.time}")
            return
        
        print("\nå¼€å§‹æ‰§è¡Œ...")
        if args.mode == 1:
            print("æ‰§è¡Œæ¨¡å¼: do_test_stream_with_realtime_data")
            starter.do_test_stream_with_realtime_data()
        elif args.mode == 3:
            print("æ‰§è¡Œæ¨¡å¼: do_query_then_insert")
            starter.do_query_then_insert()
        elif args.mode == 2:
            print("æ‰§è¡Œæ¨¡å¼: do_test_stream_with_restored_data (æ¢å¤æ•°æ®å¹¶æµ‹è¯•æŒ‡å®šæµè®¡ç®—)")
            starter.do_test_stream_with_restored_data()
        else:
            print(f"é”™è¯¯: ä¸æ”¯æŒçš„æ‰§è¡Œæ¨¡å¼ {args.mode}")
            
    except KeyboardInterrupt:
        print("\nç¨‹åºé€€å‡º")
        # æ£€æŸ¥taosdè¿›ç¨‹çŠ¶æ€
        result = subprocess.run('ps -ef | grep "taosd -c" | grep -v grep', 
                                shell=True, capture_output=True, text=True)
        if result.stdout:
            print("\ntaosdè¿›ç¨‹ä»åœ¨è¿è¡Œ:")
            print(result.stdout)
        else:
            print("\nè­¦å‘Š: æœªæ‰¾åˆ°è¿è¡Œä¸­çš„taosdè¿›ç¨‹")
    except Exception as e:
        print(f"\nç¨‹åºæ‰§è¡Œå‡ºé”™: {str(e)}")
    finally:
        print("\nå¦‚éœ€æ‰‹åŠ¨åœæ­¢taosdè¿›ç¨‹ï¼Œè¯·æ‰§è¡Œ:")
        print("pkill taosd")

if __name__ == "__main__":
    main()
